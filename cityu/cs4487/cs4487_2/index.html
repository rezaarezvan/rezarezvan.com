<!DOCTYPE html><html lang="en"> <head><!-- Global Metadata --><meta charset="utf-8"><meta name="viewport" content="width=device-width,initial-scale=1"><link rel="icon" type="image/icon" href="/favicon.ico"><meta name="generator" content="Astro v4.11.5"><!-- Canonical URL --><link rel="canonical" href="https://rezvan.xyz/cityu/cs4487/cs4487_2/"><!-- Primary Meta Tags --><title>Part 2 - Generative VS. Discriminative Models | machine learning | rezvan.xyz</title><meta name="title" content="Part 2 - Generative VS. Discriminative Models | machine learning | rezvan.xyz"><meta name="description"><!-- Open Graph / Facebook --><meta property="og:type" content="website"><meta property="og:url" content="https://rezvan.xyz/cityu/cs4487/cs4487_2/"><meta property="og:title" content="Part 2 - Generative VS. Discriminative Models | machine learning | rezvan.xyz"><meta property="og:description"><meta property="og:image" content="https://rezvan.xyz/favicon.ico"><!-- Twitter --><meta property="twitter:card" content="summary_large_image"><meta property="twitter:url" content="https://rezvan.xyz/cityu/cs4487/cs4487_2/"><meta property="twitter:title" content="Part 2 - Generative VS. Discriminative Models | machine learning | rezvan.xyz"><meta property="twitter:description"><meta property="twitter:image" content="https://rezvan.xyz/favicon.ico"><!-- PageFind --><link href="/pagefind/pagefind-ui.css" rel="stylesheet"><script src="/pagefind/pagefind-ui.js"></script><!-- KaTeX support --><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.css"><script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.js"></script><script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/contrib/auto-render.min.js" onload="renderMathInElement(document.body);"></script><!-- inline KaTeX --><script>
    function renderKaTeX() {
        if (typeof renderMathInElement !== "undefined") {
            renderMathInElement(document.body, {
                delimiters: [
                    { left: "$$", right: "$$", display: true },
                    { left: "$", right: "$", display: false },
                ],
            });
        }
    }

    document.addEventListener("DOMContentLoaded", renderKaTeX);
    document.addEventListener("astro:after-swap", renderKaTeX);
</script><meta name="astro-view-transitions-enabled" content="true"><meta name="astro-view-transitions-fallback" content="animate"><script>
    function init() {
        preloadTheme();
        onScroll();
        animate();
        updateThemeButtons();
        addCopyCodeButtons();
        setGiscusTheme();

        const backToTop = document.getElementById("back-to-top");
        backToTop?.addEventListener("click", (event) => scrollToTop(event));

        const backToPrev = document.getElementById("back-to-prev");
        backToPrev?.addEventListener("click", () => window.history.back());

        const lightThemeButton = document.getElementById("light-theme-button");
        lightThemeButton?.addEventListener("click", () => {
            localStorage.setItem("theme", "light");
            toggleTheme(false);
            updateThemeButtons();
        });

        const darkThemeButton = document.getElementById("dark-theme-button");
        darkThemeButton?.addEventListener("click", () => {
            localStorage.setItem("theme", "dark");
            toggleTheme(true);
            updateThemeButtons();
        });

        const systemThemeButton = document.getElementById(
            "system-theme-button",
        );
        systemThemeButton?.addEventListener("click", () => {
            localStorage.setItem("theme", "system");
            toggleTheme(
                window.matchMedia("(prefers-color-scheme: dark)").matches,
            );
            updateThemeButtons();
        });

        window
            .matchMedia("(prefers-color-scheme: dark)")
            .addEventListener("change", (event) => {
                if (localStorage.theme === "system") {
                    toggleTheme(event.matches);
                }
            });

        document.addEventListener("scroll", onScroll);
    }

    function updateThemeButtons() {
        const theme = localStorage.getItem("theme");
        const lightThemeButton = document.getElementById("light-theme-button");
        const darkThemeButton = document.getElementById("dark-theme-button");
        const systemThemeButton = document.getElementById(
            "system-theme-button",
        );

        function removeActiveButtonTheme(button) {
            button?.classList.remove("bg-black/5");
            button?.classList.remove("dark:bg-white/5");
        }

        function addActiveButtonTheme(button) {
            button?.classList.add("bg-black/5");
            button?.classList.add("dark:bg-white/5");
        }

        removeActiveButtonTheme(lightThemeButton);
        removeActiveButtonTheme(darkThemeButton);
        removeActiveButtonTheme(systemThemeButton);

        if (theme === "light") {
            addActiveButtonTheme(lightThemeButton);
        } else if (theme === "dark") {
            addActiveButtonTheme(darkThemeButton);
        } else {
            addActiveButtonTheme(systemThemeButton);
        }
    }

    function animate() {
        const animateElements = document.querySelectorAll(".animate");

        animateElements.forEach((element, index) => {
            setTimeout(() => {
                element.classList.add("show");
            }, index * 100);
        });
    }

    function onScroll() {
        if (window.scrollY > 0) {
            document.documentElement.classList.add("scrolled");
        } else {
            document.documentElement.classList.remove("scrolled");
        }
    }

    function scrollToTop(event) {
        event.preventDefault();
        window.scrollTo({
            top: 0,
            behavior: "smooth",
        });
    }

    function toggleTheme(dark) {
        const css = document.createElement("style");

        css.appendChild(
            document.createTextNode(
                `* {
             -webkit-transition: none !important;
             -moz-transition: none !important;
             -o-transition: none !important;
             -ms-transition: none !important;
             transition: none !important;
          }
        `,
            ),
        );

        document.head.appendChild(css);

        if (dark) {
            document.documentElement.classList.add("dark");
        } else {
            document.documentElement.classList.remove("dark");
        }

        window.getComputedStyle(css).opacity;
        document.head.removeChild(css);

        setGiscusTheme();
    }

    function preloadTheme() {
        const userTheme = localStorage.theme;

        if (userTheme === "light" || userTheme === "dark") {
            toggleTheme(userTheme === "dark");
        } else {
            toggleTheme(
                window.matchMedia("(prefers-color-scheme: dark)").matches,
            );
        }
    }

    function addCopyCodeButtons() {
        let copyButtonLabel = "📋";
        let codeBlocks = Array.from(document.querySelectorAll("pre"));

        async function copyCode(codeBlock, copyButton) {
            const codeText = codeBlock.innerText;
            const buttonText = copyButton.innerText;
            const textToCopy = codeText.replace(buttonText, "");

            await navigator.clipboard.writeText(textToCopy);
            copyButton.innerText = "✅";

            setTimeout(() => {
                copyButton.innerText = copyButtonLabel;
            }, 2000);
        }

        for (let codeBlock of codeBlocks) {
            const wrapper = document.createElement("div");
            wrapper.style.position = "relative";

            const copyButton = document.createElement("button");
            copyButton.innerText = copyButtonLabel;
            copyButton.classList = "copy-code";

            codeBlock.setAttribute("tabindex", "0");
            codeBlock.appendChild(copyButton);

            codeBlock.parentNode.insertBefore(wrapper, codeBlock);
            wrapper.appendChild(codeBlock);

            copyButton?.addEventListener("click", async () => {
                await copyCode(codeBlock, copyButton);
            });
        }
    }

    const setGiscusTheme = () => {
        const giscus = document.querySelector(".giscus-frame");

        const isDark = document.documentElement.classList.contains("dark");

        if (giscus) {
            const url = new URL(giscus.src);
            url.searchParams.set("theme", isDark ? "dark" : "light");
            giscus.src = url.toString();
        }
    };

    document.addEventListener("DOMContentLoaded", () => init());
    document.addEventListener("astro:after-swap", () => init());
    preloadTheme();
</script><link rel="stylesheet" href="/_astro/_subject_.CmU_Tg_r.css">
<style>summary[data-astro-cid-xvrfupwn]{cursor:pointer;border-top-left-radius:.5rem;border-top-right-radius:.5rem;padding:.375rem .75rem;font-weight:500;transition-property:color,background-color,border-color,text-decoration-color,fill,stroke;transition-timing-function:cubic-bezier(.4,0,.2,1);transition-duration:.15s}summary[data-astro-cid-xvrfupwn]:hover{background-color:#0000000d}summary[data-astro-cid-xvrfupwn]:hover:is(.dark *){background-color:#ffffff0d}details[data-astro-cid-xvrfupwn][open] summary[data-astro-cid-xvrfupwn]{background-color:#0000000d}details[data-astro-cid-xvrfupwn][open] summary[data-astro-cid-xvrfupwn]:is(.dark *){background-color:#ffffff0d}
</style><script type="module" src="/_astro/hoisted.DzxSAGjc.js"></script></head> <body> <header data-astro-transition-persist="astro-l7r54iwe-1"> <div class="mx-auto max-w-screen-sm px-3"> <div class="flex flex-wrap justify-between gap-y-2"> <a href="/" target="_self" class="inline-block decoration-black/30 dark:decoration-white/30 hover:decoration-black/50 focus-visible:decoration-black/50 dark:hover:decoration-white/50 dark:focus-visible:decoration-white/50 text-current hover:text-black focus-visible:text-black dark:hover:text-white dark:focus-visible:text-white transition-colors duration-300 ease-in-out">  <div class="font-semibold"> rezvan.xyz </div>  </a> <nav class="flex items-center gap-1 text-sm"> <a href="/posts" target="_self" class="inline-block decoration-black/30 dark:decoration-white/30 hover:decoration-black/50 focus-visible:decoration-black/50 dark:hover:decoration-white/50 dark:focus-visible:decoration-white/50 text-current hover:text-black focus-visible:text-black dark:hover:text-white dark:focus-visible:text-white transition-colors duration-300 ease-in-out underline underline-offset-[3px]"> posts </a> <span> / </span> <a href="/chalmers" target="_self" class="inline-block decoration-black/30 dark:decoration-white/30 hover:decoration-black/50 focus-visible:decoration-black/50 dark:hover:decoration-white/50 dark:focus-visible:decoration-white/50 text-current hover:text-black focus-visible:text-black dark:hover:text-white dark:focus-visible:text-white transition-colors duration-300 ease-in-out underline underline-offset-[3px]"> chalmers </a> <span> / </span> <a href="/cityu" target="_self" class="inline-block decoration-black/30 dark:decoration-white/30 hover:decoration-black/50 focus-visible:decoration-black/50 dark:hover:decoration-white/50 dark:focus-visible:decoration-white/50 text-current hover:text-black focus-visible:text-black dark:hover:text-white dark:focus-visible:text-white transition-colors duration-300 ease-in-out underline underline-offset-[3px]"> cityu </a> <span> / </span> <a href="/pdf/cv/cv.pdf" target="_self" class="inline-block decoration-black/30 dark:decoration-white/30 hover:decoration-black/50 focus-visible:decoration-black/50 dark:hover:decoration-white/50 dark:focus-visible:decoration-white/50 text-current hover:text-black focus-visible:text-black dark:hover:text-white dark:focus-visible:text-white transition-colors duration-300 ease-in-out underline underline-offset-[3px]"> cv </a> <span> / </span> <button id="magnifying-glass" aria-label="Search" class="flex items-center rounded border border-black/15 bg-neutral-100 px-2 py-1 text-xs transition-colors duration-300 ease-in-out hover:bg-black/5 hover:text-black focus-visible:bg-black/5 focus-visible:text-black dark:border-white/20 dark:bg-neutral-900 dark:hover:bg-white/5 dark:hover:text-white dark:focus-visible:bg-white/5 dark:focus-visible:text-white"> <svg height="16" stroke-linejoin="round" viewBox="0 0 16 16" width="16" style="color: currentcolor;"><path fill-rule="evenodd" clip-rule="evenodd" d="M3.5 7C3.5 5.067 5.067 3.5 7 3.5C8.933 3.5 10.5 5.067 10.5 7C10.5 7.88461 10.1718 8.69256 9.63058 9.30876L9.30876 9.63058C8.69256 10.1718 7.88461 10.5 7 10.5C5.067 10.5 3.5 8.933 3.5 7ZM9.96544 11.0261C9.13578 11.6382 8.11014 12 7 12C4.23858 12 2 9.76142 2 7C2 4.23858 4.23858 2 7 2C9.76142 2 12 4.23858 12 7C12 8.11014 11.6382 9.13578 11.0261 9.96544L14.0303 12.9697L14.5607 13.5L13.5 14.5607L12.9697 14.0303L9.96544 11.0261Z" fill="currentColor"></path></svg>
&nbsp;Search
</button> </nav> </div> </div> </header> <main>  <div class="mx-auto max-w-screen-sm px-3"> <div class="animate"> <a href="/cityu/cs4487" class="not-prose group relative flex w-fit flex-nowrap rounded border border-black/15 py-1.5 pl-7 pr-3 transition-colors duration-300 ease-in-out hover:bg-black/5 hover:text-black focus-visible:bg-black/5 focus-visible:text-black dark:border-white/20 dark:hover:bg-white/5 dark:hover:text-white dark:focus-visible:bg-white/5 dark:focus-visible:text-white"> <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" class="absolute left-2 top-1/2 size-4 -translate-y-1/2 fill-none stroke-current stroke-2"> <line x1="5" y1="12" x2="19" y2="12" class="translate-x-2 scale-x-0 transition-transform duration-300 ease-in-out group-hover:translate-x-0 group-hover:scale-x-100 group-focus-visible:translate-x-0 group-focus-visible:scale-x-100"></line> <polyline points="12 5 5 12 12 19" class="translate-x-1 transition-transform duration-300 ease-in-out group-hover:translate-x-0 group-focus-visible:translate-x-0"></polyline> </svg> <div class="text-sm"> Back to machine learning </div> </a> </div> <div class="my-10 space-y-1"> <div class="animate flex items-center gap-1.5"> <div class="font-base text-sm"> CS4487 </div>
&bull;
<div class="font-base text-sm"> <time datetime="2024-09-11T00:00:00.000Z"> September 11, 2024 </time> </div> 
&bull;
<div class="font-base text-sm">
Last modified:  <time datetime="2024-09-16T11:50:04.000Z"> September 16, 2024 </time> </div> 
&bull;
<div class="font-base text-sm"> 11 min read </div> </div> <h1 class="animate text-3xl font-semibold text-black dark:text-white"> Part 2 - Generative VS. Discriminative Models </h1> </div> <details open class="animate rounded-lg border border-black/15 dark:border-white/20" data-astro-cid-xvrfupwn> <summary data-astro-cid-xvrfupwn>Table of Contents</summary> <nav class="" data-astro-cid-xvrfupwn> <ul class="py-3" data-astro-cid-xvrfupwn> <li class="list-inside list-disc px-6 py-1.5 text-sm"> <a href="#the-bayes-optimal-classifier" target="_self" class="inline-block decoration-black/30 dark:decoration-white/30 hover:decoration-black/50 focus-visible:decoration-black/50 dark:hover:decoration-white/50 dark:focus-visible:decoration-white/50 text-current hover:text-black focus-visible:text-black dark:hover:text-white dark:focus-visible:text-white transition-colors duration-300 ease-in-out underline underline-offset-[3px]"> The Bayes Optimal Classifier </a>  </li><li class="list-inside list-disc px-6 py-1.5 text-sm"> <a href="#naive-bayes-classifier" target="_self" class="inline-block decoration-black/30 dark:decoration-white/30 hover:decoration-black/50 focus-visible:decoration-black/50 dark:hover:decoration-white/50 dark:focus-visible:decoration-white/50 text-current hover:text-black focus-visible:text-black dark:hover:text-white dark:focus-visible:text-white transition-colors duration-300 ease-in-out underline underline-offset-[3px]"> Naive Bayes Classifier </a>  </li><li class="list-inside list-disc px-6 py-1.5 text-sm"> <a href="#gaussian-classifier" target="_self" class="inline-block decoration-black/30 dark:decoration-white/30 hover:decoration-black/50 focus-visible:decoration-black/50 dark:hover:decoration-white/50 dark:focus-visible:decoration-white/50 text-current hover:text-black focus-visible:text-black dark:hover:text-white dark:focus-visible:text-white transition-colors duration-300 ease-in-out underline underline-offset-[3px]"> Gaussian Classifier </a> <ul class="translate-x-3"> <li class="list-inside list-disc px-6 py-1.5 text-sm"> <a href="#geometric-interpretation" target="_self" class="inline-block decoration-black/30 dark:decoration-white/30 hover:decoration-black/50 focus-visible:decoration-black/50 dark:hover:decoration-white/50 dark:focus-visible:decoration-white/50 text-current hover:text-black focus-visible:text-black dark:hover:text-white dark:focus-visible:text-white transition-colors duration-300 ease-in-out underline underline-offset-[3px]"> Geometric Interpretation </a>  </li> </ul> </li><li class="list-inside list-disc px-6 py-1.5 text-sm"> <a href="#naive-bayes-for-boolean-vectors" target="_self" class="inline-block decoration-black/30 dark:decoration-white/30 hover:decoration-black/50 focus-visible:decoration-black/50 dark:hover:decoration-white/50 dark:focus-visible:decoration-white/50 text-current hover:text-black focus-visible:text-black dark:hover:text-white dark:focus-visible:text-white transition-colors duration-300 ease-in-out underline underline-offset-[3px]"> Naive Bayes for Boolean Vectors </a> <ul class="translate-x-3"> <li class="list-inside list-disc px-6 py-1.5 text-sm"> <a href="#smoothing" target="_self" class="inline-block decoration-black/30 dark:decoration-white/30 hover:decoration-black/50 focus-visible:decoration-black/50 dark:hover:decoration-white/50 dark:focus-visible:decoration-white/50 text-current hover:text-black focus-visible:text-black dark:hover:text-white dark:focus-visible:text-white transition-colors duration-300 ease-in-out underline underline-offset-[3px]"> Smoothing </a>  </li> </ul> </li><li class="list-inside list-disc px-6 py-1.5 text-sm"> <a href="#multinomial-naive-bayes" target="_self" class="inline-block decoration-black/30 dark:decoration-white/30 hover:decoration-black/50 focus-visible:decoration-black/50 dark:hover:decoration-white/50 dark:focus-visible:decoration-white/50 text-current hover:text-black focus-visible:text-black dark:hover:text-white dark:focus-visible:text-white transition-colors duration-300 ease-in-out underline underline-offset-[3px]"> Multinomial Naive Bayes </a>  </li><li class="list-inside list-disc px-6 py-1.5 text-sm"> <a href="#linear-discriminant-analysis-lda" target="_self" class="inline-block decoration-black/30 dark:decoration-white/30 hover:decoration-black/50 focus-visible:decoration-black/50 dark:hover:decoration-white/50 dark:focus-visible:decoration-white/50 text-current hover:text-black focus-visible:text-black dark:hover:text-white dark:focus-visible:text-white transition-colors duration-300 ease-in-out underline underline-offset-[3px]"> Linear Discriminant Analysis (LDA) </a>  </li><li class="list-inside list-disc px-6 py-1.5 text-sm"> <a href="#training-lda" target="_self" class="inline-block decoration-black/30 dark:decoration-white/30 hover:decoration-black/50 focus-visible:decoration-black/50 dark:hover:decoration-white/50 dark:focus-visible:decoration-white/50 text-current hover:text-black focus-visible:text-black dark:hover:text-white dark:focus-visible:text-white transition-colors duration-300 ease-in-out underline underline-offset-[3px]"> Training LDA </a> <ul class="translate-x-3"> <li class="list-inside list-disc px-6 py-1.5 text-sm"> <a href="#geometric-interpretation-1" target="_self" class="inline-block decoration-black/30 dark:decoration-white/30 hover:decoration-black/50 focus-visible:decoration-black/50 dark:hover:decoration-white/50 dark:focus-visible:decoration-white/50 text-current hover:text-black focus-visible:text-black dark:hover:text-white dark:focus-visible:text-white transition-colors duration-300 ease-in-out underline underline-offset-[3px]"> Geometric Interpretation </a>  </li> </ul> </li><li class="list-inside list-disc px-6 py-1.5 text-sm"> <a href="#naive-bayes-vs-lda" target="_self" class="inline-block decoration-black/30 dark:decoration-white/30 hover:decoration-black/50 focus-visible:decoration-black/50 dark:hover:decoration-white/50 dark:focus-visible:decoration-white/50 text-current hover:text-black focus-visible:text-black dark:hover:text-white dark:focus-visible:text-white transition-colors duration-300 ease-in-out underline underline-offset-[3px]"> Naive Bayes vs LDA </a>  </li><li class="list-inside list-disc px-6 py-1.5 text-sm"> <a href="#summary-of-generative-models" target="_self" class="inline-block decoration-black/30 dark:decoration-white/30 hover:decoration-black/50 focus-visible:decoration-black/50 dark:hover:decoration-white/50 dark:focus-visible:decoration-white/50 text-current hover:text-black focus-visible:text-black dark:hover:text-white dark:focus-visible:text-white transition-colors duration-300 ease-in-out underline underline-offset-[3px]"> Summary of Generative Models </a>  </li><li class="list-inside list-disc px-6 py-1.5 text-sm"> <a href="#discriminative-models" target="_self" class="inline-block decoration-black/30 dark:decoration-white/30 hover:decoration-black/50 focus-visible:decoration-black/50 dark:hover:decoration-white/50 dark:focus-visible:decoration-white/50 text-current hover:text-black focus-visible:text-black dark:hover:text-white dark:focus-visible:text-white transition-colors duration-300 ease-in-out underline underline-offset-[3px]"> Discriminative Models </a> <ul class="translate-x-3"> <li class="list-inside list-disc px-6 py-1.5 text-sm"> <a href="#linear-classifier" target="_self" class="inline-block decoration-black/30 dark:decoration-white/30 hover:decoration-black/50 focus-visible:decoration-black/50 dark:hover:decoration-white/50 dark:focus-visible:decoration-white/50 text-current hover:text-black focus-visible:text-black dark:hover:text-white dark:focus-visible:text-white transition-colors duration-300 ease-in-out underline underline-offset-[3px]"> Linear Classifier </a> <ul class="translate-x-3"> <li class="list-inside list-disc px-6 py-1.5 text-sm"> <a href="#geometric-interpretation-2" target="_self" class="inline-block decoration-black/30 dark:decoration-white/30 hover:decoration-black/50 focus-visible:decoration-black/50 dark:hover:decoration-white/50 dark:focus-visible:decoration-white/50 text-current hover:text-black focus-visible:text-black dark:hover:text-white dark:focus-visible:text-white transition-colors duration-300 ease-in-out underline underline-offset-[3px]"> Geometric Interpretation </a>  </li><li class="list-inside list-disc px-6 py-1.5 text-sm"> <a href="#separating-hyperplane" target="_self" class="inline-block decoration-black/30 dark:decoration-white/30 hover:decoration-black/50 focus-visible:decoration-black/50 dark:hover:decoration-white/50 dark:focus-visible:decoration-white/50 text-current hover:text-black focus-visible:text-black dark:hover:text-white dark:focus-visible:text-white transition-colors duration-300 ease-in-out underline underline-offset-[3px]"> Separating Hyperplane </a>  </li> </ul> </li> </ul> </li><li class="list-inside list-disc px-6 py-1.5 text-sm"> <a href="#training-a-linear-classifier" target="_self" class="inline-block decoration-black/30 dark:decoration-white/30 hover:decoration-black/50 focus-visible:decoration-black/50 dark:hover:decoration-white/50 dark:focus-visible:decoration-white/50 text-current hover:text-black focus-visible:text-black dark:hover:text-white dark:focus-visible:text-white transition-colors duration-300 ease-in-out underline underline-offset-[3px]"> Training a Linear Classifier </a>  </li><li class="list-inside list-disc px-6 py-1.5 text-sm"> <a href="#logistic-regression" target="_self" class="inline-block decoration-black/30 dark:decoration-white/30 hover:decoration-black/50 focus-visible:decoration-black/50 dark:hover:decoration-white/50 dark:focus-visible:decoration-white/50 text-current hover:text-black focus-visible:text-black dark:hover:text-white dark:focus-visible:text-white transition-colors duration-300 ease-in-out underline underline-offset-[3px]"> Logistic Regression </a> <ul class="translate-x-3"> <li class="list-inside list-disc px-6 py-1.5 text-sm"> <a href="#learning-the-parameters" target="_self" class="inline-block decoration-black/30 dark:decoration-white/30 hover:decoration-black/50 focus-visible:decoration-black/50 dark:hover:decoration-white/50 dark:focus-visible:decoration-white/50 text-current hover:text-black focus-visible:text-black dark:hover:text-white dark:focus-visible:text-white transition-colors duration-300 ease-in-out underline underline-offset-[3px]"> Learning the Parameters </a> <ul class="translate-x-3"> <li class="list-inside list-disc px-6 py-1.5 text-sm"> <a href="#logistic-loss-function" target="_self" class="inline-block decoration-black/30 dark:decoration-white/30 hover:decoration-black/50 focus-visible:decoration-black/50 dark:hover:decoration-white/50 dark:focus-visible:decoration-white/50 text-current hover:text-black focus-visible:text-black dark:hover:text-white dark:focus-visible:text-white transition-colors duration-300 ease-in-out underline underline-offset-[3px]"> Logistic Loss Function </a>  </li> </ul> </li> </ul> </li><li class="list-inside list-disc px-6 py-1.5 text-sm"> <a href="#cross-validation" target="_self" class="inline-block decoration-black/30 dark:decoration-white/30 hover:decoration-black/50 focus-visible:decoration-black/50 dark:hover:decoration-white/50 dark:focus-visible:decoration-white/50 text-current hover:text-black focus-visible:text-black dark:hover:text-white dark:focus-visible:text-white transition-colors duration-300 ease-in-out underline underline-offset-[3px]"> Cross-Validation </a> <ul class="translate-x-3"> <li class="list-inside list-disc px-6 py-1.5 text-sm"> <a href="#cross-validation-algorithm" target="_self" class="inline-block decoration-black/30 dark:decoration-white/30 hover:decoration-black/50 focus-visible:decoration-black/50 dark:hover:decoration-white/50 dark:focus-visible:decoration-white/50 text-current hover:text-black focus-visible:text-black dark:hover:text-white dark:focus-visible:text-white transition-colors duration-300 ease-in-out underline underline-offset-[3px]"> Cross-Validation Algorithm </a>  </li> </ul> </li><li class="list-inside list-disc px-6 py-1.5 text-sm"> <a href="#multiclass-classification" target="_self" class="inline-block decoration-black/30 dark:decoration-white/30 hover:decoration-black/50 focus-visible:decoration-black/50 dark:hover:decoration-white/50 dark:focus-visible:decoration-white/50 text-current hover:text-black focus-visible:text-black dark:hover:text-white dark:focus-visible:text-white transition-colors duration-300 ease-in-out underline underline-offset-[3px]"> Multiclass Classification </a> <ul class="translate-x-3"> <li class="list-inside list-disc px-6 py-1.5 text-sm"> <a href="#one-vs-rest" target="_self" class="inline-block decoration-black/30 dark:decoration-white/30 hover:decoration-black/50 focus-visible:decoration-black/50 dark:hover:decoration-white/50 dark:focus-visible:decoration-white/50 text-current hover:text-black focus-visible:text-black dark:hover:text-white dark:focus-visible:text-white transition-colors duration-300 ease-in-out underline underline-offset-[3px]"> One-vs-Rest </a>  </li> </ul> </li><li class="list-inside list-disc px-6 py-1.5 text-sm"> <a href="#multiclass-logistic-regression" target="_self" class="inline-block decoration-black/30 dark:decoration-white/30 hover:decoration-black/50 focus-visible:decoration-black/50 dark:hover:decoration-white/50 dark:focus-visible:decoration-white/50 text-current hover:text-black focus-visible:text-black dark:hover:text-white dark:focus-visible:text-white transition-colors duration-300 ease-in-out underline underline-offset-[3px]"> Multiclass Logistic Regression </a> <ul class="translate-x-3"> <li class="list-inside list-disc px-6 py-1.5 text-sm"> <a href="#geometry-of-multiclass-logistic-regression" target="_self" class="inline-block decoration-black/30 dark:decoration-white/30 hover:decoration-black/50 focus-visible:decoration-black/50 dark:hover:decoration-white/50 dark:focus-visible:decoration-white/50 text-current hover:text-black focus-visible:text-black dark:hover:text-white dark:focus-visible:text-white transition-colors duration-300 ease-in-out underline underline-offset-[3px]"> Geometry of Multiclass Logistic Regression </a>  </li> </ul> </li><li class="list-inside list-disc px-6 py-1.5 text-sm"> <a href="#logistic-regression-vs-nb-and-lda" target="_self" class="inline-block decoration-black/30 dark:decoration-white/30 hover:decoration-black/50 focus-visible:decoration-black/50 dark:hover:decoration-white/50 dark:focus-visible:decoration-white/50 text-current hover:text-black focus-visible:text-black dark:hover:text-white dark:focus-visible:text-white transition-colors duration-300 ease-in-out underline underline-offset-[3px]"> Logistic Regression VS. NB and LDA </a> <ul class="translate-x-3"> <li class="list-inside list-disc px-6 py-1.5 text-sm"> <a href="#logistic-regression-summary" target="_self" class="inline-block decoration-black/30 dark:decoration-white/30 hover:decoration-black/50 focus-visible:decoration-black/50 dark:hover:decoration-white/50 dark:focus-visible:decoration-white/50 text-current hover:text-black focus-visible:text-black dark:hover:text-white dark:focus-visible:text-white transition-colors duration-300 ease-in-out underline underline-offset-[3px]"> Logistic Regression Summary </a>  </li> </ul> </li> </ul> </nav> </details> <article class="animate"> <h3 id="the-bayes-optimal-classifier">The Bayes Optimal Classifier</h3>
<p>Recall from the previous part, that the best classifier, in theory, is the Bayes Optimal Classifier.
However, it is not useful in reality due to the difficulty of estimating $p(\mathbf{x} | y = c)$ in practice.</p>
<h3 id="naive-bayes-classifier">Naive Bayes Classifier</h3>
<p>The Naive Bayes classifier is a simplified version of the Bayes Optimal Classifier.</p>
<p>It has the <em>Naive Bayes assumption</em>, which assumes that all of the feature dimensions are statistically independant given the value of the class variable, for example,
$$
p(x_1, x_2 | y) = p(x_1 | y) p(x_2 | y)
$$</p>
<p>It also accumulates evidence from each feature dimension,
$$
\log p(x_1, x_2 | y) = \log p(x_1 | y) + \log p(x_2 | y)
$$</p>
<p>This allows us to model each dimension of the observation with a simple univariate distribution.</p>
<p>Therefore, the general form for the classification is,
$$
f_{NB}(\mathbf{x}) = \underset{c \in \{1, \ldots, C\}}{\arg\max} p(y = c) \prod_{j = 1}^{N} p(x_j | y = c)
$$</p>
<h3 id="gaussian-classifier">Gaussian Classifier</h3>
<p>If we treat each dimension as an independent Gaussian and fit the Gaussian parameters with MLE, we have a Gaussian classifier.</p>
<p>But what is the geometry of the decision boundary, let’s take a look at the 2D case.</p>
<h4 id="geometric-interpretation">Geometric Interpretation</h4>
<p>We can rewrite and simplify our equation,
$$
\begin{align*}
f_{NB}(\mathbf{x}) &#x26;= \underset{c \in \{1, 2\}}{\arg\max} p(y = c) \prod_{j = 1}^{2} p(x_j | y = c) \newline
&#x26;= \underset{c \in \{1, 2\}}{\arg\max} \log p(y = c) + \sum_{j = 1}^{2} \log p(x_j | y = c) \newline
&#x26;= \underset{c \in \{1, 2\}}{\arg\max} \log p(y = c) + \sum_{j = 1}^{2} \log \mathcal{N}(x_j; \mu_{j | c}, \sigma_{j | c}^2) \newline
&#x26;= \underset{c \in \{1, 2\}}{\arg\max} \log p(y = c) + \sum_{j = 1}^{2} \log \left[ \frac{1}{\sqrt{2\pi\sigma_{j | c}^2}} \exp\left(-\frac{(x_j - \mu_{j | c})^2}{2\sigma_{j | c}^2}\right) \right] \newline
&#x26;= \underset{c \in \{1, 2\}}{\arg\max} \log p(y = c) + \sum_{j = 1}^{2} \log \left[\left(2\pi\sigma_{j | c}^2\right)^{-\frac{1}{2}} \exp\left(-\frac{(x_j - \mu_{j | c})^2}{2\sigma_{j | c}^2}\right) \right] \newline
&#x26;= \underset{c \in \{1, 2\}}{\arg\max} \log p(y = c) + \sum_{j = 1}^{2} \left( -\frac{1}{2} \log(2\pi\sigma_{j | c}^2) - \frac{(x_j - \mu_{j | c})^2}{2\sigma_{j | c}^2} \right)
\end{align*}
$$</p>
<p>Okay, so the decision boundary consists of the set of points $(x_1, x_2)$ where,
$$
\log p(y = 1) + \sum_{j = 1}^2 \log p(x_j | y = 1) = \log p(y = 2) + \sum_{j = 1}^2 \log p(x_j | y = 2)
$$</p>
<p>Which means,
$$
\log p(y = 1) + \sum_{j = 1}^2 \left(-\frac{1}{2} \log(2\pi\sigma_{j | 1}^2) - \frac{(x_j - \mu_{j | 1})^2}{2\sigma_{j | 1}^2}\right) - \newline \log p(y = 2) + \sum_{j = 1}^2 \left(-\frac{1}{2} \log(2\pi\sigma_{j | 2}^2) - \frac{(x_j - \mu_{j | 2})^2}{2\sigma_{j | 2}^2}\right) \newline = 0
$$</p>
<p>So it is a quadratic function of $(x_1, x_2)$ with the form,
$$
\sum_{j = 1}^2 (a_j x_j^2 + b_j x_j) + c = 0
$$</p>
<h3 id="naive-bayes-for-boolean-vectors">Naive Bayes for Boolean Vectors</h3>
<p>In the case we are working with boolean vectors, we can simplify the Naive Bayes classifier.</p>
<p>We still model each feature independently, but we can use the Bernoulli distribution to model the feature.</p>
<p>If there is a presence of a feature, we model it as,
$$
p(x_j = 1 | y = c) = \varphi_{j | c}
$$</p>
<p>and in the absence of a feature, we model it as,
$$
p(x_j = 0 | y = c) = 1 - \varphi_{j | c}
$$</p>
<p>Therefore, the MLE parameters are $\varphi_{j | c} = M_{j | c} / M_c$, where,
$M_{j | c}$ is the number of training examples in class $c$ that contain feature $x_j$.
$M_c$ is the number of training examples in class $c$.</p>
<p>We therefore get class-conditional distributions,
$$
p(x_1, \ldots, x_N | y = c) = \prod_{j = 1}^{N} p(x_j | y = c) \newline
\log p(x_1, \ldots, x_N | y = c) = \sum_{j = 1}^{N} \log p(x_j | y = c)
$$</p>
<p>So, for an input example $\mathbf{x}$, the log-probabilities of features present given $y = c$ adds.</p>
<h4 id="smoothing">Smoothing</h4>
<p>Some features may not be present in any training examples for a given class, which means, $M_{j | c} = 0$ and thus $\varphi_{j | c} = 0$.</p>
<p>Which is problematic, since it may appear in a real-world example.</p>
<p>To solve this we need to smooth our MLE, by adding a <em>smoothing parameter</em> $\alpha$, which can be interpreted as a “pseudo-count”.</p>
<p>So, our new parameter is,
$$
\varphi_{j | c} = \frac{M_{j | c} + \alpha}{M_c + N\alpha}
$$</p>
<p>If $\alpha = 1$, then we have <em>Laplace Smoothing</em> (also called additive smoothing).</p>
<p>In general, smoothing helps to prevent <strong>overfitting</strong> of the parameters.</p>
<h3 id="multinomial-naive-bayes">Multinomial Naive Bayes</h3>
<p>What if $x_j$ has a finite set of categories?
$$
x_j \in \chi_j = \{1, \ldots, | \chi_j |\}
$$</p>
<p>Then we need to use a multinomial (or categorical) distribution as class-conditional,
$$
p(x_j = k | y = c) = \varphi_{x, j | c} \newline
\sum_{x \in \chi_j} \varphi_{x, j | c} = 1
$$</p>
<p>Our MLE parameter, $\varphi_{x, j | c} = M_{x, j | c} / M_{j | c}$, where,
$M_{x, j | c}$ is the number of training examples in class $c$ that have feature $x_j = x$.
$M_{j | c}$ is the number of training examples in class $c$.</p>
<h3 id="linear-discriminant-analysis-lda">Linear Discriminant Analysis (LDA)</h3>
<p>LDA is a classification technique that dates back to the 1930s, with origins from Fisher.</p>
<p>It can be interpreted as a approximation to the Bayes optimal classifier, but for real-valued data.</p>
<p>Instead of a product of independent Gaussians, LDA assumes that $p(\mathbf{x} | y = c) = \mathcal{N}(\mathbf{x}; \mathbf{\mu}_c, \mathbf{\Sigma})$.
A multivariate Gaussian with a shared covariance matrix $\mathbf{\Sigma}$.</p>
<p>Which equates to,
$$
p(\mathbf{x} | y = c) = \frac{1}{|(2\pi)^N \mathbf{\Sigma}}|^{\frac{1}{2}} exp\left(-\frac{1}{2} (\mathbf{x} - \mathbf{\mu}_c)^T \mathbf{\Sigma}^{-1} (\mathbf{x} - \mathbf{\mu}_c)\right)
$$</p>
<p>The classification function is then,
$$
f_{LDA}(\mathbf{x}) = \underset{c \in \{1, \ldots, C\}}{\arg\max} p(y = c) p(\mathbf{x} | y = c)
$$</p>
<h3 id="training-lda">Training LDA</h3>
<p>As with Naive Bayes, the LDA parameters are learned using MLE.</p>
<p>Our class probabilities are,
$$
p(y = c) = \frac{1}{M} \sum_{i = 1}^{M} \mathbb{I}(y^{(i)} = c) = \frac{M_c}{M}
$$</p>
<p>Class means are,
$$
\mathbf{\mu_c} = \frac{\sum_{i = 1}^M \mathbb{I}(y^{(i)} = c) \mathbf{x}^{(i)}}{\sum_{i = 1}^M \mathbb{I}[y^{(i)} = c]} = \frac{\sum_{i = 1}^{M_c} \mathbf{x}^{(i)}}{M_c}
$$</p>
<p>where $\mathbf{x}^{(i)}$ belongs to class $c$.</p>
<p>The shared covariance matrix is,
$$
\mathbf{\Sigma} = \frac{1}{M} \sum_{i = 1}^M \left(\mathbf{x}^{(i)} - \mathbf{\mu_{y^{(i)}}}\right) \left(\mathbf{x}^{(i)} - \mathbf{\mu_{y^{(i)}}}\right)^T
$$</p>
<h4 id="geometric-interpretation-1">Geometric Interpretation</h4>
<p>Let’s take a look at the geometry of the decision boundry for LDAs.</p>
<p>The decision boundary is the set of points $\mathbf{x}$ where,
$$
\log p(y = 1) - \frac{1}{2} \log |(2\pi)^2 \mathbf{\Sigma}| - \frac{1}{2}(\mathbf{x} - \mathbf{\mu}_1)^T \mathbf{\Sigma}^{-1} (\mathbf{x} - \mathbf{\mu}_1) \newline - \log p(y = 2) - \frac{1}{2} \log |(2\pi)^2 \mathbf{\Sigma}| - \frac{1}{2}(\mathbf{x} - \mathbf{\mu}_2)^T \mathbf{\Sigma}^{-1} (\mathbf{x} - \mathbf{\mu}_2) = 0
$$</p>
<p>By cancelling out the common terms, we get,
$$
\log \frac{p(y = 1)}{p(y = 2)} - \frac{1}{2} \mathbf{\mu}_1^T \mathbf{\Sigma}^{-1} \mathbf{\mu}_1 + \frac{1}{2} \mathbf{\mu}_2^T \mathbf{\Sigma}^{-1} \mathbf{\mu}_2 + (\mathbf{\mu}_1 - \mathbf{\mu}_2)^T \mathbf{\Sigma}^{-1} \mathbf{x} = 0
$$</p>
<p>This shows that the decision boundary is linear in $\mathbf{x}$.</p>
<h3 id="naive-bayes-vs-lda">Naive Bayes vs LDA</h3>
<p>So, which is better?</p>
<p>Let’s break it down.</p>
<ul>
<li>Storage
<ul>
<li>Naive Bayes: $\mathcal{O}(N)$ parameters</li>
<li>LDA: $\mathcal{O}(N^2)$ parameters</li>
</ul>
</li>
<li>Speed
The quadratic dependence on N makes LDA slower than NB during learning and classification.</li>
<li>Interpretability
<ul>
<li>Both models have good interpretability since the parameters of $p(\mathbf{x} | y = c)$ corresponds to class conditional averages.</li>
</ul>
</li>
<li>Data
<ul>
<li>LDA will generally need more data than NB since it needs to estimate $\mathcal{O}(N^2)$ parameters in the shared covariance matrix.</li>
</ul>
</li>
</ul>
<h3 id="summary-of-generative-models">Summary of Generative Models</h3>
<p>So, what we have been looking at can also be called <em>generative classification models</em>.</p>
<p>They estimate a probability distribution of features from each class.
Given a feature, predict the class with the largest posterior probability.</p>
<ul>
<li>Advantages
<ul>
<li>Works with small amounts of data.</li>
<li>Works with multiple classes.</li>
</ul>
</li>
<li>Disadvantages
<ul>
<li>Accuracy depends on selecting an appropriate probability distribution.</li>
<li>If the probability distribution can’t model the data, the accuracy will be poor.</li>
</ul>
</li>
</ul>
<h3 id="discriminative-models">Discriminative Models</h3>
<p>Discriminative models directly model the posterior probability $p(y | \mathbf{x})$.</p>
<p>Let’s start with the simplest discriminative model, the <em>linear classifier</em>.</p>
<h4 id="linear-classifier">Linear Classifier</h4>
<p>For a linear classifier we have this “setup”.
Observation (feature vectors) $\mathbf{x} \in \mathbb{R}^N$.
Class $y \in \{-1, +1\}$.</p>
<p>Our goal is to calculate a linear function of the feature vector $\mathbf{x}$,
$$
f(\mathbf{x}) = \mathbf{w}^T \mathbf{x} + b = \sum_{j = 1}^N w_j x_j + b
$$</p>
<p>where $\mathbf{w} \in \mathbb{R}^N$ is the weight vector and $b \in \mathbb{R}$ is the bias term.</p>
<p>From this value generated by the function, if $f(\mathbf{x}) > 0$, we predict class $+1$, otherwise we predict class $-1$, or just $sign(f(\mathbf{x}))$.</p>
<h5 id="geometric-interpretation-2">Geometric Interpretation</h5>
<p>As the name suggests, the linear classifier seperates the feature space into 2 half-spaces.</p>
<p>Each space corresponds to feature values belonging to class $+1$ and class $-1$.</p>
<p>The class boundary is <em>normal</em> (orthogonal or perpendicular since we are in 2D) to $\mathbf{w}$.
This boundary is also called the <strong>separating hyperplane</strong>.</p>
<h5 id="separating-hyperplane">Separating Hyperplane</h5>
<p>In an $N$-dimensional feature space, the parameters are $\mathbf{w} \in \mathbb{R}^N$.</p>
<p>The equation $\mathbf{w}^T \mathbf{x} + b = 0$ defines an $N-1$-dimensional linear surface.</p>
<ul>
<li>For $N = 2$,$\mathbf{w}$ defines a 1D line.</li>
<li>For $N = 3$, $\mathbf{w}$ defines a 2D plane.</li>
<li>For $N = n$, $\mathbf{w}$ defines a hyperplane.</li>
</ul>
<h3 id="training-a-linear-classifier">Training a Linear Classifier</h3>
<p>But how do we set these classifier parameters ($\mathbf{w}$, $b$)?</p>
<p>Simple, learn them from the data.
But depending on which approach we take, we get different classifiers.</p>
<p>Let’s take a look at the probabilistic approach.</p>
<h3 id="logistic-regression">Logistic Regression</h3>
<p>If we take the probabilistic route, we need to map the function value $f(\mathbf{x}) = \mathbf{w}^T \mathbf{x} + b$ to a probability (value between 0 and 1).</p>
<p>Luckily, the sigmoid function does exactly this. It maps any real number to the interval $[0, 1]$,
$$
\sigma(z) = \frac{1}{1 + e^{-z}}, \text{ for } z \in \mathbb{R}
$$</p>
<p>So, given a feature vector $\mathbf{x}$, the probability of a class is,
$$
p(y = +1 | \mathbf{x}) = \sigma(f(\mathbf{x})) \newline
p(y = -1 | \mathbf{x}) = 1 - \sigma(f(\mathbf{x})) = \sigma(-f(\mathbf{x})) \ | \ \text{since } \sigma(-z) = 1 - \sigma(z)
$$</p>
<p>or simply,
$$
p(y | \mathbf{x}) = \sigma(y f(\mathbf{x})).
$$</p>
<p>So the important thing here is that we are <strong>direcrtly</strong> modeling the class posterior probability, not the class-conditional probability.</p>
<h4 id="learning-the-parameters">Learning the Parameters</h4>
<p>Given the data set $\mathcal{D} = \{(\mathbf{x}^{(i)}, y^{(i)})\}_{i = 1}^M$, we can learn the parameters ($\mathbf{w}$, $b$) using MLE.</p>
<p>Maximize the conditional log likelihood of the data $\mathcal{D}$,
$$
\begin{align*}
(\mathbf{w}^\star, b^\star) &#x26;= \underset{\mathbf{w}, b}{\arg\max} \sum_{i = 1}^M \log p(y^{(i)} | \mathbf{x}^{(i)}, \mathbf{w}; b) \newline
&#x26;= \underset{\mathbf{w}, b}{\arg\max} -\frac{1}{M} \sum_{i = 1}^M \log (1 + \exp(-y^{(i)} (\mathbf{w}^T \mathbf{x}^{(i)} + b)))
\end{align*}
$$</p>
<p>To prevent <strong>overfitting</strong>, add a prior distribution on $\mathbf{w}$, for example, a Gaussian distribution with variance $C/2$.
$$
p(\mathbf{w}) \propto \exp\left(-\frac{1}{C} \mathbf{w}^T \mathbf{w}\right)
$$</p>
<p>Now maximize,
$$
\begin{align*}
(\mathbf{w}^\star, b^\star) &#x26;= \underset{\mathbf{w}, b}{\arg\max} \frac{1}{M} \sum_{i = 1}^M \log p(y^{(i)} | \mathbf{x}^{(i)}, \mathbf{w}; b) \newline
&#x26;= \underset{\mathbf{w}, b}{\arg\max} \frac{1}{M} \sum_{i = 1}^M \log \frac{p(\mathbf{w}, y^{(i)} | \mathbf{x}^{(i)}; b)}{p(y^{(i)} | \mathbf{x}^{(i)})} \newline
&#x26;= \underset{\mathbf{w}, b}{\arg\max} \frac{1}{M} \sum_{i = 1}^M \log \frac{p(\mathbf{w}) p(y^{(i)} | \mathbf{x}^{(i)}, \mathbf{w}; b)}{p(y^{(i)} | \mathbf{x}^{(i)})} \newline
&#x26;= \underset{\mathbf{w}, b}{\arg\max} \log p(\mathbf{w}) + \frac{1}{M} \sum_{i = 1}^M \log p(y^{(i)} | \mathbf{x}^{(i)}, \mathbf{w}; b) \newline
\end{align*}
$$</p>
<p>which equivalently,
$$
(\mathbf{w}^\star, b^\star) = \underset{\mathbf{w}, b}{\arg\min} \frac{1}{C} \mathbf{w}^T \mathbf{w} + \frac{1}{M} \sum_{i = 1}^M \log (1 + \exp(-y^{(i)} (\mathbf{w}^T \mathbf{x}^{(i)} + b)))
$$</p>
<p>The first term is the regularization term. Note that $\mathbf{w}^T \mathbf{w} = \sum_{j = 1}^N w_j^2$.
Therefore, this is a penalty term so $\mathbf{w}$ doesn’t get too large. $C$ is the regularization <strong>hyperparameter</strong>.
Larger $C$ allow large values in $\mathbf{w}$, smaller $C$ penalize large values in $\mathbf{w}$.</p>
<p>The second term is the data-fit term. This is what wants to make $(\mathbf{w}, b)$ fit the data.</p>
<p>If we define $z^{(i)} = y^{(i)} f(\mathbf{x}^{(i)})$, we have a interesting observation:</p>
<ul>
<li>$z^{(i)} > 0$ when sample $i$ is correctly classified.</li>
<li>$z^{(i)} &#x3C; 0$ when sample $i$ is incorrectly classified.</li>
<li>$z^{(i)} = 0$ when sample $i$ is on the decision boundary.</li>
</ul>
<h5 id="logistic-loss-function">Logistic Loss Function</h5>
<p>This leads us to define the <strong>logistic loss function</strong>,
$$
L(z) = log(1 + \exp(-z))
$$</p>
<p>$$
\underset{\mathbf{w}, b}{\arg\max} \log p(\mathbf{w}) + \frac{1}{M} \sum_{i = 1}^M \log p(y^{(i)} | \mathbf{x}^{(i)}, \mathbf{w}; b) \newline
$$</p>
<p><strong>No-closed-form solution</strong> to solve for $(\mathbf{w}, b)$, so we need to use <strong>numerical optimization</strong>.
For example, <strong>gradient descent</strong>.</p>
<ul>
<li>$\mathbf{w} \leftarrow \mathbf{w} - \eta \frac{\partial \ell}{\partial \mathbf{w}}$</li>
<li>$\ell$ is the objective function.</li>
<li>$\eta$ is the <strong>learning rate</strong>.</li>
</ul>
<h3 id="cross-validation">Cross-Validation</h3>
<p>We need to use <strong>cross-validation</strong> on <strong>training</strong> set to select the best value of $C$.</p>
<p>Run many experiments on the traning set to see which parameters work on different versions of the data.</p>
<p>First, partition the data into folds of training and validation data.
Try a range of $C$ values on each fold (as validation set).
Simply, pick the value that works best over all folds.</p>
<h4 id="cross-validation-algorithm">Cross-Validation Algorithm</h4>
<ul>
<li>Procedure
<ol>
<li>Select a range of $C$ values to try.</li>
<li>Repeat $K$ rounds:
<ol>
<li>Split the training set into training data and validation data.</li>
<li>Learn a classifier for each value of $C$.</li>
<li>Record the accuracy on the validation data for each $C$.</li>
</ol>
</li>
<li>Select the value of that has the highest average accuracy over all $K$ rounds.</li>
<li>Retrain the classifier using all data and the selected $C$.</li>
</ol>
</li>
</ul>
<h3 id="multiclass-classification">Multiclass Classification</h3>
<p>So far, we have only learned a classifier for 2 classes $y \in \{-1, +1\}$, also called a <strong>binary classifier</strong>.</p>
<p>For more than 2 classes, a good stragety is to simply, split the problem into several binary classifier problems.</p>
<h4 id="one-vs-rest">One-vs-Rest</h4>
<p>In this strategy, when we train, for each class, train a classifier for that class versus the other classes.</p>
<p>So for example, if we have 3 classes then we train 3 binary classifiers, $1$ vs $\{2, 3\}$, $2$ vs $\{1, 3\}$, and $3$ vs $\{1, 2\}$.</p>
<p>When predicitng, calculate the probablity for each binary classifier. Select the class with the highest probablity.</p>
<h3 id="multiclass-logistic-regression">Multiclass Logistic Regression</h3>
<p>Another way to get a multiclass classifier is to define a multiclass objective function.</p>
<p>One weight vector $\mathbf{w}_c$ for each class $c$. We omit the bias $b_c$ for each class for notational simplicity.</p>
<p>So, when we had the binary classifier we used the sigmoid function, for a multiclass objective, we need to use the <strong>softmax</strong> function.
Define probabilities with the softmax function,
$$
p(y = c | x) = \frac{\exp(\mathbf{w}_c^T \mathbf{x})}{exp(\mathbf{w}_1^T \mathbf{x}) + \ldots + \exp(\mathbf{w}_C^T \mathbf{x})}
$$</p>
<p>Here we need to estimate the $\{w_c\}_{c = 1}^C$ parameters using MLE as before.</p>
<h4 id="geometry-of-multiclass-logistic-regression">Geometry of Multiclass Logistic Regression</h4>
<p>In logistic regressino, it is explcitily designed to have a linear decision boundary in the binary case.</p>
<p>In the multiclass case, the decision boundary is <strong>piece-wise linear</strong>.</p>
<h3 id="logistic-regression-vs-nb-and-lda">Logistic Regression VS. NB and LDA</h3>
<ul>
<li>
<p>Speed</p>
<ul>
<li>Learning logistic regression requires iterative numerical optimization, which will be slower than NB and LDA.</li>
</ul>
</li>
<li>
<p>Storage</p>
<ul>
<li>
<p>The model requires $\mathcal{O}(N)$ parameters, the same order as NB but much less than LDA’s $\mathcal{O}(N^2)$.</p>
</li>
</ul>
<ul>
<li>Interpretability
<ul>
<li>The “importance” of feature $x_j$ can be understood in terms of the corresponding learned weight $w_j$.</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="logistic-regression-summary">Logistic Regression Summary</h4>
<ul>
<li>Classifier
<ul>
<li>Linear function $f(\mathbf{x}) = \mathbf{w}^T \mathbf{x} + b$.</li>
<li>Given a feature vector $\mathbf{x}$ the probability of a class is
<ul>
<li>$p(y = +1 | \mathbf{x}) = \sigma(f(\mathbf{x})), p(y = -1 | \mathbf{x}) = \sigma(-f(\mathbf{x}))$.</li>
<li>Sigmod function $\sigma(z) = \frac{1}{1 + e^{-z}}$.</li>
</ul>
</li>
</ul>
<ul>
<li>Logistic loss function $L(z) = \log(1 + \exp(-z))$.</li>
</ul>
</li>
<li>Training
<ul>
<li>Maximize the likelihood of the training data</li>
<li>Use regularization to prevent overfitting.
<ul>
<li>Use cross-validation to pick the regularization parameter $C$.</li>
</ul>
</li>
</ul>
</li>
<li>Classification
<ul>
<li>Given a new sample $\mathbf{x}^\star$, pick class with the highest $p(y | \mathbf{x}^\star)$.</li>
</ul>
</li>
</ul>
<p>$$
y^\star =
\begin{cases}
+1, &#x26; \frac{p(y = +1 | \mathbf{x}^\star)}{p(y = -1 | \mathbf{x}^\star)} > 1 \newline
-1, &#x26; \text{otherwise}
\end{cases}
$$</p>
<p>or simply,</p>
<p>$$
y^\star =
\begin{cases}
+1, &#x26; f(\mathbf{x}^\star) > 0 \newline
-1, &#x26; \text{otherwise}
\end{cases}
$$</p> <div class="mt-24"> <div class="grid grid-cols-2 gap-1.5 sm:gap-3"> <a href="/cityu/cs4487/cs4487" class="group relative flex flex-nowrap rounded-lg border border-black/15 px-4 py-3 pl-10 no-underline transition-colors duration-300 ease-in-out hover:bg-black/5 hover:text-black focus-visible:bg-black/5 focus-visible:text-black dark:border-white/20 dark:hover:bg-white/5 dark:hover:text-white dark:focus-visible:bg-white/5 dark:focus-visible:text-white"> <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" class="absolute left-2 top-1/2 size-5 -translate-y-1/2 fill-none stroke-current stroke-2"> <line x1="5" y1="12" x2="19" y2="12" class="translate-x-3 scale-x-0 transition-transform duration-300 ease-in-out group-hover:translate-x-0 group-hover:scale-x-100 group-focus-visible:translate-x-0 group-focus-visible:scale-x-100"></line> <polyline points="12 5 5 12 12 19" class="translate-x-1 transition-transform duration-300 ease-in-out group-hover:translate-x-0 group-focus-visible:translate-x-0"></polyline> </svg> <div class="flex items-center text-sm"> Part 1 - Introduction </div> </a> <a href="/cityu/cs4487/cs4487_3" class="group relative flex flex-grow flex-row-reverse flex-nowrap rounded-lg border border-black/15 px-4 py-4 pr-10 no-underline transition-colors duration-300 ease-in-out hover:bg-black/5 hover:text-black focus-visible:bg-black/5 focus-visible:text-black dark:border-white/20 dark:hover:bg-white/5 dark:hover:text-white dark:focus-visible:bg-white/5 dark:focus-visible:text-white"> <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" class="absolute right-2 top-1/2 size-5 -translate-y-1/2 fill-none stroke-current stroke-2"> <line x1="5" y1="12" x2="19" y2="12" class="translate-x-3 scale-x-0 transition-transform duration-300 ease-in-out group-hover:translate-x-0 group-hover:scale-x-100 group-focus-visible:translate-x-0 group-focus-visible:scale-x-100"></line> <polyline points="12 5 19 12 12 19" class="-translate-x-1 transition-transform duration-300 ease-in-out group-hover:translate-x-0 group-focus-visible:translate-x-0"></polyline> </svg> <div class="flex items-center text-sm"> Part 3 - Optimization and Convexity </div> </a> </div> </div> <div class="mt-24"> <div class="giscus"></div> <script data-astro-rerun src="https://giscus.app/client.js" data-repo="rezaarezvan/rezvan.xyz" data-repo-id="R_kgDOHvQr3w" data-category="General" data-category-id="DIC_kwDOHvQr384CiWVC" data-mapping="pathname" data-strict="0" data-reactions-enabled="1" data-emit-metadata="0" data-input-position="bottom" data-theme="preferred_color_scheme" data-lang="en" data-loading="lazy" crossorigin="anonymous" async></script> </div> </article> </div>  </main> <footer class="animate"> <div class="mx-auto max-w-screen-sm px-3"> <div class="relative"> <div class="absolute -top-12 right-0"> <button id="back-to-top" class="group relative flex w-fit flex-nowrap rounded border border-black/15 py-1.5 pl-8 pr-3 transition-colors duration-300 ease-in-out hover:bg-black/5 hover:text-black focus-visible:bg-black/5 focus-visible:text-black dark:border-white/20 dark:hover:bg-white/5 dark:hover:text-white dark:focus-visible:bg-white/5 dark:focus-visible:text-white"> <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" class="absolute left-2 top-1/2 size-4 -translate-y-1/2 rotate-90 fill-none stroke-current stroke-2"> <line x1="5" y1="12" x2="19" y2="12" class="translate-x-2 scale-x-0 transition-transform duration-300 ease-in-out group-hover:translate-x-0 group-hover:scale-x-100 group-focus-visible:translate-x-0 group-focus-visible:scale-x-100"></line> <polyline points="12 5 5 12 12 19" class="translate-x-1 transition-transform duration-300 ease-in-out group-hover:translate-x-0 group-focus-visible:translate-x-0"></polyline> </svg> <div class="text-sm">Back to top</div> </button> </div> </div> <div class="flex items-center justify-between"> <div>&copy; 2024 • rezvan.xyz </div> <div class="flex flex-wrap items-center gap-1.5"> <button id="light-theme-button" aria-label="Light theme" class="group flex size-9 items-center justify-center rounded border border-black/15 hover:bg-black/5 focus-visible:bg-black/5 dark:border-white/20 dark:hover:bg-white/5 dark:focus-visible:bg-white/5"> <svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="transition-colors duration-300 ease-in-out group-hover:animate-pulse group-hover:stroke-black group-focus-visible:animate-pulse group-focus-visible:stroke-black group-hover:dark:stroke-white dark:group-focus-visible:stroke-white"> <circle cx="12" cy="12" r="5"></circle> <line x1="12" y1="1" x2="12" y2="3"></line> <line x1="12" y1="21" x2="12" y2="23"></line> <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line> <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line> <line x1="1" y1="12" x2="3" y2="12"></line> <line x1="21" y1="12" x2="23" y2="12"></line> <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line> <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line> </svg> </button> <button id="dark-theme-button" aria-label="Dark theme" class="group flex size-9 items-center justify-center rounded border border-black/15 hover:bg-black/5 focus-visible:bg-black/5 dark:border-white/20 dark:hover:bg-white/5 dark:focus-visible:bg-white/5"> <svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="transition-colors duration-300 ease-in-out group-hover:animate-pulse group-hover:stroke-black group-focus-visible:animate-pulse group-focus-visible:stroke-black group-hover:dark:stroke-white dark:group-focus-visible:stroke-white"> <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path> </svg> </button> <button id="system-theme-button" aria-label="System theme" class="group flex size-9 items-center justify-center rounded border border-black/15 hover:bg-black/5 focus-visible:bg-black/5 dark:border-white/20 dark:hover:bg-white/5 dark:focus-visible:bg-white/5"> <svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="transition-colors duration-300 ease-in-out group-hover:animate-pulse group-hover:stroke-black group-focus-visible:animate-pulse group-focus-visible:stroke-black group-hover:dark:stroke-white dark:group-focus-visible:stroke-white"> <rect x="2" y="3" width="20" height="14" rx="2" ry="2"></rect> <line x1="8" y1="21" x2="16" y2="21"></line> <line x1="12" y1="17" x2="12" y2="21"></line> </svg> </button> </div> </div> </div> </footer> <aside data-pagefind-ignore> <div id="backdrop" class="bg-[rgba(0, 0, 0, 0.5] invisible fixed left-0 top-0 z-50 flex h-screen w-full justify-center p-6 backdrop-blur-sm" data-astro-transition-persist="astro-3snakcvo-2"> <div id="pagefind-container" class="m-0 flex h-fit max-h-[80%] w-full max-w-screen-sm flex-col overflow-auto rounded border border-black/15 bg-neutral-100 p-2 px-4 py-3 shadow-lg dark:border-white/20 dark:bg-neutral-900"> <div id="search" class="pagefind-ui pagefind-init" data-pagefind-ui data-bundle-path="/pagefind/" data-ui-options="{&#34;showImages&#34;:false,&#34;excerptLength&#34;:15,&#34;resetStyles&#34;:false}"></div>  <div class="mr-2 pb-1 pt-4 text-right text-xs dark:prose-invert">
Press <span class="prose text-xs dark:prose-invert"><kbd class="">Esc</kbd></span> or click anywhere to close
</div> </div> </div> </aside> <script>
  const magnifyingGlass = document.getElementById("magnifying-glass");
  const backdrop = document.getElementById("backdrop");

  function openPagefind() {
    const searchDiv = document.getElementById("search");
    const search = searchDiv.querySelector("input");
    setTimeout(() => {
      search.focus();
    }, 0);
    backdrop?.classList.remove("invisible");
    backdrop?.classList.add("visible");
  }

  function closePagefind() {
    const search = document.getElementById("search");
    search.value = "";
    backdrop?.classList.remove("visible");
    backdrop?.classList.add("invisible");
  }

  // open pagefind
  magnifyingGlass?.addEventListener("click", () => {
    openPagefind();
  });

  document.addEventListener("keydown", (e) => {
    if (e.key === "/") {
      e.preventDefault();
      openPagefind();
    } else if ((e.metaKey || e.ctrlKey) && e.key === "k") {
      e.preventDefault();
      openPagefind();
    }
  });

  // close pagefind
  document.addEventListener("keydown", (e) => {
    if (e.key === "Escape" || e.keyCode === 27) {
      closePagefind();
    }
  });

  // close pagefind when searched result(link) clicked
  document.addEventListener("click", (event) => {
    if (event.target.classList.contains("pagefind-ui__result-link")) {
      closePagefind();
    }
  });

  backdrop?.addEventListener("click", (event) => {
    if (!event.target.closest("#pagefind-container")) {
      closePagefind();
    }
  });

  // prevent form submission
  const form = document.getElementById("form");
  form?.addEventListener("submit", (event) => {
    event.preventDefault();
  });
</script>  </body></html>