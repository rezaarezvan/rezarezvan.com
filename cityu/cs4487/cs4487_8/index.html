<!DOCTYPE html><html lang="en-US"> <head><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes"><meta name="generator" content="Astro v5.7.2"><meta name="robots" content="index, follow"><meta name="HandheldFriendly" content="True"><meta name="mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="format-detection" content="telephone=no,date=no,address=no,email=no,url=no"><meta name="theme-color" content="#121212" media="(prefers-color-scheme: dark)"><meta name="theme-color" content="#121212" media="(prefers-color-scheme: light)"><link rel="sitemap" href="/sitemap-index.xml"><link rel="manifest" href="/site.webmanifest"><link rel="alternate" type="application/rss+xml" title="rezarezvan.com" href="https://rezaarezvan.com/rss.xml"><!-- PageFind --><link href="/pagefind/pagefind-ui.css" rel="stylesheet"><script src="/pagefind/pagefind-ui.js"></script><!-- KaTeX support --><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.15/dist/katex.min.css" integrity="sha384-Htz9HMhiwV8GuQ28Xr9pEs1B4qJiYu/nYLLwlDklR53QibDfmQzi7rYxXhMH/5/u" crossorigin="anonymous"><script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.15/dist/katex.min.js" integrity="sha384-bxmi2jLGCvnsEqMuYLKE/KsVCxV3PqmKeK6Y6+lmNXBry6+luFkEOsmp5vD9I/7+" crossorigin="anonymous"></script><script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.15/dist/contrib/auto-render.min.js" integrity="sha384-hCXGrW6PitJEwbkoStFjeJxv+fSOOQKOPbJxSfM6G5sWZjAyWhXiTIIAmQqnlLlh" crossorigin="anonymous" onload="renderMathInElement(document.body);"></script><!-- inline KaTeX --><script>
    function renderKaTeX() {
      if (typeof renderMathInElement !== 'undefined') {
        renderMathInElement(document.body, {
          delimiters: [
            { left: '$$', right: '$$', display: true },
            { left: '$', right: '$', display: false },
          ],
        })
      }
    }

    document.addEventListener('DOMContentLoaded', renderKaTeX)
    document.addEventListener('astro:after-swap', renderKaTeX)
  </script><link rel="icon" type="image/png" href="/favicon-96x96.png" sizes="96x96"><link rel="icon" type="image/svg+xml" href="/favicon.ico"><link rel="shortcut icon" href="/favicon.ico"><link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png"><meta name="apple-mobile-web-app-title" content="rezvan-blog"><link rel="manifest" href="/site.webmanifest"><meta name="astro-view-transitions-enabled" content="true"><meta name="astro-view-transitions-fallback" content="animate"><script type="module" src="/_astro/ClientRouter.astro_astro_type_script_index_0_lang.BZs-2RF_.js"></script><script>
    function init() {
      setGiscusTheme()
    }

    const setGiscusTheme = () => {
      const giscus = document.querySelector('.giscus-frame')

      const isDark = document.documentElement.classList.contains('dark')

      if (giscus) {
        const url = new URL(giscus.src)
        url.searchParams.set('theme', isDark ? 'dark' : 'light')
        giscus.src = url.toString()
      }
    }

    document.addEventListener('DOMContentLoaded', () => init())
    document.addEventListener('astro:after-swap', () => init())
  </script><title>Part 8 - Principal Component Analysis | rezarezvan.com</title><meta name="title" content="Part 8 - Principal Component Analysis | rezarezvan.com"><meta name="description" content="Personal website and course notes repository"><link rel="canonical" href="https://rezarezvan.com"><meta property="og:title" content="Part 8 - Principal Component Analysis"><meta property="og:description" content="Personal website and course notes repository"><meta property="og:image" content="https://rezarezvan.comundefined"><meta property="og:image:alt" content="Part 8 - Principal Component Analysis"><meta property="og:type" content="website"><meta property="og:locale" content="en-US"><meta property="og:site_name" content="rezarezvan.com"><meta property="og:url" content="https://rezaarezvan.com/cityu/cs4487/cs4487_8/"><meta name="twitter:title" content="Part 8 - Principal Component Analysis"><meta name="twitter:description" content="Personal website and course notes repository"><meta property="twitter:image" content="https://rezarezvan.comundefined"><meta name="twitter:image:alt" content="Part 8 - Principal Component Analysis"><meta name="twitter:card" content="summary_large_image"><link rel="stylesheet" href="/_astro/index.CMpDWyYm.css"></head><body> <div class="flex h-fit min-h-screen flex-col gap-y-6 font-sans"> <header class="bg-background/50 sticky top-0 z-10 backdrop-blur-md" data-astro-transition-persist="astro-l7r54iwe-1"> <div class="mx-auto flex max-w-3xl flex-wrap items-center justify-between gap-4 p-4"> <a href="/" target="_self" class="transition-colors duration-300 ease-in-out flex shrink-0 items-center gap-2 text-xl font-medium"> rezarezvan.com </a> <div class="flex items-center gap-2 md:gap-4"> <nav class="hidden items-center gap-4 text-sm sm:gap-6 md:flex"> <a href="/blog" target="_self" class="inline-block duration-300 ease-in-out hover:text-foreground/30 transition-colors"> blog<span>/</span>  </a><a href="/chalmers" target="_self" class="inline-block duration-300 ease-in-out hover:text-foreground/30 transition-colors"> chalmers<span>/</span>  </a><a href="/cityu" target="_self" class="inline-block duration-300 ease-in-out hover:text-foreground/30 transition-colors"> cityu<span>/</span>  </a><a href="/about" target="_self" class="inline-block duration-300 ease-in-out hover:text-foreground/30 transition-colors"> about<span>/</span>  </a> </nav> <button id="magnifying-glass" aria-label="Search" class="flex items-center rounded border border-black/15 bg-neutral-100 px-2 py-1 text-xs transition-colors duration-300 ease-in-out hover:bg-black/5 hover:text-black focus-visible:bg-black/5 focus-visible:text-black dark:border-white/20 dark:bg-neutral-900 dark:hover:bg-white/5 dark:hover:text-white dark:focus-visible:bg-white/5 dark:focus-visible:text-white"> <svg height="16" stroke-linejoin="round" viewBox="0 0 16 16" width="16" style="color: currentcolor;"> <path fill-rule="evenodd" clip-rule="evenodd" d="M3.5 7C3.5 5.067 5.067 3.5 7 3.5C8.933 3.5 10.5 5.067 10.5 7C10.5 7.88461 10.1718 8.69256 9.63058 9.30876L9.30876 9.63058C8.69256 10.1718 7.88461 10.5 7 10.5C5.067 10.5 3.5 8.933 3.5 7ZM9.96544 11.0261C9.13578 11.6382 8.11014 12 7 12C4.23858 12 2 9.76142 2 7C2 4.23858 4.23858 2 7 2C9.76142 2 12 4.23858 12 7C12 8.11014 11.6382 9.13578 11.0261 9.96544L14.0303 12.9697L14.5607 13.5L13.5 14.5607L12.9697 14.0303L9.96544 11.0261Z" fill="currentColor"></path> </svg>
&nbsp;Search
</button> <style>astro-island,astro-slot,astro-static-slot{display:contents}</style><script>(()=>{var e=async t=>{await(await t())()};(self.Astro||(self.Astro={})).load=e;window.dispatchEvent(new Event("astro:load"));})();;(()=>{var A=Object.defineProperty;var g=(i,o,a)=>o in i?A(i,o,{enumerable:!0,configurable:!0,writable:!0,value:a}):i[o]=a;var d=(i,o,a)=>g(i,typeof o!="symbol"?o+"":o,a);{let i={0:t=>m(t),1:t=>a(t),2:t=>new RegExp(t),3:t=>new Date(t),4:t=>new Map(a(t)),5:t=>new Set(a(t)),6:t=>BigInt(t),7:t=>new URL(t),8:t=>new Uint8Array(t),9:t=>new Uint16Array(t),10:t=>new Uint32Array(t),11:t=>1/0*t},o=t=>{let[l,e]=t;return l in i?i[l](e):void 0},a=t=>t.map(o),m=t=>typeof t!="object"||t===null?t:Object.fromEntries(Object.entries(t).map(([l,e])=>[l,o(e)]));class y extends HTMLElement{constructor(){super(...arguments);d(this,"Component");d(this,"hydrator");d(this,"hydrate",async()=>{var b;if(!this.hydrator||!this.isConnected)return;let e=(b=this.parentElement)==null?void 0:b.closest("astro-island[ssr]");if(e){e.addEventListener("astro:hydrate",this.hydrate,{once:!0});return}let c=this.querySelectorAll("astro-slot"),n={},h=this.querySelectorAll("template[data-astro-template]");for(let r of h){let s=r.closest(this.tagName);s!=null&&s.isSameNode(this)&&(n[r.getAttribute("data-astro-template")||"default"]=r.innerHTML,r.remove())}for(let r of c){let s=r.closest(this.tagName);s!=null&&s.isSameNode(this)&&(n[r.getAttribute("name")||"default"]=r.innerHTML)}let p;try{p=this.hasAttribute("props")?m(JSON.parse(this.getAttribute("props"))):{}}catch(r){let s=this.getAttribute("component-url")||"<unknown>",v=this.getAttribute("component-export");throw v&&(s+=` (export ${v})`),console.error(`[hydrate] Error parsing props for component ${s}`,this.getAttribute("props"),r),r}let u;await this.hydrator(this)(this.Component,p,n,{client:this.getAttribute("client")}),this.removeAttribute("ssr"),this.dispatchEvent(new CustomEvent("astro:hydrate"))});d(this,"unmount",()=>{this.isConnected||this.dispatchEvent(new CustomEvent("astro:unmount"))})}disconnectedCallback(){document.removeEventListener("astro:after-swap",this.unmount),document.addEventListener("astro:after-swap",this.unmount,{once:!0})}connectedCallback(){if(!this.hasAttribute("await-children")||document.readyState==="interactive"||document.readyState==="complete")this.childrenConnectedCallback();else{let e=()=>{document.removeEventListener("DOMContentLoaded",e),c.disconnect(),this.childrenConnectedCallback()},c=new MutationObserver(()=>{var n;((n=this.lastChild)==null?void 0:n.nodeType)===Node.COMMENT_NODE&&this.lastChild.nodeValue==="astro:end"&&(this.lastChild.remove(),e())});c.observe(this,{childList:!0}),document.addEventListener("DOMContentLoaded",e)}}async childrenConnectedCallback(){let e=this.getAttribute("before-hydration-url");e&&await import(e),this.start()}async start(){let e=JSON.parse(this.getAttribute("opts")),c=this.getAttribute("client");if(Astro[c]===void 0){window.addEventListener(`astro:${c}`,()=>this.start(),{once:!0});return}try{await Astro[c](async()=>{let n=this.getAttribute("renderer-url"),[h,{default:p}]=await Promise.all([import(this.getAttribute("component-url")),n?import(n):()=>()=>{}]),u=this.getAttribute("component-export")||"default";if(!u.includes("."))this.Component=h[u];else{this.Component=h;for(let f of u.split("."))this.Component=this.Component[f]}return this.hydrator=p,this.hydrate},e,this)}catch(n){console.error(`[astro-island] Error hydrating ${this.getAttribute("component-url")}`,n)}}attributeChangedCallback(){this.hydrate()}}d(y,"observedAttributes",["props"]),customElements.get("astro-island")||customElements.define("astro-island",y)}})();</script><astro-island uid="IsA9h" prefix="r3" component-url="/_astro/mobile-menu.C9T2c5u4.js" component-export="default" renderer-url="/_astro/client.DXT7MGXl.js" props="{&quot;data-astro-transition-persist&quot;:[0,&quot;astro-lci6dfah-2&quot;]}" ssr client="load" opts="{&quot;name&quot;:&quot;MobileMenu&quot;,&quot;value&quot;:true}" data-astro-transition-persist="astro-lci6dfah-2" await-children><button data-slot="dropdown-menu-trigger" class="inline-flex items-center justify-center gap-2 whitespace-nowrap rounded-md text-sm font-medium transition-all disabled:pointer-events-none disabled:opacity-50 [&amp;_svg]:pointer-events-none [&amp;_svg:not([class*=&#x27;size-&#x27;])]:size-4 shrink-0 [&amp;_svg]:shrink-0 outline-none focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:ring-[3px] aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive border bg-background shadow-xs hover:bg-accent hover:text-accent-foreground dark:bg-input/30 dark:border-input dark:hover:bg-input/50 size-9 md:hidden" title="Menu" type="button" id="radix-:r3R0:" aria-haspopup="menu" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-menu h-5 w-5"><line x1="4" x2="20" y1="12" y2="12"></line><line x1="4" x2="20" y1="6" y2="6"></line><line x1="4" x2="20" y1="18" y2="18"></line></svg><span class="sr-only">Toggle menu</span></button><!--astro:end--></astro-island> <button data-slot="button" class="inline-flex items-center justify-center gap-2 whitespace-nowrap rounded-md text-sm font-medium transition-all disabled:pointer-events-none disabled:opacity-50 [&amp;_svg]:pointer-events-none [&amp;_svg:not([class*=&#x27;size-&#x27;])]:size-4 shrink-0 [&amp;_svg]:shrink-0 outline-none focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:ring-[3px] aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive border bg-background shadow-xs hover:bg-accent hover:text-accent-foreground dark:bg-input/30 dark:border-input dark:hover:bg-input/50 size-9" id="theme-toggle" title="Toggle theme"> <svg width="1em" height="1em" class="size-4 scale-100 rotate-0 transition-all dark:scale-0 dark:-rotate-90" data-icon="lucide:sun">   <symbol id="ai:lucide:sun" viewBox="0 0 24 24"><g fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2"><circle cx="12" cy="12" r="4"/><path d="M12 2v2m0 16v2M4.93 4.93l1.41 1.41m11.32 11.32l1.41 1.41M2 12h2m16 0h2M6.34 17.66l-1.41 1.41M19.07 4.93l-1.41 1.41"/></g></symbol><use href="#ai:lucide:sun"></use>  </svg> <svg width="1em" height="1em" class="absolute size-4 scale-0 rotate-90 transition-all dark:scale-100 dark:rotate-0" data-icon="lucide:moon">   <symbol id="ai:lucide:moon" viewBox="0 0 24 24"><path fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M12 3a6 6 0 0 0 9 9a9 9 0 1 1-9-9"/></symbol><use href="#ai:lucide:moon"></use>  </svg> <span class="sr-only">Toggle theme</span> </button> <script data-astro-rerun>
  const theme = (() => {
    const localStorageTheme = localStorage?.getItem('theme') ?? ''
    if (['dark', 'light'].includes(localStorageTheme)) {
      return localStorageTheme
    }
    if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
      return 'dark'
    }
    return 'light'
  })()

  if (theme === 'light') {
    document.documentElement.classList.remove('dark')
  } else {
    document.documentElement.classList.add('dark')
  }

  window.localStorage.setItem('theme', theme)
</script> <script type="module">function a(){const e=document.documentElement;e.classList.add("disable-transitions"),e.classList.toggle("dark"),window.getComputedStyle(e).getPropertyValue("opacity"),requestAnimationFrame(()=>{e.classList.remove("disable-transitions")});const t=e.classList.contains("dark");localStorage.setItem("theme",t?"dark":"light")}function s(){const e=document.getElementById("theme-toggle");e&&e.addEventListener("click",a)}s();document.addEventListener("astro:after-swap",()=>{const e=localStorage.getItem("theme"),t=document.documentElement;t.classList.add("disable-transitions"),window.getComputedStyle(t).getPropertyValue("opacity"),e==="dark"?t.classList.add("dark"):t.classList.remove("dark"),requestAnimationFrame(()=>{t.classList.remove("disable-transitions")}),s()});</script> </div> </div> </header> <main class="grow"> <div class="mx-auto flex grow flex-col gap-y-6 px-4">   <section class="grid grid-cols-[minmax(0px,1fr)_min(calc(var(--breakpoint-md)-2rem),100%)_minmax(0px,1fr)] gap-y-6"> <div class="col-start-2"> <nav aria-label="breadcrumb" data-slot="breadcrumb"> <ol data-slot="breadcrumb-list" class="text-muted-foreground flex flex-wrap items-center gap-1.5 text-sm break-words sm:gap-2.5"> <li data-slot="breadcrumb-item" class="inline-flex items-center gap-1.5"> <a data-slot="breadcrumb-link" class="hover:text-foreground transition-colors" href="/"> <svg width="1em" height="1em" class="size-4" data-icon="lucide:home">   <symbol id="ai:lucide:home" viewBox="0 0 24 24"><g fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2"><path d="M15 21v-8a1 1 0 0 0-1-1h-4a1 1 0 0 0-1 1v8"/><path d="M3 10a2 2 0 0 1 .709-1.528l7-5.999a2 2 0 0 1 2.582 0l7 5.999A2 2 0 0 1 21 10v9a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2z"/></g></symbol><use href="#ai:lucide:home"></use>  </svg> </a> </li>  <li data-slot="breadcrumb-separator" role="presentation" aria-hidden="true" class="[&amp;&gt;svg]:size-3.5"><svg width="15" height="15" viewBox="0 0 15 15" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M6.1584 3.13508C6.35985 2.94621 6.67627 2.95642 6.86514 3.15788L10.6151 7.15788C10.7954 7.3502 10.7954 7.64949 10.6151 7.84182L6.86514 11.8418C6.67627 12.0433 6.35985 12.0535 6.1584 11.8646C5.95694 11.6757 5.94673 11.3593 6.1356 11.1579L9.565 7.49985L6.1356 3.84182C5.94673 3.64036 5.95694 3.32394 6.1584 3.13508Z" fill="currentColor" fill-rule="evenodd" clip-rule="evenodd"></path></svg></li> <li data-slot="breadcrumb-item" class="inline-flex items-center gap-1.5"><a data-slot="breadcrumb-link" class="hover:text-foreground transition-colors" href="/cityu"> <span class="flex items-center gap-x-2"> <svg width="1em" height="1em" class="size-4" data-icon="lucide:graduation-cap">   <symbol id="ai:lucide:graduation-cap" viewBox="0 0 24 24"><g fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2"><path d="M21.42 10.922a1 1 0 0 0-.019-1.838L12.83 5.18a2 2 0 0 0-1.66 0L2.6 9.08a1 1 0 0 0 0 1.832l8.57 3.908a2 2 0 0 0 1.66 0zM22 10v6"/><path d="M6 12.5V16a6 3 0 0 0 12 0v-3.5"/></g></symbol><use href="#ai:lucide:graduation-cap"></use>  </svg> CityU </span> </a></li>  <li data-slot="breadcrumb-separator" role="presentation" aria-hidden="true" class="[&amp;&gt;svg]:size-3.5"><svg width="15" height="15" viewBox="0 0 15 15" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M6.1584 3.13508C6.35985 2.94621 6.67627 2.95642 6.86514 3.15788L10.6151 7.15788C10.7954 7.3502 10.7954 7.64949 10.6151 7.84182L6.86514 11.8418C6.67627 12.0433 6.35985 12.0535 6.1584 11.8646C5.95694 11.6757 5.94673 11.3593 6.1356 11.1579L9.565 7.49985L6.1356 3.84182C5.94673 3.64036 5.95694 3.32394 6.1584 3.13508Z" fill="currentColor" fill-rule="evenodd" clip-rule="evenodd"></path></svg></li> <li data-slot="breadcrumb-item" class="inline-flex items-center gap-1.5"><a data-slot="breadcrumb-link" class="hover:text-foreground transition-colors" href="/cityu/cs4487"> <span class="flex items-center gap-x-2"> <svg width="1em" height="1em" class="size-4" data-icon="lucide:book-open">   <symbol id="ai:lucide:book-open" viewBox="0 0 24 24"><path fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M12 7v14m-9-3a1 1 0 0 1-1-1V4a1 1 0 0 1 1-1h5a4 4 0 0 1 4 4a4 4 0 0 1 4-4h5a1 1 0 0 1 1 1v13a1 1 0 0 1-1 1h-6a3 3 0 0 0-3 3a3 3 0 0 0-3-3z"/></symbol><use href="#ai:lucide:book-open"></use>  </svg> Machine Learning </span> </a></li>  <li data-slot="breadcrumb-separator" role="presentation" aria-hidden="true" class="[&amp;&gt;svg]:size-3.5"><svg width="15" height="15" viewBox="0 0 15 15" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M6.1584 3.13508C6.35985 2.94621 6.67627 2.95642 6.86514 3.15788L10.6151 7.15788C10.7954 7.3502 10.7954 7.64949 10.6151 7.84182L6.86514 11.8418C6.67627 12.0433 6.35985 12.0535 6.1584 11.8646C5.95694 11.6757 5.94673 11.3593 6.1356 11.1579L9.565 7.49985L6.1356 3.84182C5.94673 3.64036 5.95694 3.32394 6.1584 3.13508Z" fill="currentColor" fill-rule="evenodd" clip-rule="evenodd"></path></svg></li> <li data-slot="breadcrumb-item" class="inline-flex items-center gap-1.5"><span data-slot="breadcrumb-page" role="link" aria-disabled="true" aria-current="page" class="text-foreground font-normal"> <span class="flex items-center gap-x-2"> <svg width="1em" height="1em" class="size-4" data-icon="lucide:file-text">   <symbol id="ai:lucide:file-text" viewBox="0 0 24 24"><g fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2"><path d="M15 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V7Z"/><path d="M14 2v4a2 2 0 0 0 2 2h4M10 9H8m8 4H8m8 4H8"/></g></symbol><use href="#ai:lucide:file-text"></use>  </svg> Part 8 - Principal Component Analysis </span> </span></li> </ol> </nav> </div>  <section class="col-start-2 flex flex-col gap-y-6 text-center"> <div class="flex flex-col"> <h1 class="mb-2 text-4xl leading-tight font-medium text-pretty sm:text-5xl"> Part 8 - Principal Component Analysis </h1> <div class="text-muted-foreground mb-4 flex flex-wrap items-center justify-center gap-2 text-sm"> <div class="flex items-center gap-2"> <span data-slot="badge" class="inline-flex items-center justify-center rounded-md border px-2 py-0.5 text-xs font-medium w-fit whitespace-nowrap shrink-0 [&amp;&gt;svg]:size-3 gap-1 [&amp;&gt;svg]:pointer-events-none focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:ring-[3px] aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive transition-[color,box-shadow] overflow-hidden text-foreground [a&amp;]:hover:bg-accent [a&amp;]:hover:text-accent-foreground">CS4487</span> <div data-orientation="vertical" role="none" data-slot="separator-root" class="bg-border shrink-0 data-[orientation=horizontal]:h-px data-[orientation=horizontal]:w-full data-[orientation=vertical]:h-full data-[orientation=vertical]:w-px h-4!"></div> <span>October 30, 2024</span> <div data-orientation="vertical" role="none" data-slot="separator-root" class="bg-border shrink-0 data-[orientation=horizontal]:h-px data-[orientation=horizontal]:w-full data-[orientation=vertical]:h-full data-[orientation=vertical]:w-px h-4!"></div>  <div class="font-base text-sm">
Last modified: April 15, 2025 </div>  <div data-orientation="vertical" role="none" data-slot="separator-root" class="bg-border shrink-0 data-[orientation=horizontal]:h-px data-[orientation=horizontal]:w-full data-[orientation=vertical]:h-full data-[orientation=vertical]:w-px h-4!"></div> <span>14 min read</span> </div> </div> </div> <nav class="col-start-2 grid grid-cols-1 gap-4 sm:grid-cols-2"> <a href="/cityu/cs4487/cs4487_9" target="_self" class="duration-300 ease-in-out gap-2 whitespace-nowrap text-sm font-medium transition-all disabled:pointer-events-none disabled:opacity-50 [&#38;_svg]:pointer-events-none [&#38;_svg:not([class*='size-'])]:size-4 shrink-0 [&#38;_svg]:shrink-0 outline-none focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:ring-[3px] aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive border bg-background shadow-xs hover:bg-accent hover:text-accent-foreground dark:bg-input/30 dark:border-input dark:hover:bg-input/50 px-4 py-2 has-[>svg]:px-3 rounded-xl group flex items-center justify-start size-full" aria-disabled="false">  <svg width="1em" height="1em" class="mr-2 size-4 transition-transform group-hover:-translate-x-1" data-icon="lucide:arrow-left">   <symbol id="ai:lucide:arrow-left" viewBox="0 0 24 24"><path fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="m12 19l-7-7l7-7m7 7H5"/></symbol><use href="#ai:lucide:arrow-left"></use>  </svg> <div class="flex flex-col items-start overflow-hidden text-wrap"> <span class="text-muted-foreground text-left text-xs">Next Post</span> <span class="w-full text-left text-sm text-ellipsis"> Part 9 - Neural Networks and Deep Learning </span> </div>  </a> <a href="/cityu/cs4487/cs4487_7" target="_self" class="duration-300 ease-in-out gap-2 whitespace-nowrap text-sm font-medium transition-all disabled:pointer-events-none disabled:opacity-50 [&#38;_svg]:pointer-events-none [&#38;_svg:not([class*='size-'])]:size-4 shrink-0 [&#38;_svg]:shrink-0 outline-none focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:ring-[3px] aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive border bg-background shadow-xs hover:bg-accent hover:text-accent-foreground dark:bg-input/30 dark:border-input dark:hover:bg-input/50 px-4 py-2 has-[>svg]:px-3 rounded-xl group flex items-center justify-end size-full" aria-disabled="false">  <div class="flex flex-col items-end overflow-hidden text-wrap"> <span class="text-muted-foreground text-right text-xs">Previous Post</span> <span class="w-full text-right text-sm text-ellipsis"> Part 7 - The Expectation Maximization Algorithm &amp; Linear Dimensionality Reduction </span> </div> <svg width="1em" height="1em" class="ml-2 size-4 transition-transform group-hover:translate-x-1" data-icon="lucide:arrow-right">   <symbol id="ai:lucide:arrow-right" viewBox="0 0 24 24"><path fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M5 12h14m-7-7l7 7l-7 7"/></symbol><use href="#ai:lucide:arrow-right"></use>  </svg>  </a> </nav> </section> <details open class="group col-start-2 rounded-xl border p-4 xl:sticky xl:top-20 xl:col-start-1 xl:mr-8 xl:ml-auto xl:h-[calc(100vh-5rem)] xl:max-w-fit xl:rounded-none xl:border-none xl:p-0"> <summary class="flex cursor-pointer items-center justify-between text-xl font-medium group-open:pb-4 xl:hidden"> <span>Table of Contents</span> <svg width="1em" height="1em" class="size-5 shrink-0 transition-transform group-open:rotate-180" data-icon="lucide:chevron-down">   <symbol id="ai:lucide:chevron-down" viewBox="0 0 24 24"><path fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="m6 9l6 6l6-6"/></symbol><use href="#ai:lucide:chevron-down"></use>  </svg> </summary> <astro-island uid="Z2oka9a" prefix="r8" component-url="/_astro/scroll-area.DmWfVO5M.js" component-export="ScrollArea" renderer-url="/_astro/client.DXT7MGXl.js" props="{&quot;className&quot;:[0,&quot;flex max-h-64 flex-col overflow-y-auto xl:max-h-[calc(100vh-8rem)]&quot;],&quot;type&quot;:[0,&quot;always&quot;]}" ssr client="load" opts="{&quot;name&quot;:&quot;ScrollArea&quot;,&quot;value&quot;:true}" await-children><div dir="ltr" data-slot="scroll-area" class="relative flex max-h-64 flex-col overflow-y-auto xl:max-h-[calc(100vh-8rem)]" style="position:relative;--radix-scroll-area-corner-width:0px;--radix-scroll-area-corner-height:0px"><style>[data-radix-scroll-area-viewport]{scrollbar-width:none;-ms-overflow-style:none;-webkit-overflow-scrolling:touch;}[data-radix-scroll-area-viewport]::-webkit-scrollbar{display:none}</style><div data-radix-scroll-area-viewport="" data-slot="scroll-area-viewport" class="ring-ring/10 dark:ring-ring/20 dark:outline-ring/40 outline-ring/50 size-full rounded-[inherit] transition-[color,box-shadow] focus-visible:ring-4 focus-visible:outline-1" style="overflow-x:hidden;overflow-y:hidden"><div style="min-width:100%;display:table"><astro-slot> <ul class="flex list-none flex-col gap-y-2 px-4 xl:mr-8" id="table-of-contents"> <li class="hidden text-lg font-medium xl:block">Table of Contents</li> <li class="text-foreground/60 px-4 text-sm xl:p-0 ml-4"> <a href="#eigenvectors" class="marker:text-foreground/30 list-item list-disc underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit xl:list-none"> Eigenvectors </a> </li><li class="text-foreground/60 px-4 text-sm xl:p-0 ml-8"> <a href="#example" class="marker:text-foreground/30 list-item list-disc underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit xl:list-none"> Example </a> </li><li class="text-foreground/60 px-4 text-sm xl:p-0 ml-4"> <a href="#linear-independence" class="marker:text-foreground/30 list-item list-disc underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit xl:list-none"> Linear Independence </a> </li><li class="text-foreground/60 px-4 text-sm xl:p-0 ml-4"> <a href="#some-matrices" class="marker:text-foreground/30 list-item list-disc underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit xl:list-none"> Some Matrices </a> </li><li class="text-foreground/60 px-4 text-sm xl:p-0 ml-4"> <a href="#eigendecomposition" class="marker:text-foreground/30 list-item list-disc underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit xl:list-none"> Eigendecomposition </a> </li><li class="text-foreground/60 px-4 text-sm xl:p-0 ml-8"> <a href="#eigendecomposition-of-symmetric-matrix" class="marker:text-foreground/30 list-item list-disc underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit xl:list-none"> Eigendecomposition of Symmetric Matrix </a> </li><li class="text-foreground/60 px-4 text-sm xl:p-0 ml-4"> <a href="#principal-component-analysis" class="marker:text-foreground/30 list-item list-disc underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit xl:list-none"> Principal Component Analysis </a> </li><li class="text-foreground/60 px-4 text-sm xl:p-0 ml-8"> <a href="#sample-variance-in-a-given-direction" class="marker:text-foreground/30 list-item list-disc underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit xl:list-none"> Sample Variance in a Given Direction </a> </li><li class="text-foreground/60 px-4 text-sm xl:p-0 ml-8"> <a href="#pre-centering" class="marker:text-foreground/30 list-item list-disc underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit xl:list-none"> Pre-Centering </a> </li><li class="text-foreground/60 px-4 text-sm xl:p-0 ml-8"> <a href="#the-direction-of-maximum-variance" class="marker:text-foreground/30 list-item list-disc underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit xl:list-none"> The Direction of Maximum Variance </a> </li><li class="text-foreground/60 px-4 text-sm xl:p-0 ml-8"> <a href="#k-largest-directions-of-variance" class="marker:text-foreground/30 list-item list-disc underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit xl:list-none"> $K$ Largest Directions of Variance </a> </li><li class="text-foreground/60 px-4 text-sm xl:p-0 ml-8"> <a href="#dimensionality-reduction-with-pca" class="marker:text-foreground/30 list-item list-disc underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit xl:list-none"> Dimensionality Reduction with PCA </a> </li><li class="text-foreground/60 px-4 text-sm xl:p-0 ml-8"> <a href="#how-to-choose-the-number-of-pcs" class="marker:text-foreground/30 list-item list-disc underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit xl:list-none"> How to Choose the Number of PCs? </a> </li><li class="text-foreground/60 px-4 text-sm xl:p-0 ml-4"> <a href="#connection-to-svd" class="marker:text-foreground/30 list-item list-disc underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit xl:list-none"> Connection to SVD </a> </li><li class="text-foreground/60 px-4 text-sm xl:p-0 ml-8"> <a href="#when-does-pca-fail" class="marker:text-foreground/30 list-item list-disc underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit xl:list-none"> When Does PCA Fail? </a> </li><li class="text-foreground/60 px-4 text-sm xl:p-0 ml-4"> <a href="#kernel-principal-component-analysis" class="marker:text-foreground/30 list-item list-disc underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit xl:list-none"> Kernel Principal Component Analysis </a> </li><li class="text-foreground/60 px-4 text-sm xl:p-0 ml-8"> <a href="#limitations-of-linear-dimensionality-reduction" class="marker:text-foreground/30 list-item list-disc underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit xl:list-none"> Limitations of Linear Dimensionality Reduction </a> </li><li class="text-foreground/60 px-4 text-sm xl:p-0 ml-8"> <a href="#feature-mapping" class="marker:text-foreground/30 list-item list-disc underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit xl:list-none"> Feature Mapping </a> </li><li class="text-foreground/60 px-4 text-sm xl:p-0 ml-8"> <a href="#feature-mapping--svd" class="marker:text-foreground/30 list-item list-disc underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit xl:list-none"> Feature Mapping + SVD </a> </li><li class="text-foreground/60 px-4 text-sm xl:p-0 ml-8"> <a href="#feature-mapping--pca" class="marker:text-foreground/30 list-item list-disc underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit xl:list-none"> Feature Mapping + PCA </a> </li><li class="text-foreground/60 px-4 text-sm xl:p-0 ml-8"> <a href="#kernel-pca" class="marker:text-foreground/30 list-item list-disc underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit xl:list-none"> Kernel PCA </a> </li><li class="text-foreground/60 px-4 text-sm xl:p-0 ml-8"> <a href="#kernel-pca-algorithm" class="marker:text-foreground/30 list-item list-disc underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit xl:list-none"> Kernel PCA Algorithm </a> </li><li class="text-foreground/60 px-4 text-sm xl:p-0 ml-4"> <a href="#summary" class="marker:text-foreground/30 list-item list-disc underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit xl:list-none"> Summary </a> </li> </ul> </astro-slot></div></div><div data-orientation="vertical" data-slot="scroll-area-scrollbar" class="flex touch-none p-px transition-colors select-none h-full w-2.5 border-l border-l-transparent" style="position:absolute;top:0;right:0;bottom:var(--radix-scroll-area-corner-height);--radix-scroll-area-thumb-height:18px"></div></div><!--astro:end--></astro-island> </details> <script type="module">function s(){const t=document.querySelector("header"),c=t?t.offsetHeight:0,a=new IntersectionObserver(e=>{e.forEach(o=>{const r=o.target.querySelector("h2, h3, h4, h5, h6");if(!r)return;const d=r.getAttribute("id"),n=document.querySelector(`#table-of-contents li a[href="#${d}"]`);if(!n)return;const i=o.isIntersecting?"add":"remove";n.classList[i]("text-foreground")})},{rootMargin:`-${c}px 0px 0px 0px`});document.querySelectorAll(".prose section").forEach(e=>{a.observe(e)})}document.addEventListener("astro:page-load",s);document.addEventListener("astro:after-swap",s);</script> <article class="prose col-start-2 max-w-none"> <!doctype html><html lang="en"><head></head><body>


<meta charset="utf-8">
<title>CS4487_8</title>
<meta content="width=device-width, initial-scale=1" name="viewport">
<link href="https://cdn.jsdelivr.net/npm/katex@0.16.21/dist/katex.min.css" rel="stylesheet">


<section><h3 id="eigenvectors">Eigenvectors</h3><p>Let’s do a quick linear algebra recap.</p><p>Assume $\mathbf{A} \in \mathbb{R}^{N \times N}, \mathbf{v} \in \mathbb{C}^{N \times 1}$, and $\lambda \in \mathbb{C}$.</p><p>If $\mathbf{A} \mathbf{v} = \lambda \mathbf{v}$, then $\mathbf{v}$ is a right eigenvector of $\mathbf{A}$ with eigenvalue $\lambda$.</p><p>If $\mathbf{A}^T \mathbf{v} = \lambda \mathbf{v}$, then $\mathbf{v}$ is a left eigenvector of $\mathbf{A}$ with eigenvalue $\lambda$.
(Equivalently, $\mathbf{v}^T \mathbf{A} = \lambda \mathbf{v}^T$.)</p><p>If $\mathbf{A}$ is symmetric such that $\mathbf{A} = \mathbf{A}^T$, then the left and right eigenvectors of $\mathbf{A}$ are the same with the same eigenvalues.</p><section><h4 id="example">Example</h4><p>$$
\begin{bmatrix}
2 &#x26; 1 \newline
1 &#x26; 2
\end{bmatrix}
\begin{bmatrix}
1 \newline
1
\end{bmatrix} =
\begin{bmatrix}
3 \newline
3
\end{bmatrix} =
3
\begin{bmatrix}
1 \newline
1
\end{bmatrix}
$$</p><p>$$
\begin{bmatrix}
1 &#x26; 1
\end{bmatrix}
\begin{bmatrix}
2 &#x26; 1 \newline
1 &#x26; 2
\end{bmatrix} =
3
\begin{bmatrix}
1 &#x26; 1
\end{bmatrix}
$$</p></section></section>
<section><h3 id="linear-independence">Linear Independence</h3><p>Linear independence is arguably the most important concept in linear algebra.</p><p>A set of vectors $\{\mathbf{v}_1, \mathbf{v}_2, \ldots, \mathbf{v}_N\}$ is linearly independent if vector equation,</p><p>$$
a_1 \mathbf{v}_1 + a_2 \mathbf{v}_2 + \ldots + a_N \mathbf{v}_N = \mathbf{0},
$$</p><p>has only the trivial solution $a_1 = a_2 = \ldots = a_N = 0$.</p><p>$\{\mathbf{v}_1, \mathbf{v}_2, \ldots, \mathbf{v}_N\}$ is linearly dependent if there exists numbers $a_1, a_2, \ldots, a_N$ not all equal to zero, such that,</p><p>$$
a_1 \mathbf{v}_1 + a_2 \mathbf{v}_2 + \ldots + a_N \mathbf{v}_N = \mathbf{0}.
$$</p><p>Assuming $a_1 \neq 0$, we have $\mathbf{v}_1 = -\frac{a_2}{a_1} \mathbf{v}_2 - \ldots - \frac{a_N}{a_1} \mathbf{v}_N$.</p></section>
<section><h3 id="some-matrices">Some Matrices</h3><p>An $N \times N$ square matrix $\mathbf{A}$ is <strong>invertible</strong> if there exists an $N \times N$ square matrix $\mathbf{B}$ such that,</p><p>$$
\mathbf{A} \mathbf{B} = \mathbf{B} \mathbf{A} = \mathbf{I}_N,
$$</p><p>Equivalently, the columns/rows of $\mathbf{A}$ are linearly independent.</p><p>A square matrix $\mathbf{Q}$ is <strong>orthogonal</strong> if its columns and rows are orthogonal unit vectors (orthonormal vectors),</p><p>$$
\mathbf{Q} \mathbf{Q}^T = \mathbf{Q}^T \mathbf{Q} = \mathbf{I}.
$$</p><p>A square matrix $\mathbf{A}$ is <strong>diagonalizable</strong> if there exists an invertible matrix $\mathbf{P}$ and a diagonal matrix $\mathbf{D}$ such that,</p><p>$$
\mathbf{P}^{-1} \mathbf{A} \mathbf{P} = \mathbf{D},
$$</p><p>or equivalently,</p><p>$$
\mathbf{A} = \mathbf{P} \mathbf{D} \mathbf{P}^{-1}.
$$</p><p><strong>Real symmetric</strong> matrices are diagonalizable by orthogonal matrices.
This can be proven by the spectral theorem.</p></section>
<section><h3 id="eigendecomposition">Eigendecomposition</h3><p>Let $\mathbf{V} \in \mathbb{R}^{N \times N}$ be a matrix whose columns $\mathbf{v_i}$ are $N$ linearly independent eigenvectors of $\mathbf{A}$ with $\mathbf{\Lambda}$ the corresponding diagonal matrix of eigenvalues such taht $\Lambda_{ii} = \lambda_i$.</p><p>Then,</p><p>$$
\begin{align*}
\mathbf{A} \mathbf{V} &#x26; = \mathbf{V} \mathbf{\Lambda} \newline
\mathbf{A} &#x26; = \mathbf{V} \mathbf{\Lambda} \mathbf{V}^{-1} \newline
\mathbf{V}^{-1} \mathbf{A} \mathbf{V} &#x26; = \mathbf{\Lambda}
\end{align*}
$$</p><section><h4 id="eigendecomposition-of-symmetric-matrix">Eigendecomposition of Symmetric Matrix</h4><p>If $\mathbf{A}$ is a real symmetric, we can choose $N$ orthonormal eigenvectors so that $\Vert \mathbf{v}_i \Vert_2^2 = 1$, $\mathbf{v}_i^T \mathbf{v}_j = 0$ and $N$ real eigenvalues $\lambda_i \in \mathbb{R}$.</p><p>As a result, we have,</p><p>$$
\begin{align*}
\mathbf{A} &#x26; = \mathbf{V} \mathbf{\Lambda} \mathbf{V}^T = \sum_{i = 1}^N \lambda_i \mathbf{v_i} \mathbf{v_i}^T \newline
\mathbf{V}^T \mathbf{A} \mathbf{V} &#x26; = \mathbf{\Lambda}
\end{align*}
$$</p></section></section>
<section><h3 id="principal-component-analysis">Principal Component Analysis</h3><p>Principal Component Analysis (PCA) is an unsupervised method, given a data matrix $\mathbf{X} \in \mathbb{R}^{M \times N}$, the goal of PCA is to identify the directions of maximum variance contained in the data.</p><p>We need to choose the basis vectors along the maximum variance (longest extent) of the data.
The basis vectors are called principal components (PC).</p><section><h4 id="sample-variance-in-a-given-direction">Sample Variance in a Given Direction</h4><p>Let $\mathbf{v} \in \mathbb{R}^N$ such that $\Vert \mathbf{v} \Vert_2 = \mathbf{v}^T \mathbf{v} = 1$.</p><p>The variance in the direction $\mathbf{v}$ is given by the expression,</p><p>$$
\frac{1}{M} \sum_{i = 1}^M (\mathbf{v}^T \mathbf{x}^{(i)} - \mathbf{\mu})^2,
$$</p><p>where $\mathbf{\mu} = \frac{1}{M} \sum_{i = 1}^M \mathbf{v}^T \mathbf{x}^{(i)}$ is the mean of the projected data.</p></section><section><h4 id="pre-centering">Pre-Centering</h4><p>Under the assumption that the data are pre-centered so that $\frac{1}{M} \sum_{i = 1}^M (\mathbf{v}^T \mathbf{x}^{(i)}) = 0$, this expression simplifies to,</p><p>$$
\begin{align*}
\frac{1}{M} \sum_{i = 1}^M (\mathbf{v}^T \mathbf{x}^{(i)})^2 &#x26; = \frac{1}{M} \sum_{i = 1}^M \left(\mathbf{v}^T \mathbf{x}^{(i)}\right)^T \left(\mathbf{v}^T \mathbf{x}^{(i)}\right) \newline
&#x26; = \frac{1}{M} \sum_{i = 1}^M \left(\mathbf{v}^T \mathbf{x}^{(i)}\right)^T \left(\mathbf{x}^{(i)}\right)^T \left((\mathbf{x}^{(i)})^T \mathbf{v}\right) \newline
&#x26; = \frac{1}{M} \mathbf{v}^T \left(\sum_{i = 1}^M \mathbf{x}^{(i)} (\mathbf{x}^{(i)})^T\right) \mathbf{v} \newline
&#x26; = \frac{1}{M} \mathbf{v}^T \mathbf{X}^T \mathbf{X} \mathbf{v}.
\end{align*}
$$</p></section><section><h4 id="the-direction-of-maximum-variance">The Direction of Maximum Variance</h4><p>Suppose we want to identify the direction $\mathbf{v}_1$ of maximum variance given the data matrix $\mathbf{X}$.</p><p>We can formulate this optimization problem as follows,</p><p>$$
\begin{align*}
\underset{\mathbf{v}}{\max} &#x26; \quad \frac{1}{M} \mathbf{v}^T \mathbf{X}^T \mathbf{X} \mathbf{v} \newline
\text{subject to} &#x26; \quad \Vert \mathbf{v} \Vert_2 = 1.
\end{align*}
$$</p><p>Letting $\mathbf{\Sigma} = \frac{1}{M} \mathbf{X}^T \mathbf{X}$, we form the Lagrangian,</p><p>$$
L(\mathbf{v}, \nu) = \mathbf{v}^T \mathbf{\Sigma} \mathbf{v} + \nu (1 - \Vert \mathbf{v} \Vert_2^2).
$$</p><p>Taking the derivative of $L(\mathbf{v}, \nu)$ with respect to $\mathbf{v}$ and setting it to zero, we have,</p><p>$$
\begin{align*}
\frac{\partial L(\mathbf{v}, \nu)}{\partial \mathbf{v}} &#x26; = 2 \mathbf{\Sigma} \mathbf{v} - 2 \nu \mathbf{v} = 0 \newline
\mathbf{\Sigma} \mathbf{v} &#x26; = \nu \mathbf{v}.
\end{align*}
$$</p><p>As $\mathbf{v} \neq 0, \mathbf{v}$ must be an eigenvector of $\mathbf{\Sigma}$ with eigenvalue $\nu$.</p><p>Assuming $\{\mathbf{v}_1, \mathbf{v}_2, \ldots, \mathbf{v}_N\}$ are the eigenvectors of $\mathbf{\Sigma}$, corresponding to eigenvalues $\sigma_1 \geq \ldots \geq \sigma_N$, respectively, we have,</p><p>$$
\begin{align*}
\mathbf{v}^{\star} &#x26; = \mathbf{v}_1 \newline
p^{\star} &#x26; = \mathbf{v}_1^T \mathbf{\Sigma} \mathbf{v}_1 = \mathbf{v}_1^T \nu \mathbf{v}_1 = \nu \mathbf{v}_1^T \mathbf{v}_1 = \nu = \sigma_1.
\end{align*}
$$</p></section><section><h4 id="k-largest-directions-of-variance">$K$ Largest Directions of Variance</h4><p>Suppose instead of just the direction of maximum variance, we want the $K$ largest directions of variance that are all mutually <em>orthogonal</em>.</p><p>Finding the second-largest direction of variance corresponds to solving the problem,</p><p>$$
\begin{align*}
\underset{\mathbf{v}}{\max} &#x26; \quad \frac{1}{M} \mathbf{v}^T \mathbf{X}^T \mathbf{X} \mathbf{v} \newline
\text{subject to} &#x26; \quad \Vert \mathbf{v} \Vert_2 = 1, \newline
&#x26; \quad \mathbf{v}^T \mathbf{v}_1 = 0.
\end{align*}
$$</p><p>We form the Lagrangian,</p><p>$$
L(\mathbf{v}, \nu, \lambda) = \mathbf{v}^T \mathbf{\Sigma} \mathbf{v} + \nu (1 - \Vert \mathbf{v} \Vert_2^2) + \lambda \mathbf{v}^T \mathbf{v}_1.
$$</p><p>Taking the derivative of $L(\mathbf{v}, \nu, \lambda)$ with respect to $\mathbf{v}$ and setting it to zero, we have,</p><p>$$
\frac{\partial L(\mathbf{v}, \nu, \lambda)}{\partial \mathbf{v}} = 2 \mathbf{\Sigma} \mathbf{v} - 2 \nu \mathbf{v} + \lambda \mathbf{v}_1 = 0.
$$</p><p>If we left-multiply by $\mathbf{v}_1^T$ on both sides, we have,
$$
\begin{align*}
2 \mathbf{v_1}^T \mathbf{\Sigma} \mathbf{v} - 2 \nu \mathbf{v_1}^T \mathbf{v} + \lambda \mathbf{v_1}^T \mathbf{v_1} &#x26; = 0 \newline
2(\mathbf{\Sigma} \mathbf{v_1})^T \mathbf{v} - 0 + \lambda &#x26; = 0 \newline
2 \sigma_1 \mathbf{v_1}^T \mathbf{v} - 0 + \lambda &#x26; = 0 \newline
\lambda = 0.
\end{align*}
$$</p><p>Therefore, we arrive at the eigenvalue equation again,</p><p>$$
\mathbf{\Sigma} \mathbf{v} = \nu \mathbf{v}.
$$</p><p>It is easy to see that $\mathbf{v}^{\star}$ is the eigenvector corresponding to the second largest eigenvalue.</p><p>In general, the top $K$ directions of variance $\mathbf{v}_1, \ldots, \mathbf{v}_K$ are given by the $K$ eigenvectors corresponding to the $K$ largest eigenvalues of $\frac{1}{M} \mathbf{X}^T \mathbf{X}$.</p><p>PCA can also be derived by picking the principal vectors that minimize the approximation error arising from projecting the data onto the $K$-dimensional subspace spanned by these vectors,</p><p>$$
\underset{\mathbf{V}}{\min} \frac{1}{M} \sum_{i = 1}^M \Vert \mathbf{x}^{(i)} - (\mathbf{v}^T \mathbf{x}^{(i)}) \mathbf{v} \Vert_2^2.
$$</p></section><section><h4 id="dimensionality-reduction-with-pca">Dimensionality Reduction with PCA</h4><p>The informal algorithm can be described as follows,</p><ol>
<li>Subtract the mean of the data.</li>
<li>The first PC $\mathbf{v}_1$ is the direction that explains the most variance of the data.</li>
<li>The second PC $\mathbf{v}_2$ is the direction perpendicular to $\mathbf{v}_1$ that explains the most variance.</li>
<li>The third PC $\mathbf{v}_3$ is the direction perpendicular to $\{\mathbf{v}_1, \mathbf{v}_2\}$ that explains the most variance.</li>
<li>$\ldots$</li>
</ol><p>The formal algorithm can be described as follows,</p><ol>
<li>Data preprocessing: Compute $\mathbf{\mu} = \frac{1}{M} \sum_i \mathbf{x}^{(i)}$ and replace each $\mathbf{x}^{(i)}$ with $\mathbf{x}^{(i)} - \mathbf{\mu}$.</li>
<li>Given pre-processed data matrix $\mathbf{X} \in \mathbb{R}^{M \times N}$, compute the sample covariance matrix $\mathbf{\Sigma} = \frac{1}{M} \mathbf{X}^T \mathbf{X}$.</li>
<li>Compute the $K$ leading eigenvectors $\mathbf{v}_1, \ldots, \mathbf{v}_K$ of $\mathbf{\Sigma}$ where $\mathbf{v}_i \in \mathbb{R}^N$.</li>
<li>Stack the eigenvectors together into an $N \times K$ matrix $\mathbf{V}$ where each column $i$ of $\mathbf{V}$ corresponds to $\mathbf{v}_i$.</li>
<li>Project the matrix $\mathbf{X}$ into the rank-$K$ subspace of maximum variance by computing the matrix product $\mathbf{Z} = \mathbf{X} \mathbf{V}$.</li>
<li>To reconstruct $\mathbf{X}$ given $\mathbf{Z}$ and $\mathbf{V}$, we use $\mathbf{\hat{X}} = \mathbf{Z} \mathbf{V}^T$.</li>
</ol></section><section><h4 id="how-to-choose-the-number-of-pcs">How to Choose the Number of PCs?</h4><p>We have two methods to set the number of components $K$.</p><ul>
<li>Preserve some percentage of the variance, e.g., 95%.</li>
<li>Whatever works well for our final task (e.g., classification, regression).</li>
</ul></section></section>
<section><h3 id="connection-to-svd">Connection to SVD</h3><p>We have seen that the minimum Frobenius norm linear dimensionality reduction problem could be solved using the rank-$K$ SVD of $\mathbf{X}$,</p><p>$$
\begin{align*}
\underset{\mathbf{U}, \mathbf{S}, \mathbf{V}}{\arg \min} &#x26; \quad \Vert \mathbf{X} - \mathbf{U} \mathbf{S} \mathbf{V}^T \Vert_F^2,
\end{align*}
$$</p><p>where $\mathbf{U} \in \mathbb{R}^{M \times K}$, $\mathbf{S} \in \mathbb{R}^{K \times K}$, and $\mathbf{V} \in \mathbb{R}^{N \times K}$.</p><p>The matrix $\mathbf{Z} = \mathbf{U} \mathbf{S}$ gives the optimal rank-$K$ representation of $\mathbf{X}$ with respect to Frobenius norm minimization.</p><p>If we let $K = N$ then $\mathbf{X} = \mathbf{U} \mathbf{S} \mathbf{V}^T$ and $\mathbf{X}^T \mathbf{X} = \mathbf{V} \mathbf{S}^T \mathbf{U}^T \mathbf{U} \mathbf{S} \mathbf{V}^T$.</p><p>Due to orthogonality of $\mathbf{U}$, we get $\mathbf{X}^T \mathbf{X} = \mathbf{V} \mathbf{S}^2 \mathbf{V}^T$.</p><p>This means that the right singular vectors of $\mathbf{X}$ are exactly the eigenvectors of $\mathbf{X}^T \mathbf{X}$.</p><p>We can also see that the eigenvalues of $\mathbf{X}^T \mathbf{X}$ are the squares of the diagonal elements of $\mathbf{S}$.</p><p>This means that the $K$ largest singular values and $K$ largest eigenvalues correspond to the same $K$ basis vectors.</p><p>According to PCA, the projection operation is $\mathbf{Z} = \mathbf{X} \mathbf{V}$, therefore,</p><p>$$
\mathbf{Z} = \mathbf{X} \mathbf{V} = (\mathbf{U} \mathbf{S} \mathbf{V}^T)(\mathbf{V}) = \mathbf{U} \mathbf{S}.
$$</p><p>Finally, note that if the decomposition are based only on the $K$ leading principal vectors, the projections $\mathbf{Z} = \mathbf{X} \mathbf{V}$ and $\mathbf{Z} = \mathbf{U} \mathbf{S}$ will still be identical.</p><p>These manipulations show that PCA on $\mathbf{X}^T \mathbf{X}$ and SVD on $\mathbf{X}$ identify exactly the same subspace and result in exactly the same projection of the data into that subspace.</p><p>As a result, generic linear dimensionality reduction simultaneously minimizes the Frobenius norm of the reconstruction error of $\mathbf{X}$ and maximizes the retained variance in the learned subspace.</p><p>Both SVD and PCA provide the same description of generic linear dimensionality reduction, an orthogonal basis for exactly the same optimal linear subspace.</p><section><h4 id="when-does-pca-fail">When Does PCA Fail?</h4><p>The primary motivation behind PCA is to decorrelate the dataset, i.e., remove second-order dependencies.</p><p>If higher-order dependencies exist between the features in the data, PCA may be insufficient at revealing all strucutre in the data.</p><p>PCA requires that each component must be perpendicular to the previous ones, but clearly, this requirement is overly stringent and the data might be arranged along non-orthogonal axes.</p></section></section>
<section><h3 id="kernel-principal-component-analysis">Kernel Principal Component Analysis</h3><p>Kernel PCA (KPCA) is a non-linear extension of PCA that can be used to extract non-linear structure in the data.</p><section><h4 id="limitations-of-linear-dimensionality-reduction">Limitations of Linear Dimensionality Reduction</h4><p>What if the data “lives” on a non-flat surface?</p><p>PCA can not capture the curvature of the data.</p><p>As usual, feature mapping can be used to overcome this.</p></section><section><h4 id="feature-mapping">Feature Mapping</h4><p>If we apply a high-dimensional feature transformation to the data $\mathbf{x}^{(i)} \rightarrow \phi(\mathbf{x}^{(i)})$, we can project the high-dimensional data to a linear surface, i.e., run PCA on $\phi(\mathbf{X})$.
In the original space, the projection will be non-linear.</p></section><section><h4 id="feature-mapping--svd">Feature Mapping + SVD</h4><p>Given a data set $\mathbf{X} \in \mathbb{R}^{M \times N}$ and a feature mapping function $\phi : \mathbb{R}^N \mapsto \mathbb{R}^L$ for $L > N$, we obtain the following SVD-based algorithm,</p><ol>
<li>Compute $\mathbf{U}, \mathbf{S}, \mathbf{V} = \text{SVD}(\phi(\mathbf{X}))$.</li>
<li>Return $\mathbf{Z} = \mathbf{U} \mathbf{S}$.</li>
</ol></section><section><h4 id="feature-mapping--pca">Feature Mapping + PCA</h4><p>Given a data set $\mathbf{X} \in \mathbb{R}^{M \times N}$ and a feature mapping function $\phi : \mathbb{R}^N \mapsto \mathbb{R}^L$ for $L > N$, we obtain the following PCA-based algorithm,</p><ol>
<li>
<p>Compute $\mathbf{\Sigma} = \frac{1}{M} \sum_i (\phi(\mathbf{x}^{(i)} - \mathbf{\mu})) (\phi(\mathbf{x}^{(i)} - \mathbf{\mu}))^T$.
where $\mathbf{\mu} = \frac{1}{M} \sum_i \phi(\mathbf{x}^{(i)})$.</p>
</li>
<li>
<p>Compute the $K$ leading eigenvectors $\mathbf{v}_1, \ldots, \mathbf{v}_K$ of $\mathbf{\Sigma}$ where $\mathbf{v}_j \in \mathbb{R}^L$ for $j = 1, \ldots, K$.</p>
</li>
<li>
<p>Stack the eigenvectors together to form $\mathbf{V} = [\mathbf{v}_1, \mathbf{v}_2, \ldots, \mathbf{v}_K]$, where $\mathbf{V} \in \mathbb{R}^{L \times K}$.</p>
</li>
<li>
<p>Project the matrix $\phi(\mathbf{X})$ into the rank-$K$ subspace of maximum variance by computing the matrix product $\mathbf{Z} = \phi(\mathbf{X}) \mathbf{V}$.</p>
</li>
</ol></section><section><h4 id="kernel-pca">Kernel PCA</h4><p>As in classification, it becomes very expensive to use an explicit feature function to map data into a high-dimensional space.</p><p>In the basic SVD-based algortihm, there’s no way to avoid this problem.</p><p>However, in the PCA-based algorithm, we are able to take advantage of the <strong>kernel</strong> trick,</p><p>$$
\mathcal{K}(\mathbf{x}^{(i)}, \mathbf{x}^{(j)}) = \phi(\mathbf{x}^{(i)})^T \phi(\mathbf{x}^{(j)}).
$$</p><p>Given $\phi : \mathbb{R}^N \mapsto \mathbb{R}^L$, we can compute the covariance matrix in the new feature space,</p><p>$$
\mathbf{\Sigma} = \frac{1}{M} \sum_{j = 1}^M \phi(\mathbf{x}^{(i)}) \phi(\mathbf{x}^{(j)})^T.
$$</p><p>Note that we have assumed that the data is pre-centered in our new feature space.
If this turns out to be false, we can center the data by subtracting the mean of the data in the new feature space.</p><p>Eigendecomposition of $\mathbf{\Sigma}$ is given by,</p><p>$$
\mathbf{\Sigma} \mathbf{v_k} = \frac{1}{M} \sum_{j = 1}^M \phi(\mathbf{x}^{(i)}) \phi(\mathbf{x}^{(j)})^T \mathbf{v}_k = \lambda_k \mathbf{v}_k, \forall k = 1, \ldots, L.
$$</p><p>It is not hard to see that $\mathbf{v}_k$ can be expressed as,</p><p>$$
\mathbf{v_k} = \sum_{j = 1}^M w_k^{(j)} \phi(\mathbf{x}^{(j)}),
$$</p><p>where $w_k^{(j)} = \frac{1}{M \lambda_k} \phi(\mathbf{x}^{(j)})^T \mathbf{v}_k$.</p><p>So, the kernel PCA is a linear combination of high-dimensional vectors, and $w_k^{(j)}$ are weights to be determined.</p><p>If we left-multiply $\phi(\mathbf{x}^{(i)})^T$ to both sides, we have,</p><p>$$
\phi(\mathbf{x}^{(i)})^T \mathbf{v_k} = \sum_{j = 1}^M w_k^{(j)} \phi(\mathbf{x}^{(i)})^T \phi(\mathbf{x}^{(j)}) = M \lambda_k w_k^{(i)}.
$$</p><p>Defining the kernel matrix $\mathbf{K} \in \mathbb{R}^{M \times M}$, where $K_{ij} = \mathcal{K}(\mathbf{x}^{(i)}, \mathbf{x}^{(j)}) = \phi(\mathbf{x}^{(i)})^T \phi(\mathbf{x}^{(j)})$.</p><p>Then,</p><p>$$
\sum_{j = 1}^M K_{ij} w_k^{(j)} = M \lambda_k w_k^{(i)}.
$$</p><p>If we consider $i = 1, \ldots, M$, the above scalar equation becomes the $i$-th component of the following vector equation,
$$
\mathbf{K} \mathbf{w}_k = M \lambda_k \mathbf{w}_k,
$$</p><p>where $\mathbf{w}_k = [w_k^{(1)}, w_k^{(2)}, \ldots, w_k^{(M)}]^T$ is the $k$-th eigenvector of $\mathbf{K}$.</p><p>$M \lambda_k$ is the eigenvalue of $\mathbf{K}$, which is proportional to the eigenvalue $\lambda_k$ of the covariance matrix $\mathbf{\Sigma}$ in the feature space.</p><p>Therefore, PCA on $\mathbf{\Sigma}$ is equivalent to PCA on $\mathbf{K}$.</p><p>For a new point $\mathbf{x}^{\star}$, the $k$-th kernel PC can be obtained by projection $\phi(\mathbf{x}^{\star})$ on the $k$-th eigenvector $\mathbf{v}_k$ of $\mathbf{\Sigma}$.</p><p>$$
\phi(\mathbf{x}^{\star})^T \mathbf{v_k} = \sum_{i = 1} w_k^{(i)} \phi(\mathbf{x}^{\star})^T \phi(\mathbf{x}^{(i)}) = \sum_{i = 1} w_k^{(i)} \mathcal{K}(\mathbf{x}^{\star}, \mathbf{x}^{(i)}).
$$</p></section><section><h4 id="kernel-pca-algorithm">Kernel PCA Algorithm</h4><p>Given a data set $\mathbf{X} \in \mathbb{R}^{M \times N}$ and a kernel function $\mathcal{K}$, kernel PCA can be computed as follows,</p><ol>
<li>
<p>Compute $K_{ij} = \mathcal{K}(\mathbf{x}^{(i)}, \mathbf{x}^{(j)})$ for all $i,j$.</p>
</li>
<li>
<p>Compute $\mathbf{K}^{\prime} = (\mathbf{I} - \mathbf{1}_M) \mathbf{K} (\mathbf{I} - \mathbf{1}_M)$ where $\mathbf{1}_M$ is an $M \times M$ matrix where every entry is $\frac{1}{M}$.
The goal is to zero center data points in the feature space.</p>
</li>
<li>
<p>Compute the $K$ leading eigenvectors $\mathbf{w}_1, \ldots, \mathbf{w}_K$ of $\mathbf{K}^{\prime}$ along with their eigenvalues $M \lambda_1, \ldots, M \lambda_K$.</p>
</li>
<li>
<p>Compute the $k$-th PC of the projected data vector $\mathbf{z} \in \mathbb{R}^{K \times 1}$,</p>
</li>
</ol><p>$$
z_k = \sum_{i = 1}^M w_k^{(i)} \mathcal{K}(\mathbf{x}, \mathbf{x}^{(i)}).
$$</p></section></section>
<section><h3 id="summary">Summary</h3><p>Kernel PCA uses the kernel trick to peform PCA in high-dimensional space.</p><ul>
<li>Coeffcients are based on a non-linear projection of the data.</li>
<li>The type of projection is based on the kernel function selected.</li>
</ul><p>Using RBF kernel, KPCA can split the data into clusters.</p><p>Kernel PCA can provide an effective pre-processing step for clustering methods as well as linear classification and regression methods.</p><p>However, exact compuation of kernel PCA can be expensive because the size of the matrix to be decomposed is $M \times M$.</p></section>


</body></html> </article> <div class="col-start-2"> <nav class="col-start-2 grid grid-cols-1 gap-4 sm:grid-cols-2"> <a href="/cityu/cs4487/cs4487_9" target="_self" class="duration-300 ease-in-out gap-2 whitespace-nowrap text-sm font-medium transition-all disabled:pointer-events-none disabled:opacity-50 [&#38;_svg]:pointer-events-none [&#38;_svg:not([class*='size-'])]:size-4 shrink-0 [&#38;_svg]:shrink-0 outline-none focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:ring-[3px] aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive border bg-background shadow-xs hover:bg-accent hover:text-accent-foreground dark:bg-input/30 dark:border-input dark:hover:bg-input/50 px-4 py-2 has-[>svg]:px-3 rounded-xl group flex items-center justify-start size-full" aria-disabled="false">  <svg width="1em" height="1em" viewBox="0 0 24 24" class="mr-2 size-4 transition-transform group-hover:-translate-x-1" data-icon="lucide:arrow-left">   <use href="#ai:lucide:arrow-left"></use>  </svg> <div class="flex flex-col items-start overflow-hidden text-wrap"> <span class="text-muted-foreground text-left text-xs">Next Post</span> <span class="w-full text-left text-sm text-ellipsis"> Part 9 - Neural Networks and Deep Learning </span> </div>  </a> <a href="/cityu/cs4487/cs4487_7" target="_self" class="duration-300 ease-in-out gap-2 whitespace-nowrap text-sm font-medium transition-all disabled:pointer-events-none disabled:opacity-50 [&#38;_svg]:pointer-events-none [&#38;_svg:not([class*='size-'])]:size-4 shrink-0 [&#38;_svg]:shrink-0 outline-none focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:ring-[3px] aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive border bg-background shadow-xs hover:bg-accent hover:text-accent-foreground dark:bg-input/30 dark:border-input dark:hover:bg-input/50 px-4 py-2 has-[>svg]:px-3 rounded-xl group flex items-center justify-end size-full" aria-disabled="false">  <div class="flex flex-col items-end overflow-hidden text-wrap"> <span class="text-muted-foreground text-right text-xs">Previous Post</span> <span class="w-full text-right text-sm text-ellipsis"> Part 7 - The Expectation Maximization Algorithm &amp; Linear Dimensionality Reduction </span> </div> <svg width="1em" height="1em" viewBox="0 0 24 24" class="ml-2 size-4 transition-transform group-hover:translate-x-1" data-icon="lucide:arrow-right">   <use href="#ai:lucide:arrow-right"></use>  </svg>  </a> </nav> </div> <div class="col-start-2"> <div class="giscus"></div> <script data-astro-rerun src="https://giscus.app/client.js" data-repo="rezaarezvan/rezarezvan.com" data-repo-id="R_kgDOHvQr3w" data-category="General" data-category-id="DIC_kwDOHvQr384CiWVC" data-mapping="pathname" data-strict="0" data-reactions-enabled="1" data-emit-metadata="0" data-input-position="bottom" data-theme="preferred_color_scheme" data-lang="en" data-loading="lazy" crossorigin="anonymous" async></script> </div> </section> <button data-slot="button" class="items-center justify-center gap-2 whitespace-nowrap rounded-md text-sm font-medium transition-all disabled:pointer-events-none disabled:opacity-50 [&amp;_svg]:pointer-events-none [&amp;_svg:not([class*=&#x27;size-&#x27;])]:size-4 shrink-0 [&amp;_svg]:shrink-0 outline-none focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:ring-[3px] aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive border bg-background shadow-xs hover:bg-accent hover:text-accent-foreground dark:bg-input/30 dark:border-input dark:hover:bg-input/50 size-9 group fixed right-8 bottom-8 z-50 hidden" id="scroll-to-top" title="Scroll to top" aria-label="Scroll to top"> <svg width="1em" height="1em" class="mx-auto size-4 transition-all group-hover:-translate-y-0.5" data-icon="lucide:arrow-up">   <symbol id="ai:lucide:arrow-up" viewBox="0 0 24 24"><path fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="m5 12l7-7l7 7m-7 7V5"/></symbol><use href="#ai:lucide:arrow-up"></use>  </svg> </button> <script type="module">document.addEventListener("astro:page-load",()=>{const o=document.getElementById("scroll-to-top"),t=document.querySelector("footer");o&&t&&(o.addEventListener("click",()=>{window.scrollTo({top:0,behavior:"smooth"})}),window.addEventListener("scroll",()=>{const e=t.getBoundingClientRect().top<=window.innerHeight;o.classList.toggle("hidden",window.scrollY<=300||e)}))});</script>  </div> </main> <footer class="py-4"> <div class="mx-auto flex max-w-3xl flex-col items-center justify-center gap-y-2 px-4 sm:flex-row sm:justify-between"> <div class="flex flex-wrap items-center justify-center gap-x-2 text-center"> <span class="text-muted-foreground text-sm">
&copy; 2025 • rezarezvan.com </span> </div> </div> </footer> <div id="backdrop" class="invisible fixed top-0 left-0 z-50 flex h-screen w-full justify-center bg-[rgba(0,0,0,0.5)] p-6 backdrop-blur-sm" data-astro-transition-persist="astro-t6dxx5el-4"> <div id="pagefind-container" class="m-0 flex h-fit max-h-[80%] w-full max-w-screen-sm flex-col overflow-auto rounded border border-black/15 bg-neutral-100 p-2 px-4 py-3 shadow-lg dark:border-white/20 dark:bg-neutral-900"> <div id="search" class="pagefind-ui pagefind-init" data-pagefind-ui data-bundle-path="/pagefind/" data-ui-options="{&#34;showImages&#34;:false,&#34;excerptLength&#34;:15,&#34;resetStyles&#34;:false}"></div> <script type="module" src="/_astro/Search.astro_astro_type_script_index_0_lang.C4tRTXsn.js"></script> <div class="dark:prose-invert mr-2 pt-4 pb-1 text-right text-xs">
Press <span class="prose dark:prose-invert text-xs"><kbd class="">Esc</kbd></span> or click anywhere to close
</div> </div> </div> <script>
  document.addEventListener('DOMContentLoaded', () => {
    const magnifyingGlass = document.getElementById('magnifying-glass')
    const backdrop = document.getElementById('backdrop')

    function openPagefind() {
      const searchDiv = document.getElementById('search')
      const search = searchDiv.querySelector('input')
      setTimeout(() => {
        search.focus()
      }, 0)
      backdrop?.classList.remove('invisible')
      backdrop?.classList.add('visible')
    }

    function closePagefind() {
      const searchDiv = document.getElementById('search')
      const search = searchDiv.querySelector('input')
      if (search) {
        search.value = ''
      }
      backdrop?.classList.remove('visible')
      backdrop?.classList.add('invisible')
    }

    // open pagefind
    magnifyingGlass?.addEventListener('click', () => {
      openPagefind()
    })

    document.addEventListener('keydown', (e) => {
      if (e.key === '/') {
        e.preventDefault()
        openPagefind()
      } else if ((e.metaKey || e.ctrlKey) && e.key === 'k') {
        e.preventDefault()
        openPagefind()
      }
    })

    // close pagefind
    document.addEventListener('keydown', (e) => {
      if (e.key === 'Escape') {
        closePagefind()
      }
    })

    // close pagefind when searched result(link) clicked
    document.addEventListener('click', (event) => {
      if (event.target.classList.contains('pagefind-ui__result-link')) {
        closePagefind()
      }
    })

    backdrop?.addEventListener('click', (event) => {
      if (!event.target.closest('#pagefind-container')) {
        closePagefind()
      }
    })

    // prevent form submission
    const form = document.getElementById('form')
    form?.addEventListener('submit', (event) => {
      event.preventDefault()
    })
  })
</script>  </div> </body></html>