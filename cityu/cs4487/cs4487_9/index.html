<!DOCTYPE html><html lang="en"> <head><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes"><meta name="generator" content="Astro v5.7.12"><meta name="robots" content="index, follow"><meta name="HandheldFriendly" content="True"><meta name="mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="format-detection" content="telephone=no,date=no,address=no,email=no,url=no"><meta name="theme-color" content="#121212" media="(prefers-color-scheme: dark)"><meta name="theme-color" content="#121212" media="(prefers-color-scheme: light)"><link rel="sitemap" href="/sitemap-index.xml"><link rel="manifest" href="/site.webmanifest"><link rel="alternate" type="application/rss+xml" title="rezarezvan.com" href="https://rezarezvan.com/rss.xml"><!-- PageFind --><link href="/pagefind/pagefind-ui.css" rel="stylesheet"><script src="/pagefind/pagefind-ui.js"></script><!-- KaTeX support --><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.22/dist/katex.min.css" integrity="sha384-5TcZemv2l/9On385z///+d7MSYlvIEw9FuZTIdZ14vJLqWphw7e7ZPuOiCHJcFCP" crossorigin="anonymous"><script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.22/dist/katex.min.js" integrity="sha384-cMkvdD8LoxVzGF/RPUKAcvmm49FQ0oxwDF3BGKtDXcEc+T1b2N+teh/OJfpU0jr6" crossorigin="anonymous"></script><script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.22/dist/contrib/auto-render.min.js" integrity="sha384-hCXGrW6PitJEwbkoStFjeJxv+fSOOQKOPbJxSfM6G5sWZjAyWhXiTIIAmQqnlLlh" crossorigin="anonymous" onload="renderMathInElement(document.body);"></script><!-- inline KaTeX --><script>
    function renderKaTeX() {
      if (typeof renderMathInElement !== 'undefined') {
        renderMathInElement(document.body, {
          delimiters: [
            { left: '$$', right: '$$', display: true },
            { left: '$', right: '$', display: false },
          ],
        })
      }
    }

    document.addEventListener('DOMContentLoaded', renderKaTeX)
    document.addEventListener('astro:after-swap', renderKaTeX)
  </script><link rel="icon" type="image/png" href="/favicon-96x96.png" sizes="96x96"><link rel="icon" type="image/svg+xml" href="/favicon.ico"><link rel="shortcut icon" href="/favicon.ico"><link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png"><meta name="apple-mobile-web-app-title" content="rezvan-blog"><link rel="manifest" href="/site.webmanifest"><meta name="astro-view-transitions-enabled" content="true"><meta name="astro-view-transitions-fallback" content="animate"><script type="module" src="/_astro/ClientRouter.astro_astro_type_script_index_0_lang.CtSceO8m.js"></script><script>
    function init() {
      setGiscusTheme()
    }

    const setGiscusTheme = () => {
      const giscus = document.querySelector('.giscus-frame')

      const isDark = document.documentElement.classList.contains('dark')

      if (giscus) {
        const url = new URL(giscus.src)
        url.searchParams.set('theme', isDark ? 'dark' : 'light')
        giscus.src = url.toString()
      }
    }

    document.addEventListener('DOMContentLoaded', () => init())
    document.addEventListener('astro:after-swap', () => init())
  </script><title>Part 9 - Neural Networks and Deep Learning | rezarezvan.com</title><meta name="title" content="Part 9 - Neural Networks and Deep Learning | rezarezvan.com"><meta name="description" content="Personal website and course notes repository"><link rel="canonical" href="https://rezarezvan.com"><meta property="og:title" content="Part 9 - Neural Networks and Deep Learning"><meta property="og:description" content="Personal website and course notes repository"><meta property="og:image" content="https://rezarezvan.comundefined"><meta property="og:image:alt" content="Part 9 - Neural Networks and Deep Learning"><meta property="og:type" content="website"><meta property="og:locale" content="en"><meta property="og:site_name" content="rezarezvan.com"><meta property="og:url" content="https://rezarezvan.com/cityu/cs4487/cs4487_9/"><meta name="twitter:title" content="Part 9 - Neural Networks and Deep Learning"><meta name="twitter:description" content="Personal website and course notes repository"><meta property="twitter:image" content="https://rezarezvan.comundefined"><meta name="twitter:image:alt" content="Part 9 - Neural Networks and Deep Learning"><meta name="twitter:card" content="summary_large_image"><link rel="stylesheet" href="/_astro/index.DmLwr0zB.css"></head><body> <div class="flex h-fit min-h-screen flex-col gap-y-6 font-sans"> <header class="bg-background/50 sticky top-0 z-10 backdrop-blur-md" data-astro-transition-persist="astro-l7r54iwe-1"> <div class="mx-auto flex max-w-3xl flex-wrap items-center justify-between gap-4 p-4"> <a href="/" target="_self" class="transition-colors duration-300 ease-in-out flex shrink-0 items-center gap-2 text-xl font-medium"> rezarezvan.com </a> <div class="flex items-center gap-2 md:gap-4"> <nav class="hidden items-center gap-4 text-sm sm:gap-6 md:flex"> <a href="/blog" target="_self" class="inline-block duration-300 ease-in-out hover:text-foreground/30 transition-colors"> blog<span>/</span>  </a><a href="/chalmers" target="_self" class="inline-block duration-300 ease-in-out hover:text-foreground/30 transition-colors"> chalmers<span>/</span>  </a><a href="/cityu" target="_self" class="inline-block duration-300 ease-in-out hover:text-foreground/30 transition-colors"> cityu<span>/</span>  </a><a href="/about" target="_self" class="inline-block duration-300 ease-in-out hover:text-foreground/30 transition-colors"> about<span>/</span>  </a><a href="/research" target="_self" class="inline-block duration-300 ease-in-out hover:text-foreground/30 transition-colors"> research<span>/</span>  </a> </nav> <button id="magnifying-glass" aria-label="Search" class="flex items-center rounded border border-black/15 bg-neutral-100 px-2 py-1 text-xs transition-colors duration-300 ease-in-out hover:bg-black/5 hover:text-black focus-visible:bg-black/5 focus-visible:text-black dark:border-white/20 dark:bg-neutral-900 dark:hover:bg-white/5 dark:hover:text-white dark:focus-visible:bg-white/5 dark:focus-visible:text-white"> <svg height="16" stroke-linejoin="round" viewBox="0 0 16 16" width="16" style="color: currentcolor;"> <path fill-rule="evenodd" clip-rule="evenodd" d="M3.5 7C3.5 5.067 5.067 3.5 7 3.5C8.933 3.5 10.5 5.067 10.5 7C10.5 7.88461 10.1718 8.69256 9.63058 9.30876L9.30876 9.63058C8.69256 10.1718 7.88461 10.5 7 10.5C5.067 10.5 3.5 8.933 3.5 7ZM9.96544 11.0261C9.13578 11.6382 8.11014 12 7 12C4.23858 12 2 9.76142 2 7C2 4.23858 4.23858 2 7 2C9.76142 2 12 4.23858 12 7C12 8.11014 11.6382 9.13578 11.0261 9.96544L14.0303 12.9697L14.5607 13.5L13.5 14.5607L12.9697 14.0303L9.96544 11.0261Z" fill="currentColor"></path> </svg>
&nbsp;Search
</button> <style>astro-island,astro-slot,astro-static-slot{display:contents}</style><script>(()=>{var e=async t=>{await(await t())()};(self.Astro||(self.Astro={})).load=e;window.dispatchEvent(new Event("astro:load"));})();;(()=>{var A=Object.defineProperty;var g=(i,o,a)=>o in i?A(i,o,{enumerable:!0,configurable:!0,writable:!0,value:a}):i[o]=a;var d=(i,o,a)=>g(i,typeof o!="symbol"?o+"":o,a);{let i={0:t=>m(t),1:t=>a(t),2:t=>new RegExp(t),3:t=>new Date(t),4:t=>new Map(a(t)),5:t=>new Set(a(t)),6:t=>BigInt(t),7:t=>new URL(t),8:t=>new Uint8Array(t),9:t=>new Uint16Array(t),10:t=>new Uint32Array(t),11:t=>1/0*t},o=t=>{let[l,e]=t;return l in i?i[l](e):void 0},a=t=>t.map(o),m=t=>typeof t!="object"||t===null?t:Object.fromEntries(Object.entries(t).map(([l,e])=>[l,o(e)]));class y extends HTMLElement{constructor(){super(...arguments);d(this,"Component");d(this,"hydrator");d(this,"hydrate",async()=>{var b;if(!this.hydrator||!this.isConnected)return;let e=(b=this.parentElement)==null?void 0:b.closest("astro-island[ssr]");if(e){e.addEventListener("astro:hydrate",this.hydrate,{once:!0});return}let c=this.querySelectorAll("astro-slot"),n={},h=this.querySelectorAll("template[data-astro-template]");for(let r of h){let s=r.closest(this.tagName);s!=null&&s.isSameNode(this)&&(n[r.getAttribute("data-astro-template")||"default"]=r.innerHTML,r.remove())}for(let r of c){let s=r.closest(this.tagName);s!=null&&s.isSameNode(this)&&(n[r.getAttribute("name")||"default"]=r.innerHTML)}let p;try{p=this.hasAttribute("props")?m(JSON.parse(this.getAttribute("props"))):{}}catch(r){let s=this.getAttribute("component-url")||"<unknown>",v=this.getAttribute("component-export");throw v&&(s+=` (export ${v})`),console.error(`[hydrate] Error parsing props for component ${s}`,this.getAttribute("props"),r),r}let u;await this.hydrator(this)(this.Component,p,n,{client:this.getAttribute("client")}),this.removeAttribute("ssr"),this.dispatchEvent(new CustomEvent("astro:hydrate"))});d(this,"unmount",()=>{this.isConnected||this.dispatchEvent(new CustomEvent("astro:unmount"))})}disconnectedCallback(){document.removeEventListener("astro:after-swap",this.unmount),document.addEventListener("astro:after-swap",this.unmount,{once:!0})}connectedCallback(){if(!this.hasAttribute("await-children")||document.readyState==="interactive"||document.readyState==="complete")this.childrenConnectedCallback();else{let e=()=>{document.removeEventListener("DOMContentLoaded",e),c.disconnect(),this.childrenConnectedCallback()},c=new MutationObserver(()=>{var n;((n=this.lastChild)==null?void 0:n.nodeType)===Node.COMMENT_NODE&&this.lastChild.nodeValue==="astro:end"&&(this.lastChild.remove(),e())});c.observe(this,{childList:!0}),document.addEventListener("DOMContentLoaded",e)}}async childrenConnectedCallback(){let e=this.getAttribute("before-hydration-url");e&&await import(e),this.start()}async start(){let e=JSON.parse(this.getAttribute("opts")),c=this.getAttribute("client");if(Astro[c]===void 0){window.addEventListener(`astro:${c}`,()=>this.start(),{once:!0});return}try{await Astro[c](async()=>{let n=this.getAttribute("renderer-url"),[h,{default:p}]=await Promise.all([import(this.getAttribute("component-url")),n?import(n):()=>()=>{}]),u=this.getAttribute("component-export")||"default";if(!u.includes("."))this.Component=h[u];else{this.Component=h;for(let f of u.split("."))this.Component=this.Component[f]}return this.hydrator=p,this.hydrate},e,this)}catch(n){console.error(`[astro-island] Error hydrating ${this.getAttribute("component-url")}`,n)}}attributeChangedCallback(){this.hydrate()}}d(y,"observedAttributes",["props"]),customElements.get("astro-island")||customElements.define("astro-island",y)}})();</script><astro-island uid="Z1gBHq4" prefix="r15" component-url="/_astro/mobile-menu._xVVdQfr.js" component-export="default" renderer-url="/_astro/client.Bg5MhsdL.js" props="{&quot;data-astro-transition-persist&quot;:[0,&quot;astro-lci6dfah-2&quot;]}" ssr client="load" opts="{&quot;name&quot;:&quot;MobileMenu&quot;,&quot;value&quot;:true}" data-astro-transition-persist="astro-lci6dfah-2" await-children><button data-slot="dropdown-menu-trigger" class="inline-flex items-center justify-center gap-2 whitespace-nowrap rounded-md text-sm font-medium transition-all disabled:pointer-events-none disabled:opacity-50 [&amp;_svg]:pointer-events-none [&amp;_svg:not([class*=&#x27;size-&#x27;])]:size-4 shrink-0 [&amp;_svg]:shrink-0 outline-none focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:ring-[3px] aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive border bg-background shadow-xs hover:bg-accent hover:text-accent-foreground dark:bg-input/30 dark:border-input dark:hover:bg-input/50 size-9 md:hidden" title="Menu" type="button" id="radix-:r15R0:" aria-haspopup="menu" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-menu h-5 w-5"><line x1="4" x2="20" y1="12" y2="12"></line><line x1="4" x2="20" y1="6" y2="6"></line><line x1="4" x2="20" y1="18" y2="18"></line></svg><span class="sr-only">Toggle menu</span></button><!--astro:end--></astro-island> <button data-slot="button" class="inline-flex items-center justify-center gap-2 whitespace-nowrap rounded-md text-sm font-medium transition-all disabled:pointer-events-none disabled:opacity-50 [&amp;_svg]:pointer-events-none [&amp;_svg:not([class*=&#x27;size-&#x27;])]:size-4 shrink-0 [&amp;_svg]:shrink-0 outline-none focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:ring-[3px] aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive border bg-background shadow-xs hover:bg-accent hover:text-accent-foreground dark:bg-input/30 dark:border-input dark:hover:bg-input/50 size-9" id="theme-toggle" title="Toggle theme"> <svg width="1em" height="1em" class="size-4 scale-100 rotate-0 transition-all dark:scale-0 dark:-rotate-90" data-icon="lucide:sun">   <symbol id="ai:lucide:sun" viewBox="0 0 24 24"><g fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2"><circle cx="12" cy="12" r="4"/><path d="M12 2v2m0 16v2M4.93 4.93l1.41 1.41m11.32 11.32l1.41 1.41M2 12h2m16 0h2M6.34 17.66l-1.41 1.41M19.07 4.93l-1.41 1.41"/></g></symbol><use href="#ai:lucide:sun"></use>  </svg> <svg width="1em" height="1em" class="absolute size-4 scale-0 rotate-90 transition-all dark:scale-100 dark:rotate-0" data-icon="lucide:moon">   <symbol id="ai:lucide:moon" viewBox="0 0 24 24"><path fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M12 3a6 6 0 0 0 9 9a9 9 0 1 1-9-9"/></symbol><use href="#ai:lucide:moon"></use>  </svg> <span class="sr-only">Toggle theme</span> </button> <script data-astro-rerun>
  const theme = (() => {
    const localStorageTheme = localStorage?.getItem('theme') ?? ''
    if (['dark', 'light'].includes(localStorageTheme)) {
      return localStorageTheme
    }
    if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
      return 'dark'
    }
    return 'light'
  })()

  if (theme === 'light') {
    document.documentElement.classList.remove('dark')
  } else {
    document.documentElement.classList.add('dark')
  }

  window.localStorage.setItem('theme', theme)
</script> <script type="module">function a(){const e=document.documentElement;e.classList.add("disable-transitions"),e.classList.toggle("dark"),window.getComputedStyle(e).getPropertyValue("opacity"),requestAnimationFrame(()=>{e.classList.remove("disable-transitions")});const t=e.classList.contains("dark");localStorage.setItem("theme",t?"dark":"light")}function s(){const e=document.getElementById("theme-toggle");e&&e.addEventListener("click",a)}s();document.addEventListener("astro:after-swap",()=>{const e=localStorage.getItem("theme"),t=document.documentElement;t.classList.add("disable-transitions"),window.getComputedStyle(t).getPropertyValue("opacity"),e==="dark"?t.classList.add("dark"):t.classList.remove("dark"),requestAnimationFrame(()=>{t.classList.remove("disable-transitions")}),s()});</script> </div> </div> </header> <main class="grow"> <div class="mx-auto flex grow flex-col gap-y-6 px-4">   <section class="grid grid-cols-[minmax(0px,1fr)_min(calc(var(--breakpoint-md)-2rem),100%)_minmax(0px,1fr)] gap-y-6"> <div class="col-start-2"> <nav aria-label="breadcrumb" data-slot="breadcrumb"> <ol data-slot="breadcrumb-list" class="text-muted-foreground flex flex-wrap items-center gap-1.5 text-sm break-words sm:gap-2.5"> <li data-slot="breadcrumb-item" class="inline-flex items-center gap-1.5"> <a data-slot="breadcrumb-link" class="hover:text-foreground transition-colors" href="/"> <svg width="1em" height="1em" class="size-4" data-icon="lucide:home">   <symbol id="ai:lucide:home" viewBox="0 0 24 24"><g fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2"><path d="M15 21v-8a1 1 0 0 0-1-1h-4a1 1 0 0 0-1 1v8"/><path d="M3 10a2 2 0 0 1 .709-1.528l7-5.999a2 2 0 0 1 2.582 0l7 5.999A2 2 0 0 1 21 10v9a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2z"/></g></symbol><use href="#ai:lucide:home"></use>  </svg> </a> </li>  <li data-slot="breadcrumb-separator" role="presentation" aria-hidden="true" class="[&amp;&gt;svg]:size-3.5"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-chevron-right"><path d="m9 18 6-6-6-6"></path></svg></li> <li data-slot="breadcrumb-item" class="inline-flex items-center gap-1.5"><a data-slot="breadcrumb-link" class="hover:text-foreground transition-colors" href="/cityu"> <span class="flex items-center gap-x-2"> <svg width="1em" height="1em" class="size-4" data-icon="lucide:graduation-cap">   <symbol id="ai:lucide:graduation-cap" viewBox="0 0 24 24"><g fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2"><path d="M21.42 10.922a1 1 0 0 0-.019-1.838L12.83 5.18a2 2 0 0 0-1.66 0L2.6 9.08a1 1 0 0 0 0 1.832l8.57 3.908a2 2 0 0 0 1.66 0zM22 10v6"/><path d="M6 12.5V16a6 3 0 0 0 12 0v-3.5"/></g></symbol><use href="#ai:lucide:graduation-cap"></use>  </svg> CityU </span> </a></li>  <li data-slot="breadcrumb-separator" role="presentation" aria-hidden="true" class="[&amp;&gt;svg]:size-3.5"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-chevron-right"><path d="m9 18 6-6-6-6"></path></svg></li> <li data-slot="breadcrumb-item" class="inline-flex items-center gap-1.5"><a data-slot="breadcrumb-link" class="hover:text-foreground transition-colors" href="/cityu/cs4487"> <span class="flex items-center gap-x-2"> <svg width="1em" height="1em" class="size-4" data-icon="lucide:book-open">   <symbol id="ai:lucide:book-open" viewBox="0 0 24 24"><path fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M12 7v14m-9-3a1 1 0 0 1-1-1V4a1 1 0 0 1 1-1h5a4 4 0 0 1 4 4a4 4 0 0 1 4-4h5a1 1 0 0 1 1 1v13a1 1 0 0 1-1 1h-6a3 3 0 0 0-3 3a3 3 0 0 0-3-3z"/></symbol><use href="#ai:lucide:book-open"></use>  </svg> Machine Learning </span> </a></li>  <li data-slot="breadcrumb-separator" role="presentation" aria-hidden="true" class="[&amp;&gt;svg]:size-3.5"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-chevron-right"><path d="m9 18 6-6-6-6"></path></svg></li> <li data-slot="breadcrumb-item" class="inline-flex items-center gap-1.5"><span data-slot="breadcrumb-page" role="link" aria-disabled="true" aria-current="page" class="text-foreground font-normal"> <span class="flex items-center gap-x-2"> <svg width="1em" height="1em" class="size-4" data-icon="lucide:file-text">   <symbol id="ai:lucide:file-text" viewBox="0 0 24 24"><g fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2"><path d="M15 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V7Z"/><path d="M14 2v4a2 2 0 0 0 2 2h4M10 9H8m8 4H8m8 4H8"/></g></symbol><use href="#ai:lucide:file-text"></use>  </svg> Part 9 - Neural Networks and Deep Learning </span> </span></li> </ol> </nav> </div>  <section class="col-start-2 flex flex-col gap-y-6 text-center"> <div class="flex flex-col"> <h1 class="mb-2 text-4xl leading-tight font-medium text-pretty sm:text-5xl"> Part 9 - Neural Networks and Deep Learning </h1> <div class="text-muted-foreground mb-4 flex flex-wrap items-center justify-center gap-2 text-sm"> <div class="flex items-center gap-2"> <span data-slot="badge" class="inline-flex items-center justify-center rounded-md border px-2 py-0.5 text-xs font-medium w-fit whitespace-nowrap shrink-0 [&amp;&gt;svg]:size-3 gap-1 [&amp;&gt;svg]:pointer-events-none focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:ring-[3px] aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive transition-[color,box-shadow] overflow-hidden text-foreground [a&amp;]:hover:bg-accent [a&amp;]:hover:text-accent-foreground">CS4487</span> <div data-orientation="vertical" role="none" data-slot="separator-root" class="bg-border shrink-0 data-[orientation=horizontal]:h-px data-[orientation=horizontal]:w-full data-[orientation=vertical]:h-full data-[orientation=vertical]:w-px h-4!"></div> <span>November 06, 2024</span> <div data-orientation="vertical" role="none" data-slot="separator-root" class="bg-border shrink-0 data-[orientation=horizontal]:h-px data-[orientation=horizontal]:w-full data-[orientation=vertical]:h-full data-[orientation=vertical]:w-px h-4!"></div>  <div data-orientation="vertical" role="none" data-slot="separator-root" class="bg-border shrink-0 data-[orientation=horizontal]:h-px data-[orientation=horizontal]:w-full data-[orientation=vertical]:h-full data-[orientation=vertical]:w-px h-4!"></div> <span>17 min read</span> </div> </div> </div> <nav class="col-start-2 grid grid-cols-1 gap-4 sm:grid-cols-2"> <a href="/cityu/cs4487/cs4487_10" target="_self" class="duration-300 ease-in-out gap-2 whitespace-nowrap text-sm font-medium transition-all disabled:pointer-events-none disabled:opacity-50 [&#38;_svg]:pointer-events-none [&#38;_svg:not([class*='size-'])]:size-4 shrink-0 [&#38;_svg]:shrink-0 outline-none focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:ring-[3px] aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive border bg-background shadow-xs hover:bg-accent hover:text-accent-foreground dark:bg-input/30 dark:border-input dark:hover:bg-input/50 px-4 py-2 has-[>svg]:px-3 rounded-xl group flex items-center justify-start size-full" aria-disabled="false">  <svg width="1em" height="1em" class="mr-2 size-4 transition-transform group-hover:-translate-x-1" data-icon="lucide:arrow-left">   <symbol id="ai:lucide:arrow-left" viewBox="0 0 24 24"><path fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="m12 19l-7-7l7-7m7 7H5"/></symbol><use href="#ai:lucide:arrow-left"></use>  </svg> <div class="flex flex-col items-start overflow-hidden text-wrap"> <span class="text-muted-foreground text-left text-xs">Next Post</span> <span class="w-full text-left text-sm text-ellipsis"> Part 10 - Neural Networks and Deep Learning Part 2 </span> </div>  </a> <a href="/cityu/cs4487/cs4487_8" target="_self" class="duration-300 ease-in-out gap-2 whitespace-nowrap text-sm font-medium transition-all disabled:pointer-events-none disabled:opacity-50 [&#38;_svg]:pointer-events-none [&#38;_svg:not([class*='size-'])]:size-4 shrink-0 [&#38;_svg]:shrink-0 outline-none focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:ring-[3px] aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive border bg-background shadow-xs hover:bg-accent hover:text-accent-foreground dark:bg-input/30 dark:border-input dark:hover:bg-input/50 px-4 py-2 has-[>svg]:px-3 rounded-xl group flex items-center justify-end size-full" aria-disabled="false">  <div class="flex flex-col items-end overflow-hidden text-wrap"> <span class="text-muted-foreground text-right text-xs">Previous Post</span> <span class="w-full text-right text-sm text-ellipsis"> Part 8 - Principal Component Analysis </span> </div> <svg width="1em" height="1em" class="ml-2 size-4 transition-transform group-hover:translate-x-1" data-icon="lucide:arrow-right">   <symbol id="ai:lucide:arrow-right" viewBox="0 0 24 24"><path fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M5 12h14m-7-7l7 7l-7 7"/></symbol><use href="#ai:lucide:arrow-right"></use>  </svg>  </a> </nav> </section> <details open class="group col-start-2 rounded-xl border p-4 xl:sticky xl:top-20 xl:col-start-1 xl:mr-8 xl:ml-auto xl:h-[calc(100vh-5rem)] xl:max-w-fit xl:rounded-none xl:border-none xl:p-0"> <summary class="flex cursor-pointer items-center justify-between text-xl font-medium group-open:pb-4 xl:hidden"> <span>Table of Contents</span> <svg width="1em" height="1em" class="size-5 shrink-0 transition-transform group-open:rotate-180" data-icon="lucide:chevron-down">   <symbol id="ai:lucide:chevron-down" viewBox="0 0 24 24"><path fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="m6 9l6 6l6-6"/></symbol><use href="#ai:lucide:chevron-down"></use>  </svg> </summary> <astro-island uid="Z2v3hG7" prefix="r23" component-url="/_astro/scroll-area.BFWcSHDf.js" component-export="ScrollArea" renderer-url="/_astro/client.Bg5MhsdL.js" props="{&quot;className&quot;:[0,&quot;flex max-h-64 flex-col overflow-y-auto xl:max-h-[calc(100vh-8rem)]&quot;],&quot;type&quot;:[0,&quot;always&quot;]}" ssr client="load" opts="{&quot;name&quot;:&quot;ScrollArea&quot;,&quot;value&quot;:true}" await-children><div dir="ltr" data-slot="scroll-area" class="relative flex max-h-64 flex-col overflow-y-auto xl:max-h-[calc(100vh-8rem)]" style="position:relative;--radix-scroll-area-corner-width:0px;--radix-scroll-area-corner-height:0px"><style>[data-radix-scroll-area-viewport]{scrollbar-width:none;-ms-overflow-style:none;-webkit-overflow-scrolling:touch;}[data-radix-scroll-area-viewport]::-webkit-scrollbar{display:none}</style><div data-radix-scroll-area-viewport="" data-slot="scroll-area-viewport" class="ring-ring/10 dark:ring-ring/20 dark:outline-ring/40 outline-ring/50 size-full rounded-[inherit] transition-[color,box-shadow] focus-visible:ring-4 focus-visible:outline-1" style="overflow-x:hidden;overflow-y:hidden"><div style="min-width:100%;display:table"><astro-slot> <ul class="flex list-none flex-col gap-y-2 px-4 xl:mr-8" id="table-of-contents"> <li class="hidden text-lg font-medium xl:block">Table of Contents</li> <li class="text-foreground/60 px-4 text-sm xl:p-0 ml-4"> <a href="#history" class="marker:text-foreground/30 list-item list-disc underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit xl:list-none"> History </a> </li><li class="text-foreground/60 px-4 text-sm xl:p-0 ml-8"> <a href="#original-idea" class="marker:text-foreground/30 list-item list-disc underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit xl:list-none"> Original Idea </a> </li><li class="text-foreground/60 px-4 text-sm xl:p-0 ml-8"> <a href="#synapses" class="marker:text-foreground/30 list-item list-disc underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit xl:list-none"> Synapses </a> </li><li class="text-foreground/60 px-4 text-sm xl:p-0 ml-8"> <a href="#multiple-outputs" class="marker:text-foreground/30 list-item list-disc underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit xl:list-none"> Multiple Outputs? </a> </li><li class="text-foreground/60 px-4 text-sm xl:p-0 ml-8"> <a href="#multi-layer-perceptron" class="marker:text-foreground/30 list-item list-disc underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit xl:list-none"> Multi-Layer Perceptron </a> </li><li class="text-foreground/60 px-4 text-sm xl:p-0 ml-12"> <a href="#decline-in-the-1990s" class="marker:text-foreground/30 list-item list-disc underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit xl:list-none"> Decline in the 1990s </a> </li><li class="text-foreground/60 px-4 text-sm xl:p-0 ml-8"> <a href="#deep-learning" class="marker:text-foreground/30 list-item list-disc underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit xl:list-none"> Deep Learning </a> </li><li class="text-foreground/60 px-4 text-sm xl:p-0 ml-4"> <a href="#perceptron" class="marker:text-foreground/30 list-item list-disc underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit xl:list-none"> Perceptron </a> </li><li class="text-foreground/60 px-4 text-sm xl:p-0 ml-8"> <a href="#mcculloch-and-pitts-neuron-1943" class="marker:text-foreground/30 list-item list-disc underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit xl:list-none"> McCulloch and Pitts Neuron (1943) </a> </li><li class="text-foreground/60 px-4 text-sm xl:p-0 ml-8"> <a href="#the-perceptron-1950" class="marker:text-foreground/30 list-item list-disc underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit xl:list-none"> The Perceptron (1950) </a> </li><li class="text-foreground/60 px-4 text-sm xl:p-0 ml-8"> <a href="#perception-algorithm" class="marker:text-foreground/30 list-item list-disc underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit xl:list-none"> Perception Algorithm </a> </li><li class="text-foreground/60 px-4 text-sm xl:p-0 ml-8"> <a href="#perceptron-loss-function" class="marker:text-foreground/30 list-item list-disc underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit xl:list-none"> Perceptron Loss Function </a> </li><li class="text-foreground/60 px-4 text-sm xl:p-0 ml-4"> <a href="#multi-layer-perceptron-1" class="marker:text-foreground/30 list-item list-disc underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit xl:list-none"> Multi-Layer Perceptron </a> </li><li class="text-foreground/60 px-4 text-sm xl:p-0 ml-8"> <a href="#activation-functions" class="marker:text-foreground/30 list-item list-disc underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit xl:list-none"> Activation Functions </a> </li><li class="text-foreground/60 px-4 text-sm xl:p-0 ml-12"> <a href="#sigmoid-or-logistic-activation-function" class="marker:text-foreground/30 list-item list-disc underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit xl:list-none"> Sigmoid or Logistic Activation Function </a> </li><li class="text-foreground/60 px-4 text-sm xl:p-0 ml-12"> <a href="#tanh-activation-function" class="marker:text-foreground/30 list-item list-disc underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit xl:list-none"> Tanh Activation Function </a> </li><li class="text-foreground/60 px-4 text-sm xl:p-0 ml-12"> <a href="#relu-activation-function" class="marker:text-foreground/30 list-item list-disc underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit xl:list-none"> ReLU Activation Function </a> </li><li class="text-foreground/60 px-4 text-sm xl:p-0 ml-12"> <a href="#variants-of-relu" class="marker:text-foreground/30 list-item list-disc underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit xl:list-none"> Variants of ReLU </a> </li><li class="text-foreground/60 px-4 text-sm xl:p-0 ml-12"> <a href="#maxout-activation-function" class="marker:text-foreground/30 list-item list-disc underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit xl:list-none"> Maxout Activation Function </a> </li><li class="text-foreground/60 px-4 text-sm xl:p-0 ml-12"> <a href="#other-emerging-activation-functions" class="marker:text-foreground/30 list-item list-disc underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit xl:list-none"> Other Emerging Activation Functions </a> </li><li class="text-foreground/60 px-4 text-sm xl:p-0 ml-8"> <a href="#training-an-mlp" class="marker:text-foreground/30 list-item list-disc underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit xl:list-none"> Training an MLP </a> </li><li class="text-foreground/60 px-4 text-sm xl:p-0 ml-8"> <a href="#backpropagation-backward-propagation" class="marker:text-foreground/30 list-item list-disc underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit xl:list-none"> Backpropagation (Backward Propagation) </a> </li><li class="text-foreground/60 px-4 text-sm xl:p-0 ml-4"> <a href="#universal-approximation-theorem" class="marker:text-foreground/30 list-item list-disc underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit xl:list-none"> Universal Approximation Theorem </a> </li><li class="text-foreground/60 px-4 text-sm xl:p-0 ml-4"> <a href="#gradient-descent-with-the-chain-rule" class="marker:text-foreground/30 list-item list-disc underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit xl:list-none"> Gradient Descent with the Chain Rule </a> </li><li class="text-foreground/60 px-4 text-sm xl:p-0 ml-4"> <a href="#convolutional-neural-networks-cnn" class="marker:text-foreground/30 list-item list-disc underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit xl:list-none"> Convolutional Neural Networks (CNN) </a> </li><li class="text-foreground/60 px-4 text-sm xl:p-0 ml-8"> <a href="#image-inputs-and-neural-networks" class="marker:text-foreground/30 list-item list-disc underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit xl:list-none"> Image Inputs and Neural Networks </a> </li><li class="text-foreground/60 px-4 text-sm xl:p-0 ml-8"> <a href="#from-fully-connected-to-convolutional-layer" class="marker:text-foreground/30 list-item list-disc underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit xl:list-none"> From Fully Connected to Convolutional Layer </a> </li><li class="text-foreground/60 px-4 text-sm xl:p-0 ml-12"> <a href="#padding" class="marker:text-foreground/30 list-item list-disc underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit xl:list-none"> Padding </a> </li><li class="text-foreground/60 px-4 text-sm xl:p-0 ml-12"> <a href="#spatial-subsampling" class="marker:text-foreground/30 list-item list-disc underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit xl:list-none"> Spatial Subsampling </a> </li><li class="text-foreground/60 px-4 text-sm xl:p-0 ml-8"> <a href="#adding-back-mlp" class="marker:text-foreground/30 list-item list-disc underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit xl:list-none"> Adding back MLP </a> </li><li class="text-foreground/60 px-4 text-sm xl:p-0 ml-4"> <a href="#origin-of-convolution" class="marker:text-foreground/30 list-item list-disc underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit xl:list-none"> Origin of Convolution </a> </li><li class="text-foreground/60 px-4 text-sm xl:p-0 ml-8"> <a href="#where-does-convolution-come-from" class="marker:text-foreground/30 list-item list-disc underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit xl:list-none"> Where Does Convolution Come From? </a> </li><li class="text-foreground/60 px-4 text-sm xl:p-0 ml-8"> <a href="#time-invariant-systems" class="marker:text-foreground/30 list-item list-disc underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit xl:list-none"> Time Invariant Systems </a> </li><li class="text-foreground/60 px-4 text-sm xl:p-0 ml-8"> <a href="#linear-systems" class="marker:text-foreground/30 list-item list-disc underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit xl:list-none"> Linear Systems </a> </li><li class="text-foreground/60 px-4 text-sm xl:p-0 ml-8"> <a href="#unit-sample-response" class="marker:text-foreground/30 list-item list-disc underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit xl:list-none"> Unit Sample Response </a> </li><li class="text-foreground/60 px-4 text-sm xl:p-0 ml-8"> <a href="#unit-sample-decomposition" class="marker:text-foreground/30 list-item list-disc underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit xl:list-none"> Unit Sample Decomposition </a> </li><li class="text-foreground/60 px-4 text-sm xl:p-0 ml-8"> <a href="#modeling-lti-systems" class="marker:text-foreground/30 list-item list-disc underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit xl:list-none"> Modeling LTI Systems </a> </li><li class="text-foreground/60 px-4 text-sm xl:p-0 ml-8"> <a href="#discrete-convolution" class="marker:text-foreground/30 list-item list-disc underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit xl:list-none"> Discrete Convolution </a> </li><li class="text-foreground/60 px-4 text-sm xl:p-0 ml-4"> <a href="#summary" class="marker:text-foreground/30 list-item list-disc underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit xl:list-none"> Summary </a> </li> </ul> </astro-slot></div></div><div data-orientation="vertical" data-slot="scroll-area-scrollbar" class="flex touch-none p-px transition-colors select-none h-full w-2.5 border-l border-l-transparent" style="position:absolute;top:0;right:0;bottom:var(--radix-scroll-area-corner-height);--radix-scroll-area-thumb-height:18px"></div></div><!--astro:end--></astro-island> </details> <script type="module">function s(){const t=document.querySelector("header"),c=t?t.offsetHeight:0,a=new IntersectionObserver(e=>{e.forEach(o=>{const r=o.target.querySelector("h2, h3, h4, h5, h6");if(!r)return;const d=r.getAttribute("id"),n=document.querySelector(`#table-of-contents li a[href="#${d}"]`);if(!n)return;const i=o.isIntersecting?"add":"remove";n.classList[i]("text-foreground")})},{rootMargin:`-${c}px 0px 0px 0px`});document.querySelectorAll(".prose section").forEach(e=>{a.observe(e)})}document.addEventListener("astro:page-load",s);document.addEventListener("astro:after-swap",s);</script> <article class="prose col-start-2 max-w-none"> <!doctype html><html lang="en"><head></head><body>


<meta charset="utf-8">
<title>CS4487_9</title>
<meta content="width=device-width, initial-scale=1" name="viewport">
<link href="https://cdn.jsdelivr.net/npm/katex@0.16.21/dist/katex.min.css" rel="stylesheet">

<svg xmlns="http://www.w3.org/2000/svg" style="display:none"><defs>
        <symbol id="info" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
          <path d="M13 16h-1v-4h-1m1-4h.01M21 12a9 9 0 11-18 0 9 9 0 0118 0z"></path>
        </symbol>
        <symbol id="lightbulb" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
          <path d="M9.663 17h4.673M12 3v1m6.364 1.636l-.707.707M21 12h-1M4 12H3m3.343-5.657l-.707-.707m2.828 9.9a5 5 0 117.072 0l-.548.547A3.374 3.374 0 0014 18.469V19a2 2 0 11-4 0v-.531c0-.895-.356-1.754-.988-2.386l-.548-.547z"></path>
        </symbol>
        <symbol id="alert-triangle" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
          <path d="M12 9v2m0 4h.01m-6.938 4h13.856c1.54 0 2.502-1.667 1.732-3L13.732 4c-.77-1.333-2.694-1.333-3.464 0L3.34 16c-.77 1.333.192 3 1.732 3z"></path>
        </symbol>
        <symbol id="shield-alert" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
          <path d="M20.618 5.984A11.955 11.955 0 0112 2.944a11.955 11.955 0 01-8.618 3.04A12.02 12.02 0 003 9c0 5.591 3.824 10.29 9 11.622 5.176-1.332 9-6.03 9-11.622 0-1.042-.133-2.052-.382-3.016zM12 9v2m0 4h.01"></path>
        </symbol>
        <symbol id="message-square-warning" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
          <path d="M21 15a2 2 0 01-2 2H7l-4 4V5a2 2 0 012-2h14a2 2 0 012 2zM12 8v4m0 4h.01"></path>
        </symbol>
        <symbol id="book-open" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
          <path d="M12 6.253v13m0-13C10.832 5.477 9.246 5 7.5 5S4.168 5.477 3 6.253v13C4.168 18.477 5.754 18 7.5 18s3.332.477 4.5 1.253m0-13C13.168 5.477 14.754 5 16.5 5c1.747 0 3.332.477 4.5 1.253v13C19.832 18.477 18.247 18 16.5 18c-1.746 0-3.332.477-4.5 1.253"></path>
        </symbol>
        <symbol id="anchor" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
          <path d="M8 12h.01M12 12h.01M16 12h.01M21 12a9 9 0 11-18 0 9 9 0 0118 0z"></path>
        </symbol>
        <symbol id="pen-tool" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
          <path d="M12 19l7-7 3 3-7 7-3-3z"></path>
        </symbol>
        <symbol id="check-circle" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
          <path d="M9 12l2 2 4-4m6 2a9 9 0 11-18 0 9 9 0 0118 0z"></path>
        </symbol>
        <symbol id="puzzle" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
          <path d="M11 4a2 2 0 114 0v1a1 1 0 001 1h3a1 1 0 011 1v3a1 1 0 01-1 1h-1a2 2 0 100 4h1a1 1 0 011 1v3a1 1 0 01-1 1h-3a1 1 0 01-1-1v-1a2 2 0 10-4 0v1a1 1 0 01-1 1H7a1 1 0 01-1-1v-3a1 1 0 00-1-1H4a2 2 0 110-4h1a1 1 0 001-1V7a1 1 0 011-1h3a1 1 0 001-1V4z"></path>
        </symbol>
        <symbol id="git-branch" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
          <path d="M3 3v12h12M8 8l8 8"></path>
        </symbol>
        <symbol id="file-text" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
          <path d="M9 12h6m-6 4h6m2 5H7a2 2 0 01-2-2V5a2 2 0 012-2h5.586a1 1 0 01.707.293l5.414 5.414a1 1 0 01.293.707V19a2 2 0 01-2 2z"></path>
        </symbol>
        <symbol id="help-circle" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
          <path d="M18.364 5.636l-3.536 3.536m0 5.656l3.536 3.536M9.172 9.172L5.636 5.636m3.536 9.192l-3.536 3.536M21 12a9 9 0 11-18 0 9 9 0 0118 0zm-5 0a4 4 0 11-8 0 4 4 0 018 0z"></path>
        </symbol>
        <symbol id="check-square" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
          <path d="M9 5H7a2 2 0 00-2 2v12a2 2 0 002 2h10a2 2 0 002-2V7a2 2 0 00-2-2h-2M9 5a2 2 0 002 2h2a2 2 0 002-2M9 5a2 2 0 012-2h2a2 2 0 012 2m-6 9l2 2 4-4"></path>
        </symbol>
        <symbol id="message-circle" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
          <path d="M8 12h.01M12 12h.01M16 12h.01M21 12c0 4.418-4.03 8-9 8a9.863 9.863 0 01-4.255-.949L3 20l1.395-3.72C3.512 15.042 3 13.574 3 12c0-4.418 4.03-8 9-8s9 3.582 9 8z"></path>
        </symbol>
        <symbol id="rotate-ccw" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
          <path d="M3 2v6h6M3 8a9 9 0 015.168 1.637c.773.516 2.21 1.756 3.005 2.318.942.665 2.253.788 3.295.16.9-.545 1.553-1.723 2.592-2.605A9 9 0 018.709 21.5L7.5 20.295"></path>
        </symbol>
        <symbol id="code" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
          <path d="M10 20l4-16m4 4l4 4-4 4M6 16l-4-4 4-4"></path>
        </symbol>
        <symbol id="dumbbell" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
          <path d="M6.5 6.5h11m-11 11h11M5 20a2 2 0 100-4 2 2 0 000 4zM19 20a2 2 0 100-4 2 2 0 000 4zM5 10a2 2 0 100-4 2 2 0 000 4zM19 10a2 2 0 100-4 2 2 0 000 4z"></path>
        </symbol>
        <symbol id="alert-circle" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
          <path d="M12 8v4m0 4h.01M21 12a9 9 0 11-18 0 9 9 0 0118 0z"></path>
        </symbol>
        <symbol id="check" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
          <path d="M5 13l4 4L19 7"></path>
        </symbol>
        <symbol id="check-circle-2" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
          <path d="M9 12l2 2 4-4m6 2a9 9 0 11-18 0 9 9 0 0118 0z"></path>
        </symbol>
        <symbol id="list" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
          <path d="M9 5H7a2 2 0 00-2 2v12a2 2 0 002 2h10a2 2 0 002-2V7a2 2 0 00-2-2h-2M9 5a2 2 0 002 2h2a2 2 0 002-2M9 5a2 2 0 012-2h2a2 2 0 012 2m-3 7h3m-3 4h3m-6-4h.01M9 16h.01"></path>
        </symbol>
        <symbol id="chevron-down" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
          <path d="M19 9l-7 7-7-7"></path>
        </symbol></defs></svg>
<section><h3 id="history">History</h3><p>The history of deep learning is fun and interesting, and many do not seem to have the proper timeline, so let’s take a look.</p><section><h4 id="original-idea">Original Idea</h4><p>The perceptron is the original idea of a neural network, and it was originally proposed by Warren McCulloch and Walter Pitts in 1943 and later on Rosenblatt in 1957.</p><p>The idea was to simulate a neuron in the brain.</p><ol>
<li>It takes binary inputs (input from nearby neurons)</li>
<li>Multiplies the inputs by weights (synaptic strength)</li>
<li>Sum and threshold the input to get binary output (output axon)</li>
</ol><p>We train the weights from the data.</p><figure><img alt="Biological Neuron and Perceptron" width="1466" height="416" loading="lazy" decoding="async" src="/_astro/P.lkf7wZDR_HWsGq.webp" ><figcaption>Biological Neuron and Perceptron</figcaption></figure></section><section><h4 id="synapses">Synapses</h4><p>Let’s take a moment and talk about the biological background of these ideas.</p><p>Synapses are junctions at which neurons communicate with one another.</p><p>Most synapses are chemical (i.e., chemical messengers).
Other synpases are electrical (i.e., ions flow directly between cells).</p><p>At a chemical synapse, an action potential triggers the presynaptic neuron to release neurotransmitters.
These molecules bind to receptors on the postsynaptic cell and make it more or less likely to fire an action potential</p><figure><img alt="Two Neurons Connected by a Synapse" width="804" height="310" loading="lazy" decoding="async" src="/_astro/S.BVv-ba9a_ZyTRAh.webp" ><figcaption>Two Neurons Connected by a Synapse</figcaption></figure></section><section><h4 id="multiple-outputs">Multiple Outputs?</h4><p>The perceptron can only have one output, but what if we want multiple outputs?</p><p>Multiple outputs can be handled by using multiple perceptrons.</p><figure><img alt="Multiple Perceptrons" width="474" height="472" loading="lazy" decoding="async" src="/_astro/MP.BEZvJR89_2wTxzQ.webp" ><figcaption>Multiple Perceptrons</figcaption></figure><p>But there is a problem with this, this is a linear classifier, we can not solve any complex problems using this.</p></section><section><h4 id="multi-layer-perceptron">Multi-Layer Perceptron</h4><p>If we add “hidden layers” between the input and output neurons, we might have a solution to this problem</p><ol>
<li>Each layer extracts some features from previous layers.</li>
<li>We can represent complex non-linear functions.</li>
<li>We can train the weights using the backpropagation algorithm (1970-80s).</li>
</ol><p>This is a modern day neural network!</p><p>But again, there are a few problems with (early) neural networks.</p><ul>
<li>Difficult to train.</li>
<li>Sensitivity to initialization.</li>
<li>Computational expensive (at that time).</li>
</ul><section><h5 id="decline-in-the-1990s">Decline in the 1990s</h5><p>Because of these problems, neural networks became less popular in the 1990s.</p><p>Support Vector Machines (SVM) had good accuracy along with,</p><ul>
<li>Easy to use - only one global optimum.</li>
<li>Learning is not sensitive to initialization.</li>
<li>Theory about performance guarantees.</li>
</ul><p>Only a few groups continued to work on neural networks during this time period, some notable names are LeCun, Bengio, Hinton and Schmidhuber.</p></section></section><section><h4 id="deep-learning">Deep Learning</h4><p>Neural networks resurged in the 2000s, due to a number of factors,</p><ul>
<li>Improvements in network architectures.
<ul>
<li>Developed nodes that are easier to train.</li>
</ul>
</li>
<li>Better training algorithms.
<ul>
<li>Better (stochastic) optimizers for large-scale nonlinear problems.</li>
<li>Better ways to prevent overfitting.</li>
<li>Better initialization methods.</li>
</ul>
</li>
<li>Infrastructure for faster computing.
<ul>
<li>Massively parallel GPUs.</li>
<li>Distributed computing.</li>
</ul>
</li>
<li>More labeled data.
<ul>
<li>From the internet.</li>
<li>Crowd-sourcing for labeling data (Amazon Mechanical Turk).</li>
</ul>
</li>
</ul><p>With this, we began to train neural networks with more and more layers, this is the start of the deep learning era.</p><p>Let’s now dive into each of these topics in more detail.</p></section></section>
<section><h3 id="perceptron">Perceptron</h3><p>As we have seen, the perceptron is the basic building block of a neural network.</p><section><h4 id="mcculloch-and-pitts-neuron-1943">McCulloch and Pitts Neuron (1943)</h4><p>This idea tries to model a single neuron as we have seen.</p><p>We have an input $\mathbf{x} \in \mathbb{R}^N$, which is a $N$-dim vector.
We apply a weight vector to the inputs, we sum and apply a threshold function to get the output.</p><p>Let’s formally write this as,</p><p>$$
y = f(\mathbf{w}^T \mathbf{x}) = f(\sum_{j=0}^{N} w_j x_j),
$$</p><p>where $\mathbf{w}$ is the weight vector and $f(\cdot)$ is the activation function, e.g. $f(a) = \begin{cases} 1 &#x26; a > 0 \newline 0 &#x26; \text{otherwise} \end{cases}$.</p></section><section><h4 id="the-perceptron-1950">The Perceptron (1950)</h4><p>The perceptron is a simple algorithm for adapting the weights in a McCulloch/Pitts neuron, which was developed in the 1950s by Rosenblatt @ Cornell.</p><p>The perceptron training criteria is,</p><ul>
<li>Train the perceptron on data $\mathcal{D} = \{(\mathbf{x}^{(i)}, y^{(i)})\}_{i=1}^M$.</li>
<li>Only look at the points that are misclassified, i.e.,
<ul>
<li>Loss is based on how badly points are misclassified.</li>
<li>$\ell(\mathbf{w}) = \sum_{i=1}^M \begin{cases} -y^{(i)} \mathbf{w}^T \mathbf{x}^{(i)} &#x26; \mathbf{x}^{(i)} \text{ is misclassified} \newline 0 &#x26; \text{otherwise} \end{cases}$.</li>
</ul>
</li>
<li>Minimize the loss, $\mathbf{w}^{\star} = \underset{\mathbf{w}}{\arg\min} \ell(\mathbf{w})$.</li>
</ul><p>Since the computational power was not enough back then, they could only look at one data point at a time, with for exampele stochastic gradient descent (SGD).</p><p><strong>Procedure:</strong></p><ol>
<li>Start with all-zero weight vector $\mathbf{w}^{(0)}$, and initialize $t$ to 0.</li>
<li>For all $(\mathbf{x}^{(i)}, y^{(i)}) \in \mathcal{D}$ compute the activation $a^{(i)} = (\mathbf{w}^{(t)})^T \mathbf{x}^{(i)}$.</li>
<li>If $y^{(i)} a^{(i)} &#x3C; 0$, then $\mathbf{w}^{(t+1)} = \alpha y^{(i)} \mathbf{x}^{(i)}$ and $t \leftarrow t+1$.</li>
<li>Repeat Steps 1-3 until no more points are misclassified.</li>
</ol><p><strong>Notes</strong></p><ul>
<li>$\alpha$ is the update step (i.e., learning rate) for SGD.
<ul>
<li>The effect of the update step is to rotate $\mathbf{w}$ towards the misclassified point $\mathbf{x}^{(i)}$.</li>
</ul>
</li>
<li>If $y^{(i)} = 1$ and $\hat{y}^{(i)} = \text{sign}(a^{(i)}) = -1$, the activation is initially negative and will be increased.</li>
<li>If $y^{(i)} = -1$ and $\hat{y}^{(i)} = \text{sign}(a^{(i)}) = 1$, the activation is initially positive and will be decreased.</li>
</ul></section><section><h4 id="perception-algorithm">Perception Algorithm</h4><p>This algorithm fails to converge if the data is not linearly separable.</p><p>Rosenblatt proved that the algorithm will converge if the data is linearly separable.
The number of iterations is inversely proportional to the seperation (margin) between classes.
This was one of the first machine learning results!</p><p>Different initializations can yield different weight vectors, and hence different decision boundaries.</p></section><section><h4 id="perceptron-loss-function">Perceptron Loss Function</h4><p>We can define a loss function for this algorithm.</p><p>Firstly, let’s define the margin of a point as,</p><p>$$
z^{(i)} = y^{(i)} \mathbf{w}^T \mathbf{x}^{(i)},
$$</p><p>Then, the loss function $\ell(z^{(i)})$ can be defined as,</p><p>$$
\ell(z^{(i)}) = \max(0, -z^{(i)}).
$$</p></section></section>
<section><h3 id="multi-layer-perceptron-1">Multi-Layer Perceptron</h3><p>As we discussed earlier, if we add “hidden layers” between the inputs and the outputs, we can model more complex functions.</p><p>Formally, for one layer we can write,</p><p>$$
\mathbf{h} = f(\mathbf{W}^T \mathbf{x}),
$$</p><p>where $\mathbf{W}$ is the weight matrix, one column for each output node.</p><p>Input $\mathbf{x}$ from previous layer.</p><p>Output $\mathbf{h}$ to next layer.</p><p>$f(\cdot)$ is the activation function - applied to each dimension to get output.</p><section><h4 id="activation-functions">Activation Functions</h4><p>There are many activation functions that can be used in neural networks.
All for different purposes and different properties.</p><figure><img alt="Activation Functions" width="1192" height="546" loading="lazy" decoding="async" src="/_astro/AF.DHZ-rzKK_Za38XO.webp" ><figcaption>Activation Functions</figcaption></figure><section><h5 id="sigmoid-or-logistic-activation-function">Sigmoid or Logistic Activation Function</h5><p>The sigmoid function is defined as,</p><p>$$
\sigma(x) = \frac{1}{1 + e^{-x}}.
$$</p><p>Sigmoid function translates the input ranged in $[-\infty, \infty]$ to the range in $(0, 1)$.</p><p>A more generalized sigmoid function that is used for (multi)class classification is the softmax function.</p><p>The sigmoid function has some problems though.</p><p>The $exp(\cdot)$ function is computationally expensive.</p><p>It also has the <strong>vanishing gradient problem</strong>.</p></section><section><h5 id="tanh-activation-function">Tanh Activation Function</h5><p>The tanh function is defined as,</p><p>$$
\tanh(x) = \frac{e^{2x} - 1}{e^{2x} + 1}.
$$</p><p>It is bound to the range $(-1, 1)$.</p><p>The gradient is stronger (i.e., steeper) for tanh than sigmoid.</p><p>Like sigmoid however, tanh also has a vanishing gradient problem.</p><p>But, optimization is easier for tanh, hence in practice it is always preferred over sigmoid.</p></section><section><h5 id="relu-activation-function">ReLU Activation Function</h5><p>The ReLU (Rectified Linear Unit) function is defined as,</p><p>$$
\text{ReLU}(x) =
\begin{cases}
x, &#x26; \text{if } x \geq 0 \newline
0, &#x26; \text{if } x &#x3C; 0
\end{cases}.
$$</p><p>ReLU is the identity function for positive values and zero for negative values.
It is traditionally known as <strong>half-wave rectification</strong> in signal processing.</p><p>Benefits of ReLU are,</p><ul>
<li>Cheap to compute and easy to optimize.</li>
<li>It converges faster.</li>
<li>No vanishing gradient problem.</li>
<li>Can output a true zero value, leading to representational sparsity.</li>
</ul><p>Problesm of ReLU are,</p><ul>
<li>If one neuron gets negative it is unlikely for it to recover.
This is called the “dying ReLU” problem.</li>
</ul></section><section><h5 id="variants-of-relu">Variants of ReLU</h5><p>Leaky ReLU is defined as,</p><p>$$
\text{LReLU}(x) =
\begin{cases}
x, &#x26; \text{if } x \geq 0 \newline
ax, &#x26; \text{if } x &#x3C; 0
\end{cases}.
$$</p><p>Leaky ReLU attempts to fix the “dying ReLU” problem.
Instead of the function being zero when $x &#x3C; 0$, a leaky ReLU gives a small slope.</p><p>$a$ is a parameter constrained to be positive.
It can be pre-determined or learned from the data.</p><p>The ELU (Exponential Linear Unit) function is defined as,</p><p>$$
\text{ELU}(x) =
\begin{cases}
x, &#x26; \text{if } x \geq 0 \newline
a(e^x - 1), &#x26; \text{if } x &#x3C; 0
\end{cases}.
$$</p><p>It follows the same rule for $x \geq 0$ as ReLU, and increases exponentially for $x &#x3C; 0$.</p><p>ELU tries to make the mean activations closer to zero which speeds up training (by adjusting $a$).</p><p>Empirically, ELU leads to higher performance.</p></section><section><h5 id="maxout-activation-function">Maxout Activation Function</h5><p>The maxout function is defined as,</p><p>$$
\text{Maxout}(\mathbf{x}; \mathbf{w_1}, \mathbf{w_2}) = \max(\mathbf{w_1}^T \mathbf{x}, \mathbf{w_2}^T \mathbf{x}).
$$</p><p>It is a piecewise linear function.</p><p>The maxout activation is a generalization of ReLU and leaky ReLU.
It is a learnable activation function.</p><p>The maxout neuron, therefore, enjoys all the benefits of ReLU (linear regime of operation, no saturation) and does not have its drawbacks (dying ReLU).</p><p>However, it increases the total number of parameters for each neuron and hence, a higher total number of parameters need to be trained.</p></section><section><h5 id="other-emerging-activation-functions">Other Emerging Activation Functions</h5><p>There are many other activation functions that are being developed and used in practice.</p><p>Gaussain Error Linear Unit (GELU),</p><p>$$
\text{GELU}(x) = x \Phi(x),
$$</p><p>where $\Phi(x)$ is the normal cumulative distribution function (CDF).</p><p>Softplus,</p><p>$$
\text{Softplus}(x) = \log(1 + \exp(x)).
$$</p><p>As a continuous and differentiable approximation to the ReLU function.</p><p>Swish,</p><p>$$
\text{Swish}(x) = x \cdot \text{sigmoid}(\beta x) = \frac{x}{1 + \exp(-\beta x)}.
$$</p><p>$\beta$ is either constant or a trainable parameter.</p></section></section><section><h4 id="training-an-mlp">Training an MLP</h4><p>For classification, we use the cross-entropy function as the loss.</p><ul>
<li>$\ell = -\sum_{j=1}^C y_j \log(\hat{y}_j)$
<ul>
<li>$y_j$ is 1 for the true class, and 0 otherwise.</li>
<li>$\hat{y}_j$ is the softmax output for the $j$-th class.</li>
</ul>
</li>
</ul><p>Use (stochastic) gradient descent as the optimization tool.</p><ul>
<li>$w_{ij} \leftarrow w_{ij} - \alpha \frac{\partial \ell}{\partial w_{ij}}$.
<ul>
<li>Layer $i$, node $j$.</li>
</ul>
</li>
<li>$\alpha$ is the learning rate, which controls convergence rate.
<ul>
<li>Too small → converges very slowly.</li>
<li>Too large → possibly does not converge.</li>
</ul>
</li>
</ul></section><section><h4 id="backpropagation-backward-propagation">Backpropagation (Backward Propagation)</h4><p>Backpropagation is the algorithm used to train neural networks.</p><p>We do a forward pass to calculate the prediction, and do a backward pass to update the weights that were responsible for an error.</p></section></section>
<section><h3 id="universal-approximation-theorem">Universal Approximation Theorem</h3><p>It can be shown that a sigmoid network with one hidden layer (of infinite nodes) is a unversial function approximator.</p><p>In terms of classification, this means neural netwroks with one hidden layer (of unbounded size) can represent any decision boundary and thus have infinite capacity.</p><p>It was also shown that deep networks can be more efficient at representing certain types of functions than shallow (single layer) networks.</p><p>It is not the specific choice of the activation function, but rather the mulit-layer feedforward architecture itself which gives neural networks the potential of being universal approximators.</p><p>It does not touch upon the algorithmic learnability of those parameters.</p></section>
<section><h3 id="gradient-descent-with-the-chain-rule">Gradient Descent with the Chain Rule</h3><p>Suppose we have a 2-layer network.</p><ul>
<li>$\ell$ is the cost function.</li>
<li>$g_1, g_2$ are the output functions of the two layers.
<ul>
<li>$g_j(\mathbf{x}) = f(\mathbf{W_j}^T \mathbf{x})$, and $\mathbf{W_1}, \mathbf{W_2}$ are the weight matrices.</li>
</ul>
</li>
<li>Prediction for input $\mathbf{x}$, $\hat{y} = g_2(g_1(\mathbf{x}))$.</li>
<li>Cost for input $\mathbf{x}$, $\ell(g_2(g_1(\mathbf{x})))$.</li>
</ul><p>If we apply the chain rule to get the gradients of the weights,</p><p>$$
\begin{aligned}
\frac{\partial \ell}{\partial \mathbf{W_2}} &#x26;= \frac{\partial \ell}{\partial g_2} \frac{\partial g_2}{\partial \mathbf{W_2}} \newline
\frac{\partial \ell}{\partial \mathbf{W_1}} &#x26;= \frac{\partial \ell}{\partial g_2} \frac{\partial g_2}{\partial g_1} \frac{\partial g_1}{\partial \mathbf{W_1}}.
\end{aligned}
$$</p><p>We can define a set of recursive relationships.</p><ol>
<li>Calculate the output of each node from the first layer to the last layer.</li>
<li>Calculate the gradient of each node from the first layer to the last layer.</li>
</ol><p><strong>NB</strong>
The gradients multiply in each layer!</p><p>If two gradients are small (&#x3C; 1), their product will be even smaller. This is the vanishing gradient problem.</p></section>
<section><h3 id="convolutional-neural-networks-cnn">Convolutional Neural Networks (CNN)</h3><p>CNNs are a type of neural network that is designed to recognize visual patterns directly from pixel images with minimal preprocessing.</p><p>Let’s see how we can combine images and neural networks.</p><section><h4 id="image-inputs-and-neural-networks">Image Inputs and Neural Networks</h4><p>In MLP (multi-layer perceptron), each node accepts all nodes in the previous layer.</p><p>For an image input, we first need to transform the image into a (flat) vector, which is the input to the network.</p><p>But this comes with a few problems.</p><ul>
<li>This ignores spatial relationships between pixels in the image.
<ul>
<li>Images contain local structures.
<ul>
<li>Groups of neighboring pixels correspond to visual structures (edges, corners, textures).</li>
<li>Pixels far from each other are typically not correlated.</li>
</ul>
</li>
</ul>
</li>
</ul></section><section><h4 id="from-fully-connected-to-convolutional-layer">From Fully Connected to Convolutional Layer</h4><p>Say we have an image of $32 \times 32 \times 3$ (RGB) image., if we were to stretch/flatten it, we would get $3072 \times 1$ input instead.</p><p>If we now have 10 classes, we would have a weight matrix of $10 \times 3072$.</p><p>This is a lot of parameters!</p><p>Instead, we can use a convolutional layer.
We preserve the original $32 \times 32 \times 3$ structure, this also preserves spatial structure.</p><p>But how would we even use these convolutional layers?</p><p>We use convolutional filters, which are small matrices that slide over the image.
Or, rather, we <strong>convolve</strong> the filter with the image, i.e., “slide over the image spatially”, computing dot products.</p><p>Note that filters always extend the full depth of the input volume.</p><section><h5 id="padding">Padding</h5><p>We have different types of padding,</p><ul>
<li>Valid Padding
<ul>
<li>No padding is added to the input image, the output image is smaller than the input image.</li>
</ul>
</li>
<li>Same padding
<ul>
<li>Padding is added to the input image, such that the size of the output image is the same as the input image.</li>
</ul>
</li>
<li>Full Padding
<ul>
<li>Padding is added to the input image, such that the size of the output image is greater than the input image.</li>
</ul>
</li>
<li>Constant Padding (including zero padding)
<ul>
<li>Add a border of constant-value pixels around the edges of the original image.</li>
</ul>
</li>
<li>Replicate Padding
<ul>
<li>The pixels of the padding are copied from the border values.</li>
</ul>
</li>
<li>Reflection Padding
<ul>
<li>The pixels at the edges of the image are mirrored to create a boundary of reflected pixels.</li>
</ul>
</li>
<li>Circular Padding
<ul>
<li>Copy the pixels at the dges of the images and append them to the opposite side of the image.</li>
</ul>
</li>
</ul></section><section><h5 id="spatial-subsampling">Spatial Subsampling</h5><p>We can reduce the feature map size by subsampling the feature maps.</p><p><em>Stride</em> for convolution filters - step size when moving the windows across the image.</p><p>Use the maximum over the pooling window.</p></section></section><section><h4 id="adding-back-mlp">Adding back MLP</h4><p>After several convolutional layers, input the feature map into an MLP to get the final classification.</p></section></section>
<section><h3 id="origin-of-convolution">Origin of Convolution</h3><p>As you have seen, I’ve not decided to go super in depth about CNNs, there are a lot of better resources to do that, but let’s dive into the origin of convolutions, since it is a very interesting topic.</p><section><h4 id="where-does-convolution-come-from">Where Does Convolution Come From?</h4><p>Convolution arises from the field of signal processing, which describes the output (In terms of the input) of an important class of operations (or systems) known as <em>linear-time-invariant</em> (LTI) systems.</p><p>A discrete-time signal such as $x[n]$ or $y[n]$ is described by an infinite sequence of values, i.e., the time index $n$ takes values in $-\infty$ to $\infty$.</p><p>The sequence of output values $y[\cdot]$ is the response of system $S$ to the input sequence $x[\cdot]$.</p></section><section><h4 id="time-invariant-systems">Time Invariant Systems</h4><p>Let $y[n]$ be the response of $S$ to the input $x[n]$.</p><p>If for all possible sequences $x[n]$ and integers $N$,</p><p>$$
S(x[n - N]) = y[n - N],
$$</p><p>then the system is said to be time-invariant.</p><p>then the system $S$ is said to be time-invariant (TI).</p><p>A time shift in the input sequence to $S$ results in an identical time shift of the output sequence.</p></section><section><h4 id="linear-systems">Linear Systems</h4><p>Let $y_1[n]$ be the response of $S$ to an arbitrary input $x_1[n]$ and $y_2[n]$ be the response to an arbitrary input $x_2[n]$.</p><p>If, for arbitrary scalar coefficients $a$ and $b$, we have,</p><p>$$
S(a x_1[n] + b x_2[n]) = a y_1[n] + b y_2[n],
$$</p><p>then the system $S$ is said to be linear.</p><p>If the input is the weighted sum of several signals, the response is the superposition (i.e., the same weighted sum) of the response to those signals.</p><p>One key consequence, if the input is identically 0 for a linear system, the output must also be identically 0.</p></section><section><h4 id="unit-sample-response">Unit Sample Response</h4><p>The unit sample response of a system is the response of the system to a unit impulse.</p><p>The unit impulse function is defined as,</p><p>$$
\delta[n] =
\begin{cases}
1, &#x26; \text{if } n = 0 \newline
0, &#x26; \text{otherwise}
\end{cases}.
$$</p><p>Which means that,</p><p>$$
\delta[n - N] =
\begin{cases}
1, &#x26; \text{if } n = N \newline
0, &#x26; \text{otherwise}
\end{cases}.
$$</p><p>We will always denote the unit sample response as $h[n]$.</p></section><section><h4 id="unit-sample-decomposition">Unit Sample Decomposition</h4><p>A discrete-time signal can be decomposed into a sum of time-shifted and scaled unit samples.</p><p>So, in general we can write,</p><p>$$
x[n] = \sum_{k = -\infty}^{\infty} x[k] \delta[n - k].
$$</p></section><section><h4 id="modeling-lti-systems">Modeling LTI Systems</h4><p>If system $S$ is both linear and time-invariant (LTI), then we can use the unit sample response to predict the response to any input waveform $x[n]$.</p><p>$$
\begin{aligned}
x[n] &#x26;= \sum_{k = -\infty}^{\infty} x[k] \delta[n - k] \newline
y[n] &#x26;= \sum_{k = -\infty}^{\infty} x[k] h[n - k]
\end{aligned}
$$</p><p>This is the convolution sum!</p></section><section><h4 id="discrete-convolution">Discrete Convolution</h4><p>Discrete convolution typically contains the following steps.</p><ol>
<li>List the index $k$ covering a sufficient range.</li>
<li>List the input $x[k]$.</li>
<li>Obtain the <strong>reversed</strong> sequence $h[-k]$, and align the rightmost element of $h[n - k]$ with the leftmost element of $x[k]$.</li>
<li>Cross-multiply and sum (i.e., dot product) the nonzero overlap terms to produce $y[n]$.</li>
<li>Slide $h[n - k]$ to the right by one position.</li>
<li>Repeat Steps 4 and 5. Stop if all the output values are zero of if required.</li>
</ol></section></section>
<section><h3 id="summary">Summary</h3><ul>
<li>Different types of neural networks.
<ul>
<li>Perceptron - single node (similar to logistic regression).</li>
<li>MLP - collection of perceptrons in layers.
<ul>
<li>Also called fully connected networks.</li>
</ul>
</li>
<li>CNN - Convolutional filters for extracting local image features.
<ul>
<li>Originates from LTI systems in signal processing.</li>
</ul>
</li>
</ul>
</li>
<li><strong>Training</strong>
<ul>
<li>Optimization using <em>variants</em> of stochastic gradient descent.</li>
</ul>
</li>
<li><strong>Advantages</strong>
<ul>
<li>Large capacity to learn from large amounts of data.</li>
</ul>
</li>
<li><strong>Disadvantages</strong>
<ul>
<li>Lots of parameters - easy to overfit data.
<ul>
<li>Need to <em>regularize</em> parameters.</li>
<li>Need to monitor the training process.</li>
</ul>
</li>
<li>Sensitive to initialization, learning rate, training algorithm.</li>
</ul>
</li>
</ul></section>


</body></html> </article> <div class="col-start-2"> <nav class="col-start-2 grid grid-cols-1 gap-4 sm:grid-cols-2"> <a href="/cityu/cs4487/cs4487_10" target="_self" class="duration-300 ease-in-out gap-2 whitespace-nowrap text-sm font-medium transition-all disabled:pointer-events-none disabled:opacity-50 [&#38;_svg]:pointer-events-none [&#38;_svg:not([class*='size-'])]:size-4 shrink-0 [&#38;_svg]:shrink-0 outline-none focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:ring-[3px] aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive border bg-background shadow-xs hover:bg-accent hover:text-accent-foreground dark:bg-input/30 dark:border-input dark:hover:bg-input/50 px-4 py-2 has-[>svg]:px-3 rounded-xl group flex items-center justify-start size-full" aria-disabled="false">  <svg width="1em" height="1em" viewBox="0 0 24 24" class="mr-2 size-4 transition-transform group-hover:-translate-x-1" data-icon="lucide:arrow-left">   <use href="#ai:lucide:arrow-left"></use>  </svg> <div class="flex flex-col items-start overflow-hidden text-wrap"> <span class="text-muted-foreground text-left text-xs">Next Post</span> <span class="w-full text-left text-sm text-ellipsis"> Part 10 - Neural Networks and Deep Learning Part 2 </span> </div>  </a> <a href="/cityu/cs4487/cs4487_8" target="_self" class="duration-300 ease-in-out gap-2 whitespace-nowrap text-sm font-medium transition-all disabled:pointer-events-none disabled:opacity-50 [&#38;_svg]:pointer-events-none [&#38;_svg:not([class*='size-'])]:size-4 shrink-0 [&#38;_svg]:shrink-0 outline-none focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:ring-[3px] aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive border bg-background shadow-xs hover:bg-accent hover:text-accent-foreground dark:bg-input/30 dark:border-input dark:hover:bg-input/50 px-4 py-2 has-[>svg]:px-3 rounded-xl group flex items-center justify-end size-full" aria-disabled="false">  <div class="flex flex-col items-end overflow-hidden text-wrap"> <span class="text-muted-foreground text-right text-xs">Previous Post</span> <span class="w-full text-right text-sm text-ellipsis"> Part 8 - Principal Component Analysis </span> </div> <svg width="1em" height="1em" viewBox="0 0 24 24" class="ml-2 size-4 transition-transform group-hover:translate-x-1" data-icon="lucide:arrow-right">   <use href="#ai:lucide:arrow-right"></use>  </svg>  </a> </nav> </div> <div class="col-start-2"> <div class="giscus"></div> <script data-astro-rerun src="https://giscus.app/client.js" data-repo="rezaarezvan/rezarezvan.com" data-repo-id="R_kgDOHvQr3w" data-category="General" data-category-id="DIC_kwDOHvQr384CiWVC" data-mapping="pathname" data-strict="0" data-reactions-enabled="1" data-emit-metadata="0" data-input-position="bottom" data-theme="preferred_color_scheme" data-lang="en" data-loading="lazy" crossorigin="anonymous" async></script> </div> </section> <button data-slot="button" class="items-center justify-center gap-2 whitespace-nowrap rounded-md text-sm font-medium transition-all disabled:pointer-events-none disabled:opacity-50 [&amp;_svg]:pointer-events-none [&amp;_svg:not([class*=&#x27;size-&#x27;])]:size-4 shrink-0 [&amp;_svg]:shrink-0 outline-none focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:ring-[3px] aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive border bg-background shadow-xs hover:bg-accent hover:text-accent-foreground dark:bg-input/30 dark:border-input dark:hover:bg-input/50 size-9 group fixed right-8 bottom-8 z-50 hidden" id="scroll-to-top" title="Scroll to top" aria-label="Scroll to top"> <svg width="1em" height="1em" class="mx-auto size-4 transition-all group-hover:-translate-y-0.5" data-icon="lucide:arrow-up">   <symbol id="ai:lucide:arrow-up" viewBox="0 0 24 24"><path fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="m5 12l7-7l7 7m-7 7V5"/></symbol><use href="#ai:lucide:arrow-up"></use>  </svg> </button> <script type="module">document.addEventListener("astro:page-load",()=>{const o=document.getElementById("scroll-to-top"),t=document.querySelector("footer");o&&t&&(o.addEventListener("click",()=>{window.scrollTo({top:0,behavior:"smooth"})}),window.addEventListener("scroll",()=>{const e=t.getBoundingClientRect().top<=window.innerHeight;o.classList.toggle("hidden",window.scrollY<=300||e)}))});</script>  </div> </main> <footer class="py-4"> <div class="mx-auto flex max-w-3xl flex-col items-center justify-center gap-y-2 px-4 sm:flex-row sm:justify-between"> <div class="flex flex-wrap items-center justify-center gap-x-2 text-center"> <span class="text-muted-foreground text-sm">
&copy; 2025 • rezarezvan.com </span> </div> </div> </footer> <div id="backdrop" class="invisible fixed top-0 left-0 z-50 flex h-screen w-full justify-center bg-[rgba(0,0,0,0.5)] p-6 backdrop-blur-sm" data-astro-transition-persist="astro-t6dxx5el-4"> <div id="pagefind-container" class="m-0 flex h-fit max-h-[80%] w-full max-w-screen-sm flex-col overflow-auto rounded border border-black/15 bg-neutral-100 p-2 px-4 py-3 shadow-lg dark:border-white/20 dark:bg-neutral-900"> <div id="search" class="pagefind-ui pagefind-init" data-pagefind-ui data-bundle-path="/pagefind/" data-ui-options="{&#34;showImages&#34;:false,&#34;excerptLength&#34;:15,&#34;resetStyles&#34;:false}"></div> <script type="module" src="/_astro/Search.astro_astro_type_script_index_0_lang.mBpmxV9R.js"></script> <div class="dark:prose-invert mr-2 pt-4 pb-1 text-right text-xs">
Press <span class="prose dark:prose-invert text-xs"><kbd class="">Esc</kbd></span> or click anywhere to close
</div> </div> </div> <script>
  document.addEventListener('DOMContentLoaded', () => {
    const magnifyingGlass = document.getElementById('magnifying-glass')
    const backdrop = document.getElementById('backdrop')

    function openPagefind() {
      const searchDiv = document.getElementById('search')
      const search = searchDiv.querySelector('input')
      setTimeout(() => {
        search.focus()
      }, 0)
      backdrop?.classList.remove('invisible')
      backdrop?.classList.add('visible')
    }

    function closePagefind() {
      const searchDiv = document.getElementById('search')
      const search = searchDiv.querySelector('input')
      if (search) {
        search.value = ''
      }
      backdrop?.classList.remove('visible')
      backdrop?.classList.add('invisible')
    }

    // open pagefind
    magnifyingGlass?.addEventListener('click', () => {
      openPagefind()
    })

    document.addEventListener('keydown', (e) => {
      if (e.key === 'Escape') {
        closePagefind()
      }
    })

    // close pagefind when searched result(link) clicked
    document.addEventListener('click', (event) => {
      if (event.target.classList.contains('pagefind-ui__result-link')) {
        closePagefind()
      }
    })

    backdrop?.addEventListener('click', (event) => {
      if (!event.target.closest('#pagefind-container')) {
        closePagefind()
      }
    })

    // prevent form submission
    const form = document.getElementById('form')
    form?.addEventListener('submit', (event) => {
      event.preventDefault()
    })
  })
</script>  </div> </body></html>