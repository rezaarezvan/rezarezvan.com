<!DOCTYPE html>
<html><head lang="en">
	<meta charset="utf-8" />
	<meta http-equiv="X-UA-Compatible" content="IE=edge"><title>DSA: Part 10 - Complexity (2) - rezvan</title><link rel="icon" type="image/png" href=images/icon.png /><meta name="viewport" content="width=device-width, initial-scale=1">
	<meta name="description" content="We have actually covered everything in this course - in this part we&rsquo;ll do some exercises!
Order of growth of Functions Let&rsquo;s find out the complexity ($\mathcal{O}$) of: $$ T(n) = 5(3n^2 &#43; 2n &#43; 6)(4\ log_{10}(n) &#43; 1) $$
Since we seek the growth rate - we can use our rules about complexity. We can remove all constants: $$ T(n) = (n^2 &#43; n)(log_{10}(n)) $$
The next rule we can apply is, &ldquo;the most dominating factor &lsquo;wins&rsquo;&rdquo; as I like to call it." />
	<meta property="og:image" content=""/>
	<meta property="og:title" content="DSA: Part 10 - Complexity (2)" />
<meta property="og:description" content="We have actually covered everything in this course - in this part we&rsquo;ll do some exercises!
Order of growth of Functions Let&rsquo;s find out the complexity ($\mathcal{O}$) of: $$ T(n) = 5(3n^2 &#43; 2n &#43; 6)(4\ log_{10}(n) &#43; 1) $$
Since we seek the growth rate - we can use our rules about complexity. We can remove all constants: $$ T(n) = (n^2 &#43; n)(log_{10}(n)) $$
The next rule we can apply is, &ldquo;the most dominating factor &lsquo;wins&rsquo;&rdquo; as I like to call it." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://rezvan.xyz/school/DSA_10/" /><meta property="article:section" content="school" />
<meta property="article:published_time" content="2022-12-09T18:49:03+01:00" />
<meta property="article:modified_time" content="2022-12-09T18:49:03+01:00" />
<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="DSA: Part 10 - Complexity (2)"/>
<meta name="twitter:description" content="We have actually covered everything in this course - in this part we&rsquo;ll do some exercises!
Order of growth of Functions Let&rsquo;s find out the complexity ($\mathcal{O}$) of: $$ T(n) = 5(3n^2 &#43; 2n &#43; 6)(4\ log_{10}(n) &#43; 1) $$
Since we seek the growth rate - we can use our rules about complexity. We can remove all constants: $$ T(n) = (n^2 &#43; n)(log_{10}(n)) $$
The next rule we can apply is, &ldquo;the most dominating factor &lsquo;wins&rsquo;&rdquo; as I like to call it."/>
<script src="https://cdn.jsdelivr.net/npm/feather-icons/dist/feather.min.js"></script>
	<link href="https://fonts.googleapis.com/css2?family=IBM+Plex+Mono:ital,wght@1,500&display=swap" rel="stylesheet">
        <link href="https://fonts.googleapis.com/css2?family=Fira+Sans&display=swap" rel="stylesheet">
        <link href="https://fonts.googleapis.com/css?family=Roboto+Mono" rel="stylesheet">

	
	<link rel="stylesheet" type="text/css" media="screen" href="https://rezvan.xyz/css/main.ded288734bf67c9f89d72102879afaadf50fed4138fb485737334085f5465104.css" />
		<link id="darkModeStyle" rel="stylesheet" type="text/css" href="https://rezvan.xyz/css/dark.b47837a877382f31178bb7a2c2135fbe9c39b1d4a1cc529faee0363b6dbdc408.css"  disabled />
	

	
	
		<script type="text/javascript"
		src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
		</script>
	
		
		<script type="text/x-mathjax-config">
		MathJax.Hub.Config({
			tex2jax: {
				inlineMath: [['$','$'], ['\\(','\\)']],
				displayMath: [['$$','$$'], ['\[','\]']],
				processEscapes: true,
				processEnvironments: true,
				skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
				TeX: { equationNumbers: { autoNumber: "AMS" },
						 extensions: ["AMSmath.js", "AMSsymbols.js"] }
			}
		});
		</script>
	

	
	
		<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.css">
		<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.js"></script>
		<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/contrib/auto-render.min.js" onload="renderMathInElement(document.body);"></script>
		
		
		<script>
			document.addEventListener("DOMContentLoaded", function() {
					renderMathInElement(document.body, {
							delimiters: [
									{left: "$$", right: "$$", display: true},
									{left: "$", right: "$", display: false}
							]
					});
			});
			</script>
	
	
	
</head>
<body>
        <div class="content"><header>
	<div class="main">
		<a href="https://rezvan.xyz/">rezvan</a>
	</div>
	<nav>
		
		<a href="/">home</a>
		
		<a href="/about">about</a>
		
		<a href="/contact">contact</a>
		
		<a href="/cv">cv</a>
		
		<a href="/school">school</a>
		
		<a href="/tags">tags</a>
		
		| <span id="dark-mode-toggle" onclick="toggleTheme()"></span>
		<script src="https://rezvan.xyz/js/themetoggle.js"></script>
		
	</nav>
</header>

<main>
	<article>
		<div class="title">
			<h1 class="title">DSA: Part 10 - Complexity (2)</h1>
			<div class="meta">Posted on Dec 9, 2022</div>
		</div>
		

		<section class="body">
			<p>We have actually covered everything in this course - in this part we&rsquo;ll do some exercises!</p>
<h3 id="order-of-growth-of-functions">Order of growth of Functions</h3>
<p>Let&rsquo;s find out the complexity ($\mathcal{O}$) of:
$$
T(n) = 5(3n^2 + 2n + 6)(4\ log_{10}(n) + 1)
$$</p>
<p>Since we seek the growth rate - we can use our rules about complexity. We can remove all constants:
$$
T(n) = (n^2 + n)(log_{10}(n))
$$</p>
<p>The next rule we can apply is, &ldquo;the most dominating factor &lsquo;wins&rsquo;&rdquo; as I like to call it. Therefore:
$$
T(n) = (n^2)(log_{10}(n))
$$</p>
<p>Then we just multiply!
$$
T(n) = n^2\ log_{10}(n)
$$</p>
<p>And since we usually write $log$ when using Big-O notation:
$$
T(n) =  n^2\ log(n)
$$</p>
<p>Now we can say that $T(n)$ has a $\mathcal{O}(n^2\ log(n))$ complexity!. Since we are talking about $\mathcal{O}$, this means this function has a <strong>lower</strong> bound of this. This means that $T(n)$ also has a complexity of $\mathcal{O}(n^3)$ for example.</p>
<p>So what we <em>really</em> mean is that $T(n)$ has a $\Theta(n^2\ log(n))$ complexity.</p>
<p><strong>Suppose an algorithm takes time <em>t</em> on an input of size <em>n</em>. How many times longer does it take on an input of size 10n if&hellip;</strong></p>
<ul>
<li>
<p>If the algorithm is $\Theta(n)$?</p>
</li>
<li>
<p>If the algorithm is $\Theta(n^2)$?</p>
</li>
<li>
<p>If the algorithm is $\Theta(n^3)$?</p>
</li>
<li>
<p>If the algorithm is $\Theta(n\ log(n))$?</p>
</li>
<li>
<p>If the algorithm is $\Theta(log(n))$?</p>
</li>
</ul>
<p>This is quite easy! We just plug in our new $n$, and see how much $t$ grows!</p>
<ul>
<li>
<p>If the algorithm is $\Theta(n)$?</p>
<ul>
<li>We get $10n \rightarrow 10t$!</li>
</ul>
</li>
<li>
<p>If the algorithm is $\Theta(n^2)$?</p>
<ul>
<li>We get $100n \rightarrow 100t$!</li>
</ul>
</li>
<li>
<p>If the algorithm is $\Theta(n^3)$?</p>
<ul>
<li>We get $1000n \rightarrow 1000t$!</li>
</ul>
</li>
<li>
<p>If the algorithm is $\Theta(n\ log(n))$?</p>
<ul>
<li>
<p>We get $10n\ \cdot log(10n)$!</p>
</li>
<li>
<p>This isn&rsquo;t just $10 log(10)&quot; times more - it&rsquo;s a <em>little</em> bit longer, or so called &ldquo;logarithmic linear&rdquo;.</p>
</li>
</ul>
</li>
<li>
<p>If the algorithm is $\Theta(log(n))$?</p>
<ul>
<li>
<p>We get $log(10n)$!</p>
</li>
<li>
<p>This means just a constant <strong>more</strong> time!</p>
</li>
</ul>
</li>
</ul>
<h3 id="complexity-analysis">Complexity Analysis</h3>
<p>Let&rsquo;s analyze the following snippet of code and it&rsquo;s complexity.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-fallback" data-lang="fallback"><span style="display:flex;"><span>found = false
</span></span><span style="display:flex;"><span>for x in list:
</span></span><span style="display:flex;"><span>    for y in list:
</span></span><span style="display:flex;"><span>        if x + y == 0:
</span></span><span style="display:flex;"><span>            found = true
</span></span></code></pre></div><p>If we say that the length of <code>list</code> is $n$. In the first loop we will have a complexity of $\mathcal{O}(n)$.
The inner loop will follow, using our previous rule of &rsquo;nested loops means multiplication&rsquo;.
This means our final program will have the complexity of $\mathcal{O}(n^2)$.</p>
<p>Now let&rsquo;s see over this code snippet:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-fallback" data-lang="fallback"><span style="display:flex;"><span>found = false
</span></span><span style="display:flex;"><span>for i in 0 .. n - 1:
</span></span><span style="display:flex;"><span>    for j in i .. n - 1:
</span></span><span style="display:flex;"><span>        x = list[i]
</span></span><span style="display:flex;"><span>        y = list[j]
</span></span><span style="display:flex;"><span>        if x + y == 0:
</span></span><span style="display:flex;"><span>            found = true
</span></span></code></pre></div><p>In this snippet - we&rsquo;ll have the first loop iterating $n$ times -
however, the second loop, it will iterate $(0, \dots ,n -1), (1, \dots , n - 2), \dots$</p>
<p>This means that the number of times the second loop will run is between 1 and $n$ times - using our definition of complexity.
Let&rsquo;s call the number of times our loop runs $m$, $m \leq n$ which means m has an complexity of $\mathcal{O}(n)$.</p>
<p>This finally means we have a total complexity of $\mathcal{O}(n^2)$</p>
<p>Now let&rsquo;s do the same, but for three numbers!</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-fallback" data-lang="fallback"><span style="display:flex;"><span>found = false
</span></span><span style="display:flex;"><span>for i in 0 .. n - 1:
</span></span><span style="display:flex;"><span>    for j in i .. n - 1:
</span></span><span style="display:flex;"><span>        for k in j .. n - 1:
</span></span><span style="display:flex;"><span>            x = list[i]
</span></span><span style="display:flex;"><span>            y = list[j]
</span></span><span style="display:flex;"><span>            z = list[k]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>            if x + y + z == 0:
</span></span><span style="display:flex;"><span>                found = true
</span></span></code></pre></div><p>Exactly the same logic goes as from the last question to this, we can prove that each loop has a complexity of $\mathcal{O}(n)$.</p>
<p>Which gives the total complexity of $\mathcal{O}(n^3)$.</p>
<p>Now let&rsquo;s look at a similar program:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-fallback" data-lang="fallback"><span style="display:flex;"><span>pairs_list = []
</span></span><span style="display:flex;"><span>for i in 0 .. n - 1:
</span></span><span style="display:flex;"><span>    for j in i .. n - 1:
</span></span><span style="display:flex;"><span>        x = list[i]
</span></span><span style="display:flex;"><span>        y = list[j]
</span></span><span style="display:flex;"><span>        pairs_list.add(x + y)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>found = false
</span></span><span style="display:flex;"><span>for xplusy in pairs_list:
</span></span><span style="display:flex;"><span>    for zplusw in pairs_list:
</span></span><span style="display:flex;"><span>        if xplusy + zplusw == 0:
</span></span><span style="display:flex;"><span>            found = true
</span></span></code></pre></div><p>As we&rsquo;ve have stated above, the first part of the program will have a complexity of $\mathcal{O}(n^2)$.
Note that the <code>add()</code> function takes $\mathcal{O}(1)$ for dynamic arrays.</p>
<p>However, in the next block, the new array length is $n^2$, since we have added all possible permutations of pairs.
So the loops will now through $n^2$ elements. Which in total results a complexity of $\mathcal{O}(n^4)$.</p>
<p>From our earlier rules, we &lsquo;add&rsquo; blocks of codes, so the complexity is $\mathcal{O}(n^2) + \mathcal{O}(n^4)$.
Which means the resulting complexity becomes $\mathcal{O}(n^4)$.</p>
<h3 id="data-structure-complexities">Data Structure Complexities</h3>
<p>Let&rsquo;s refresh our memory and state all the complexities for our data structures and their functions.</p>
<ul>
<li>
<p>Dynamic Arrays:</p>
<ul>
<li>
<p>Get/Set:</p>
<ul>
<li>$\mathcal{O}(1)$</li>
</ul>
</li>
<li>
<p>Add/Remove <strong>at end</strong>:</p>
<ul>
<li>$\mathcal{O}(1)$</li>
</ul>
</li>
<li>
<p>Add/remove <strong>elsewhere</strong>:</p>
<ul>
<li>$\mathcal{O}(n)$</li>
</ul>
</li>
</ul>
</li>
<li>
<p>Stacks/queues:</p>
<ul>
<li>
<p>Push/Pop:</p>
<ul>
<li>$\mathcal{O}(1)$</li>
</ul>
</li>
<li>
<p>Enqueue/Dequeue:</p>
<ul>
<li>$\mathcal{O}(1)$</li>
</ul>
</li>
</ul>
</li>
<li>
<p>Binary Heaps:</p>
<ul>
<li>
<p>Add/RemoveMin (or Max):</p>
<ul>
<li>$\mathcal{O}(log(n))$</li>
</ul>
</li>
<li>
<p>getMin (or Max):</p>
<ul>
<li>$\mathcal{O}(1)$</li>
</ul>
</li>
</ul>
</li>
<li>
<p>BSTs:</p>
<ul>
<li>
<p>Add/Remove/Search (worst case, meaning it&rsquo;s already sorted):</p>
<ul>
<li>$\mathcal{O}(n)$</li>
</ul>
</li>
<li>
<p>Otherwise:</p>
<ul>
<li>$\mathcal{O}(log(n))$</li>
</ul>
</li>
</ul>
</li>
<li>
<p>Stacks/queues:</p>
<ul>
<li>Add/Remove/Search (Always!):
<ul>
<li>$\mathcal{O}(log(n))$</li>
</ul>
</li>
</ul>
</li>
<li>
<p>Hash Tables:</p>
<ul>
<li>Add/Remove/Search (Given that the hash function is &lsquo;good&rsquo;):
<ul>
<li>$\mathcal{O}(1)$</li>
</ul>
</li>
</ul>
</li>
<li>
<p>General Tree:</p>
<ul>
<li>
<p>If you <strong>down</strong> in a tree, you&rsquo;ll visit:</p>
<ul>
<li>$\mathcal{O}(height)$ nodes</li>
</ul>
</li>
<li>
<p>If you explore every node, you&rsquo;ll visit:</p>
<ul>
<li>$\mathcal{O}(n)$ nodes</li>
</ul>
</li>
<li>
<p>A tree has the <strong>worst</strong> case $\mathcal{O}(n)$ height.</p>
</li>
<li>
<p>A <strong>balanced</strong> tree is <strong>always</strong> $\mathcal{O}(log(n))$ height.</p>
</li>
</ul>
</li>
</ul>
<h3 id="analyzing-more-complexities">Analyzing more complexities</h3>
<p>Let&rsquo;s take a look at program which utilise different data structures now:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-fallback" data-lang="fallback"><span style="display:flex;"><span>pairs_list = []
</span></span><span style="display:flex;"><span>for i in 0 .. n - 1:
</span></span><span style="display:flex;"><span>    for j in i .. n - 1:
</span></span><span style="display:flex;"><span>        x = list[i]
</span></span><span style="display:flex;"><span>        y = list[j]
</span></span><span style="display:flex;"><span>        pairs_list.add(x + y)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>merge_sort(pairs_list)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>found = false
</span></span><span style="display:flex;"><span>for xplusy in pairs_list:
</span></span><span style="display:flex;"><span>    if binary_search(pairs_list, -xplusy):
</span></span><span style="display:flex;"><span>        found = true
</span></span></code></pre></div><p>So, we&rsquo;ve seen that first part, we know it&rsquo;s $\mathcal{O}(n^2)$.
But now we see a <code>merge_sort()</code> - this has a complexity of $\mathcal{O}(n\ log(n))$.
As we stated before, the list after the first block has a length of $n^2$.
Which means <code>merge_sort()</code> will have a complexity of $\mathcal{O}(n^2\ log(n^2))$</p>
<p>This will just sort it so no length is added.</p>
<p>Then the next block, the for loop will have a complexity of $\mathcal{O}(n^2)$.
The binary search algorithm, has a complexity of $\mathcal{O}(log(n^2))$.</p>
<p>So this block will in total have a complexity of $\mathcal{O}(n^2\ log(n^2))$.</p>
<p>So if we add these blocks together and apply our rules we will get a total complexity of:
$\mathcal{O}(n^2\ log(n^2))$. We can apply some log rules to this:
$$
\mathcal{O}(n^2\ log(n^2))
\newline
\mathcal{O}(n^2\ 2\ log(n))
\newline
\mathcal{O}(n^2\ log(n))
$$</p>
<p>So finally our answer is, $\mathcal{O}(n^2 log(n))$</p>
<p>Let&rsquo;s now look at a case using a tree:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-fallback" data-lang="fallback"><span style="display:flex;"><span>pairs_set = empty AVL_tree
</span></span><span style="display:flex;"><span>for i in 0 .. n - 1:
</span></span><span style="display:flex;"><span>    for j in i .. n - 1:
</span></span><span style="display:flex;"><span>        x = pairs_set[i]
</span></span><span style="display:flex;"><span>        y = pairs_set[j]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        if pairs_set.contains(-(x+y)):
</span></span><span style="display:flex;"><span>            return true
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        pairs_set.add(x+y)
</span></span></code></pre></div><p>As we&rsquo;ve seen before, the loops are $\mathcal{O}(n^2)$ - now the interesting part is the <code>contains()</code> to check if an element is present.
To check whether an element is present in a tree, has a complexity of $\mathcal{O}(log(n))$.
The rest of the operations are constant so we can ignore them (including the <code>add()</code> for the AVL tree).</p>
<p>So therefore the final complexity is $\mathcal{O}(n^2\ log(n))$. In the absolute worst case the <code>contains()</code> will be $\mathcal{O}(n)$, but let&rsquo;s ignore that :).</p>
<p>Now let&rsquo;s look at a hash table:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-fallback" data-lang="fallback"><span style="display:flex;"><span>pairs_set = empty Hash_table
</span></span><span style="display:flex;"><span>for i in 0 .. n - 1:
</span></span><span style="display:flex;"><span>    for j in i .. n - 1:
</span></span><span style="display:flex;"><span>        x = pairs.set[i]
</span></span><span style="display:flex;"><span>        y = pairs_set[j]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        if pairs_set.contains(-(x + y)):
</span></span><span style="display:flex;"><span>            return true
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        pairs_set.add(x + y)
</span></span></code></pre></div><p>As per usual, the loops makes this $\mathcal{O}(n^2)$, now, a search in a hash table is $\mathcal{O}(1)$, if our hash function is &lsquo;good&rsquo;.</p>
<p>The rest of the operations are constant. So therefore the overall complexity is $\mathcal{O}(n^2)$.</p>
<p>Now let&rsquo;s look at a BST example:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-fallback" data-lang="fallback"><span style="display:flex;"><span>pairs_set = empty BST
</span></span><span style="display:flex;"><span>for i in 0 .. n - 1:
</span></span><span style="display:flex;"><span>    for j in i .. n - 1:
</span></span><span style="display:flex;"><span>        x = pairs_set[i]
</span></span><span style="display:flex;"><span>        y = pairs_set[j]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        if pairs_set.contains(-(x + y)):
</span></span><span style="display:flex;"><span>            return true
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        pairs_set.add(x + y)
</span></span></code></pre></div><p>The usual $\mathcal{O}(n^2)$ loops :). Now the <code>contains()</code> is the interesting part.
Since this is a BST, the <code>contains()</code> will have a complexity of $\mathcal{O}(n)$ in the worst case, since the BST can become unbalanced.</p>
<p>The same applies for <code>add()</code>. Since the rest of the operations are constant so therefore it will be, $\mathcal{O}(n^4)$.</p>
<h3 id="different-kinds-of-complexiites">Different kinds of complexiites</h3>
<p>We also need to consider the different cases</p>
<ul>
<li>
<p>Best-case</p>
<ul>
<li>This is not useful.</li>
</ul>
</li>
<li>
<p>Worst-case</p>
<ul>
<li>This is the most useful.</li>
</ul>
</li>
<li>
<p>Average-case</p>
<ul>
<li>Can be useful sometimes, mostly gives us a &lsquo;indicator&rsquo;.</li>
</ul>
</li>
</ul>
<p>Let&rsquo;s now talk about <strong>expected</strong> and <strong>amortised</strong> complexity.</p>
<h4 id="expected-complexity">Expected Complexity</h4>
<p>This is useful for randomised algorithms! It&rsquo;s the average over all possible random choice for a particular input.</p>
<p>For example, if we choose a random pivot, we turn quicksort from average-case $\mathcal{O}(n\ log(n))$ to expected $\mathcal{O}(n\ log(n))$</p>
<h4 id="amortised-complexity">Amortised Complexity:</h4>
<p>Amortised complexity is, the average over any sequence of operations, this is super useful!</p>
<p>For example, we use this to make dynamic arrays have a amortised complexity of $\mathcal{O}(1)$.</p>
<p>However, when we&rsquo;re calculating the total runtime of a program, it&rsquo;s safe to forget about this amortised bit and just treat each operation as costing $\mathcal{O}(1)$.</p>
<h3 id="conclusion">Conclusion</h3>
<p>This was it for this part - and the final part in this series. I really enjoyed this DSA course, super fun :).</p>

		</section>

		<div class="post-tags">
			
			
			<nav class="nav tags">
				<ul class="tags">
					
					<li><a href="/tags/Data-Structures-Algorithms">Data Structures &amp; Algorithms</a></li>
					
				</ul>
			</nav>
			
			
		</div>
		</article>
</main>
<footer>
    <div style="display:flex"><a class="soc" href="https://github.com/rezaarezvan" rel="me" title="GitHub"><i data-feather="github"></i></a>
        <a class="border"></a><a class="soc" href="https://twitter.com/rzvan__/" rel="me" title="Twitter"><i data-feather="twitter"></i></a>
        <a class="border"></a></div><p class="footer_msg">memento mori</p></footer>


<script>
    feather.replace()
</script></div>
    </body>
</html>
