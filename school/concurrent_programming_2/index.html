<!DOCTYPE html>
<html>
<head>
	<meta charset="utf-8"><meta property="og:site_name" content="rezvan"><title>Concurrent Programming: Part 2 - Races, Locks, and Semaphores | rezvan</title>
  <meta property="og:title" content="Concurrent Programming: Part 2 - Races, Locks, and Semaphores | rezvan"><meta property="og:description" content="">
  <meta property="og:type" content="blog">
  <meta property="og:link" content="https://rezvan.xyz/school/concurrent_programming_2/"><link rel="shortcut icon" type="image/png" href=https://rezvan.xyz//images/icon.png />
  <meta property="og:image" content="https://rezvan.xyz//images/icon.png" /><meta name="viewport" content="width=device-width, initial-scale=1">
	<link rel="stylesheet" type="text/css" media="screen" href="https://rezvan.xyz//css/main.css" />    
</head>

<body>
  <div class="wrapper">
	<div class="content">
		<div class="header_main">

    <a href="https://rezvan.xyz/"><p class="header_title">rezvan</p>
    </a>

    <br>

    <nav id="main">
        
        <a href="/About/">About</a>
        
        <a href="/CV/">CV</a>
        
        <a href="/school/">School</a>
        
    </nav></div>

  <article><div class="title_wrapper">
			<h1 class="title">Concurrent Programming: Part 2 - Races, Locks, and Semaphores</h1><p class="single_time">Jan 19, 2023</p></div>
		<section class="post">
			<p>In the last part we covered the basics and some principles for concurrent programs.
In this part we&rsquo;ll cover how we define concurrent problems, the outcome we want and some solutions.</p>
<h3 id="races">Races</h3>
<p>As we saw in the last part - a different trace leads to a different outcome -
this means that concurrent programs are <em>non-deterministic</em>.</p>
<p>Why concurrent programs are non-deterministic is due to the scheduler&rsquo;s decisions.</p>
<p>When we have a problem with different possible outcomes, we need to label what is a faulty run and a successful run.</p>
<p>A <strong>race condition</strong> is a situation where the correctness of a concurrent program depends on the specific execution.
If we try to define this a bit easier, since concurrent programs can are non-deterministic, this means we have to &ldquo;race&rdquo; the program.</p>
<p>There are different types of race-conditions. A data race is one example.</p>
<p>A data race is a when two (or more) threads access a shared memory location and where at least one access is a <em>write</em>.
The threads use no synchronization mechanism to protect said data.</p>
<p>A simple example is the counter program, in the case where the program spat out 1, instead of 2, it was due to this data race.</p>
<p>One thing to note is that: Not every race-condition is a data race and not every data is a race-condition either.</p>
<p>The first one is quite intuitive, the race isn&rsquo;t always about data, it can be an access call to files/network.
The latter is not clear from the start, but there is a simple explanation.
A data race might not <em>always</em> affect the result, therefore it might not be a race condition.</p>
<h3 id="synchronization-problems">Synchronization problems</h3>
<p>Now that we&rsquo;ve seen how we can outline the problem, lets where the problem stems from and how we can identify where in code.</p>
<p>We call the part of a program where threads access the shared resource a <strong>critical section</strong>.
It&rsquo;s quite obvious that no more than 1 thread should be in this critical section at a time.
We call this property the <strong>mutual exclusion property</strong>. Therefore, we can call this concurrent program problem for <strong>mutual exclusion problem</strong>.</p>
<p>Let&rsquo;s define some more technical terms to this mutual exclusion property as well. A <strong>deadlock</strong> is when the program/group of threads can&rsquo;t proceed further.
For example, if we have 10 threads, <code>t1, t2, t3, ... , t10</code>. If <code>t10</code> has to wait for <code>t9</code> and <code>t9</code> for <code>t8</code> and so on. If <code>t1</code>happens to be stuck, we achieve a so-called deadlock.
A good example is the <a href="https://en.wikipedia.org/wiki/Dining_philosophers_problem">dining philosophers problem</a>. Many times deadlocks are created from &lsquo;circular dependency&rsquo; problems.</p>
<p><strong>Starvation</strong> is when we have threads trying to enter the critical section, but never succeeds. So we have threads that are &ldquo;starved&rdquo; from entering the critical section.</p>
<p>A <strong>good solution</strong> to the mutual exclusion property solves all these invariants. Note, freedom from starvation implies freedom from deadlock as well!</p>
<p>To solve starvation, we need to become <em>fair</em>, <strong>fairness</strong> is a situation where all threads that request to enter the critical section <em>eventually</em> gets it.</p>
<p>Alright, now we have clearly defined the outline of the problem, the problem and each &lsquo;sub-problem&rsquo;. Let&rsquo;s look at how we can achieve a good solution.</p>
<h3 id="locks">Locks</h3>
<p>Locks are one of (if not the simplest) synchronization mechanism that can ensure a good solution to the mutual exclusion property.</p>
<p>A lock (interface) can be described as:</p>
<pre tabindex="0"><code>interface Lock {

    // Acquire lock
    void lock();

    // Release lock
    void unlock();
}
</code></pre><p>It&rsquo;s a quite simple to see how we can use this:</p>
<pre tabindex="0"><code>int cnt;

lock.lock();
    cnt = counter;
    counter = cnt + 1;
lock.unlock()
</code></pre><p>This <strong>ensures</strong> exactly one lock gets the lock and, after it&rsquo;s finished, another lock will acquire it and so on. In this simple program, it will become sequential even, but that&rsquo;s besides the point.</p>
<p>The idea of locks still ensures a solution for the mutual exclusion problem.</p>
<h3 id="semaphores">Semaphores</h3>
<p>Semaphores are a further generalization of locks. Instead of the only possible states being <code>locked</code> and <code>unlocked</code> (one can see this as 0 and 1). We have a counting mechanism:</p>
<pre tabindex="0"><code>interface Semaphore {

    // current value of counter
    int count();

    // increment counter
    void up();

    // decrement counter
    void down();
}
</code></pre><p>When we initialize a semaphore, it is set to a non-negative value, <code>C</code>, which is the capacity.
When we call <code>sem.up()</code>, we increment <code>C</code>by one.
A call to <code>sem.down()</code>, first <strong>wait</strong> until <code>C</code> is positive, and then <em>uninterruptedly</em> decrements the value of <code>C</code> by one.</p>
<p>Let&rsquo;s look at the counter program with semaphores now:</p>
<pre tabindex="0"><code>int cnt;

sem.down();
    cnt = counter;
    counter = cnt + 1;
sem.up();
</code></pre><p>As we can see, it&rsquo;s really similar. But how do we &lsquo;wait until <code>C</code>is positive&rsquo;?</p>
<p>We need to understand something called <em>invariant</em> first.</p>
<p>An <em>invariant</em> is a <em>property</em> that always holds between method calls. The invariant should hold initially, at the beginning of a method call, and at the end of it.</p>
<p>A good example is, a bank account should never become negative, when you create an account it should hold true. Also when you make an transaction.</p>
<p>A semaphore, with capacity <code>C</code> satifies the invariant:</p>
<pre tabindex="0"><code>invariant{
    count() &gt;= 0;
    count() == C + # of calls to up - # of calls to down;
}
</code></pre><p>This makes sense, we shouldn&rsquo;t ever go past 0, and the number of calls to the up and down methods, should correspond to the current count number.</p>
<p>A special semaphore case is when we have capacity 1, (0 and 1), this is called a <strong>binary</strong> semaphore and are essentially the same as locks.</p>
<p>The only difference is that, in a lock, the thread with the lock is the <strong>only one</strong> that can release the lock as well.
But in a binary semaphore, a thread may decrement the semaphore down to 0 from 1, but another thread can, legally, increment the semaphore back up to 1 again.</p>
<p>This is called <em>transferring of permissions</em>, binary semaphores thus supports this.</p>
<h3 id="barriers">Barriers</h3>
<p>The last thing we&rsquo;ll cover in this part is a so-called <em>barrier</em>.
A <em>barrier</em> is a form of synchronization where there is a entry-point (barrier) in a program&rsquo;s execution that all threads in a <em>group</em> have to reach <strong>before any of them</strong> is allowed to continue.</p>
<p>A simple and good example, let&rsquo;s say we use a kind of array as our synchronization mechanism:
In thread <code>t0</code>&rsquo;s <code>run()</code>:</p>
<pre tabindex="0"><code>// code before barrier

// t0 done
done[t0].up();

// wait for t1
done[t1].down();

// code after barrier
</code></pre><p>And for thread <code>t1</code>&rsquo;s <code>run()</code>:</p>
<pre tabindex="0"><code>// code before barrier

// t1 done
done[t1].up();

// wait for t0
done[t0].down();

// code after barrier
</code></pre><p>We can see that this ensures they wait for each other at this point at the program.</p>
<h3 id="summary">Summary</h3>
<p>This concludes this part - races, locks and semaphores are an important part in solving concurrent problems that can occur.</p>

		</section>
  </article>
	</div>

	<footer><p class="footer_msg">Memento mori</p></footer>

  </div>
</body>
</html>
