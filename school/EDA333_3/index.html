<!DOCTYPE html>
<html>
<head>
	<meta charset="utf-8"><meta property="og:site_name" content="rezvan"><title>Computer System Engineering: Part 3 - Pipelining | rezvan</title>
  <meta property="og:title" content="Computer System Engineering: Part 3 - Pipelining | rezvan"><meta property="og:description" content="">
  <meta property="og:type" content="blog">
  <meta property="og:link" content="https://rezvan.xyz/school/EDA333_3/"><link rel="shortcut icon" type="image/png" href=https://rezvan.xyz//images/icon.png />
  <meta property="og:image" content="https://rezvan.xyz//images/icon.png" /><meta name="viewport" content="width=device-width, initial-scale=1">
	<link rel="stylesheet" type="text/css" media="screen" href="https://rezvan.xyz//css/main.css" />    
</head>

<body>
  <div class="wrapper">
	<div class="content">
		<div class="header_main">

    <a href="https://rezvan.xyz/"><p class="header_title">rezvan</p><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.3/dist/katex.min.css" integrity="sha384-Juol1FqnotbkyZUT5Z7gUPjQ9gzlwCENvUZTpQBAPxtusdwFLRy382PSDx5UUJ4/" crossorigin="anonymous">

<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.3/dist/katex.min.js" integrity="sha384-97gW6UIJxnlKemYavrqDHSX3SiygeOwIZhwyOKRfSaf0JWKRVj9hLASHgFTzT+0O" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.3/dist/contrib/auto-render.min.js" integrity="sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05" crossorigin="anonymous" onload="renderMathInElement(document.body);"></script>

<script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement(document.body, {
            delimiters: [
                {left: "$$", right: "$$", display: true},
                {left: "$", right: "$", display: false}
            ]
        });
    });
</script>

    </a>

    <br>

    <nav id="main">
        
        <a href="/about/">about</a>
        
        <a href="/cv/">cv</a>
        
        <a href="/school/">school</a>
        
    </nav></div>

  <article><div class="title_wrapper">
			<h1 class="title">Computer System Engineering: Part 3 - Pipelining</h1><p class="single_time">Mar 27, 2023</p></div>
		<section class="post">
			<p>In this part we&rsquo;ll cover the idea of pipelining - and it&rsquo;s performance effects it has on computer systems.</p>
<p>Let&rsquo;s first cover what every computer does to perform complex tasks.</p>
<h3 id="instruction-execution">Instruction execution</h3>
<p>Every computer does these five stages:</p>
<ol>
<li>
<p><strong>Fetch</strong> Instruction. PC → Instruction memory.</p>
</li>
<li>
<p><strong>Decode</strong> the instruction and read from registers.</p>
</li>
<li>
<p><strong>Execute</strong> the instruction.</p>
<ul>
<li>
<p>Arithmetic/logical computation.</p>
</li>
<li>
<p>Computation of effective memory address.</p>
</li>
<li>
<p>Computation of jump address/conditional address.</p>
</li>
</ul>
</li>
<li>
<p><strong>Read / Write from / to memory</strong> for load/store instructions.</p>
</li>
<li>
<p><strong>Write back</strong> the result into the result register (RF).</p>
</li>
</ol>
<p>Let&rsquo;s take a look how this logic is implemented:
<img src="/images/SL.png#center" alt=""></p>
<p>A good refresher that we&rsquo;ll need to remember is that:</p>
<blockquote>
<p>The longest critical path determines our clock frequency.</p>
</blockquote>
<p>Let&rsquo;s now look into each stage, so we understand them properly.</p>
<h4 id="instruction-fetch-if">Instruction Fetch (IF)</h4>
<p>Let&rsquo;s begin by dissecting the <strong>fetch</strong> stage:</p>
<p><img src="/images/IF.png#center" alt=""></p>
<p>We see that everything starts in PC, we read our current address (PC Value), we have this black box of a decoder which outputs the instruction (32-bits).</p>
<p>Notice that we also take our current PC value and add <code>4</code> to it, why <code>4</code>?, because each instruction is 32-bits, or 4 bytes.</p>
<h4 id="r-format-instructions">R-Format Instructions</h4>
<p>For instructions with the R-format, we have the following:
<img src="/images/RF.png#center" alt=""></p>
<p>We take in our two register operands, compute the arithmetic/logical computation and store the result to the result register.</p>
<h4 id="loadstore-instructions">Load/Store Instructions</h4>
<p>For instructions that we either load/store to memory:</p>
<p><img src="/images/LS.png#center" alt=""></p>
<p>Here we have two important parts, we need to read our register operands but also compute our offset.</p>
<p>Since the offset is 16-bits and the register operands 32-bits, we need to sign extend our 16-bit offset to 32-bits.</p>
<h4 id="conditional-jump-instructions">Conditional jump instructions</h4>
<p>For these type of instructions, we need to compare our registers, we do this by doing a subtraction and looking at the &ldquo;zero&rdquo; output from our ALU.</p>
<p>But we also need to compute our jump address, to do this we do:</p>
<ul>
<li>
<p>Sign extend our offset</p>
</li>
<li>
<p>Left shift by 2 bits, due to word displacement</p>
</li>
<li>
<p>Now add this offset to PC.</p>
</li>
</ul>
<h3 id="in-depth-overview">In-depth overview</h3>
<p>Now let&rsquo;s take a look at the first picture, but with some more details:</p>
<p><img src="/images/TP.png#center" alt=""></p>
<p>If we try to deduce what our critical path is, we quickly find that load instructions are really slow.</p>
<p>Since they go through:</p>
<blockquote>
<p>Instruction memory → Registers → ALU → Data memory → Registers</p>
</blockquote>
<p>Now, let&rsquo;s pipeline this processor to increase the <em>speed</em>.</p>
<h3 id="pipelined-version">Pipelined version</h3>
<p>Naturally, since we have five stages, let&rsquo;s pipeline it into 5 separate stages as well!</p>
<p><img src="/images/PL.png#center" alt="">
Note: The dotted lines represents registers that separate each stage</p>
<p>As we can see now, we can handle 5 separate instructions at once!</p>
<p>If our pipelining is &ldquo;balanced&rdquo;, meaning each stage takes the same amount of time, then we can see a resulting speed up of:
$$
\textbf{Speedup} = \frac{T_{c \quad | \quad \text{Non-pipelined version}}}{T_{c \quad | \quad \text{Pipelined version}}} \approx \text{Number of pipeline stages}
$$</p>
<p>If our pipelining is unbalanced, we&rsquo;ll see a smaller increase.</p>
<p>However, doing 5 instructions at once comes with a cost, we no longer have a perfect CPU. We have several hazards that we need to consider now.</p>
<h3 id="hazards">Hazards</h3>
<p>There are three different types of hazards that we&rsquo;ll need to take care off:</p>
<ul>
<li>
<p>Structural hazards</p>
<ul>
<li>A stage is currently busy doing an operation</li>
</ul>
</li>
<li>
<p>Data hazards</p>
<ul>
<li>An instruction that depends on a earlier instruction.</li>
</ul>
</li>
<li>
<p>Control hazards</p>
<ul>
<li>The condition and potential address of a jump has not yet by the instruction fetch.</li>
</ul>
</li>
</ul>
<p>Let&rsquo;s look into how to solve each of these.</p>
<h4 id="structural-hazards">Structural hazards</h4>
<p>As we defined earlier, it is when two or more instruction need to access the same stage simultaneously.</p>
<p>There are two main examples of this:</p>
<ul>
<li>
<p>Registers: Reading and writing to the same register:</p>
<ul>
<li>Solution: Write and read in separate half cycles.</li>
</ul>
</li>
<li>
<p>If the pipeline only has one (1) shared memory:</p>
<ul>
<li>Solution: Don&rsquo;t. All pipeline models use separate memory for instructions and data memory.</li>
</ul>
</li>
</ul>
<h4 id="data-hazards">Data hazards</h4>
<p>If we have the following MIPS:</p>
<pre tabindex="0"><code>add    $s0, $t0, $t1
add    $t2, $s0, $t3
</code></pre><p>Notice that both instructions either write or read <code>$s0</code>.</p>
<p>A data hazard occurs specifically after a RAW (<strong>R</strong>ead <strong>A</strong>fter <strong>W</strong>rite)</p>
<p>There are two solutions:</p>
<ul>
<li>
<p>If the case is like above we can do:</p>
<ul>
<li>
<p>Forwarding (Bypassing)</p>
<ul>
<li>
<p>Use the result instantly when computed from the ALU</p>
</li>
<li>
<p>Do not wait to store it until the Write Back phase.</p>
</li>
<li>
<p>But, does require more logic and path in our data path.</p>
</li>
<li>
<p>But, no stalling!</p>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p>Forwarding doesn&rsquo;t solve all cases, for example, load instructions.</p>
<ul>
<li>
<p>We cannot do a forwarding, &ldquo;back in time&rdquo;</p>
</li>
<li>
<p>Therefore, requires a stalling cycle.</p>
</li>
</ul>
</li>
</ul>
<p>But consider this following example:</p>
<pre tabindex="0"><code>lw  $t1, 0($t0)
lw  $t2, 4($t0)
add $t3, $t1, $t2
sw  $t3, 12($t0)
lw  $t4, 8($t0)
add $t5, $t1, $t4
sw  $t5, 16($t0)
</code></pre><p>In this we&rsquo;ll have two stalling cycles, but with some smart thinking (or a smart compiler) we can instead do:</p>
<pre tabindex="0"><code>lw  $t1, 0($t0)
lw  $t2, 4($t0)
lw  $t4, 8($t0)
add $t3, $t1, $t2
sw  $t3, 12($t0)
add $t5, $t1, $t4
sw  $t5, 16($t0)
</code></pre><p>Just by changing one line we reduced our clock cycle count from 9 to 7!</p>
<h4 id="control-hazards">Control hazards</h4>
<ul>
<li>
<p>Problem: We want to compare registers and compute the jump address earlier in the program</p>
<ul>
<li>
<p>Solution: Move/Add more logic to the instruction decode stage.</p>
</li>
<li>
<p>This will result that we only need to wait (stall) for one cycle!</p>
</li>
</ul>
</li>
</ul>
<p>But, often longer pipelines cannot do this approach, since it will still result in a lot of stalling cycles.</p>
<p>The solution in modern CPUs is, predict the jump! If we fail to predict, then we stall to restore our failed prediction.</p>
<p>There are two different types:</p>
<ul>
<li>
<p>At compile time/Static jump-predictions:</p>
<ul>
<li>
<p>Based on typical jump-behavior</p>
</li>
<li>
<p>Examples: loops and if-conditions:</p>
<ul>
<li>
<p>Predict backwards jump as &ldquo;taken&rdquo;</p>
</li>
<li>
<p>Predict forward jump as &ldquo;not taken&rdquo;</p>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p>At run time/Dynamic jump-predictions:</p>
<ul>
<li>
<p>Hardware keeps track/notes the current jump-behavior</p>
<ul>
<li>Keeps statistics of jumps</li>
</ul>
</li>
<li>
<p>From the statistics tries to predict, can be as simple as, do as the last time.</p>
</li>
</ul>
</li>
</ul>
<h3 id="summary">Summary</h3>
<p>Okay, so we&rsquo;ve seen the power and beauty of pipelining.</p>
<p>So let&rsquo;s make a little summary:</p>
<ul>
<li>
<p>Pipelining boosts the performance, by increasing the total instruction-flow to the CPU.</p>
<ul>
<li>Multiple instructions execute in parallel.</li>
</ul>
</li>
<li>
<p>Although great, it comes with some hazards:</p>
<ul>
<li>
<p>Structural hazards, data hazards (RAW), and control hazards.</p>
</li>
<li>
<p>Can both be solved with hardware and software.</p>
</li>
</ul>
</li>
<li>
<p>There is a strong correlation between the ISA and the complexity of the pipeline.</p>
</li>
</ul>
<p>That last one might not be so clear from the start, but if we had very complex functions like</p>
<pre tabindex="0"><code>add M[$t0], M[$t1], M[$t2]
</code></pre><p>This would be a headache, since then we are in the execute stage and read/write to memory simultaneously.</p>

		</section>
  </article>
	</div>

	<footer><p class="footer_msg">memento mori</p></footer>

  </div>
</body>
</html>
