<!DOCTYPE html>
<html>
<head>
	<meta charset="utf-8"><meta property="og:site_name" content="rezvan"><title>Concurrent Programming: Part 8 - Synchronization problems with message-passing | rezvan</title>
  <meta property="og:title" content="Concurrent Programming: Part 8 - Synchronization problems with message-passing | rezvan"><meta property="og:description" content="">
  <meta property="og:type" content="blog">
  <meta property="og:link" content="https://rezvan.xyz/school/Concurrent_programming_8/"><link rel="shortcut icon" type="image/png" href=https://rezvan.xyz//images/icon.png />
  <meta property="og:image" content="https://rezvan.xyz//images/icon.png" /><meta name="viewport" content="width=device-width, initial-scale=1">
	<link rel="stylesheet" type="text/css" media="screen" href="https://rezvan.xyz//css/main.css" />

    <head>
    <link rel="stylesheet" href="../../themes/void/static/css/main.css">
</head>

<div class="js-toggle-wrapper">
    <div class="js-toggle">
        <div class="js-toggle-track">
            <div class="js-toggle-track-check">
                <img src="data:image/png;base64,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" role="presentation" style="pointer-events: none;" width="16" height="16">
            </div>
            <div class="js-toggle-track-x">
                <img src="data:image/png;base64,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" role="presentation" style="pointer-events: none;" width="16" height="16">
            </div>
        </div>
        <div class="js-toggle-thumb"></div>
        <input class="js-toggle-screenreader-only" type="checkbox" aria-label="Switch between Dark and Light mode">
    </div>
</div>

<style>

 

body.dark-mode,
body.dark-mode main {
    background-color: #0a0a0a;
    color: #eee;
}

body.dark-mode a {
    color: #eee;
    text-decoration: none;
}

body.dark-mode p {
    color: #eee;
}

body.dark-mode article a{
    text-decoration: underline;
}

body.dark-mode .post_listed .title {
    color: #eee;
}

body.dark-mode .post_listed .title:hover {
    background-color: #eee;
    color: #0a0a0a;
}

body.dark-mode .post_listed .post_time {
    color: #aaa;
}

body.dark-mode .header_title {
    color: #fff;
}

body.dark-mode .nav a {
    color: #eee;
}

body.dark-mode .nav a:visited {
    color: #eee;
}

body.dark-mode .nav a:hover {
    color: #0a0a0a;
}

 
body.dark-mode .title {
    color: #eee;
}


.js-toggle-wrapper {
    display: table;
     
    margin: 5px auto;
}

.js-toggle {
    touch-action: pan-x;
    display: inline-block;
    position: relative;
    cursor: pointer;
    background-color: transparent;
    border: 0;
    padding: 0;
    -webkit-touch-callout: none;
    user-select: none;
    -webkit-tap-highlight-color: rgba(0, 0, 0, 0);
    -webkit-tap-highlight-color: transparent;
  }

  .js-toggle-screenreader-only {
    border: 0;
    clip: rect(0 0 0 0);
    height: 1px;
    margin: -1px;
    overflow: hidden;
    padding: 0;
    position: absolute;
    width: 1px;
  }

  .js-toggle-track {
    width: 50px;
    height: 24px;
    padding: 0;
    border-radius: 30px;
    background-color: hsl(222, 14%, 7%);
    transition: all 0.2s ease;
  }

  .js-toggle-track-check {
    position: absolute;
    width: 17px;
    height: 17px;
    left: 5px;
    top: 0px;
    bottom: 0px;
    margin-top: auto;
    margin-bottom: auto;
    line-height: 0;
    opacity: 0;
    transition: opacity 0.25s ease;
  }

  .js-toggle--checked .js-toggle-track-check {
    opacity: 1;
    transition: opacity 0.25s ease;
  }

  .js-toggle-track-x {
    position: absolute;
    width: 17px;
    height: 17px;
    right: 5px;
    top: 0px;
    bottom: 0px;
    margin-top: auto;
    margin-bottom: auto;
    line-height: 0;
    opacity: 1;
    transition: opacity 0.25s ease;
  }

  .js-toggle--checked .js-toggle-track-x {
    opacity: 0;
  }

  .js-toggle-thumb {
    position: absolute;
    top: 1px;
    left: 1px;
    width: 22px;
    height: 22px;
    border-radius: 50%;
    background-color: #fafafa;
    box-sizing: border-box;
    transition: all 0.5s cubic-bezier(0.23, 1, 0.32, 1) 0ms;
    transform: translateX(0);
  }

  .js-toggle--checked .js-toggle-thumb {
    transform: translateX(26px);
    border-color: #19ab27;
  }

  .js-toggle--focus .js-toggle-thumb {
    box-shadow: 0px 0px 2px 3px rgb(255, 167, 196);
  }

  .js-toggle:active .js-toggle-thumb {
    box-shadow: 0px 0px 5px 5px rgb(255, 167, 196);
  }
</style>

<script>
    var body = document.body;
	var switcher = document.getElementsByClassName('js-toggle')[0];

	
	switcher.addEventListener("click", function() {
        this.classList.toggle('js-toggle--checked');
        this.classList.add('js-toggle--focus');
		
		if (this.classList.contains('js-toggle--checked')) {
			body.classList.add('dark-mode');
			
			localStorage.setItem('darkMode', 'true');
		} else {
			body.classList.remove('dark-mode');
			setTimeout(function() {
				localStorage.removeItem('darkMode');
			}, 100);
		}
	})

	
	if (localStorage.getItem('darkMode')) {
		
        switcher.classList.add('js-toggle--checked');
        body.classList.add('dark-mode');
	}
</script>


</head>

<body>
  <div class="wrapper">
	<div class="content">
		<div class="header_main">

    <a href="https://rezvan.xyz/"><p class="header_title">rezvan</p>
    </a>

    <br>

    <nav id="main">
        
        <a href="/">home</a>
        
        <a href="/about/">about</a>
        
        <a href="/contact/">contact</a>
        
        <a href="/cv/">cv</a>
        
        <a href="/school/">school</a>
        
    </nav></div>

  <article><div class="title_wrapper">
			<h1 class="title">Concurrent Programming: Part 8 - Synchronization problems with message-passing</h1><p class="single_time">Feb 7, 2023</p></div>
		<section class="post">
			<p>In this part we&rsquo;ll cover the classical problems that occur when dealing with synchronization.</p>
<p>But within this paradigm, we don&rsquo;t encounter the same problems as when using semaphores.
Mutual exclusion is not an issue, since we never share any resource,
the big problem today will be synchronization and coordination.</p>
<p>We&rsquo;ll see that many problems have the solution of a server-client architecture.</p>
<h3 id="barriers">Barriers</h3>
<p>Let&rsquo;s quickly recap what our barriers should be able to do:</p>
<pre tabindex="0"><code>-module(barrier).

% Initialize barrier for ‘Expected’ processes
init(Expected) -&gt;
    % TODO

% Block at ‘Barrier’ until all processes have reached it
wait(Barrier) -&gt;
    % TODO
</code></pre><p>Since we are talking about processes, it&rsquo;s natural to have a process for the barrier itself.
This process keeps track of what <em>other</em> processes that has arrived at the barrier point.</p>
<p>When a new process arrives at the barrier, it sends a <code>arrived</code> message to the barrier process.
When the list of all arrived processes is complete, the barrier process sends a <code>continue</code> message to everyone.</p>
<p>After notifying all other processes, the barrier processes itself, goes back to its initial state.</p>
<p>So we need to implement the barrier&rsquo;s event loop as a server function:</p>
<pre tabindex="0"><code>barrier(Arrived, Expected, PidRefs)
</code></pre><p>Let&rsquo;s implement this:</p>
<pre tabindex="0"><code>% event loop of barrier for ‘Expected’ processes
% Arrived: number of processes arrived so far
% PidRefs: list of {Pid, Ref} of processes arrived so far

% All processes arrived notify all waiting processes:
barrier(Arrived, Expected, PidRefs) when Arrived =:= Expected -&gt;
    [To ! {continue, Ref} || {To, Ref} &lt;- PidRefs],

    % Reset barrier
    barrier(0, Expected, []);

% Still waiting for some processes
barrier(Arrived, Expected, PidRefs) -&gt;
    receive
        {arrived, From, Ref} -&gt;
            % one more arrived: add {From, Ref} to PidRefs list:
            barrier(Arrived + 1, Expected, [{From, Ref}|PidRefs])
end.
</code></pre><p>Now for the <code>wait</code> function:</p>
<pre tabindex="0"><code>% Block at ‘Barrier’ until all processes have reached it
wait(Barrier) -&gt;
    % Notify barrier of arrival
    Ref = make _ ref(),

    % Wait for signal to continue
    Barrier ! {arrived, self(), Ref},

    receive {continue, Ref} -&gt; through end.
</code></pre><p>And finally, the <code>init</code> function, simple:</p>
<pre tabindex="0"><code>% Initialize barrier for ‘Expected’ processes
init(Expected) -&gt;
    spawn(fun () -&gt; barrier(0, Expected, []) end).
</code></pre><h3 id="resource-allocator">Resource allocator</h3>
<p>Let&rsquo;s recap the problem, an *<em>allocator</em> grants <em>users</em>, exclusive access to a number of resources.</p>
<p>Users asynchronously request and release resources back.
The allocator ensures exclusive access to a single user, and keeps tracks of the number of available resources.</p>
<p>So our module would look like:</p>
<pre tabindex="0"><code>-module(allocator).

% Register allocator with list of Resources
init(Resources) -&gt;
    % TODO

% Get N resources from allocator
request(N) -&gt;
    % TODO

% Release Resources to allocator
release(Resources) -&gt;
    % TODO
</code></pre><p>The user would perform something like:</p>
<pre tabindex="0"><code>user() -&gt;
    % How many resources are needed?
    N = howMany(),

    % Get resources from allocator
    Resources = allocator:request(N),

    % Do something with resources
    use(Resources),

    % Release resources
    allocator:release(Resources),

    user().
</code></pre><p>Again, in the message-passing world, using a server-client architecture often solves the problem.</p>
<p>We dedicate a process to the allocator, which keeps track of list of resources.</p>
<p>When a process requests for some resources that are available, the allocator sends a <code>granted</code> message.
Then accordingly removes those resources from the list.</p>
<p>When a process releases some resources, the allocator sends a <code>released</code>, and then adds the resources to the list.</p>
<p>If requests exceed the availability, the fall into our built-in mailbox.
The allocator process will resolve this as soon as they pattern-match again (resources available again).</p>
<pre tabindex="0"><code>allocator(Resources) -&gt;
    % Count how many resources are available
    Available = length(Resources),
    receive

        % Serve requests if enough resources are available
        {request, From, Ref, N} when N =&lt; Available -&gt;

            % Granted ++ Remaining =:= Resources
            % Length(Granted) =:= N
            {Granted, Remaining} = lists:split(N, Resources),

            % Send resources to requesting process
            From ! {granted, Ref, Granted},

            % Continue with Remaining resources
            allocator(Remaining);


        % Serve releases
        {releases, From, Ref, Released} -&gt;
            % Notify releasing process
            From ! {released, Ref},

            % Continue with previous and released resources
            allocator(Resources ++ Released)
</code></pre><p>The request function:</p>
<pre tabindex="0"><code>% Get N resources from allocator, gets blocked if not available
request(N) -&gt;
    Ref = make_ref(),
    allocator ! {request, self(), Ref, N},
    recieve {granted, Ref, Granted} -&gt; Granted end.

% Release Resources to allocator
release(Resources) -&gt;
    Ref = make_ref(),
    allocator ! {release, self(), Ref, Resources},
    recieve {released, Ref} -&gt; released end.
</code></pre><h3 id="producer-consumer">Producer-consumer</h3>
<p>Recap; Implement a <code>buffer</code> such that:</p>
<ul>
<li>
<p>Producers and consumers access the buffer atomically</p>
</li>
<li>
<p>Consumers block when the buffer is empty</p>
</li>
<li>
<p>Producers block when the buffer is full (bounded buffer variant)</p>
</li>
</ul>
<pre tabindex="0"><code>-module(buffer).

% Initialize buffer with size Bound
init_buffer(Bound) -&gt;
    % TODO

% Put Item in Buffer; Block if full
put(Buffer, Item) -&gt;
    % TODO

% Get Item from Buffer; Block if empty
get(Buffer) -&gt;
    % TODO
</code></pre><p>The producer and buffer:</p>
<pre tabindex="0"><code>producer(Buffer) -&gt;
    Item = produce(),
    buffer:put(Buffer, Item),
    producer(Buffer).


consumer(Buffer) -&gt;
    Item = buffer:get(Buffer),
    % Do something with Item

    consume(Item),
    consumer(Buffer).
</code></pre><p>At this point you pretty much can see the pattern here that arises:</p>
<pre tabindex="0"><code>buffer(Content, Count, Bound) -&gt;
    receive

    % Serve gets when buffer not empty
    {get, From, Ref} when Count &gt; 0 -&gt;
        % Match first item
        [First | Rest] = Content,

        % Send it out
        From ! {item, Ref, First},

        % Remove it from buffer
        buffer(Rest, Count-1, Bound);

    % Serve puts when buffer not full
    {put, From, Ref, Item} when Count &lt; Bound -&gt;

        % Send ack
        From ! {done, Ref},

        % Add item to end
        buffer(Content ++ [Item], Count + 1, Bound)
end.
</code></pre><p>In this solution, both a bounded and unbounded will work - due to Erlang&rsquo;s order between numbers and atoms!</p>
<p>Now for get and put:</p>
<pre tabindex="0"><code>% Get item from ‘Buffer’; block if empty
get(Buffer) -&gt;
    Ref = make_ref(),
    Buffer ! {get, self(), Ref},
    receive {item, Ref, Item} -&gt; Item end.

% Put ‘Item’ in ‘Buffer’; block if full
put(Buffer, Item) -&gt;
    Ref = make_ref(),
    Buffer ! {put, self(), Ref, Item},
    receive {done, Ref} -&gt; done end.
</code></pre><h3 id="readers-writers">Readers-writers</h3>
<pre tabindex="0"><code>-module(board).

% Register board with Name
init(Name) -&gt;
    % TODO

% Get read access to Board
begin_read(Board) -&gt;
    % TODO

% Release read access to Board
end_read(Board) -&gt;
    % TODO

% Get write access to Board
begin_write(Board) -&gt;
    % TODO

% Release write access to Board
end_write(Board) -&gt;
    % TODO
</code></pre><p>Our first naive server function would be:</p>
<pre tabindex="0"><code>% ‘Readers’ active readers and ‘Writers’ active writers
board_row(Readers, Writers) -&gt;
receive
    {begin_read, From, Ref} when Writers =:= 0 -&gt;
        From ! {ok_ to_ read, Ref},
        board_row(Readers+1, Writers);

    {begin_write, From, Ref} when (Writers =:= 0) and (Readers =:= 0) -&gt;
        From ! {ok_ to_ write, Ref},
        board_row(Readers, Writers+1);

    {end_read, From, Ref} -&gt; From ! {ok, Ref},
        board_row(Readers-1, Writers);

    {end_write, From, Ref} -&gt; From ! {ok, Ref},
        board_row(Readers, Writers-1)
end.
</code></pre><p>Just as our naive solution when using semaphores,
this doesn&rsquo;t prevent starvation due to this version prioritizes readers.</p>
<p>The solution based on two monitors is a approach here, but it&rsquo;s quite cumbersome for a message-passing program.</p>
<p>We instead implement two <strong>macro states</strong>:</p>
<ul>
<li>
<p>Empty - no readers or writers</p>
</li>
<li>
<p>Readers - Readers but no writers</p>
</li>
</ul>
<p>The initial board is in empty state, then:</p>
<ul>
<li>
<p>When board is in state <code>emtpy</code>:</p>
<ul>
<li>
<p>Read requests - served immediately, then switches to <code>readers</code> state.</p>
</li>
<li>
<p>Write requests - served immediately and <strong>synchronously</strong>, wait until writing ends, then go into <code>empty</code> state.</p>
</li>
</ul>
</li>
<li>
<p>When board is in state <code>readers</code>:</p>
<ul>
<li>
<p>Read requests - served immediately and stays in <code>readers</code>.</p>
</li>
<li>
<p>Write requests - served <em>as soon as possible</em>, board waits until all reading ends, <em>then</em> request is served. Back to <code>empty</code> state.</p>
</li>
</ul>
</li>
</ul>
<p>For this we&rsquo;ll need two server functions, <code>empty_board</code> and <code>readers_board</code>:</p>
<pre tabindex="0"><code>% Board with no readers and no writers
empty_board() -&gt;
    receive

    % Serve read request
    {begin_read, From, Ref} -&gt;

        % Notify reader
        From ! {ok_to_read, Ref},

        % Board has one reader
        readers_board(1);

    % Serve write request synchronously
    {begin_write, From, Ref} -&gt;
        % Notify writer
        From ! {ok_to_write, Ref},

        % Wait for writer to finish
        Receive
            {end_write, _From, _Ref} -&gt;
                % Board is empty again
                empty_board()
        end
end.

% Board with no readers (and no writers)
readers_ board(0) -&gt; empty_ board();

% Board with ‘Readers’ active readers
% (and no writers)
readers_board(Readers) -&gt;
    receive

        % Serve write request
        {begin_write, From, Ref} -&gt;
            % Wait until all ‘Readers’ have finished
            [receive {end_read, _From, _Ref} -&gt; end_read end || _ &lt;- lists:seq(1, Readers)],

            % Notify writer
            From ! {ok_to_write, Ref},

            % Wait for writer to finish
            receive
                {end_write, _From, _Ref} -&gt; empty_board()
            end;

        % Serve read request
        {begin_read, From, Ref} -&gt;
            % Notify reader
            From ! {ok _ to _ read, Ref},

            % Board has one more reader
            readers _ board(Readers+1);

        % Serve end read
        {end_read, From, Ref} -&gt;

            % Board has one less reader
            readers_board(Readers-1)
end.
</code></pre><h3 id="dining-philosophers">Dining Philosophers</h3>
<pre tabindex="0"><code>-module(philosophers).

% Set up table of N philosophers
init(N) -&gt;
    % TODO

% Philosopher picks up Fork
get_fork(Fork) -&gt;
    % TODO

% Philosopher releases Fork
put_fork(Fork) -&gt;
    % TODO
</code></pre><p>We could explore the solutions we did based on locking and breaking symmetry -
but there is a solution which better fits into the message-passing paradigm</p>
<p>We have a waiter (process) who supervises access to the table.
So each philosopher asks for <em>permission</em> to sit at the table <strong>before</strong> picking up both forks.</p>
<p>So, as long as the waiter allows strictly fewer philosopher than the total number of forks to sit around the table, deadlock and starvation are avoided.</p>
<p>Waiter interface:</p>
<pre tabindex="0"><code>% Ask Waiter to be seated; may wait
sit(Waiter) -&gt;
    % TODO

% Ssk Waiter to leave
leave(Waiter) -&gt;
    % TODO
</code></pre><p>Our server function:</p>
<pre tabindex="0"><code>waiter(Eating, Seats) -&gt;
    receive

    % Serve as long as seats are available
    {sit, From, Ref} when Eating &lt; Seats -&gt;
        From ! {ok_to_sit, Ref},

        % One more eating
        waiter(Eating+1, Seats);

    % Can leave at any time
    {leave, From, Ref} -&gt;
        From ! {ok_to_leave, Ref},

        % One less eating
        waiter(Eating-1, Seats)
end.
</code></pre><p>And <code>sit</code> and <code>leave</code>:</p>
<pre tabindex="0"><code>% ask Waiter to be seated; may wait
sit(Waiter) -&gt;
    Ref = make _ ref(),
    Waiter ! {sit, self(), Ref},
    receive {ok_to_sit, Ref} -&gt; ok end.

% ask Waiter to leave
leave(Waiter) -&gt;
    Ref = make _ ref(),
    Waiter ! {leave, self(), Ref},
    receive {ok_to_leave, Ref} -&gt; ok end.
</code></pre><p>Now, each <code>fork</code> is also a process, which keeps track of whether the for is free or not.</p>
<p>Server function:</p>
<pre tabindex="0"><code>% Fork not held by anyone
fork() -&gt;
    receive
        {get, From, Ref} -&gt;
            From ! {ack, Ref},

            % Fork held
            fork(From)
end.

% a fork held by Owner
fork(Owner) -&gt;
    receive
        {put, Owner, _ Ref} -&gt;
            % Fork not held
            fork()
end.
</code></pre><p>and the <code>get</code> and <code>put</code> for the forks:</p>
<pre tabindex="0"><code>% Pick up Fork; block until available
get_fork(Fork) -&gt;
    Ref = make _ ref(),
    Fork ! {get, self(), Ref},
    receive {ack, Ref} -&gt; ack end.

% Put down Fork
put_fork(Fork) -&gt;
    Ref = make _ ref(),
    Fork ! {put, self(), Ref}.
</code></pre><p>And finally, the <code>init</code> function for the whole problem:</p>
<pre tabindex="0"><code>% Set up table of ‘N’ philosophers
init(N) -&gt;
    % Spawn waiter process
    Waiter = spawn(fun () -&gt; waiter(0, N-1) end),

    % [1, 2, ..., N]
    Ids = lists:seq(1,N),

    % Spawn fork processes
    Forks = [spawn(fun fork/0) || _ &lt;- Ids],

    % Spawn philosopher processes
    [spawn(fun () -&gt;
        Left = lists:nth(I, Forks),

        % 1-based indexes
        Right = lists:nth(1+(I rem N), Forks),
        philosopher(#forks{left=Left, right=Right}, Waiter)
    end) || I &lt;- Ids].
</code></pre>
		</section>
  </article>
	</div>

	<footer><p class="footer_msg">memento mori</p></footer>

  </div>
</body>
</html>
