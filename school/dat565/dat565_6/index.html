<!doctype html><html><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><title>rezvan | Part 6 - Mathematical models</title><link rel=icon type=image/png href=https://rezvan.xyz/images/icon.png><meta name=viewport content="width=device-width,initial-scale=1">
<meta name=description content="Introduction In this part we&rsquo;ll cover some central mathematical models and their applications.
Mathematical models All models are wrong, but some models are useful - George Box
Before we start, let&rsquo;s remember that a model is not perfect by any means, and it is just a tool for a subset of tasks.
Linear VS. Non-linear models Let&rsquo;s define what a linear and non-linear model is.
In mathematics, a linear polynomial has the form $f(x) = ax + b$ for some constants $a, b$, so it corresponds to a line drawn on the Cartesian plane."><meta property="og:image" content="https://raw.githubusercontent.com/rezaarezvan/rezvan.xyz/main/images/icon.png"><meta property="og:url" content="https://rezvan.xyz/school/dat565/dat565_6/"><meta property="og:site_name" content="rezvan"><meta property="og:title" content="Part 6 - Mathematical models"><meta property="og:description" content="Introduction In this part we’ll cover some central mathematical models and their applications.
Mathematical models All models are wrong, but some models are useful - George Box
Before we start, let’s remember that a model is not perfect by any means, and it is just a tool for a subset of tasks.
Linear VS. Non-linear models Let’s define what a linear and non-linear model is.
In mathematics, a linear polynomial has the form $f(x) = ax + b$ for some constants $a, b$, so it corresponds to a line drawn on the Cartesian plane."><meta property="og:locale" content="en_us"><meta property="og:type" content="article"><meta property="article:section" content="school"><meta property="article:published_time" content="2024-02-02T00:00:00+00:00"><meta property="article:modified_time" content="2024-05-26T11:09:10+02:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="Part 6 - Mathematical models"><meta name=twitter:description content="Introduction In this part we’ll cover some central mathematical models and their applications.
Mathematical models All models are wrong, but some models are useful - George Box
Before we start, let’s remember that a model is not perfect by any means, and it is just a tool for a subset of tasks.
Linear VS. Non-linear models Let’s define what a linear and non-linear model is.
In mathematics, a linear polynomial has the form $f(x) = ax + b$ for some constants $a, b$, so it corresponds to a line drawn on the Cartesian plane."><link rel=stylesheet href=https://rezvan.xyz/css/combined.min.285bd67a05674fdcb27bb67f867c7ac6b2e0c0b5535c536ba4bb37cd80e377e9.css integrity="sha256-KFvWegVnT9yye7Z/hnx6xrLgwLVTXFNrpLs3zYDjd+k="><link id=lightSyntaxStyle rel=stylesheet href=https://rezvan.xyz/css/light_syntax.min.d9e0828a4ff7f2d7317942062fc751fa487b2ac2c47b934ad082abd7d3ca6690.css integrity="sha256-2eCCik/38tcxeUIGL8dR+kh7KsLEe5NK0IKr19PKZpA="><link id=darkModeStyle rel=stylesheet href=https://rezvan.xyz/css/dark.min.113ab1177b874ffa2011e31f94df77b25b4c0aee6c35e5db0e6c54ebe2071597.css integrity="sha256-ETqxF3uHT/ogEeMflN93sltMCu5sNeXbDmxU6+IHFZc=" disabled><link id=darkSyntaxStyle rel=stylesheet href=https://rezvan.xyz/css/dark_syntax.min.1a878f3d8fb43359bd3b44bc70c4074f682f11066c6537bf6248b696cbe56586.css integrity="sha256-GoePPY+0M1m9O0S8cMQHT2gvEQZsZTe/Yki2lsvlZYY=" disabled><script type=text/javascript src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script type=text/x-mathjax-config>
		MathJax.Hub.Config({
			tex2jax: {
				inlineMath: [['$','$'], ['\\(','\\)']],
				displayMath: [['$$','$$'], ['\[','\]']],
				processEscapes: true,
				processEnvironments: true,
				skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
				TeX: { equationNumbers: { autoNumber: "AMS" },
						 extensions: ["AMSmath.js", "AMSsymbols.js"] }
			}
		});
		</script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.css><script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.js></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/contrib/auto-render.min.js onload=renderMathInElement(document.body)></script><script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}]})})</script></head><body><header><nav id=site-navbar><div class=navbar-content><a href=https://rezvan.xyz/ class=logo>rezvan.xyz</a><div class=navbar-links><a href=/principles class=nav-link><span class=bracket>[</span>principles<span class=bracket>]</span></a>
<a href=/cv class=nav-link><span class=bracket>[</span>cv<span class=bracket>]</span></a>
<a href=/posts class=nav-link><span class=bracket>[</span>posts<span class=bracket>]</span></a>
<a href=/school class=nav-link><span class=bracket>[</span>school<span class=bracket>]</span></a></div><div class=theme-toggle><span id=dark-mode-toggle onclick=toggleTheme() aria-label="Toggle theme">○
</span><script src=https://rezvan.xyz/js/themetoggle.js></script></div></div></nav></header><div class=content><main><article><div class=title><h1>Part 6 - Mathematical models</h1><div class=meta>Posted on Feb 2, 2024</div><div class=meta>(Last updated: May 26, 2024)</div></div><section class=body><h3 id=introduction>Introduction</h3><p>In this part we&rsquo;ll cover some central mathematical models and their applications.</p><h3 id=mathematical-models>Mathematical models</h3><blockquote><p>All models are wrong, but some models are useful - George Box</p></blockquote><p>Before we start, let&rsquo;s remember that a model is not perfect by any means, and it is just a tool for a subset of tasks.</p><h4 id=linear-vs-non-linear-models>Linear VS. Non-linear models</h4><p>Let&rsquo;s define what a linear and non-linear model is.</p><p>In mathematics, a <strong>linear polynomial</strong> has the form $f(x) = ax + b$ for some constants $a, b$, so it corresponds to a line drawn on the Cartesian plane.</p><p>In general, a linear polynomial of $k$ variables has the form:
$$
f(x_1, x_2, \ldots, x_k) = b + \sum_{i = 1}^k a_ix_i
$$</p><p>A <strong>linear map</strong> between vector spaces $V$ and $W$ over a field $K$ is a function, $f\ :\ V \to W$ that satisfies for all $x, y \in V$ and $c \in K$:
$$
\begin{align*}
f(x + y) & = f(x) + f(y) \\
f(cx) & = cf(x)
\end{align*}
$$</p><p>In particular, if our linear model is interpreted as a line, it must also go through the origin.</p><p>Non-linear is that which is not linear, e.g., higher-order polynomial functions, exponential or logarithm functions, trigonometric functions etc.</p><p>Pros of linear models:</p><ul><li>Linear models are easily interpretable</li><li>Linear models are very efficient to compute</li><li>Linear models are tractable and can be manipulated mathematically.</li></ul><p>Cons of linear models:</p><ul><li>They are ill-suited to model non-linear effects.</li><li>A lot of things in the world have non-linear relationship</li></ul><p>However, sometimes it is possible to linearize models, e.g., by applying an appropriate transformation.</p><h3 id=black-box-vs-descriptive-models>Black box vs. descriptive models</h3><p>A model is a <strong>black box</strong> if we can observe that the outputs have predictive power, but we cannot explain why the outputs are what they are.</p><p><strong>Descriptive models</strong> come with semantics that help human beings understand the reasoning behind the answer.</p><h3 id=first-principle-vs-data-driven-models>First-principle vs. data-driven models</h3><p><strong>First-principle models</strong> are based on theoretical understanding of the phenomena in question.</p><p><strong>Data-driven</strong> models are based on observations. The actual model might have no understanding of the domain, but only make inferences
based on observed probabilities.</p><h3 id=stochastic-vs-deterministic-models>Stochastic vs. deterministic models</h3><p><strong>Stochastic models</strong> include some kind of random component. This can be explicit randomization,
as in the case of a <a href=https://en.wikipedia.org/wiki/Monte_Carlo_method>Monte Carlo simulation</a>.
The underlying mathematical model can make use of probability, as in logistic regression,
for example, yielding a probability for each potential class, explicitly modelling uncertainty.</p><p><strong>Deterministic models</strong> simply yield the same result every time, and may not include a notion of uncertainty.</p><h3 id=flat-vs-hierarchical-models>Flat vs. hierarchical models</h3><p>A <strong>flat model</strong> is one where there is only one problem that is being solved, without sub-problems with a parent-child relationship.</p><p>A <strong>hierarchical model</strong> has structure that has parent-child relationship between sub-problems.</p><h3 id=evaluating-models>Evaluating models</h3><p>It is usually not possible to know in advance which model is the best choice for a given problem and/or dataset.</p><p>Given two or more models, we must evaluate them to determine which one performs better.</p><p>Human insight should not be ignored: our domain knowledge can suggest whether the model makes any sense.</p><p>However, sometimes, we need to compute an appropriate metric for the model with respect to the data.
What is appropriate depends on the problem type (classification/regression) and what we are interested in.
We are often interested in generalization performance, that is, how well the model does with inputs that are not part of the data the model has seen.
Understanding whether our model is any good means it needs to be measured against a baseline.</p><h3 id=train-test-split>Train-test split</h3><p>Generalization performance needs to be evaluated on data that was never used to train the model.</p><p>We call this the test set, never ever make evaluate the model on the training set.</p><p>Evaluating generalization on data that the model has seen in training is worthless.</p><p>If the model has parameters, we need to potentially split the training set in two: the actual training set and the validation set.</p><ul><li>Train the model with respect to the training set using different choices for the parameters.</li><li>Evaluate against the validation set.</li><li>Choose the parameters that performed the best with regard to the validation set.</li><li>Evaluate the model against the test set.</li></ul><p>The simplest way to construct the sets is by partitioning the dataset uniformly at random.
We often like to use more data for the training set than test set.</p><p>Rule of thumb: if we do a simple train-test split, use 75% of data for the training set
and 25% for the test set. If we need a validation set as well, split the data 50-25-25.</p><p>Train-test-split is easily done using <code>sklearn.model_selection.train_test_split</code></p><h3 id=cross-validation>Cross-validation</h3><p>What if we have very little data?</p><p>Then the training set can become too small if we split it.</p><p>Cross-validation is a method to amplify the size of the sets by partitioning data into $k$ disjoint parts,
and then systematically using $k-1$ parts for training
and the remaining part for testing, and
computing the metric, e.g., as average
and standard deviation.</p><p>The extreme case occurs when $k=n$, which is known as <em>leave-one-out</em> cross-validation.</p><p>Often, we would then train the final model with all data, assuming it will do as well as during cross-validation.</p><h3 id=baseline-models>Baseline models</h3><p>Baseline model is something that we compare against to see if we can get an improvement.</p><p>To understand if our model is worth anything, we should have some kind of baseline and conclusively show that our model beats the baseline.</p><h3 id=evaluating-binary-classifiers>Evaluating binary classifiers</h3><p>A binary classifier classifies objects into two classes: a <strong>positive</strong> and a <strong>negative</strong> class.</p><p>Often positive instances are the more interesting or rarer ones.</p><p>The performance of a classifier can often be presented using a <strong>confusion matrix</strong></p><ul><li><strong>True Positives (TP)</strong> are correctly identified positives</li><li><strong>True Negatives (TN)</strong> are correctly identified negatives</li><li><strong>False Positives (FP)</strong> are incorrectly identified positives</li><li><strong>False Negatives (FN)</strong> are incorrectly identified negatives</li></ul><table><thead><tr><th style=text-align:center></th><th style=text-align:center>Predicted positive</th><th style=text-align:center>Predicted negative</th></tr></thead><tbody><tr><td style=text-align:center>Actual positive</td><td style=text-align:center><strong>True Positives (TP)</strong></td><td style=text-align:center><strong>False Negatives (FN)</strong></td></tr><tr><td style=text-align:center>Actual negative</td><td style=text-align:center><strong>False Positives (FP)</strong></td><td style=text-align:center><strong>True Negatives (TN)</strong></td></tr></tbody></table><h4 id=accuracy>Accuracy</h4><p>The simplest metric for classifiers is probably <strong>accuracy</strong>.</p><p>Accuracy measures the fraction of correct classifications out of all classifications:
$$
Accuracy = \frac{TP + TN}{TP + TN + FP + FN}
$$</p><p>For binary classifiers, accuracy is at its worst when it is around <strong>$0.5$</strong>.</p><p>Accuracy of <strong>$0$</strong> would mean we get perfect accuracy by swapping the class labels.</p><p>Accuracy does little to tell why or what is wrong.</p><h4 id=precision-and-recall>Precision and recall</h4><p><strong>Precision</strong> and <strong>recall</strong> are basic metrics for binary classifiers.</p><p>Precision measures the fraction of interesting finds among the returned positives.
$$
Precision = \frac{TP}{TP + FP}
$$</p><p>Recall measures how large a fraction of interesting values we are able to pick up from the set of all positive instances.
$$
Recall = \frac{TP}{TP + FN}
$$</p><p>There is usually a tradeoff between precision and recall.</p><h3 id=multi-class-classification>Multi-class classification</h3><p>Accuracy is easily extended to multiple classes (simply count the fraction of correct classifications).</p><p><strong>Top-$k$ success rule</strong> gives credit if the correct class label was among the top-$k$ possibilities.</p><p>Confusion matrices can be generalized to multi-class cases. Correct predictions would be on the diagonal.</p><p>Precision and recall can also be generalized into multi-class environments.</p><table><thead><tr><th style=text-align:center></th><th style=text-align:center>Predicted A</th><th style=text-align:center>Predicted B</th><th style=text-align:center>Predicted C</th></tr></thead><tbody><tr><td style=text-align:center>Actual A</td><td style=text-align:center>0.97</td><td style=text-align:center>0.03</td><td style=text-align:center>0.00</td></tr><tr><td style=text-align:center>Actual B</td><td style=text-align:center>0.16</td><td style=text-align:center>0.84</td><td style=text-align:center>0.00</td></tr><tr><td style=text-align:center>Actual C</td><td style=text-align:center>0.00</td><td style=text-align:center>0.00</td><td style=text-align:center>1.00</td></tr></tbody></table><h3 id=evaluating-regression-models>Evaluating regression models</h3><p>Regression models are usually evaluated by computing error statistics.</p><p>Suppose $\hat{y}$ is the predicted value and $y$ is the correct value.</p><ul><li>Plain difference $\hat{y} - y$ is simple but signed, so it is inappropriate if the signedness is not significant.</li><li>Absolute error $|\hat{y} - y|$ is a simple statistic, but is sensitive to variations in scale.</li><li>Relative error $\left| \frac{\hat{y} - y}{y} \right|$ can be used even in the presence of variable scales but behaves erratically near 0.</li><li>Squared error $\left(\hat{y} - y\right)^2$ is always positive and penalizes large deviations more.</li></ul><p>The (signed) error statistics can be plotted as a histogram; this shows the distribution of error
If the histogram is not bell-shaped (approximately normal), this indicates there is a systemic source of error.</p><p>A common summary statistic is <strong>M</strong>ean <strong>S</strong>quared <strong>E</strong>rror, the mean of squared errors:
$$
MSE(\hat{y}, y) = \frac{1}{n} \sum_{i = 1}^n \left(\hat{y}_i - y_i \right)^2
$$</p><p>A related statistic is the <strong>R</strong>oot <strong>M</strong>ean <strong>S</strong>quared that has the same units as the values themselves:
$$
RMS(\hat{y}, y) = \sqrt{MSE(\hat{y}, y)}
$$</p></section></article><nav class=navigation><div class="nav-item previous"><a href=/school/dat565/dat565_5/ title="Previous: Part 5 - Statistical analysis">&larr; Previous</a></div><div class="nav-item next"><a href=/school/dat565/dat565_7/ title="Next: Part 7 - Linear and logistic regression">Next &rarr;</a></div></nav></main></div><footer id=site-footer><div class=social-links><a href=https://github.com/rezaarezvan title class=social-link><span class=bracket>[</span>github<span class=bracket>]</span></a>
<a href=https://x.com/rzvan__/ title class=social-link><span class=bracket>[</span>x<span class=bracket>]</span></a></div><div class=footer-marquee><div class=footer-marquee__content><span class=footer-marquee__item>memento mori • amor fati • sic parvis magna • per aspera ad astra</span>
<span class=footer-marquee__item>memento mori • amor fati • sic parvis magna • per aspera ad astra</span></div></div></footer></body></html>