<!DOCTYPE html><html lang="en"> <head><meta charset="UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1.0"><meta name="generator" content="Astro v4.14.2"><link rel="icon" type="image" href="/favicon.ico"><title>Part 6 - Mathematical models</title><!-- KaTeX support --><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.css"><script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.js"></script><script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/contrib/auto-render.min.js" onload="renderMathInElement(document.body);"></script><!-- inline KaTeX --><link rel="stylesheet" href="/_astro/index.CwgzIfsj.css">
<link rel="stylesheet" href="/_astro/_slug_.hCvEQTvV.css">
<style>article[data-astro-cid-v5ro3oot]{max-width:80ch;margin:0 auto}.nav-button[data-astro-cid-v5ro3oot]{display:flex;align-items:center;padding:.5rem;border-radius:.5rem;transition:background-color .3s ease;text-decoration:none;color:var(--text-color);background-color:var(--bg-color);border:1px solid var(--border-color)}.nav-button[data-astro-cid-v5ro3oot]:hover{background-color:var(--hover-color)}.nav-button[data-astro-cid-v5ro3oot] .arrow[data-astro-cid-v5ro3oot]{font-size:1.5rem;line-height:1}.nav-button[data-astro-cid-v5ro3oot] .text[data-astro-cid-v5ro3oot]{display:flex;flex-direction:column;margin:0 .5rem}.nav-button[data-astro-cid-v5ro3oot] .label[data-astro-cid-v5ro3oot]{font-size:.8rem;text-transform:uppercase;letter-spacing:.05em;color:var(--muted-color)}.nav-button[data-astro-cid-v5ro3oot] .title[data-astro-cid-v5ro3oot]{font-weight:500}.prev-button[data-astro-cid-v5ro3oot]{justify-content:flex-start}.next-button[data-astro-cid-v5ro3oot]{justify-content:flex-end;text-align:right}@media (max-width: 640px){.nav-button[data-astro-cid-v5ro3oot]{width:100%}.next-button[data-astro-cid-v5ro3oot]{justify-content:flex-start;text-align:left}.next-button[data-astro-cid-v5ro3oot] .text[data-astro-cid-v5ro3oot]{order:2;margin-left:.5rem}.next-button[data-astro-cid-v5ro3oot] .arrow[data-astro-cid-v5ro3oot]{order:1}}
</style><script type="module">document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}]})});
</script></head> <body> <div class="container mx-auto px-4 flex flex-col md:flex-row min-h-screen"> <aside class="w-full md:w-64 border-b md:border-r md:border-b-0 border-[var(--border-color)] border-dashed pt-8"> <header class="flex flex-col h-full"> <div class="flex items-center mb-4"> <script>
  function setTheme(mode) {
    localStorage.setItem("theme-storage", mode);
    document.documentElement.setAttribute('data-theme', mode);
  }
  function toggleTheme() {
    const currentTheme = localStorage.getItem("theme-storage") || "light";
    const newTheme = currentTheme === "light" ? "dark" : "light";
    setTheme(newTheme);
  }
  const savedTheme = localStorage.getItem("theme-storage") || "light";
  setTheme(savedTheme);
  window.toggleTheme = toggleTheme;
</script> <button id="theme-toggle" onclick="toggleTheme()" aria-label="Toggle theme" class="w-6 h-6 cursor-pointer"> <div class="w-5 h-5 border-2 border-primary rounded-full transition-colors duration-300 ease-in-out hover:bg-primary"></div> </button> <a href="/" class="text-2xl font-semibold ml-3 h-10 pr-3">rezvan.xyz</a> </div> <nav class="flex flex-wrap gap-2 md:flex-col md:gap-2"> <a href="/principles" class="transition-colors">
[principles]
</a><a href="/cv" class="transition-colors">
[cv]
</a><a href="/posts" class="transition-colors">
[posts]
</a><a href="/school" class="transition-colors">
[school]
</a> </nav> </header> </aside> <main class="flex-grow px-4 md:px-8 py-8 overflow-y-auto">  <article class="prose prose-sm sm:prose lg:prose-lg xl:prose-xl max-w-none" data-astro-cid-v5ro3oot> <h1 class="text-3xl sm:text-4xl font-bold mb-4" data-astro-cid-v5ro3oot>Part 6 - Mathematical models</h1> <p class="text-sm text-muted-foreground mb-4" data-astro-cid-v5ro3oot>
Date: 2/2/2024 </p> <div class="markdown-content" data-astro-cid-v5ro3oot>  <h3 id="introduction">Introduction</h3>
<p>In this part we’ll cover some central mathematical models and their applications.</p>
<h3 id="mathematical-models">Mathematical models</h3>
<blockquote>
<p>All models are wrong, but some models are useful - George Box</p>
</blockquote>
<p>Before we start, let’s remember that a model is not perfect by any means, and it is just a tool for a subset of tasks.</p>
<h4 id="linear-vs-non-linear-models">Linear VS. Non-linear models</h4>
<p>Let’s define what a linear and non-linear model is.</p>
<p>In mathematics, a <strong>linear polynomial</strong> has the form $f(x) = ax + b$ for some constants $a, b$, so it corresponds to a line drawn on the Cartesian plane.</p>
<p>In general, a linear polynomial of $k$ variables has the form:
$$
f(x_1, x_2, \ldots, x_k) = b + \sum_{i = 1}^k a_ix_i
$$</p>
<p>A <strong>linear map</strong> between vector spaces $V$ and $W$ over a field $K$ is a function, $f\ :\ V \to W$ that satisfies for all $x, y \in V$ and $c \in K$:
$$
\begin{align*}
f(x + y) &#x26; = f(x) + f(y) \newline
f(cx) &#x26; =  cf(x)
\end{align*}
$$</p>
<p>In particular, if our linear model is interpreted as a line, it must also go through the origin.</p>
<p>Non-linear is that which is not linear, e.g., higher-order polynomial functions, exponential or logarithm functions, trigonometric functions etc.</p>
<p>Pros of linear models:</p>
<ul>
<li>Linear models are easily interpretable</li>
<li>Linear models are very efficient to compute</li>
<li>Linear models are tractable and can be manipulated mathematically.</li>
</ul>
<p>Cons of linear models:</p>
<ul>
<li>They are ill-suited to model non-linear effects.</li>
<li>A lot of things in the world have non-linear relationship</li>
</ul>
<p>However, sometimes it is possible to linearize models, e.g., by applying an appropriate transformation.</p>
<h3 id="black-box-vs-descriptive-models">Black box vs. descriptive models</h3>
<p>A model is a <strong>black box</strong> if we can observe that the outputs have predictive power, but we cannot explain why the outputs are what they are.</p>
<p><strong>Descriptive models</strong> come with semantics that help human beings understand the reasoning behind the answer.</p>
<h3 id="first-principle-vs-data-driven-models">First-principle vs. data-driven models</h3>
<p><strong>First-principle models</strong> are based on theoretical understanding of the phenomena in question.</p>
<p><strong>Data-driven</strong> models are based on observations. The actual model might have no understanding of the domain, but only make inferences
based on observed probabilities.</p>
<h3 id="stochastic-vs-deterministic-models">Stochastic vs. deterministic models</h3>
<p><strong>Stochastic models</strong> include some kind of random component. This can be explicit randomization,
as in the case of a <a href="https://en.wikipedia.org/wiki/Monte_Carlo_method">Monte Carlo simulation</a>.
The underlying mathematical model can make use of probability, as in logistic regression,
for example, yielding a probability for each potential class, explicitly modelling uncertainty.</p>
<p><strong>Deterministic models</strong> simply yield the same result every time, and may not include a notion of uncertainty.</p>
<h3 id="flat-vs-hierarchical-models">Flat vs. hierarchical models</h3>
<p>A <strong>flat model</strong> is one where there is only one problem that is being solved, without sub-problems with a parent-child relationship.</p>
<p>A <strong>hierarchical model</strong> has structure that has parent-child relationship between sub-problems.</p>
<h3 id="evaluating-models">Evaluating models</h3>
<p>It is usually not possible to know in advance which model is the best choice for a given problem and/or dataset.</p>
<p>Given two or more models, we must evaluate them to determine which one performs better.</p>
<p>Human insight should not be ignored: our domain knowledge can suggest whether the model makes any sense.</p>
<p>However, sometimes, we need to compute an appropriate metric for the model with respect to the data.
What is appropriate depends on the problem type (classification/regression) and what we are interested in.
We are often interested in generalization performance, that is, how well the model does with inputs that are not part of the data the model has seen.
Understanding whether our model is any good means it needs to be measured against a baseline.</p>
<h3 id="train-test-split">Train-test split</h3>
<p>Generalization performance needs to be evaluated on data that was never used to train the model.</p>
<p>We call this the test set, never ever make evaluate the model on the training set.</p>
<p>Evaluating generalization on data that the model has seen in training is worthless.</p>
<p>If the model has parameters, we need to potentially split the training set in two: the actual training set and the validation set.</p>
<ul>
<li>Train the model with respect to the training set using different choices for the parameters.</li>
<li>Evaluate against the validation set.</li>
<li>Choose the parameters that performed the best with regard to the validation set.</li>
<li>Evaluate the model against the test set.</li>
</ul>
<p>The simplest way to construct the sets is by partitioning the dataset uniformly at random.
We often like to use more data for the training set than test set.</p>
<p>Rule of thumb: if we do a simple train-test split, use 75% of data for the training set
and 25% for the test set. If we need a validation set as well, split the data 50-25-25.</p>
<p>Train-test-split is easily done using <code>sklearn.model_selection.train_test_split</code></p>
<h3 id="cross-validation">Cross-validation</h3>
<p>What if we have very little data?</p>
<p>Then the training set can become too small if we split it.</p>
<p>Cross-validation is a method to amplify the size of the sets by partitioning data into $k$ disjoint parts,
and then systematically using $k-1$ parts for training
and the remaining part for testing, and
computing the metric, e.g., as average
and standard deviation.</p>
<p>The extreme case occurs when $k=n$, which is known as <em>leave-one-out</em> cross-validation.</p>
<p>Often, we would then train the final model with all data, assuming it will do as well as during cross-validation.</p>
<h3 id="baseline-models">Baseline models</h3>
<p>Baseline model is something that we compare against to see if we can get an improvement.</p>
<p>To understand if our model is worth anything, we should have some kind of baseline and conclusively show that our model beats the baseline.</p>
<h3 id="evaluating-binary-classifiers">Evaluating binary classifiers</h3>
<p>A binary classifier classifies objects into two classes: a <strong>positive</strong> and a <strong>negative</strong> class.</p>
<p>Often positive instances are the more interesting or rarer ones.</p>
<p>The performance of a classifier can often be presented using a <strong>confusion matrix</strong></p>
<ul>
<li><strong>True Positives (TP)</strong> are correctly identified positives</li>
<li><strong>True Negatives (TN)</strong> are correctly identified negatives</li>
<li><strong>False Positives (FP)</strong> are incorrectly identified positives</li>
<li><strong>False Negatives (FN)</strong> are incorrectly identified negatives</li>
</ul>




















<table><thead><tr><th align="center"></th><th align="center">Predicted positive</th><th align="center">Predicted negative</th></tr></thead><tbody><tr><td align="center">Actual positive</td><td align="center"><strong>True Positives (TP)</strong></td><td align="center"><strong>False Negatives (FN)</strong></td></tr><tr><td align="center">Actual negative</td><td align="center"><strong>False Positives (FP)</strong></td><td align="center"><strong>True Negatives (TN)</strong></td></tr></tbody></table>
<h4 id="accuracy">Accuracy</h4>
<p>The simplest metric for classifiers is probably <strong>accuracy</strong>.</p>
<p>Accuracy measures the fraction of correct classifications out of all classifications:
$$
Accuracy = \frac{TP + TN}{TP + TN + FP + FN}
$$</p>
<p>For binary classifiers, accuracy is at its worst when it is around <strong>$0.5$</strong>.</p>
<p>Accuracy of <strong>$0$</strong> would mean we get perfect accuracy by swapping the class labels.</p>
<p>Accuracy does little to tell why or what is wrong.</p>
<h4 id="precision-and-recall">Precision and recall</h4>
<p><strong>Precision</strong> and <strong>recall</strong> are basic metrics for binary classifiers.</p>
<p>Precision measures the fraction of interesting finds among the returned positives.
$$
Precision = \frac{TP}{TP + FP}
$$</p>
<p>Recall measures how large a fraction of interesting values we are able to pick up from the set of all positive instances.
$$
Recall = \frac{TP}{TP + FN}
$$</p>
<p>There is usually a tradeoff between precision and recall.</p>
<h3 id="multi-class-classification">Multi-class classification</h3>
<p>Accuracy is easily extended to multiple classes (simply count the fraction of correct classifications).</p>
<p><strong>Top-$k$ success rule</strong> gives credit if the correct class label was among the top-$k$ possibilities.</p>
<p>Confusion matrices can be generalized to multi-class cases. Correct predictions would be on the diagonal.</p>
<p>Precision and recall can also be generalized into multi-class environments.</p>





























<table><thead><tr><th align="center"></th><th align="center">Predicted A</th><th align="center">Predicted B</th><th align="center">Predicted C</th></tr></thead><tbody><tr><td align="center">Actual A</td><td align="center">0.97</td><td align="center">0.03</td><td align="center">0.00</td></tr><tr><td align="center">Actual B</td><td align="center">0.16</td><td align="center">0.84</td><td align="center">0.00</td></tr><tr><td align="center">Actual C</td><td align="center">0.00</td><td align="center">0.00</td><td align="center">1.00</td></tr></tbody></table>
<h3 id="evaluating-regression-models">Evaluating regression models</h3>
<p>Regression models are usually evaluated by computing error statistics.</p>
<p>Suppose $\hat{y}$ is the predicted value and $y$ is the correct value.</p>
<ul>
<li>Plain difference $\hat{y} - y$ is simple but signed, so it is inappropriate if the signedness is not significant.</li>
<li>Absolute error $|\hat{y} - y|$ is a simple statistic, but is sensitive to variations in scale.</li>
<li>Relative error $\left| \frac{\hat{y} - y}{y} \right|$ can be used even in the presence of variable scales but behaves erratically near 0.</li>
<li>Squared error $\left(\hat{y} - y\right)^2$ is always positive and penalizes large deviations more.</li>
</ul>
<p>The (signed) error statistics can be plotted as a histogram; this shows the distribution of error
If the histogram is not bell-shaped (approximately normal), this indicates there is a systemic source of error.</p>
<p>A common summary statistic is <strong>M</strong>ean <strong>S</strong>quared <strong>E</strong>rror, the mean of squared errors:
$$
MSE(\hat{y}, y) = \frac{1}{n} \sum_{i = 1}^n \left(\hat{y}_i - y_i \right)^2
$$</p>
<p>A related statistic is the <strong>R</strong>oot <strong>M</strong>ean <strong>S</strong>quared that has the same units as the values themselves:
$$
RMS(\hat{y}, y) = \sqrt{MSE(\hat{y}, y)}
$$</p>  </div> <nav class="flex flex-col sm:flex-row justify-between mt-8 pt-4 border-t border-border" data-astro-cid-v5ro3oot> <a href="/school/dat565/dat565_5" class="nav-button prev-button mb-4 sm:mb-0" data-astro-cid-v5ro3oot> <span class="arrow" data-astro-cid-v5ro3oot>←</span> <span class="text" data-astro-cid-v5ro3oot> <span class="label" data-astro-cid-v5ro3oot>Previous</span> <span class="title" data-astro-cid-v5ro3oot>Part 5 - Statistical analysis</span> </span> </a> <a href="/school/dat565/dat565_7" class="nav-button next-button" data-astro-cid-v5ro3oot> <span class="text" data-astro-cid-v5ro3oot> <span class="label" data-astro-cid-v5ro3oot>Next</span> <span class="title" data-astro-cid-v5ro3oot>Part 7 - Linear and logistic regression</span> </span> <span class="arrow" data-astro-cid-v5ro3oot>→</span> </a> </nav> </article>  </main> </div> </body></html> 