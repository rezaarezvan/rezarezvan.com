<!DOCTYPE html>
<html>
<head>
	<meta charset="utf-8"><meta property="og:site_name" content="rezvan"><title>DSA: Part 3 - Dynamic Arrays | rezvan</title>
  <meta property="og:title" content="DSA: Part 3 - Dynamic Arrays | rezvan"><meta property="og:description" content="">
  <meta property="og:type" content="blog">
  <meta property="og:link" content="https://rezvan.xyz/school/dsa_3/"><link rel="shortcut icon" type="image/png" href=https://rezvan.xyz//images/icon.png />
  <meta property="og:image" content="https://rezvan.xyz//images/icon.png" /><meta name="viewport" content="width=device-width, initial-scale=1">
	<link rel="stylesheet" type="text/css" media="screen" href="https://rezvan.xyz//css/main.css" />    
</head>

<body>
  <div class="wrapper">
	<div class="content">
		<div class="header_main">

    <a href="https://rezvan.xyz/"><p class="header_title">rezvan</p><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.3/dist/katex.min.css" integrity="sha384-Juol1FqnotbkyZUT5Z7gUPjQ9gzlwCENvUZTpQBAPxtusdwFLRy382PSDx5UUJ4/" crossorigin="anonymous">

<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.3/dist/katex.min.js" integrity="sha384-97gW6UIJxnlKemYavrqDHSX3SiygeOwIZhwyOKRfSaf0JWKRVj9hLASHgFTzT+0O" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.3/dist/contrib/auto-render.min.js" integrity="sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05" crossorigin="anonymous" onload="renderMathInElement(document.body);"></script>

<script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement(document.body, {
            delimiters: [
                {left: "$$", right: "$$", display: true},
                {left: "$", right: "$", display: false}
            ]
        });
    });
</script>

    </a>

    <br>

    <nav id="main">
        
        <a href="/About/">About</a>
        
        <a href="/CV/">CV</a>
        
        <a href="/school/">School</a>
        
    </nav></div>

  <article><div class="title_wrapper">
			<h1 class="title">DSA: Part 3 - Dynamic Arrays</h1><p class="single_time">Nov 27, 2022</p></div>
		<section class="post">
			<h3 id="dynamic-arrays">Dynamic arrays</h3>
<p>Finally we have arrived at the DS of DSA. In (almost) all programming languages the most common built in data structure are arrays.
We have seen them, worked with them - nothing new. We&rsquo;ve probably even worked with dynamic arrays, they are an essential data structure - sometimes we don&rsquo;t know how much data we&rsquo;ll need.</p>
<p>But how are dynamic arrays <em>actually</em> implemented into a language? The ideas is actually quite simple - we use a fixed length array and make a larger, fixed length, array when we have ran out of space.</p>
<h3 id="different-approaches">Different approaches</h3>
<h4 id="naive-approach">Naive Approach</h4>
<p>A very naive and brute force implementation would be, if we append a value to a array which doesn&rsquo;t have space, we copy the old array and make the index one larger so we can fit the new value.
The problem with this approach is that it&rsquo;s <em>really</em> slow. If I want to append 10 items to a list of size 1, we need to copy each time we append.</p>
<p>The complexity of this becomes $\mathcal{O}(n^2)$, which again, is really bad.</p>
<h4 id="a-better-but-naive--approach">A Better, but Naive  Approach</h4>
<p>A better approach would be that each we need to resize the array - we make some extra space for future appends. Let&rsquo;s say each time we need to resize the array we add 10 more indexes, for future use.</p>
<p>This is actually 10 times faster than our first approach! But it&rsquo;s still $\mathcal{O}(n^2)$ so&hellip;</p>
<h4 id="multiplicative-approach">Multiplicative Approach</h4>
<p>So, instead of resizing by a constant - why not just double the array size each time? With this approach:</p>
<p>To reach an array of size $2^n$ we would need to do $1 + 2 + 4 + \dots + 2^{n-1}$ total element copies
This sums up to $2^n - 1$ which makes this approach $\mathcal{O}(n)$!</p>
<h3 id="worst-case-complexities">Worst-case Complexities</h3>
<p>One might go through an example about the worst-case complexity of these two approaches. If we do that we find that both have a worst-case complexity
of $\mathcal{O}(n)$. If we ever need to resize, we would need to copy $n$ elements from the old array to the new one.</p>
<p>If we now suppose we call the <code>add</code> function $n$ times instead. What&rsquo;s the worst-case complexity now? For the constant approach it&rsquo;s quite obvious that it becomes
$\mathcal{O}(n^2)$, for each call, in the worst-case, we would need to copy n items, then n adds in total.</p>
<p>For our multiplicative approach - this instead becomes $\mathcal{O}(n)$. But this is still &rsquo;too slow&rsquo; - we would like a $\mathcal{O}(1)$ operation.</p>
<p>But don&rsquo;t worry - here we have something called <strong>amortized complexity</strong> which plays a huge role.</p>
<h3 id="amortized-complexity">Amortized Complexity</h3>
<p>If <code>add</code> had a $\mathcal{O}(1)$ worst-case complexity, $n$ calls would take $\mathcal{O}(n)$ time right?
But as we stated, our approach took $\mathcal{O}(n)$ for n calls - so we can say that <code>add</code> has a $\mathcal{O}(1)$ <em>amortized</em> complexity!</p>
<p>Basically what amortized complexity is, we take an <em>average</em> cost of the operation over n calls.</p>
<p>Now that we&rsquo;ve defined how the most important feature of dynamic arrays should work - let&rsquo;s implement one!</p>
<h3 id="implementation">Implementation</h3>
<p>A python implementation of a dynamic array:</p>
<pre tabindex="0"><code>class dynamic_array:
    def __init__(self):
        self.array = [None]
        self.size  = 0

    def get(self, i):
        if 0 &lt;= i &lt; self.size:
            return &#34;Error, index out of bounds&#34;

        return self.array[i]

    def set(self, i, val):
        if 0 &lt;= i &lt; self.size:
            return &#34;Error, index out of bounds&#34;

        self.array[i] = val

    def append(self, val):
        if self.size == len(self.array):
            self.resize()

        self.array[self.size] = val
        self.size += 1

    def resize(self):
        new_array = [None] * 2
        
        for i in range(len(self.array)):
            new_array[i] = self.array[i]

        self.array = new_array
</code></pre><p>Now this isn&rsquo;t a perfect implementation - but it works okay.</p>
<p>Now that we understand <em>really</em> how dynamic arrays work - we can actually start implementing some more <em>interesting</em> data structures</p>
<h3 id="stacks-and-queues">Stacks and Queues</h3>
<p>Stacks and Queues are quite popular and powerful data structures. But just to refresh let&rsquo;s go over how both data structures work.</p>
<h4 id="stacks">Stacks</h4>
<p>A Stack is a so called <strong>LIFO</strong> data structure. LIFO stands for &lsquo;<strong>L</strong>ast <strong>I</strong>n <strong>F</strong>irst <strong>O</strong>ut&rsquo;. One can visualize it as a literal stack of items (therefore the name). If have a <strong>stack</strong>
of things, we might take items from the top and keep throwing away items til we reach the bottom. This is exactly how the stack data structure works!</p>
<h5 id="important-functions-for-stacks">Important Functions for Stacks</h5>
<p>These operations that I was talking about have names - if we remove the top item, we call it <code>pop()</code> - and if we place an item on the top of the stack
it&rsquo;s called <code>push()</code>. We have some helper functions that are usually needed for an implementation as well - the <code>peek()</code> function gives us the item at the top of the stack.
The <code>size()</code> returns how large the stack currently is.</p>
<h4 id="queues">Queues</h4>
<p>A queue is a so called <strong>FIFO</strong> data structure, &lsquo;<strong>F</strong>irst <strong>In</strong> <strong>F</strong>irst <strong>O</strong>ut&rsquo;. Just as the stack data structure, we can visualize this as a literal queue.
If someone joins the queue you are put in last - and the first person to join queue will be the first to leave the queue as well.</p>
<h3 id="how-to-implement-stacks-and-queues">How to implement Stacks and Queues</h3>
<p>Now that we understood the basics of these data structures - let&rsquo;s see how one can implement them. But before we dive right in let&rsquo;s see the different approaches to this.
Both stacks and queues can be implemented with Dynamic arrays as we covered - but equally as good with linked lists. We&rsquo;ll start with how we can implement it using a linked list - but let&rsquo;s refresh our memory of what a linked list is.</p>
<h4 id="linked-lists">Linked Lists</h4>
<p>A (singly) linked list consist of &lsquo;Node&rsquo; objects in a sequence - these node objects can contain one or multiple values - each node is &lsquo;pointing&rsquo; to the next node in the sequence.
A singly linked list points to the first node and the last node in the list points to nothing (Nothing can for example be <code>Null</code>)
Since it would be inefficient to calculate the size each time we call <code>size()</code>, since we would need to traverse the whole list, we instead keep a dynamic size variable that we can access.</p>
<p>Here&rsquo;s how the boilerplate classes for a Linked List might look:</p>
<pre tabindex="0"><code>class Node:
    def __init__(self, val, next = None):
        self.val = val
        self.next = next

class LinkedList:
    def __init__(self, val = None):
        self.head = None
        self.size = 0
</code></pre><p>With our new knowledge about linked lists - we can return to stacks!</p>
<h4 id="stacks-as-linked-lists">Stacks as linked lists</h4>
<p>An implementation with a linked list for a stack is perfect - we only care about the top element in stack, therefore, when we <code>push()</code>,
we first make the new nodes next point to the current head. Then we redirect head to our new node and increase size. When we want to <code>pop()</code> -
we first store the value of our current head node temporarily, to return the value popped. Then we redirect head to the <code>next</code> of the node we want to pop.</p>
<p>In many languages we do not need to manually remove the node from the list - since it will be handled by garbage collection. But in a language like C, we would need to <code>free()</code> that node from memory.</p>
<p>So let&rsquo;s implement a stack using a linked list.</p>
<h4 id="implementation-of-a-stack-using-a-linked-list">Implementation of a stack using a linked list</h4>
<pre tabindex="0"><code>class Node:
    def __init__(self, val):
        self.val = val
        self.next = None


class Stack:
    def __init__(self):
        self.head = None
        self.size = 0

    def is_empty(self):
        if self.head == None:
            return True

        return False

    def push(self, val):
        if self.head == None:
            self.head = Node(val)
            return
 f
        new = Node(val)
        new.next = self.head
        self.head = new
        self.size += 1

    def pop(self):
        if self.head == None:
            return None

        pop = self.head.val
        self.head = self.head.next
        self.size -= 1
        return pop
</code></pre><p>Now let&rsquo;s implement a stack using a dynamic array.</p>
<h4 id="implementation-of-a-stack-using-a-dynamic-array">Implementation of a stack using a dynamic array</h4>
<p>Before we start the implementation, let&rsquo;s consider <strong>how</strong> we should implement it before.
One thing that might not be obvious might be that, using the first element as the top - will work - but be super slow.</p>
<p>If we pop the first element - we would need to push forward the rest of the stack by 1 step. Which would take $\mathcal{O}(n)$. We want $\mathcal{O}(1)$!</p>
<p>So instead let&rsquo;s use the last element as the top!</p>
<pre tabindex="0"><code>class Stack:
    def __init__(self):
        self.stack = [None]
        self.size = 0

    def is_empty(self):
        return self.size == 0

    def push(self, val):
        if self.size == len(self.stack):
            self.resize(2 * self.size)

        self.stack[self.size] = val
        self.size += 1

    def pop(self):
        self.size -= 1
        pop = self.stack[self.size]
        self.stack[self.size] = None
        if self.size == (len(self.stack) // 4):
            self.resize(len(self.stack) // 2)

        return pop

    def resize(self, factor):
        new_array = [None] * factor

        for i in range(self.size):
            new_array[i] = self.stack[i]

        self.stack = new_array
</code></pre><h4 id="implementation-of-a-queue-using-linked-lists">Implementation of a queue using linked lists</h4>
<p>Now it&rsquo;s now to implement queues! Using a linked list seems as a very natural approach since we have a sequence of pointers forward.
However, in a queue we always need to the first and the last element. Therefore, we need another pointer to the end of the list as well.</p>
<pre tabindex="0"><code>class Node:
    def __init__(self, val):
        self.val = val
        self.next = None

class Queue:
    def __init__(self):
        self.last = None
        self.first = None
        self.size = 0

    def is_empty(self):
        if self.first == None:
            return True

        return False

    def enqueue(self, val):
        new_node = Node(val)
        if self.is_empty():
            self.first = new_node
            self.last = new_node
        else:
            self.last.next = new_node
            self.last = new_node

        self.size += 1

    def dequeue(self):
        if self.is_empty():
            return None

        exit = self.first
        self.first = self.first.next
        self.size -= 1
        return exit.val
</code></pre><p>Quite simple and elegant!</p>
<h4 id="implementation-of-a-queue-using-a-dynamic-array">Implementation of a queue using a (dynamic) array</h4>
<p>One thing we have go through first is that - our implementation will be a so called circular array. Our pointers to the head and tail can (and will cross).</p>
<pre tabindex="0"><code>class Queue:
    def __init__(self):
        self.queue = [None]
        self.head = 0
        self.tail = 1

    def is_empty(self):
        return self.head == (self.tail + 1) % len(self.queue)

    def enqueue(self, val):
        if (self.tail + 1) % len(self.queue) == self.head:
            self.resize(2 * len(self.queue))

        self.queue[self.tail] = val
        self.tail = (self.tail + 1) % len(self.queue)

    def dequeue(self):
        if self.is_empty():
            raise Exception(&#34;Queue is empty&#34;)

        result = self.queue[self.head]
        self.head = (self.head + 1) % len(self.queue)

        return result

    def resize(self, new_size):
        old_queue = self.queue
        self.queue = [None] * new_size

        if self.head &lt; self.tail:
            for i in range(self.tail - self.head):
                self.queue[i] = old_queue[(self.head + i) % len(old_queue)]

            self.head = 0
            self.tail = self.tail - self.head

        else:
            for i in range(len(old_queue) - 1):
                _index = (self.head + i) % len(old_queue)
                self.queue[i] = old_queue[_index]

            self.head = 0
            self.tail = self.tail - self.head - 1
</code></pre><p>That&rsquo;s it for this part - in the next part we&rsquo;ll cover something called &lsquo;<strong>A</strong>bstract <strong>D</strong>ata <strong>T</strong>ypes&rsquo; or for short ADTs.
We&rsquo;ll define what a ADT is and what&rsquo;s the difference between them and ordinary data structures.</p>

		</section>
  </article>
	</div>

	<footer><p class="footer_msg">Memento mori</p></footer>

  </div>
</body>
</html>
