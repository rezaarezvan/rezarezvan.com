<!DOCTYPE html>
<html><head lang="en">
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge"><title>rezvan | Computer System Engineering: Part 3 - Pipelining</title><link rel="icon" type="image/png" href="/icon.png" /><meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description"
        content="In this part we&rsquo;ll cover the idea of pipelining - and it&rsquo;s performance effects it has on computer systems.
Let&rsquo;s first cover what every computer does to perform complex tasks.
Instruction execution Every computer does these five stages:
Fetch Instruction. PC → Instruction memory.
Decode the instruction and read from registers.
Execute the instruction.
Arithmetic/logical computation.
Computation of effective memory address.
Computation of jump address/conditional address.
Read / Write from / to memory for load/store instructions." />
    <meta property="og:image" content="https://raw.githubusercontent.com/rezaarezvan/rezvan.xyz/main/images/icon.png" />
    <meta property="og:title" content="Computer System Engineering: Part 3 - Pipelining" />
<meta property="og:description" content="In this part we&rsquo;ll cover the idea of pipelining - and it&rsquo;s performance effects it has on computer systems.
Let&rsquo;s first cover what every computer does to perform complex tasks.
Instruction execution Every computer does these five stages:
Fetch Instruction. PC → Instruction memory.
Decode the instruction and read from registers.
Execute the instruction.
Arithmetic/logical computation.
Computation of effective memory address.
Computation of jump address/conditional address.
Read / Write from / to memory for load/store instructions." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://rezvan.xyz/school/EDA333/EDA333_3/" /><meta property="article:section" content="school" />
<meta property="article:published_time" content="2023-03-27T00:00:00+00:00" />
<meta property="article:modified_time" content="2023-03-27T00:00:00+00:00" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Computer System Engineering: Part 3 - Pipelining"/>
<meta name="twitter:description" content="In this part we&rsquo;ll cover the idea of pipelining - and it&rsquo;s performance effects it has on computer systems.
Let&rsquo;s first cover what every computer does to perform complex tasks.
Instruction execution Every computer does these five stages:
Fetch Instruction. PC → Instruction memory.
Decode the instruction and read from registers.
Execute the instruction.
Arithmetic/logical computation.
Computation of effective memory address.
Computation of jump address/conditional address.
Read / Write from / to memory for load/store instructions."/>
<script src="https://cdn.jsdelivr.net/npm/feather-icons/dist/feather.min.js"></script>
    <link href="https://fonts.googleapis.com/css2?family=IBM+Plex+Mono:ital,wght@1,500&display=swap" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css2?family=Fira+Sans&display=swap" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css?family=Roboto+Mono" rel="stylesheet">

    
    <link rel="stylesheet" type="text/css" media="screen" href="https://rezvan.xyz/css/main.55ceafd1ab15172b8770201b55c83270fac8611fcdae31fccb3a7fd94ac6da6e.css" />
    <link id="darkModeStyle" rel="stylesheet" type="text/css" href="https://rezvan.xyz/css/dark.b95ac7b1169ab6755ef14c75e8e49c983d2d56c40ee0c3d69d357d42339b5e31.css"  disabled />
    

    
    
    <script type="text/javascript"
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
        </script>

    
    <script type="text/x-mathjax-config">
		MathJax.Hub.Config({
			tex2jax: {
				inlineMath: [['$','$'], ['\\(','\\)']],
				displayMath: [['$$','$$'], ['\[','\]']],
				processEscapes: true,
				processEnvironments: true,
				skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
				TeX: { equationNumbers: { autoNumber: "AMS" },
						 extensions: ["AMSmath.js", "AMSsymbols.js"] }
			}
		});
		</script>
    

    
    
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.css">
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.js"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/contrib/auto-render.min.js"
        onload="renderMathInElement(document.body);"></script>

    
    <script>
        document.addEventListener("DOMContentLoaded", function () {
            renderMathInElement(document.body, {
                delimiters: [
                    {left: "$$", right: "$$", display: true},
                    {left: "$", right: "$", display: false}
                ]
            });
        });
    </script>
    

    
</head>
<body>
    <div class="content"><header>
    <div class="main">
        <a href="https://rezvan.xyz/">rezvan</a>
    </div>
    <nav id="site-navbar">
        
        <a href="/">home</a>
        
        <a href="/about">about</a>
        
        <a href="/principles">principles</a>
        
        <a href="/contact">contact</a>
        
        <a href="/cv">cv</a>
        
        <a href="/school">school</a>
        
        <a href="/tags">tags</a>
        
        | <span id="dark-mode-toggle" onclick="toggleTheme()"></span>
        <script src="https://rezvan.xyz/js/themetoggle.js"></script>
        
    </nav>
</header>

<main>
    <article>
        <div class="title">
            <h1 class="title">Computer System Engineering: Part 3 - Pipelining</h1>
            <div class="meta">Posted on Mar 27, 2023</div>
        </div>
        

        <section class="body">
            <p>In this part we&rsquo;ll cover the idea of pipelining - and it&rsquo;s performance effects it has on computer systems.</p>
<p>Let&rsquo;s first cover what every computer does to perform complex tasks.</p>
<h3 id="instruction-execution">Instruction execution</h3>
<p>Every computer does these five stages:</p>
<ol>
<li>
<p><strong>Fetch</strong> Instruction. PC → Instruction memory.</p>
</li>
<li>
<p><strong>Decode</strong> the instruction and read from registers.</p>
</li>
<li>
<p><strong>Execute</strong> the instruction.</p>
<ul>
<li>
<p>Arithmetic/logical computation.</p>
</li>
<li>
<p>Computation of effective memory address.</p>
</li>
<li>
<p>Computation of jump address/conditional address.</p>
</li>
</ul>
</li>
<li>
<p><strong>Read / Write from / to memory</strong> for load/store instructions.</p>
</li>
<li>
<p><strong>Write back</strong> the result into the result register (RF).</p>
</li>
</ol>
<p>Let&rsquo;s take a look how this logic is implemented:
<img src="/school/images/SL.png#center" alt=""></p>
<p>A good refresher that we&rsquo;ll need to remember is that:</p>
<blockquote>
<p>The longest critical path determines our clock frequency.</p>
</blockquote>
<p>Let&rsquo;s now look into each stage, so we understand them properly.</p>
<h4 id="instruction-fetch-if">Instruction Fetch (IF)</h4>
<p>Let&rsquo;s begin by dissecting the <strong>fetch</strong> stage:</p>
<p><img src="/school/images/IF.png#center" alt=""></p>
<p>We see that everything starts in PC, we read our current address (PC Value), we have this black box of a decoder which outputs the instruction (32-bits).</p>
<p>Notice that we also take our current PC value and add <code>4</code> to it, why <code>4</code>?, because each instruction is 32-bits, or 4 bytes.</p>
<h4 id="r-format-instructions">R-Format Instructions</h4>
<p>For instructions with the R-format, we have the following:
<img src="/school/images/RF.png#center" alt=""></p>
<p>We take in our two register operands, compute the arithmetic/logical computation and store the result to the result register.</p>
<h4 id="loadstore-instructions">Load/Store Instructions</h4>
<p>For instructions that we either load/store to memory:</p>
<p><img src="/school/images/LS.png#center" alt=""></p>
<p>Here we have two important parts, we need to read our register operands but also compute our offset.</p>
<p>Since the offset is 16-bits and the register operands 32-bits, we need to sign extend our 16-bit offset to 32-bits.</p>
<h4 id="conditional-jump-instructions">Conditional jump instructions</h4>
<p>For these type of instructions, we need to compare our registers, we do this by doing a subtraction and looking at the &ldquo;zero&rdquo; output from our ALU.</p>
<p>But we also need to compute our jump address, to do this we do:</p>
<ul>
<li>
<p>Sign extend our offset</p>
</li>
<li>
<p>Left shift by 2 bits, due to word displacement</p>
</li>
<li>
<p>Now add this offset to PC.</p>
</li>
</ul>
<h3 id="in-depth-overview">In-depth overview</h3>
<p>Now let&rsquo;s take a look at the first picture, but with some more details:</p>
<p><img src="/school/images/TP.png#center" alt=""></p>
<p>If we try to deduce what our critical path is, we quickly find that load instructions are really slow.</p>
<p>Since they go through:</p>
<blockquote>
<p>Instruction memory → Registers → ALU → Data memory → Registers</p>
</blockquote>
<p>Now, let&rsquo;s pipeline this processor to increase the <em>speed</em>.</p>
<h3 id="pipelined-version">Pipelined version</h3>
<p>Naturally, since we have five stages, let&rsquo;s pipeline it into 5 separate stages as well!</p>
<p><img src="/school/images/PL.png#center" alt="">
Note: The dotted lines represents registers that separate each stage</p>
<p>As we can see now, we can handle 5 separate instructions at once!</p>
<p>If our pipelining is &ldquo;balanced&rdquo;, meaning each stage takes the same amount of time, then we can see a resulting speed up of:
$$
\textbf{Speedup} = \frac{T_{c \quad | \quad \text{Non-pipelined version}}}{T_{c \quad | \quad \text{Pipelined version}}} \approx \text{Number of pipeline stages}
$$</p>
<p>If our pipelining is unbalanced, we&rsquo;ll see a smaller increase.</p>
<p>However, doing 5 instructions at once comes with a cost, we no longer have a perfect CPU. We have several hazards that we need to consider now.</p>
<h3 id="hazards">Hazards</h3>
<p>There are three different types of hazards that we&rsquo;ll need to take care off:</p>
<ul>
<li>
<p>Structural hazards</p>
<ul>
<li>A stage is currently busy doing an operation</li>
</ul>
</li>
<li>
<p>Data hazards</p>
<ul>
<li>An instruction that depends on a earlier instruction.</li>
</ul>
</li>
<li>
<p>Control hazards</p>
<ul>
<li>The condition and potential address of a jump has not yet by the instruction fetch.</li>
</ul>
</li>
</ul>
<p>Let&rsquo;s look into how to solve each of these.</p>
<h4 id="structural-hazards">Structural hazards</h4>
<p>As we defined earlier, it is when two or more instruction need to access the same stage simultaneously.</p>
<p>There are two main examples of this:</p>
<ul>
<li>
<p>Registers: Reading and writing to the same register:</p>
<ul>
<li>Solution: Write and read in separate half cycles.</li>
</ul>
</li>
<li>
<p>If the pipeline only has one (1) shared memory:</p>
<ul>
<li>Solution: Don&rsquo;t. All pipeline models use separate memory for instructions and data memory.</li>
</ul>
</li>
</ul>
<h4 id="data-hazards">Data hazards</h4>
<p>If we have the following MIPS:</p>
<pre tabindex="0"><code>add    $s0, $t0, $t1
add    $t2, $s0, $t3
</code></pre><p>Notice that both instructions either write or read <code>$s0</code>.</p>
<p>A data hazard occurs specifically after a RAW (<strong>R</strong>ead <strong>A</strong>fter <strong>W</strong>rite)</p>
<p>There are two solutions:</p>
<ul>
<li>
<p>If the case is like above we can do:</p>
<ul>
<li>
<p>Forwarding (Bypassing)</p>
<ul>
<li>
<p>Use the result instantly when computed from the ALU</p>
</li>
<li>
<p>Do not wait to store it until the Write Back phase.</p>
</li>
<li>
<p>But, does require more logic and path in our data path.</p>
</li>
<li>
<p>But, no stalling!</p>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p>Forwarding doesn&rsquo;t solve all cases, for example, load instructions.</p>
<ul>
<li>
<p>We cannot do a forwarding, &ldquo;back in time&rdquo;</p>
</li>
<li>
<p>Therefore, requires a stalling cycle.</p>
</li>
</ul>
</li>
</ul>
<p>But consider this following example:</p>
<pre tabindex="0"><code>lw  $t1, 0($t0)
lw  $t2, 4($t0)
add $t3, $t1, $t2
sw  $t3, 12($t0)
lw  $t4, 8($t0)
add $t5, $t1, $t4
sw  $t5, 16($t0)
</code></pre><p>In this we&rsquo;ll have two stalling cycles, but with some smart thinking (or a smart compiler) we can instead do:</p>
<pre tabindex="0"><code>lw  $t1, 0($t0)
lw  $t2, 4($t0)
lw  $t4, 8($t0)
add $t3, $t1, $t2
sw  $t3, 12($t0)
add $t5, $t1, $t4
sw  $t5, 16($t0)
</code></pre><p>Just by changing one line we reduced our clock cycle count from 9 to 7!</p>
<h4 id="control-hazards">Control hazards</h4>
<ul>
<li>
<p>Problem: We want to compare registers and compute the jump address earlier in the program</p>
<ul>
<li>
<p>Solution: Move/Add more logic to the instruction decode stage.</p>
</li>
<li>
<p>This will result that we only need to wait (stall) for one cycle!</p>
</li>
</ul>
</li>
</ul>
<p>But, often longer pipelines cannot do this approach, since it will still result in a lot of stalling cycles.</p>
<p>The solution in modern CPUs is, predict the jump! If we fail to predict, then we stall to restore our failed prediction.</p>
<p>There are two different types:</p>
<ul>
<li>
<p>At compile time/Static jump-predictions:</p>
<ul>
<li>
<p>Based on typical jump-behavior</p>
</li>
<li>
<p>Examples: loops and if-conditions:</p>
<ul>
<li>
<p>Predict backwards jump as &ldquo;taken&rdquo;</p>
</li>
<li>
<p>Predict forward jump as &ldquo;not taken&rdquo;</p>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p>At run time/Dynamic jump-predictions:</p>
<ul>
<li>
<p>Hardware keeps track/notes the current jump-behavior</p>
<ul>
<li>Keeps statistics of jumps</li>
</ul>
</li>
<li>
<p>From the statistics tries to predict, can be as simple as, do as the last time.</p>
</li>
</ul>
</li>
</ul>
<h3 id="summary">Summary</h3>
<p>Okay, so we&rsquo;ve seen the power and beauty of pipelining.</p>
<p>So let&rsquo;s make a little summary:</p>
<ul>
<li>
<p>Pipelining boosts the performance, by increasing the total instruction-flow to the CPU.</p>
<ul>
<li>Multiple instructions execute in parallel.</li>
</ul>
</li>
<li>
<p>Although great, it comes with some hazards:</p>
<ul>
<li>
<p>Structural hazards, data hazards (RAW), and control hazards.</p>
</li>
<li>
<p>Can both be solved with hardware and software.</p>
</li>
</ul>
</li>
<li>
<p>There is a strong correlation between the ISA and the complexity of the pipeline.</p>
</li>
</ul>
<p>That last one might not be so clear from the start, but if we had very complex functions like</p>
<pre tabindex="0"><code>add M[$t0], M[$t1], M[$t2]
</code></pre><p>This would be a headache, since then we are in the execute stage and read/write to memory simultaneously.</p>

        </section>

        <div class="post-tags">
            
            
            <nav class="nav tags">
                <ul class="tags">
                    
                    <li><a href="/tags/Computer-System-Engineering">Computer System Engineering</a></li>
                    
                </ul>
            </nav>
            
            
        </div>
        </article>
</main>
<footer>
    <div style="display:flex"><a class="soc" href="https://github.com/rezaarezvan" rel="me" title="GitHub"><i data-feather="github"></i></a>
        <a class="border"></a><a class="soc" href="https://twitter.com/rzvan__/" rel="me" title="Twitter"><i data-feather="twitter"></i></a>
        <a class="border"></a></div><p class="footer_msg">memento mori</p></footer>


<script>
    feather.replace()
</script></div>
</body>

</html>
