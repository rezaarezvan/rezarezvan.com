<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Concurrent Programming on rezvan</title>
    <link>https://rezvan.xyz/school/concurrent-programming/</link>
    <description>Recent content in Concurrent Programming on rezvan</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 19 Feb 2023 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://rezvan.xyz/school/concurrent-programming/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Concurrent Programming: Part 10 - Parallel linked lists</title>
      <link>https://rezvan.xyz/school/tda384/tda384_10/</link>
      <pubDate>Sun, 19 Feb 2023 00:00:00 +0000</pubDate>
      <guid>https://rezvan.xyz/school/tda384/tda384_10/</guid>
      <description>In this part we&amp;rsquo;ll cover the synchronization challenges that arise when designing (correct) and efficient parallelizations.&#xA;But let&amp;rsquo;s first see the burdens with locks&#xA;The trouble with locks Standard techniques for concurrent programming are ultimately based on locks.&#xA;Programming with locks has several drawbacks:&#xA;Performance overhead.&#xA;Lock granularity is hard to choose:&#xA;Not enough locking: race conditions.&#xA;Too much locking: not enough parallelism.&#xA;Risk of deadlock and starvation.&#xA;Lock-based implementations do not compose (easily).</description>
    </item>
    <item>
      <title>Concurrent Programming: Part 9 - Parallelizing computations</title>
      <link>https://rezvan.xyz/school/tda384/tda384_9/</link>
      <pubDate>Mon, 13 Feb 2023 00:00:00 +0000</pubDate>
      <guid>https://rezvan.xyz/school/tda384/tda384_9/</guid>
      <description>Concurrent programming introduces:&#xA;The potential for parallel execution (faster, better resource usage) The risk of race conditions (incorrect, unpredictable computations) The challenge of concurrent programming is introducing parallelism without affecting correctness.&#xA;Let&amp;rsquo;s define how to parallelize:&#xA;A task $(F, D)$ consists in computing the result F $(D)$ of applying function $F$ to input data $D$&#xA;A parallelization of $(F, D)$ is a collection $(F_1 , D_1 ),\ (F_2 , D_2),\ \dots$ of tasks such that $F (D)$ equals the composition of $F_1 (D_1),\ F_2 (D_2),\ \dots $</description>
    </item>
    <item>
      <title>Concurrent Programming: Part 8 - Synchronization problems with message-passing</title>
      <link>https://rezvan.xyz/school/tda384/tda384_8/</link>
      <pubDate>Tue, 07 Feb 2023 14:05:43 +0100</pubDate>
      <guid>https://rezvan.xyz/school/tda384/tda384_8/</guid>
      <description>In this part we&amp;rsquo;ll cover the classical problems that occur when dealing with synchronization.&#xA;But within this paradigm, we don&amp;rsquo;t encounter the same problems as when using semaphores. Mutual exclusion is not an issue, since we never share any resource, the big problem today will be synchronization and coordination.&#xA;We&amp;rsquo;ll see that many problems have the solution of a server-client architecture.&#xA;Barriers Let&amp;rsquo;s quickly recap what our barriers should be able to do:</description>
    </item>
    <item>
      <title>Concurrent Programming: Part 6 &amp; 7 - Message-Passing Concurrency</title>
      <link>https://rezvan.xyz/school/tda384/tda384_6/</link>
      <pubDate>Sat, 04 Feb 2023 00:00:00 +0000</pubDate>
      <guid>https://rezvan.xyz/school/tda384/tda384_6/</guid>
      <description>So far we have looked at threads which share memory. The so-called shared memory model, but in this part we&amp;rsquo;ll cover distributed memory model, specifically, message-passing concurrency.&#xA;For this we&amp;rsquo;ll cover and use the programming language, Erlang!&#xA;So let&amp;rsquo;s quickly have a crash course over Erlang!&#xA;What is Erlang? Erlang is a functional programming language with message-passing features. The message-passing part is concurrent and implements the actor model, where Erlang processes are actors.</description>
    </item>
    <item>
      <title>Concurrent Programming: Part 5 - Monitors</title>
      <link>https://rezvan.xyz/school/tda384/tda384_5/</link>
      <pubDate>Fri, 03 Feb 2023 18:16:30 +0100</pubDate>
      <guid>https://rezvan.xyz/school/tda384/tda384_5/</guid>
      <description>In this series we&amp;rsquo;ve covered locks and semaphores as synchronization mechanism. Although these are essential in concurrent programs, they&amp;rsquo;re quite low-level synchronization mechanisms.&#xA;Semaphores for example have the problem that:&#xA;They are global and unstructured, it can be quite difficult to understand what a certain semaphore does in a given piece of code. Often, we are prone to deadlocks or incorrect behavior, it&amp;rsquo;s easy to forget a simple up() or down() call in your programs.</description>
    </item>
    <item>
      <title>Concurrent Programming: Part 4 - Synchronization problems with semaphores</title>
      <link>https://rezvan.xyz/school/tda384/tda384_4/</link>
      <pubDate>Wed, 01 Feb 2023 00:00:00 +0000</pubDate>
      <guid>https://rezvan.xyz/school/tda384/tda384_4/</guid>
      <description>In this part we&amp;rsquo;ll cover how to solve some classical synchronization problems using threads and semaphores.&#xA;Dining Philosophers To refresh our memory on the problem let&amp;rsquo;s cover it again:&#xA;The dining philosophers problem describes how to avoid deadlock (circular conditions).&#xA;We have five philosophers (threads) sitting at a dining table. A fork is between each adjacent pair of philosophers.&#xA;Each philosopher alternates between thinking (non-critical section) and eating (critical section). In order to eat, a philosopher needs to pick up both forks that lie to the right and left of the philosopher.</description>
    </item>
    <item>
      <title>Concurrent Programming: Part 3 - Models of concurrency &amp; synchronization algorithms</title>
      <link>https://rezvan.xyz/school/tda384/tda384_3/</link>
      <pubDate>Tue, 31 Jan 2023 00:00:00 +0000</pubDate>
      <guid>https://rezvan.xyz/school/tda384/tda384_3/</guid>
      <description>In this part we&amp;rsquo;ll cover how we can achieve mutual exclusion in a program using only atomic read and writes.&#xA;Analyzing Concurrency When analyzing concurrent programs we often look at states and transitions.&#xA;A state in these diagrams are possible program states. Transitions on the other hand, connects these states to an execution order.&#xA;One to thing to note is that, the structural properties in these diagrams, captures the semantics properties of the corresponding program.</description>
    </item>
    <item>
      <title>Concurrent Programming: Part 2 - Races, Locks, and Semaphores</title>
      <link>https://rezvan.xyz/school/tda384/tda384_2/</link>
      <pubDate>Thu, 19 Jan 2023 00:00:00 +0000</pubDate>
      <guid>https://rezvan.xyz/school/tda384/tda384_2/</guid>
      <description>In the last part we covered the basics and some principles for concurrent programs. In this part we&amp;rsquo;ll cover how we define concurrent problems, the outcome we want and some solutions.&#xA;Races As we saw in the last part - a different trace leads to a different outcome - this means that concurrent programs are non-deterministic.&#xA;Why concurrent programs are non-deterministic is due to the scheduler&amp;rsquo;s decisions.&#xA;When we have a problem with different possible outcomes, we need to label what is a faulty run and a successful run.</description>
    </item>
    <item>
      <title>Concurrent Programming: Part 1 - Introduction</title>
      <link>https://rezvan.xyz/school/tda384/tda384/</link>
      <pubDate>Mon, 16 Jan 2023 00:00:00 +0000</pubDate>
      <guid>https://rezvan.xyz/school/tda384/tda384/</guid>
      <description>Concurrency, multi-threading, parallelism. These are all big terms thrown around in the computer-science world. For an outsider it can be quite confusing what these exactly are and how they differ from each other. In this series we&amp;rsquo;ll cover and dive into concurrency and its applications.&#xA;Let&amp;rsquo;s start by defining what we mean by concurrency.&#xA;Introduction Concurrency, in its very definition is, the fact of two or more events or circumstances happening or existing at the same time.</description>
    </item>
  </channel>
</rss>
