<!DOCTYPE html>
<html><head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge"><title>rezvan | Computer System Engineering: Part 8 - Parallel Processors</title><link rel="icon" type="image/png" href="https://rezvan.xyz/images/icon.png" /><meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description"
        content="In this part we&rsquo;ll talk about parallel processors, multithreading and other different techniques that we can use to speed up our programs and computers.
Multithreading We&rsquo;ve seen and learned about threads when we covered concurrent programming.
The idea here is same, if we can utilize threads to parallelize our programs, we can achieve a higher efficiency rate on our clock cycles.
But when and how do we decide choose what thread?" />
    <meta property="og:image" content="https://raw.githubusercontent.com/rezaarezvan/rezvan.xyz/main/images/icon.png" />
    <meta property="og:title" content="Computer System Engineering: Part 8 - Parallel Processors" />
<meta property="og:description" content="In this part we&rsquo;ll talk about parallel processors, multithreading and other different techniques that we can use to speed up our programs and computers.
Multithreading We&rsquo;ve seen and learned about threads when we covered concurrent programming.
The idea here is same, if we can utilize threads to parallelize our programs, we can achieve a higher efficiency rate on our clock cycles.
But when and how do we decide choose what thread?" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://rezvan.xyz/school/eda333/eda333_8/" /><meta property="article:section" content="school" />
<meta property="article:published_time" content="2023-04-28T18:12:01+02:00" />
<meta property="article:modified_time" content="2023-04-28T18:12:01+02:00" />

<meta name="twitter:card" content="summary"/><meta name="twitter:title" content="Computer System Engineering: Part 8 - Parallel Processors"/>
<meta name="twitter:description" content="In this part we&rsquo;ll talk about parallel processors, multithreading and other different techniques that we can use to speed up our programs and computers.
Multithreading We&rsquo;ve seen and learned about threads when we covered concurrent programming.
The idea here is same, if we can utilize threads to parallelize our programs, we can achieve a higher efficiency rate on our clock cycles.
But when and how do we decide choose what thread?"/>
<script src="https://rezvan.xyz/js/feather.min.js"></script>
    

    
    
    <link rel="stylesheet" type="text/css" media="screen" href="https://rezvan.xyz/css/main.e78c3f2ddb05c4f5f0aa7553861677149e3602644857702209900dcba4ebbdf7.css" />
    <link id="lightSyntaxStyle" rel="stylesheet" type="text/css" media="screen" href="https://rezvan.xyz/css/light_syntax.65408cc3a5c02070b661c3e4e79306fc261cc63620f4adce9a30eafcba4ab79e.css" />
    
    <link id="darkModeStyle" rel="stylesheet" type="text/css" href="https://rezvan.xyz/css/dark.2b7c17d8b1c965837e6d0b727b269c478440b4aff7f6aa57b84e0dc8ddfd15dc.css"  disabled />
    <link id="darkSyntaxStyle" rel="stylesheet" type="text/css" media="screen" href="https://rezvan.xyz/css/dark_syntax.2b10cc1a2156b30874a063b7439a993bc3b43d476c5e1d8598d769c929c7b381.css" />
    

    
    
    <script type="text/javascript"
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
        </script>

    
    <script type="text/x-mathjax-config">
		MathJax.Hub.Config({
			tex2jax: {
				inlineMath: [['$','$'], ['\\(','\\)']],
				displayMath: [['$$','$$'], ['\[','\]']],
				processEscapes: true,
				processEnvironments: true,
				skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
				TeX: { equationNumbers: { autoNumber: "AMS" },
						 extensions: ["AMSmath.js", "AMSsymbols.js"] }
			}
		});
		</script>
    

    
    
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.css">
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.js"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/contrib/auto-render.min.js"
        onload="renderMathInElement(document.body);"></script>

    
    <script>
        document.addEventListener("DOMContentLoaded", function () {
            renderMathInElement(document.body, {
                delimiters: [
                    {left: "$$", right: "$$", display: true},
                    {left: "$", right: "$", display: false}
                ]
            });
        });
    </script>
    
</head>
<body>
    <div class="content"><header>
    <nav id="site-navbar">
        
        <a href="/">home</a>
        
        <a href="/about">about</a>
        
        <a href="/principles">principles</a>
        
        <a href="/contact">contact</a>
        
        <a href="/cv">cv</a>
        
        <a href="/school">school</a>
        
        | <span id="dark-mode-toggle" onclick="toggleTheme()"></span>
        <script src="https://rezvan.xyz/js/themetoggle.js"></script>
        
    </nav>
</header>

<main>
    <article>
        <div class="title">
            <h1>Computer System Engineering: Part 8 - Parallel Processors</h1>
            <div class="meta">Posted on Apr 28, 2023</div>
        </div>
        
        <section class="body">
            <p>In this part we&rsquo;ll talk about parallel processors, multithreading and other different techniques that we can use to speed up our programs and computers.</p>
<h3 id="multithreading">Multithreading</h3>
<p>We&rsquo;ve seen and learned about threads when we covered concurrent programming.</p>
<p>The idea here is same, if we can utilize threads to parallelize our programs, we can achieve a higher efficiency rate on our clock cycles.</p>
<p>But when and how do we decide choose what thread? There are three different approaches:</p>
<ul>
<li>
<p>Interleaved</p>
<ul>
<li>Switch thread each clock cycle.</li>
</ul>
</li>
<li>
<p>Blocked</p>
<ul>
<li>Switch thread when experience long latency (usually a cache miss).</li>
</ul>
</li>
<li>
<p>Simultaneous:</p>
<ul>
<li>Threads share the architecture resources.</li>
</ul>
</li>
</ul>
<h4 id="interleaved-multithreading">Interleaved multithreading</h4>
<p>To achieve interleaved multithreading - we need to add a new stage into our pipeline. The <strong>T</strong>hread <strong>S</strong>elect stage.</p>
<p>This thread selection usually uses a round-robin to select thread. However, we also need to have a setup of all individual registers, but also program counters, for each thread.</p>
<p>Note, we have an inefficient use of CPU resources due to frequent context switching.</p>
<p><img src="/school/images/TI.png#center" alt=""></p>
<h4 id="blocked-multithreading">Blocked multithreading</h4>
<p>To achieve blocked multithreading - our thread selection stages now relies on some kind of signal where we &ldquo;have waited for too long&rdquo;.</p>
<p>Usually this is due to a cache miss. One important fact is that, when a cache miss arises, we need to flush the entire pipeline.</p>
<p>Which means we&rsquo;ll lose some clock cycles in the end. Cache misses are in the 100-500s number of clock cycles, so losing a few clock cycles for that price is still really good.</p>
<p><img src="/school/images/BT.png#center" alt=""></p>
<h3 id="simultaneous-multithreading">Simultaneous multithreading</h3>
<p>Is an interesting one. Instead of fetching just one instruction, we fetch multiple to our threads. To achieve this, we need to basically dupe all of our hardware.</p>
<p>But the efficiency on the CPU resources becomes immense.</p>
<p><img src="/school/images/SM.png#center" alt=""></p>
<h3 id="amdahls-law">Amdahl&rsquo;s Law</h3>
<p>We&rsquo;ve discussed this law earlier, so I won&rsquo;t go into much detail - Amdahl&rsquo;s law describes to us that, the sequential part of a program is the bottleneck for potential speed up from parallelism.</p>
<p>Formula for speed up:
$$
Speed up = \dfrac{1}{x + \dfrac{(1 - x)}{N}}
$$</p>
<p>Where, $x$, is the portion of the program which is sequential. $N$, is the number of threads.</p>
<h3 id="parallel-processorscomputers">Parallel processors/computers</h3>
<p>The main goal with parallel processors and computers is that we want to connect multiple processors/computers to achieve better performance, natural.</p>
<p><strong>C</strong>hip-<strong>M</strong>ulti-<strong>P</strong>rocessor, or CMP. They are parallel processors on a <em>singular</em> chip. They have so called on-chip communication.</p>
<p>But in today&rsquo;s computers we mostly see multicore processors. These are chips that consists of multiple processors (cores).</p>
<p>However, we can&rsquo;t just put as many cores and increase the frequency of these chips to whatever. The power wall, memory wall and, ILP (Instruction Level Programming) wall are all a huge road block.</p>
<h3 id="flynns-classification-of-computers">Flynn&rsquo;s classification of computers</h3>
<p>You&rsquo;ve probably heard of SIMD, we&rsquo;ll cover all four types that exist!</p>
<p>Let&rsquo;s begin with the most simple one, <strong>SISD</strong>. Single Instruction, Single Data.</p>
<p>We fetch a single instruction and use a single data-flow to memory.</p>
<p><img src="/school/images/SISD.png#center" alt=""></p>
<p>SIMD, or, Single Instruction Multipe Data. This model is when we fetch a single instruction, but perform multiple instances of that instruction. This is a very powerful for performing vectorized operations.</p>
<p>Note, each processor has it own <strong>local</strong> memory and data.</p>
<p><img src="/school/images/SIMD.png#center" alt=""></p>
<p>The next class is, MIMD, or Multiple Instruction Multiple Data. As the name suggests, it&rsquo;s basically parallelizing SIMD.</p>
<p><img src="/school/images/MIMD.png#center" alt=""></p>
<p>We also have MISD, Multiple Instruction Single Data. This is a very niche class that is used basically only for machine learning areas (hardware accelerators).</p>
<h3 id="cache-coherence">Cache Coherence</h3>
<p>When we&rsquo;re dealing with multiple processors - we need to decide how we use our main memory.</p>
<p>Just as in concurrent programming, we have two paradigms, shared memory and message passing.</p>
<p>For our <strong>S</strong>hare <strong>M</strong>emory multi<strong>P</strong>rocessor, we need to use synchronization primitives, to avoid cache invalidation.</p>
<p>We can solve these problems using FSMs as well to set up a clear protocol.</p>
<p>For message passing, we do not share memory - but we send messages between processors to synchronize.</p>

        </section>
    </article>

    <nav class="navigation"
        style="display: flex; justify-content: space-between; align-items: center; margin-top: 20px;">
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        

        
        
        <a class="previous" href="/school/eda333/eda333_7/" title="Previous: Computer System Engineering: Part 7 - Floating-point arithmetic"
            style="flex-grow: 0; text-align: left;">&larr; Previous</a>
        
        

        
        
        <a class="next" href="/school/eda333/eda333_summary/" title="Next: Computer System Engineering: Summary"
            style="flex-grow: 0; text-align: right;">Next &rarr;</a>
        
        
    </nav>
</main>
<footer id="site-footer">
    
    <a href="https://github.com/rezaarezvan" title="">github</a>
    
    <a href="https://x.com/rzvan__/" title="">x</a>
    <p class="footer_msg">memento mori</p></footer></div>
</body>

</html>
