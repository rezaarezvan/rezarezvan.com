<!DOCTYPE html><html lang="en"> <head><meta charset="UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1.0"><meta name="generator" content="Astro v4.11.5"><link rel="icon" type="image" href="/favicon.ico"><title>Part 10 - Complexity (2)</title><!-- KaTeX support --><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.css"><script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.js"></script><script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/contrib/auto-render.min.js" onload="renderMathInElement(document.body);"></script><!-- inline KaTeX --><link rel="stylesheet" href="/_astro/index.CwgzIfsj.css">
<link rel="stylesheet" href="/_astro/_slug_.hCvEQTvV.css">
<style>article[data-astro-cid-v5ro3oot]{max-width:80ch;margin:0 auto}.nav-button[data-astro-cid-v5ro3oot]{display:flex;align-items:center;padding:.5rem;border-radius:.5rem;transition:background-color .3s ease;text-decoration:none;color:var(--text-color);background-color:var(--bg-color);border:1px solid var(--border-color)}.nav-button[data-astro-cid-v5ro3oot]:hover{background-color:var(--hover-color)}.nav-button[data-astro-cid-v5ro3oot] .arrow[data-astro-cid-v5ro3oot]{font-size:1.5rem;line-height:1}.nav-button[data-astro-cid-v5ro3oot] .text[data-astro-cid-v5ro3oot]{display:flex;flex-direction:column;margin:0 .5rem}.nav-button[data-astro-cid-v5ro3oot] .label[data-astro-cid-v5ro3oot]{font-size:.8rem;text-transform:uppercase;letter-spacing:.05em;color:var(--muted-color)}.nav-button[data-astro-cid-v5ro3oot] .title[data-astro-cid-v5ro3oot]{font-weight:500}.prev-button[data-astro-cid-v5ro3oot]{justify-content:flex-start}.next-button[data-astro-cid-v5ro3oot]{justify-content:flex-end;text-align:right}@media (max-width: 640px){.nav-button[data-astro-cid-v5ro3oot]{width:100%}.next-button[data-astro-cid-v5ro3oot]{justify-content:flex-start;text-align:left}.next-button[data-astro-cid-v5ro3oot] .text[data-astro-cid-v5ro3oot]{order:2;margin-left:.5rem}.next-button[data-astro-cid-v5ro3oot] .arrow[data-astro-cid-v5ro3oot]{order:1}}
</style><script type="module">document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}]})});
</script></head> <body> <div class="container mx-auto px-4 flex flex-col md:flex-row min-h-screen"> <aside class="w-full md:w-64 border-b md:border-r md:border-b-0 border-[var(--border-color)] border-dashed pt-8"> <header class="flex flex-col h-full"> <div class="flex items-center mb-4"> <script>
  function setTheme(mode) {
    localStorage.setItem("theme-storage", mode);
    document.documentElement.setAttribute('data-theme', mode);
  }
  function toggleTheme() {
    const currentTheme = localStorage.getItem("theme-storage") || "light";
    const newTheme = currentTheme === "light" ? "dark" : "light";
    setTheme(newTheme);
  }
  const savedTheme = localStorage.getItem("theme-storage") || "light";
  setTheme(savedTheme);
  window.toggleTheme = toggleTheme;
</script> <button id="theme-toggle" onclick="toggleTheme()" aria-label="Toggle theme" class="w-6 h-6 cursor-pointer"> <div class="w-5 h-5 border-2 border-primary rounded-full transition-colors duration-300 ease-in-out hover:bg-primary"></div> </button> <a href="/" class="text-2xl font-semibold ml-3 h-10 pr-3">rezvan.xyz</a> </div> <nav class="flex flex-wrap gap-2 md:flex-col md:gap-2"> <a href="/principles" class="transition-colors">
[principles]
</a><a href="/cv" class="transition-colors">
[cv]
</a><a href="/posts" class="transition-colors">
[posts]
</a><a href="/chalmers" class="transition-colors">
[chalmers]
</a><a href="/cityu" class="transition-colors">
[cityu]
</a> </nav> </header> </aside> <main class="flex-grow px-4 md:px-8 py-8 overflow-y-auto">  <article class="prose prose-sm sm:prose lg:prose-lg xl:prose-xl max-w-none" data-astro-cid-v5ro3oot> <h1 class="text-3xl sm:text-4xl font-bold mb-4" data-astro-cid-v5ro3oot>Part 10 - Complexity (2)</h1> <p class="text-sm text-muted-foreground mb-4" data-astro-cid-v5ro3oot>
Date: 12/10/2022 </p> <div class="markdown-content" data-astro-cid-v5ro3oot>  <p>We have actually covered everything in this course - in this part we’ll do some exercises!</p>
<h3 id="order-of-growth-of-functions">Order of growth of Functions</h3>
<p>Let’s find out the complexity ($\mathcal{O}$) of:
$$
T(n) = 5(3n^2 + 2n + 6)(4\ log_{10}(n) + 1)
$$</p>
<p>Since we seek the growth rate - we can use our rules about complexity. We can remove all constants:
$$
T(n) = (n^2 + n)(log_{10}(n))
$$</p>
<p>The next rule we can apply is, “the most dominating factor ‘wins’” as I like to call it. Therefore:
$$
T(n) = (n^2)(log_{10}(n))
$$</p>
<p>Then we just multiply!
$$
T(n) = n^2\ log_{10}(n)
$$</p>
<p>And since we usually write $log$ when using Big-O notation:
$$
T(n) =  n^2\ log(n)
$$</p>
<p>Now we can say that $T(n)$ has a $\mathcal{O}(n^2\ log(n))$ complexity!. Since we are talking about $\mathcal{O}$, this means this function has a <strong>lower</strong> bound of this. This means that $T(n)$ also has a complexity of $\mathcal{O}(n^3)$ for example.</p>
<p>So what we <em>really</em> mean is that $T(n)$ has a $\Theta(n^2\ log(n))$ complexity.</p>
<p><strong>Suppose an algorithm takes time <em>t</em> on an input of size <em>n</em>. How many times longer does it take on an input of size 10n if…</strong></p>
<ul>
<li>If the algorithm is $\Theta(n)$?</li>
<li>If the algorithm is $\Theta(n^2)$?</li>
<li>If the algorithm is $\Theta(n^3)$?</li>
<li>If the algorithm is $\Theta(n\ log(n))$?</li>
<li>If the algorithm is $\Theta(log(n))$?</li>
</ul>
<p>This is quite easy! We just plug in our new $n$, and see how much $t$ grows!</p>
<ul>
<li>If the algorithm is $\Theta(n)$?
<ul>
<li>We get $10n \rightarrow 10t$!</li>
</ul>
</li>
<li>If the algorithm is $\Theta(n^2)$?
<ul>
<li>We get $100n \rightarrow 100t$!</li>
</ul>
</li>
<li>If the algorithm is $\Theta(n^3)$?
<ul>
<li>We get $1000n \rightarrow 1000t$!</li>
</ul>
</li>
<li>If the algorithm is $\Theta(n\ log(n))$?
<ul>
<li>We get $10n\ \cdot log(10n)$!</li>
<li>This isn’t just $10 log(10)” times more - it’s a <em>little</em> bit longer, or so called “logarithmic linear”.</li>
</ul>
</li>
<li>If the algorithm is $\Theta(log(n))$?
<ul>
<li>We get $log(10n)$!</li>
<li>This means just a constant <strong>more</strong> time!</li>
</ul>
</li>
</ul>
<h3 id="complexity-analysis">Complexity Analysis</h3>
<p>Let’s analyze the following snippet of code and, it’s complexity.</p>
<pre class="astro-code dracula" style="background-color:#282A36;color:#F8F8F2; overflow-x: auto; white-space: pre-wrap; word-wrap: break-word;" tabindex="0" data-language="plaintext"><code><span class="line"><span>found = false</span></span>
<span class="line"><span>for x in list:</span></span>
<span class="line"><span>    for y in list:</span></span>
<span class="line"><span>        if x + y == 0:</span></span>
<span class="line"><span>            found = true</span></span>
<span class="line"><span></span></span></code></pre>
<p>If we say that the length of <code>list</code> is $n$. In the first loop we will have a complexity of $\mathcal{O}(n)$.
The inner loop will follow, using our previous rule of ‘nested loops means multiplication’.
This means our final program will have the complexity of $\mathcal{O}(n^2)$.</p>
<p>Now let’s see over this code snippet:</p>
<pre class="astro-code dracula" style="background-color:#282A36;color:#F8F8F2; overflow-x: auto; white-space: pre-wrap; word-wrap: break-word;" tabindex="0" data-language="plaintext"><code><span class="line"><span>found = false</span></span>
<span class="line"><span>for i in 0 .. n - 1:</span></span>
<span class="line"><span>    for j in i .. n - 1:</span></span>
<span class="line"><span>        x = list[i]</span></span>
<span class="line"><span>        y = list[j]</span></span>
<span class="line"><span>        if x + y == 0:</span></span>
<span class="line"><span>            found = true</span></span>
<span class="line"><span></span></span></code></pre>
<p>In this snippet - we’ll have the first loop iterating $n$ times -
however, the second loop, it will iterate $(0, \dots ,n -1), (1, \dots , n - 2), \dots$</p>
<p>This means that the number of times the second loop will run is between 1 and $n$ times - using our definition of complexity.
Let’s call the number of times our loop runs $m$, $m \leq n$ which means m has a complexity of $\mathcal{O}(n)$.</p>
<p>This finally means we have a total complexity of $\mathcal{O}(n^2)$</p>
<p>Now let’s do the same, but for three numbers!</p>
<pre class="astro-code dracula" style="background-color:#282A36;color:#F8F8F2; overflow-x: auto; white-space: pre-wrap; word-wrap: break-word;" tabindex="0" data-language="plaintext"><code><span class="line"><span>found = false</span></span>
<span class="line"><span>for i in 0 .. n - 1:</span></span>
<span class="line"><span>    for j in i .. n - 1:</span></span>
<span class="line"><span>        for k in j .. n - 1:</span></span>
<span class="line"><span>            x = list[i]</span></span>
<span class="line"><span>            y = list[j]</span></span>
<span class="line"><span>            z = list[k]</span></span>
<span class="line"><span></span></span>
<span class="line"><span>            if x + y + z == 0:</span></span>
<span class="line"><span>                found = true</span></span>
<span class="line"><span></span></span></code></pre>
<p>Exactly the same logic goes as from the last question to this, we can prove that each loop has a complexity of $\mathcal{O}(n)$.</p>
<p>Which gives the total complexity of $\mathcal{O}(n^3)$.</p>
<p>Now let’s look at a similar program:</p>
<pre class="astro-code dracula" style="background-color:#282A36;color:#F8F8F2; overflow-x: auto; white-space: pre-wrap; word-wrap: break-word;" tabindex="0" data-language="plaintext"><code><span class="line"><span>pairs_list = []</span></span>
<span class="line"><span>for i in 0 .. n - 1:</span></span>
<span class="line"><span>    for j in i .. n - 1:</span></span>
<span class="line"><span>        x = list[i]</span></span>
<span class="line"><span>        y = list[j]</span></span>
<span class="line"><span>        pairs_list.add(x + y)</span></span>
<span class="line"><span></span></span>
<span class="line"><span>found = false</span></span>
<span class="line"><span>for xplusy in pairs_list:</span></span>
<span class="line"><span>    for zplusw in pairs_list:</span></span>
<span class="line"><span>        if xplusy + zplusw == 0:</span></span>
<span class="line"><span>            found = true</span></span>
<span class="line"><span></span></span></code></pre>
<p>As we’ve stated above, the first part of the program will have a complexity of $\mathcal{O}(n^2)$.
Note that the <code>add()</code> function takes $\mathcal{O}(1)$ for dynamic arrays.</p>
<p>However, in the next block, the new array length is $n^2$, since we have added all possible permutations of pairs.
So the loops will now through $n^2$ elements. Which in total results a complexity of $\mathcal{O}(n^4)$.</p>
<p>From our earlier rules, we ‘add’ blocks of codes, so the complexity is $\mathcal{O}(n^2) + \mathcal{O}(n^4)$.
Which means the resulting complexity becomes $\mathcal{O}(n^4)$.</p>
<h3 id="data-structure-complexities">Data Structure Complexities</h3>
<p>Let’s refresh our memory and state all the complexities for our data structures and their functions.</p>
<ul>
<li>Dynamic Arrays:
<ul>
<li>Get/Set:
<ul>
<li>$\mathcal{O}(1)$</li>
</ul>
</li>
<li>Add/Remove <strong>at end</strong>:
<ul>
<li>$\mathcal{O}(1)$</li>
</ul>
</li>
<li>Add/remove <strong>elsewhere</strong>:
<ul>
<li>$\mathcal{O}(n)$</li>
</ul>
</li>
</ul>
</li>
<li>Stacks/queues:
<ul>
<li>Push/Pop:
<ul>
<li>$\mathcal{O}(1)$</li>
</ul>
</li>
<li>Enqueue/Dequeue:
<ul>
<li>$\mathcal{O}(1)$</li>
</ul>
</li>
</ul>
</li>
<li>Binary Heaps:
<ul>
<li>Add/RemoveMin (or Max):
<ul>
<li>$\mathcal{O}(log(n))$</li>
</ul>
</li>
<li>getMin (or Max):
<ul>
<li>$\mathcal{O}(1)$</li>
</ul>
</li>
</ul>
</li>
<li>BSTs:
<ul>
<li>Add/Remove/Search (worst case, meaning it’s already sorted):
<ul>
<li>$\mathcal{O}(n)$</li>
</ul>
</li>
<li>Otherwise:
<ul>
<li>$\mathcal{O}(log(n))$</li>
</ul>
</li>
</ul>
</li>
<li>Stacks/queues:
<ul>
<li>Add/Remove/Search (Always!):
<ul>
<li>$\mathcal{O}(log(n))$</li>
</ul>
</li>
</ul>
</li>
<li>Hash Tables:
<ul>
<li>Add/Remove/Search (Given that the hash function is ‘good’):
<ul>
<li>$\mathcal{O}(1)$</li>
</ul>
</li>
</ul>
</li>
<li>General Tree:
<ul>
<li>If you <strong>down</strong> in a tree, you’ll visit:
<ul>
<li>$\mathcal{O}(height)$ nodes</li>
</ul>
</li>
<li>If you explore every node, you’ll visit:
<ul>
<li>$\mathcal{O}(n)$ nodes</li>
</ul>
</li>
<li>A tree has the <strong>worst</strong> case $\mathcal{O}(n)$ height.</li>
<li>A <strong>balanced</strong> tree is <strong>always</strong> $\mathcal{O}(log(n))$ height.</li>
</ul>
</li>
</ul>
<h3 id="analyzing-more-complexities">Analyzing more complexities</h3>
<p>Let’s take a look at program which utilizes different data structures now:</p>
<pre class="astro-code dracula" style="background-color:#282A36;color:#F8F8F2; overflow-x: auto; white-space: pre-wrap; word-wrap: break-word;" tabindex="0" data-language="plaintext"><code><span class="line"><span>pairs_list = []</span></span>
<span class="line"><span>for i in 0 .. n - 1:</span></span>
<span class="line"><span>    for j in i .. n - 1:</span></span>
<span class="line"><span>        x = list[i]</span></span>
<span class="line"><span>        y = list[j]</span></span>
<span class="line"><span>        pairs_list.add(x + y)</span></span>
<span class="line"><span></span></span>
<span class="line"><span>merge_sort(pairs_list)</span></span>
<span class="line"><span></span></span>
<span class="line"><span>found = false</span></span>
<span class="line"><span>for xplusy in pairs_list:</span></span>
<span class="line"><span>    if binary_search(pairs_list, -xplusy):</span></span>
<span class="line"><span>        found = true</span></span>
<span class="line"><span></span></span></code></pre>
<p>So, we’ve seen that first part, we know it’s $\mathcal{O}(n^2)$.
But now we see a <code>merge_sort()</code> - this has a complexity of $\mathcal{O}(n\ log(n))$.
As we stated before, the list after the first block has a length of $n^2$.
Which means <code>merge_sort()</code> will have a complexity of $\mathcal{O}(n^2\ log(n^2))$</p>
<p>This will just sort it so, no length is added.</p>
<p>Then the next block, the for loop will have a complexity of $\mathcal{O}(n^2)$.
The binary search algorithm, has a complexity of $\mathcal{O}(log(n^2))$.</p>
<p>So this block will in total have a complexity of $\mathcal{O}(n^2\ log(n^2))$.</p>
<p>So if we add these blocks together and apply our rules we will get a total complexity of:
$\mathcal{O}(n^2\ log(n^2))$. We can apply some log rules to this:
$$
\mathcal{O}(n^2\ log(n^2))
\newline
\mathcal{O}(n^2\ 2\ log(n))
\newline
\mathcal{O}(n^2\ log(n))
$$</p>
<p>So finally our answer is, $\mathcal{O}(n^2 log(n))$</p>
<p>Let’s now look at a case using a tree:</p>
<pre class="astro-code dracula" style="background-color:#282A36;color:#F8F8F2; overflow-x: auto; white-space: pre-wrap; word-wrap: break-word;" tabindex="0" data-language="plaintext"><code><span class="line"><span>pairs_set = empty AVL_tree</span></span>
<span class="line"><span>for i in 0 .. n - 1:</span></span>
<span class="line"><span>    for j in i .. n - 1:</span></span>
<span class="line"><span>        x = pairs_set[i]</span></span>
<span class="line"><span>        y = pairs_set[j]</span></span>
<span class="line"><span></span></span>
<span class="line"><span>        if pairs_set.contains(-(x+y)):</span></span>
<span class="line"><span>            return true</span></span>
<span class="line"><span></span></span>
<span class="line"><span>        pairs_set.add(x+y)</span></span>
<span class="line"><span></span></span></code></pre>
<p>As we’ve seen before, the loops are $\mathcal{O}(n^2)$ - now the interesting part is the <code>contains()</code> to check if an element is present.
To check whether an element is present in a tree, has a complexity of $\mathcal{O}(log(n))$.
The rest of the operations are constant so, we can ignore them (including the <code>add()</code> for the AVL tree).</p>
<p>So-therefore the final complexity is $\mathcal{O}(n^2\ log(n))$. In the absolute worst case the <code>contains()</code> will be $\mathcal{O}(n)$, but let’s ignore that :).</p>
<p>Now let’s look at a hash table:</p>
<pre class="astro-code dracula" style="background-color:#282A36;color:#F8F8F2; overflow-x: auto; white-space: pre-wrap; word-wrap: break-word;" tabindex="0" data-language="plaintext"><code><span class="line"><span>pairs_set = empty Hash_table</span></span>
<span class="line"><span>for i in 0 .. n - 1:</span></span>
<span class="line"><span>    for j in i .. n - 1:</span></span>
<span class="line"><span>        x = pairs.set[i]</span></span>
<span class="line"><span>        y = pairs_set[j]</span></span>
<span class="line"><span></span></span>
<span class="line"><span>        if pairs_set.contains(-(x + y)):</span></span>
<span class="line"><span>            return true</span></span>
<span class="line"><span></span></span>
<span class="line"><span>        pairs_set.add(x + y)</span></span>
<span class="line"><span></span></span></code></pre>
<p>As per usual, the loops together create a complexity of $\mathcal{O}(n^2)$, now, a search in a hash table is $\mathcal{O}(1)$, if our hash function is ‘good’.</p>
<p>The rest of the operations are constant. Therefore, the overall complexity is $\mathcal{O}(n^2)$.</p>
<p>Now let’s look at a BST example:</p>
<pre class="astro-code dracula" style="background-color:#282A36;color:#F8F8F2; overflow-x: auto; white-space: pre-wrap; word-wrap: break-word;" tabindex="0" data-language="plaintext"><code><span class="line"><span>pairs_set = empty BST</span></span>
<span class="line"><span>for i in 0 .. n - 1:</span></span>
<span class="line"><span>    for j in i .. n - 1:</span></span>
<span class="line"><span>        x = pairs_set[i]</span></span>
<span class="line"><span>        y = pairs_set[j]</span></span>
<span class="line"><span></span></span>
<span class="line"><span>        if pairs_set.contains(-(x + y)):</span></span>
<span class="line"><span>            return true</span></span>
<span class="line"><span></span></span>
<span class="line"><span>        pairs_set.add(x + y)</span></span>
<span class="line"><span></span></span></code></pre>
<p>The usual $\mathcal{O}(n^2)$ loops :). Now the <code>contains()</code> is the interesting part.
Since this is a BST, the <code>contains()</code> will have a complexity of $\mathcal{O}(n)$ in the worst case, since the BST can become unbalanced.</p>
<p>The same applies for <code>add()</code>. Since the rest of the operations are constant therefore it will be, $\mathcal{O}(n^4)$.</p>
<h3 id="different-kinds-of-complexities">Different kinds of complexities</h3>
<p>We also need to consider the different cases</p>
<ul>
<li>Best-case
<ul>
<li>This is not useful.</li>
</ul>
</li>
<li>Worst-case
<ul>
<li>This is the most useful.</li>
</ul>
</li>
<li>Average-case
<ul>
<li>Can be useful sometimes, mostly gives us a ‘indicator’.</li>
</ul>
</li>
</ul>
<p>Let’s now talk about <strong>expected</strong> and <strong>amortised</strong> complexity.</p>
<h4 id="expected-complexity">Expected Complexity</h4>
<p>This is useful for randomized algorithms! It’s the average over all possible random choice for a particular input.</p>
<p>For example, if we choose a random pivot, we turn quicksort from average-case $\mathcal{O}(n\ log(n))$ to expected $\mathcal{O}(n\ log(n))$</p>
<h4 id="amortised-complexity">Amortised Complexity:</h4>
<p>Amortised complexity is, the average over any sequence of operations, this is super useful!</p>
<p>For example, we use this to make dynamic arrays have an amortised complexity of $\mathcal{O}(1)$.</p>
<p>However, when we’re calculating the total runtime of a program, it’s safe to forget about this amortised bit and just treat each operation as costing $\mathcal{O}(1)$.</p>
<h3 id="conclusion">Conclusion</h3>
<p>This was it for this part - and the final part in this series. I really enjoyed this DSA course, super fun :).</p>  </div> <nav class="flex flex-col sm:flex-row justify-between mt-8 pt-4 border-t border-border" data-astro-cid-v5ro3oot>   </nav> </article>  </main> </div> </body></html> 