<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Concurrent Programming on rezvan</title>
    <link>https://rezvan.xyz/tags/Concurrent-Programming/</link>
    <description>Recent content in Concurrent Programming on rezvan</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 19 Feb 2023 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://rezvan.xyz/tags/Concurrent-Programming/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Concurrent Programming: Part 10 - Parallel linked lists</title>
      <link>https://rezvan.xyz/school/Concurrent_programming_10/</link>
      <pubDate>Sun, 19 Feb 2023 00:00:00 +0000</pubDate>
      <guid>https://rezvan.xyz/school/Concurrent_programming_10/</guid>
      <description>In this part we&amp;rsquo;ll cover the synchronization challenges that arise when designing (correct) and efficient parallelizations.
But let&amp;rsquo;s first see the burdens with locks
The trouble with locks Standard techniques for concurrent programming are ultimately based on locks.
Programming with locks has several drawbacks:
Performance overhead.
Lock granularity is hard to choose:
Not enough locking: race conditions.
Too much locking: not enough parallelism.
Risk of deadlock and starvation.
Lock-based implementations do not compose (easily).</description>
    </item>
    <item>
      <title>Concurrent Programming: Part 9 - Parallelizing computations</title>
      <link>https://rezvan.xyz/school/Concurrent_programming_9/</link>
      <pubDate>Mon, 13 Feb 2023 00:00:00 +0000</pubDate>
      <guid>https://rezvan.xyz/school/Concurrent_programming_9/</guid>
      <description>Concurrent programming introduces:
The potential for parallel execution (faster, better resource usage) The risk of race conditions (incorrect, unpredictable computations) The challenge of concurrent programming is introducing parallelism without affecting correctness.
Let&amp;rsquo;s define how to parallelize:
A task $(F, D)$ consists in computing the result F $(D)$ of applying function $F$ to input data $D$
A parallelization of $(F, D)$ is a collection $(F_1 , D_1 ),\ (F_2 , D_2),\ \dots$ of tasks such that $F (D)$ equals the composition of $F_1 (D_1),\ F_2 (D_2),\ \dots $</description>
    </item>
    <item>
      <title>Concurrent Programming: Part 8 - Synchronization problems with message-passing</title>
      <link>https://rezvan.xyz/school/Concurrent_programming_8/</link>
      <pubDate>Tue, 07 Feb 2023 14:05:43 +0100</pubDate>
      <guid>https://rezvan.xyz/school/Concurrent_programming_8/</guid>
      <description>In this part we&amp;rsquo;ll cover the classical problems that occur when dealing with synchronization.
But within this paradigm, we don&amp;rsquo;t encounter the same problems as when using semaphores. Mutual exclusion is not an issue, since we never share any resource, the big problem today will be synchronization and coordination.
We&amp;rsquo;ll see that many problems have the solution of a server-client architecture.
Barriers Let&amp;rsquo;s quickly recap what our barriers should be able to do:</description>
    </item>
    <item>
      <title>Concurrent Programming: Part 6 &amp; 7 - Message-Passing Concurrency</title>
      <link>https://rezvan.xyz/school/Concurrent_programming_6/</link>
      <pubDate>Sat, 04 Feb 2023 00:00:00 +0000</pubDate>
      <guid>https://rezvan.xyz/school/Concurrent_programming_6/</guid>
      <description>So far we have looked at threads which share memory. The so-called shared memory model, but in this part we&amp;rsquo;ll cover distributed memory model, specifically, message-passing concurrency.
For this we&amp;rsquo;ll cover and use the programming language, Erlang!
So let&amp;rsquo;s quickly have a crash course over Erlang!
What is Erlang? Erlang is a functional programming language with message-passing features. The message-passing part is concurrent and implements the actor model, where Erlang processes are actors.</description>
    </item>
    <item>
      <title>Concurrent Programming: Part 5 - Monitors</title>
      <link>https://rezvan.xyz/school/Concurrent_programming_5/</link>
      <pubDate>Fri, 03 Feb 2023 18:16:30 +0100</pubDate>
      <guid>https://rezvan.xyz/school/Concurrent_programming_5/</guid>
      <description>In this series we&amp;rsquo;ve covered locks and semaphores as synchronization mechanism. Although these are essential in concurrent programs, they&amp;rsquo;re quite low-level synchronization mechanisms.
Semaphores for example have the problem that:
They are global and unstructured, it can be quite difficult to understand what a certain semaphore does in a given piece of code. Often, we are prone to deadlocks or incorrect behavior, it&amp;rsquo;s easy to forget a simple up() or down() call in your programs.</description>
    </item>
    <item>
      <title>Concurrent Programming: Part 4 - Synchronization problems with semaphores</title>
      <link>https://rezvan.xyz/school/Concurrent_programming_4/</link>
      <pubDate>Wed, 01 Feb 2023 00:00:00 +0000</pubDate>
      <guid>https://rezvan.xyz/school/Concurrent_programming_4/</guid>
      <description>In this part we&amp;rsquo;ll cover how to solve some classical synchronization problems using threads and semaphores.
Dining Philosophers To refresh our memory on the problem let&amp;rsquo;s cover it again:
The dining philosophers problem describes how to avoid deadlock (circular conditions).
We have five philosophers (threads) sitting at a dining table. A fork is between each adjacent pair of philosophers.
Each philosopher alternates between thinking (non-critical section) and eating (critical section). In order to eat, a philosopher needs to pick up both forks that lie to the right and left of the philosopher.</description>
    </item>
    <item>
      <title>Concurrent Programming: Part 3 - Models of concurrency &amp; synchronization algorithms</title>
      <link>https://rezvan.xyz/school/Concurrent_programming_3/</link>
      <pubDate>Tue, 31 Jan 2023 00:00:00 +0000</pubDate>
      <guid>https://rezvan.xyz/school/Concurrent_programming_3/</guid>
      <description>In this part we&amp;rsquo;ll cover how we can achieve mutual exclusion in a program using only atomic read and writes.
Analyzing Concurrency When analyzing concurrent programs we often look at states and transitions.
A state in these diagrams are possible program states. Transitions on the other hand, connects these states to an execution order.
One to thing to note is that, the structural properties in these diagrams, captures the semantics properties of the corresponding program.</description>
    </item>
    <item>
      <title>Concurrent Programming: Part 2 - Races, Locks, and Semaphores</title>
      <link>https://rezvan.xyz/school/Concurrent_programming_2/</link>
      <pubDate>Thu, 19 Jan 2023 00:00:00 +0000</pubDate>
      <guid>https://rezvan.xyz/school/Concurrent_programming_2/</guid>
      <description>In the last part we covered the basics and some principles for concurrent programs. In this part we&amp;rsquo;ll cover how we define concurrent problems, the outcome we want and some solutions.
Races As we saw in the last part - a different trace leads to a different outcome - this means that concurrent programs are non-deterministic.
Why concurrent programs are non-deterministic is due to the scheduler&amp;rsquo;s decisions.
When we have a problem with different possible outcomes, we need to label what is a faulty run and a successful run.</description>
    </item>
    <item>
      <title>Concurrent Programming: Part 1 - Introduction</title>
      <link>https://rezvan.xyz/school/Concurrent_programming/</link>
      <pubDate>Mon, 16 Jan 2023 00:00:00 +0000</pubDate>
      <guid>https://rezvan.xyz/school/Concurrent_programming/</guid>
      <description>Concurrency, multi-threading, parallelism. These are all big terms thrown around in the computer-science world. For an outsider it can be quite confusing what these exactly are and how they differ from each other. In this series we&amp;rsquo;ll cover and dive into concurrency and its applications.
Let&amp;rsquo;s start by defining what we mean by concurrency.
Introduction Concurrency, in its very definition is, the fact of two or more events or circumstances happening or existing at the same time.</description>
    </item>
  </channel>
</rss>
