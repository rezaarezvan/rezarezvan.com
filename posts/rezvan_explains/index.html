<!DOCTYPE html><html lang="en"> <head><!-- Global Metadata --><meta charset="utf-8"><meta name="viewport" content="width=device-width,initial-scale=1"><link rel="icon" type="image/icon" href="/favicon.ico"><meta name="generator" content="Astro v5.5.5"><!-- Canonical URL --><link rel="canonical" href="https://rezvan.xyz/posts/rezvan_explains/"><!-- Primary Meta Tags --><title>Rezvan Explains: Classical Machine Learning | rezarezvan.com</title><meta name="title" content="Rezvan Explains: Classical Machine Learning | rezarezvan.com"><meta name="description"><!-- Open Graph / Facebook --><meta property="og:type" content="website"><meta property="og:url" content="https://rezvan.xyz/posts/rezvan_explains/"><meta property="og:title" content="Rezvan Explains: Classical Machine Learning | rezarezvan.com"><meta property="og:description"><meta property="og:image" content="https://rezvan.xyz/favicon.ico"><!-- Twitter --><meta property="twitter:card" content="summary_large_image"><meta property="twitter:url" content="https://rezvan.xyz/posts/rezvan_explains/"><meta property="twitter:title" content="Rezvan Explains: Classical Machine Learning | rezarezvan.com"><meta property="twitter:description"><meta property="twitter:image" content="https://rezvan.xyz/favicon.ico"><!-- PageFind --><link href="/pagefind/pagefind-ui.css" rel="stylesheet"><script src="/pagefind/pagefind-ui.js"></script><!-- KaTeX support --><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.15/dist/katex.min.css" integrity="sha384-Htz9HMhiwV8GuQ28Xr9pEs1B4qJiYu/nYLLwlDklR53QibDfmQzi7rYxXhMH/5/u" crossorigin="anonymous"><script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.15/dist/katex.min.js" integrity="sha384-bxmi2jLGCvnsEqMuYLKE/KsVCxV3PqmKeK6Y6+lmNXBry6+luFkEOsmp5vD9I/7+" crossorigin="anonymous"></script><script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.15/dist/contrib/auto-render.min.js" integrity="sha384-hCXGrW6PitJEwbkoStFjeJxv+fSOOQKOPbJxSfM6G5sWZjAyWhXiTIIAmQqnlLlh" crossorigin="anonymous" onload="renderMathInElement(document.body);"></script><!-- inline KaTeX --><script>
    function renderKaTeX() {
        if (typeof renderMathInElement !== "undefined") {
            renderMathInElement(document.body, {
                delimiters: [
                    { left: "$$", right: "$$", display: true },
                    { left: "$", right: "$", display: false },
                ],
            });
        }
    }

    document.addEventListener("DOMContentLoaded", renderKaTeX);
    document.addEventListener("astro:after-swap", renderKaTeX);
</script><meta name="astro-view-transitions-enabled" content="true"><meta name="astro-view-transitions-fallback" content="animate"><script type="module" src="/_astro/ClientRouter.astro_astro_type_script_index_0_lang.CMTcOisY.js"></script><script>
    function init() {
        preloadTheme();
        onScroll();
        animate();
        updateThemeButtons();
        addCopyCodeButtons();
        setGiscusTheme();

        const backToTop = document.getElementById("back-to-top");
        backToTop?.addEventListener("click", (event) => scrollToTop(event));

        const backToPrev = document.getElementById("back-to-prev");
        backToPrev?.addEventListener("click", () => window.history.back());

        const lightThemeButton = document.getElementById("light-theme-button");
        lightThemeButton?.addEventListener("click", () => {
            localStorage.setItem("theme", "light");
            toggleTheme(false);
            updateThemeButtons();
        });

        const darkThemeButton = document.getElementById("dark-theme-button");
        darkThemeButton?.addEventListener("click", () => {
            localStorage.setItem("theme", "dark");
            toggleTheme(true);
            updateThemeButtons();
        });

        const systemThemeButton = document.getElementById(
            "system-theme-button",
        );
        systemThemeButton?.addEventListener("click", () => {
            localStorage.setItem("theme", "system");
            toggleTheme(
                window.matchMedia("(prefers-color-scheme: dark)").matches,
            );
            updateThemeButtons();
        });

        window
            .matchMedia("(prefers-color-scheme: dark)")
            .addEventListener("change", (event) => {
                if (localStorage.theme === "system") {
                    toggleTheme(event.matches);
                }
            });

        document.addEventListener("scroll", onScroll);
    }

    function updateThemeButtons() {
        const theme = localStorage.getItem("theme");
        const lightThemeButton = document.getElementById("light-theme-button");
        const darkThemeButton = document.getElementById("dark-theme-button");
        const systemThemeButton = document.getElementById(
            "system-theme-button",
        );

        function removeActiveButtonTheme(button) {
            button?.classList.remove("bg-black/5");
            button?.classList.remove("dark:bg-white/5");
        }

        function addActiveButtonTheme(button) {
            button?.classList.add("bg-black/5");
            button?.classList.add("dark:bg-white/5");
        }

        removeActiveButtonTheme(lightThemeButton);
        removeActiveButtonTheme(darkThemeButton);
        removeActiveButtonTheme(systemThemeButton);

        if (theme === "light") {
            addActiveButtonTheme(lightThemeButton);
        } else if (theme === "dark") {
            addActiveButtonTheme(darkThemeButton);
        } else {
            addActiveButtonTheme(systemThemeButton);
        }
    }

    function animate() {
        const animateElements = document.querySelectorAll(".animate");

        animateElements.forEach((element, index) => {
            setTimeout(() => {
                element.classList.add("show");
            }, index * 100);
        });
    }

    function onScroll() {
        if (window.scrollY > 0) {
            document.documentElement.classList.add("scrolled");
        } else {
            document.documentElement.classList.remove("scrolled");
        }
    }

    function scrollToTop(event) {
        event.preventDefault();
        window.scrollTo({
            top: 0,
            behavior: "smooth",
        });
    }

    function toggleTheme(dark) {
        const css = document.createElement("style");

        css.appendChild(
            document.createTextNode(
                `* {
             -webkit-transition: none !important;
             -moz-transition: none !important;
             -o-transition: none !important;
             -ms-transition: none !important;
             transition: none !important;
          }
        `,
            ),
        );

        document.head.appendChild(css);

        if (dark) {
            document.documentElement.classList.add("dark");
        } else {
            document.documentElement.classList.remove("dark");
        }

        window.getComputedStyle(css).opacity;
        document.head.removeChild(css);

        setGiscusTheme();
    }

    function preloadTheme() {
        const userTheme = localStorage.theme;

        if (userTheme === "light" || userTheme === "dark") {
            toggleTheme(userTheme === "dark");
        } else {
            toggleTheme(
                window.matchMedia("(prefers-color-scheme: dark)").matches,
            );
        }
    }

    function addCopyCodeButtons() {
        let copyButtonLabel = "ðŸ“‹";
        let codeBlocks = Array.from(document.querySelectorAll("pre"));

        async function copyCode(codeBlock, copyButton) {
            const codeText = codeBlock.innerText;
            const buttonText = copyButton.innerText;
            const textToCopy = codeText.replace(buttonText, "");

            await navigator.clipboard.writeText(textToCopy);
            copyButton.innerText = "âœ…";

            setTimeout(() => {
                copyButton.innerText = copyButtonLabel;
            }, 2000);
        }

        for (let codeBlock of codeBlocks) {
            const wrapper = document.createElement("div");
            wrapper.style.position = "relative";

            const copyButton = document.createElement("button");
            copyButton.innerText = copyButtonLabel;
            copyButton.classList = "copy-code";

            codeBlock.setAttribute("tabindex", "0");
            codeBlock.appendChild(copyButton);

            codeBlock.parentNode.insertBefore(wrapper, codeBlock);
            wrapper.appendChild(codeBlock);

            copyButton?.addEventListener("click", async () => {
                await copyCode(codeBlock, copyButton);
            });
        }
    }

    const setGiscusTheme = () => {
        const giscus = document.querySelector(".giscus-frame");

        const isDark = document.documentElement.classList.contains("dark");

        if (giscus) {
            const url = new URL(giscus.src);
            url.searchParams.set("theme", isDark ? "dark" : "light");
            giscus.src = url.toString();
        }
    };

    document.addEventListener("DOMContentLoaded", () => init());
    document.addEventListener("astro:after-swap", () => init());
    preloadTheme();
</script><link rel="stylesheet" href="/_astro/_subject_.WmXrNcmP.css">
<link rel="stylesheet" href="/_astro/index.C6eUsQXi.css">
<style>summary[data-astro-cid-xvrfupwn]{cursor:pointer;border-top-left-radius:.5rem;border-top-right-radius:.5rem;padding:.375rem .75rem;font-weight:500;transition-property:color,background-color,border-color,text-decoration-color,fill,stroke;transition-timing-function:cubic-bezier(.4,0,.2,1);transition-duration:.15s}summary[data-astro-cid-xvrfupwn]:hover{background-color:#0000000d}summary[data-astro-cid-xvrfupwn]:hover:is(.dark *){background-color:#ffffff0d}details[data-astro-cid-xvrfupwn][open] summary[data-astro-cid-xvrfupwn]{background-color:#0000000d}details[data-astro-cid-xvrfupwn][open] summary[data-astro-cid-xvrfupwn]:is(.dark *){background-color:#ffffff0d}
</style></head> <body> <header data-astro-transition-persist="astro-l7r54iwe-1"> <div class="mx-auto max-w-screen-sm px-3"> <div class="flex flex-wrap justify-between gap-y-4"> <div class="flex flex-col gap-y-2"> <a href="/" target="_self" class="inline-block decoration-black/30 dark:decoration-white/30 hover:decoration-black/50 focus-visible:decoration-black/50 dark:hover:decoration-white/50 dark:focus-visible:decoration-white/50 text-current hover:text-black focus-visible:text-black dark:hover:text-white dark:focus-visible:text-white transition-colors duration-300 ease-in-out">  <div class="font-semibold"> rezarezvan.com </div>  </a> <div class="flex gap-x-2"> <button id="light-theme-button" aria-label="Light theme" class="group flex size-6 items-center justify-center rounded border border-black/15 hover:bg-black/5 focus-visible:bg-black/5 dark:border-white/20 dark:hover:bg-white/5 dark:focus-visible:bg-white/5"> <svg xmlns="http://www.w3.org/2000/svg" width="14" height="14" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="transition-colors duration-300 ease-in-out group-hover:animate-pulse group-hover:stroke-black group-focus-visible:animate-pulse group-focus-visible:stroke-black group-hover:dark:stroke-white dark:group-focus-visible:stroke-white"> <circle cx="12" cy="12" r="5"></circle> <line x1="12" y1="1" x2="12" y2="3"></line> <line x1="12" y1="21" x2="12" y2="23"></line> <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line> <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line> <line x1="1" y1="12" x2="3" y2="12"></line> <line x1="21" y1="12" x2="23" y2="12"></line> <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line> <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line> </svg> </button> <button id="dark-theme-button" aria-label="Dark theme" class="group flex size-6 items-center justify-center rounded border border-black/15 hover:bg-black/5 focus-visible:bg-black/5 dark:border-white/20 dark:hover:bg-white/5 dark:focus-visible:bg-white/5"> <svg xmlns="http://www.w3.org/2000/svg" width="14" height="14" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="transition-colors duration-300 ease-in-out group-hover:animate-pulse group-hover:stroke-black group-focus-visible:animate-pulse group-focus-visible:stroke-black group-hover:dark:stroke-white dark:group-focus-visible:stroke-white"> <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path> </svg> </button> <button id="system-theme-button" aria-label="System theme" class="group flex size-6 items-center justify-center rounded border border-black/15 hover:bg-black/5 focus-visible:bg-black/5 dark:border-white/20 dark:hover:bg-white/5 dark:focus-visible:bg-white/5"> <svg xmlns="http://www.w3.org/2000/svg" width="14" height="14" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="transition-colors duration-300 ease-in-out group-hover:animate-pulse group-hover:stroke-black group-focus-visible:animate-pulse group-focus-visible:stroke-black group-hover:dark:stroke-white dark:group-focus-visible:stroke-white"> <rect x="2" y="3" width="20" height="14" rx="2" ry="2"></rect> <line x1="8" y1="21" x2="16" y2="21"></line> <line x1="12" y1="17" x2="12" y2="21"></line> </svg> </button> </div> </div> <nav class="flex items-center gap-1 text-sm"> <a href="/posts" target="_self" class="inline-block decoration-black/30 dark:decoration-white/30 hover:decoration-black/50 focus-visible:decoration-black/50 dark:hover:decoration-white/50 dark:focus-visible:decoration-white/50 text-current hover:text-black focus-visible:text-black dark:hover:text-white dark:focus-visible:text-white transition-colors duration-300 ease-in-out underline underline-offset-[3px]"> posts </a> <span>/</span> <a href="/chalmers" target="_self" class="inline-block decoration-black/30 dark:decoration-white/30 hover:decoration-black/50 focus-visible:decoration-black/50 dark:hover:decoration-white/50 dark:focus-visible:decoration-white/50 text-current hover:text-black focus-visible:text-black dark:hover:text-white dark:focus-visible:text-white transition-colors duration-300 ease-in-out underline underline-offset-[3px]"> chalmers </a> <span>/</span> <a href="/cityu" target="_self" class="inline-block decoration-black/30 dark:decoration-white/30 hover:decoration-black/50 focus-visible:decoration-black/50 dark:hover:decoration-white/50 dark:focus-visible:decoration-white/50 text-current hover:text-black focus-visible:text-black dark:hover:text-white dark:focus-visible:text-white transition-colors duration-300 ease-in-out underline underline-offset-[3px]"> cityu </a> <span>/</span> <a href="/pdf/cv/cv.pdf" target="_self" class="inline-block decoration-black/30 dark:decoration-white/30 hover:decoration-black/50 focus-visible:decoration-black/50 dark:hover:decoration-white/50 dark:focus-visible:decoration-white/50 text-current hover:text-black focus-visible:text-black dark:hover:text-white dark:focus-visible:text-white transition-colors duration-300 ease-in-out underline underline-offset-[3px]"> cv </a> <span>/</span> <button id="magnifying-glass" aria-label="Search" class="flex items-center rounded border border-black/15 bg-neutral-100 px-2 py-1 text-xs transition-colors duration-300 ease-in-out hover:bg-black/5 hover:text-black focus-visible:bg-black/5 focus-visible:text-black dark:border-white/20 dark:bg-neutral-900 dark:hover:bg-white/5 dark:hover:text-white dark:focus-visible:bg-white/5 dark:focus-visible:text-white"> <svg height="16" stroke-linejoin="round" viewBox="0 0 16 16" width="16" style="color: currentcolor;"> <path fill-rule="evenodd" clip-rule="evenodd" d="M3.5 7C3.5 5.067 5.067 3.5 7 3.5C8.933 3.5 10.5 5.067 10.5 7C10.5 7.88461 10.1718 8.69256 9.63058 9.30876L9.30876 9.63058C8.69256 10.1718 7.88461 10.5 7 10.5C5.067 10.5 3.5 8.933 3.5 7ZM9.96544 11.0261C9.13578 11.6382 8.11014 12 7 12C4.23858 12 2 9.76142 2 7C2 4.23858 4.23858 2 7 2C9.76142 2 12 4.23858 12 7C12 8.11014 11.6382 9.13578 11.0261 9.96544L14.0303 12.9697L14.5607 13.5L13.5 14.5607L12.9697 14.0303L9.96544 11.0261Z" fill="currentColor"></path> </svg>
&nbsp;Search
</button> </nav> </div> </div> </header> <main>  <div class="mx-auto max-w-screen-sm px-3"> <div class="animate grid gap-4"> <a href="/posts" class="not-prose group relative flex w-fit flex-nowrap rounded border border-black/15 py-1.5 pl-7 pr-3 transition-colors duration-300 ease-in-out hover:bg-black/5 hover:text-black focus-visible:bg-black/5 focus-visible:text-black dark:border-white/20 dark:hover:bg-white/5 dark:hover:text-white dark:focus-visible:bg-white/5 dark:focus-visible:text-white"> <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" class="absolute left-2 top-1/2 size-4 -translate-y-1/2 fill-none stroke-current stroke-2"> <line x1="5" y1="12" x2="19" y2="12" class="translate-x-2 scale-x-0 transition-transform duration-300 ease-in-out group-hover:translate-x-0 group-hover:scale-x-100 group-focus-visible:translate-x-0 group-focus-visible:scale-x-100"></line> <polyline points="12 5 5 12 12 19" class="translate-x-1 transition-transform duration-300 ease-in-out group-hover:translate-x-0 group-focus-visible:translate-x-0"></polyline> </svg> <div class="text-sm"> Back to posts </div> </a> <div class="grid grid-cols-2 gap-1.5 sm:gap-3"> <div class="invisible"></div> <a href="/posts/uncertainty" class="group relative flex flex-grow flex-row-reverse flex-nowrap rounded-lg border border-black/15 px-4 py-4 pr-10 no-underline transition-colors duration-300 ease-in-out hover:bg-black/5 hover:text-black focus-visible:bg-black/5 focus-visible:text-black dark:border-white/20 dark:hover:bg-white/5 dark:hover:text-white dark:focus-visible:bg-white/5 dark:focus-visible:text-white"> <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" class="absolute right-2 top-1/2 size-5 -translate-y-1/2 fill-none stroke-current stroke-2"> <line x1="5" y1="12" x2="19" y2="12" class="translate-x-3 scale-x-0 transition-transform duration-300 ease-in-out group-hover:translate-x-0 group-hover:scale-x-100 group-focus-visible:translate-x-0 group-focus-visible:scale-x-100"></line> <polyline points="12 5 19 12 12 19" class="-translate-x-1 transition-transform duration-300 ease-in-out group-hover:translate-x-0 group-focus-visible:translate-x-0"></polyline> </svg> <div class="flex items-center text-sm"> Uncertainty makes the soul </div> </a> </div> </div> <div class="my-10 space-y-1"> <div class="animate flex items-center gap-1.5"> <div class="font-base text-sm"> <time datetime="2025-01-20T00:00:00.000Z"> January 20, 2025 </time> </div> 
&bull;
<div class="font-base text-sm">
Last modified:  <time datetime="2025-04-02T12:51:49.000Z"> April 02, 2025 </time> </div> 
&bull;
<div class="font-base text-sm"> 49 min read </div> </div> <h1 class="animate text-3xl font-semibold text-black dark:text-white"> Rezvan Explains: Classical Machine Learning </h1> </div> <details open class="animate rounded-lg border border-black/15 dark:border-white/20" data-astro-cid-xvrfupwn> <summary data-astro-cid-xvrfupwn>Table of Contents</summary> <nav class="" data-astro-cid-xvrfupwn> <ul class="py-3" data-astro-cid-xvrfupwn> <li class="list-inside list-disc px-6 py-1.5 text-sm"> <a href="#preqrequisites-and-notation" target="_self" class="inline-block decoration-black/30 dark:decoration-white/30 hover:decoration-black/50 focus-visible:decoration-black/50 dark:hover:decoration-white/50 dark:focus-visible:decoration-white/50 text-current hover:text-black focus-visible:text-black dark:hover:text-white dark:focus-visible:text-white transition-colors duration-300 ease-in-out underline underline-offset-[3px]"> Preqrequisites and Notation </a>  </li><li class="list-inside list-disc px-6 py-1.5 text-sm"> <a href="#what-why-and-how" target="_self" class="inline-block decoration-black/30 dark:decoration-white/30 hover:decoration-black/50 focus-visible:decoration-black/50 dark:hover:decoration-white/50 dark:focus-visible:decoration-white/50 text-current hover:text-black focus-visible:text-black dark:hover:text-white dark:focus-visible:text-white transition-colors duration-300 ease-in-out underline underline-offset-[3px]"> What, Why, and How? </a> <ul class="translate-x-3"> <li class="list-inside list-disc px-6 py-1.5 text-sm"> <a href="#statistics-vs-machine-learning" target="_self" class="inline-block decoration-black/30 dark:decoration-white/30 hover:decoration-black/50 focus-visible:decoration-black/50 dark:hover:decoration-white/50 dark:focus-visible:decoration-white/50 text-current hover:text-black focus-visible:text-black dark:hover:text-white dark:focus-visible:text-white transition-colors duration-300 ease-in-out underline underline-offset-[3px]"> Statistics VS. Machine Learning </a>  </li><li class="list-inside list-disc px-6 py-1.5 text-sm"> <a href="#humble-beginnings" target="_self" class="inline-block decoration-black/30 dark:decoration-white/30 hover:decoration-black/50 focus-visible:decoration-black/50 dark:hover:decoration-white/50 dark:focus-visible:decoration-white/50 text-current hover:text-black focus-visible:text-black dark:hover:text-white dark:focus-visible:text-white transition-colors duration-300 ease-in-out underline underline-offset-[3px]"> Humble Beginnings </a>  </li> </ul> </li><li class="list-inside list-disc px-6 py-1.5 text-sm"> <a href="#different-types-of-learning" target="_self" class="inline-block decoration-black/30 dark:decoration-white/30 hover:decoration-black/50 focus-visible:decoration-black/50 dark:hover:decoration-white/50 dark:focus-visible:decoration-white/50 text-current hover:text-black focus-visible:text-black dark:hover:text-white dark:focus-visible:text-white transition-colors duration-300 ease-in-out underline underline-offset-[3px]"> Different Types of Learning </a> <ul class="translate-x-3"> <li class="list-inside list-disc px-6 py-1.5 text-sm"> <a href="#supervised-learning" target="_self" class="inline-block decoration-black/30 dark:decoration-white/30 hover:decoration-black/50 focus-visible:decoration-black/50 dark:hover:decoration-white/50 dark:focus-visible:decoration-white/50 text-current hover:text-black focus-visible:text-black dark:hover:text-white dark:focus-visible:text-white transition-colors duration-300 ease-in-out underline underline-offset-[3px]"> Supervised Learning </a> <ul class="translate-x-3"> <li class="list-inside list-disc px-6 py-1.5 text-sm"> <a href="#the-classification-task" target="_self" class="inline-block decoration-black/30 dark:decoration-white/30 hover:decoration-black/50 focus-visible:decoration-black/50 dark:hover:decoration-white/50 dark:focus-visible:decoration-white/50 text-current hover:text-black focus-visible:text-black dark:hover:text-white dark:focus-visible:text-white transition-colors duration-300 ease-in-out underline underline-offset-[3px]"> The Classification Task </a>  </li><li class="list-inside list-disc px-6 py-1.5 text-sm"> <a href="#the-classification-learning-problem" target="_self" class="inline-block decoration-black/30 dark:decoration-white/30 hover:decoration-black/50 focus-visible:decoration-black/50 dark:hover:decoration-white/50 dark:focus-visible:decoration-white/50 text-current hover:text-black focus-visible:text-black dark:hover:text-white dark:focus-visible:text-white transition-colors duration-300 ease-in-out underline underline-offset-[3px]"> The Classification Learning Problem </a> <ul class="translate-x-3"> <li class="list-inside list-disc px-6 py-1.5 text-sm"> <a href="#metrics" target="_self" class="inline-block decoration-black/30 dark:decoration-white/30 hover:decoration-black/50 focus-visible:decoration-black/50 dark:hover:decoration-white/50 dark:focus-visible:decoration-white/50 text-current hover:text-black focus-visible:text-black dark:hover:text-white dark:focus-visible:text-white transition-colors duration-300 ease-in-out underline underline-offset-[3px]"> Metrics </a>  </li> </ul> </li><li class="list-inside list-disc px-6 py-1.5 text-sm"> <a href="#different-approaches" target="_self" class="inline-block decoration-black/30 dark:decoration-white/30 hover:decoration-black/50 focus-visible:decoration-black/50 dark:hover:decoration-white/50 dark:focus-visible:decoration-white/50 text-current hover:text-black focus-visible:text-black dark:hover:text-white dark:focus-visible:text-white transition-colors duration-300 ease-in-out underline underline-offset-[3px]"> Different Approaches </a> <ul class="translate-x-3"> <li class="list-inside list-disc px-6 py-1.5 text-sm"> <a href="#generative-models" target="_self" class="inline-block decoration-black/30 dark:decoration-white/30 hover:decoration-black/50 focus-visible:decoration-black/50 dark:hover:decoration-white/50 dark:focus-visible:decoration-white/50 text-current hover:text-black focus-visible:text-black dark:hover:text-white dark:focus-visible:text-white transition-colors duration-300 ease-in-out underline underline-offset-[3px]"> Generative Models </a> <ul class="translate-x-3"> <li class="list-inside list-disc px-6 py-1.5 text-sm"> <a href="#bayes-optimal-classifier" target="_self" class="inline-block decoration-black/30 dark:decoration-white/30 hover:decoration-black/50 focus-visible:decoration-black/50 dark:hover:decoration-white/50 dark:focus-visible:decoration-white/50 text-current hover:text-black focus-visible:text-black dark:hover:text-white dark:focus-visible:text-white transition-colors duration-300 ease-in-out underline underline-offset-[3px]"> Bayes Optimal Classifier </a>  </li><li class="list-inside list-disc px-6 py-1.5 text-sm"> <a href="#maximum-likelihood-estimate" target="_self" class="inline-block decoration-black/30 dark:decoration-white/30 hover:decoration-black/50 focus-visible:decoration-black/50 dark:hover:decoration-white/50 dark:focus-visible:decoration-white/50 text-current hover:text-black focus-visible:text-black dark:hover:text-white dark:focus-visible:text-white transition-colors duration-300 ease-in-out underline underline-offset-[3px]"> Maximum Likelihood Estimate </a>  </li><li class="list-inside list-disc px-6 py-1.5 text-sm"> <a href="#bayes-optimal-classifier-summary" target="_self" class="inline-block decoration-black/30 dark:decoration-white/30 hover:decoration-black/50 focus-visible:decoration-black/50 dark:hover:decoration-white/50 dark:focus-visible:decoration-white/50 text-current hover:text-black focus-visible:text-black dark:hover:text-white dark:focus-visible:text-white transition-colors duration-300 ease-in-out underline underline-offset-[3px]"> Bayes Optimal Classifier Summary </a>  </li><li class="list-inside list-disc px-6 py-1.5 text-sm"> <a href="#naive-bayes-classifier" target="_self" class="inline-block decoration-black/30 dark:decoration-white/30 hover:decoration-black/50 focus-visible:decoration-black/50 dark:hover:decoration-white/50 dark:focus-visible:decoration-white/50 text-current hover:text-black focus-visible:text-black dark:hover:text-white dark:focus-visible:text-white transition-colors duration-300 ease-in-out underline underline-offset-[3px]"> Naive Bayes Classifier </a>  </li><li class="list-inside list-disc px-6 py-1.5 text-sm"> <a href="#linear-discriminant-analysis-lda" target="_self" class="inline-block decoration-black/30 dark:decoration-white/30 hover:decoration-black/50 focus-visible:decoration-black/50 dark:hover:decoration-white/50 dark:focus-visible:decoration-white/50 text-current hover:text-black focus-visible:text-black dark:hover:text-white dark:focus-visible:text-white transition-colors duration-300 ease-in-out underline underline-offset-[3px]"> Linear Discriminant Analysis (LDA) </a>  </li> </ul> </li><li class="list-inside list-disc px-6 py-1.5 text-sm"> <a href="#summary-generative-models" target="_self" class="inline-block decoration-black/30 dark:decoration-white/30 hover:decoration-black/50 focus-visible:decoration-black/50 dark:hover:decoration-white/50 dark:focus-visible:decoration-white/50 text-current hover:text-black focus-visible:text-black dark:hover:text-white dark:focus-visible:text-white transition-colors duration-300 ease-in-out underline underline-offset-[3px]"> Summary Generative Models </a>  </li><li class="list-inside list-disc px-6 py-1.5 text-sm"> <a href="#discriminative-models" target="_self" class="inline-block decoration-black/30 dark:decoration-white/30 hover:decoration-black/50 focus-visible:decoration-black/50 dark:hover:decoration-white/50 dark:focus-visible:decoration-white/50 text-current hover:text-black focus-visible:text-black dark:hover:text-white dark:focus-visible:text-white transition-colors duration-300 ease-in-out underline underline-offset-[3px]"> Discriminative Models </a> <ul class="translate-x-3"> <li class="list-inside list-disc px-6 py-1.5 text-sm"> <a href="#logistic-regression" target="_self" class="inline-block decoration-black/30 dark:decoration-white/30 hover:decoration-black/50 focus-visible:decoration-black/50 dark:hover:decoration-white/50 dark:focus-visible:decoration-white/50 text-current hover:text-black focus-visible:text-black dark:hover:text-white dark:focus-visible:text-white transition-colors duration-300 ease-in-out underline underline-offset-[3px]"> Logistic Regression </a>  </li><li class="list-inside list-disc px-6 py-1.5 text-sm"> <a href="#support-vector-machines-svms" target="_self" class="inline-block decoration-black/30 dark:decoration-white/30 hover:decoration-black/50 focus-visible:decoration-black/50 dark:hover:decoration-white/50 dark:focus-visible:decoration-white/50 text-current hover:text-black focus-visible:text-black dark:hover:text-white dark:focus-visible:text-white transition-colors duration-300 ease-in-out underline underline-offset-[3px]"> Support Vector Machines (SVMs) </a>  </li><li class="list-inside list-disc px-6 py-1.5 text-sm"> <a href="#maximum-margin-principle" target="_self" class="inline-block decoration-black/30 dark:decoration-white/30 hover:decoration-black/50 focus-visible:decoration-black/50 dark:hover:decoration-white/50 dark:focus-visible:decoration-white/50 text-current hover:text-black focus-visible:text-black dark:hover:text-white dark:focus-visible:text-white transition-colors duration-300 ease-in-out underline underline-offset-[3px]"> Maximum Margin Principle </a>  </li><li class="list-inside list-disc px-6 py-1.5 text-sm"> <a href="#computing-the-margin" target="_self" class="inline-block decoration-black/30 dark:decoration-white/30 hover:decoration-black/50 focus-visible:decoration-black/50 dark:hover:decoration-white/50 dark:focus-visible:decoration-white/50 text-current hover:text-black focus-visible:text-black dark:hover:text-white dark:focus-visible:text-white transition-colors duration-300 ease-in-out underline underline-offset-[3px]"> Computing the Margin </a>  </li><li class="list-inside list-disc px-6 py-1.5 text-sm"> <a href="#why-is-maximize-the-margin-a-good-idea" target="_self" class="inline-block decoration-black/30 dark:decoration-white/30 hover:decoration-black/50 focus-visible:decoration-black/50 dark:hover:decoration-white/50 dark:focus-visible:decoration-white/50 text-current hover:text-black focus-visible:text-black dark:hover:text-white dark:focus-visible:text-white transition-colors duration-300 ease-in-out underline underline-offset-[3px]"> Why is Maximize the Margin a Good Idea? </a>  </li><li class="list-inside list-disc px-6 py-1.5 text-sm"> <a href="#soft-margin" target="_self" class="inline-block decoration-black/30 dark:decoration-white/30 hover:decoration-black/50 focus-visible:decoration-black/50 dark:hover:decoration-white/50 dark:focus-visible:decoration-white/50 text-current hover:text-black focus-visible:text-black dark:hover:text-white dark:focus-visible:text-white transition-colors duration-300 ease-in-out underline underline-offset-[3px]"> Soft-Margin </a>  </li><li class="list-inside list-disc px-6 py-1.5 text-sm"> <a href="#convex-optimization" target="_self" class="inline-block decoration-black/30 dark:decoration-white/30 hover:decoration-black/50 focus-visible:decoration-black/50 dark:hover:decoration-white/50 dark:focus-visible:decoration-white/50 text-current hover:text-black focus-visible:text-black dark:hover:text-white dark:focus-visible:text-white transition-colors duration-300 ease-in-out underline underline-offset-[3px]"> (Convex) Optimization </a>  </li><li class="list-inside list-disc px-6 py-1.5 text-sm"> <a href="#standard-form-of-convex-optimization" target="_self" class="inline-block decoration-black/30 dark:decoration-white/30 hover:decoration-black/50 focus-visible:decoration-black/50 dark:hover:decoration-white/50 dark:focus-visible:decoration-white/50 text-current hover:text-black focus-visible:text-black dark:hover:text-white dark:focus-visible:text-white transition-colors duration-300 ease-in-out underline underline-offset-[3px]"> Standard Form of Convex Optimization </a>  </li><li class="list-inside list-disc px-6 py-1.5 text-sm"> <a href="#duality-and-kkt-conditions" target="_self" class="inline-block decoration-black/30 dark:decoration-white/30 hover:decoration-black/50 focus-visible:decoration-black/50 dark:hover:decoration-white/50 dark:focus-visible:decoration-white/50 text-current hover:text-black focus-visible:text-black dark:hover:text-white dark:focus-visible:text-white transition-colors duration-300 ease-in-out underline underline-offset-[3px]"> Duality and KKT Conditions </a>  </li><li class="list-inside list-disc px-6 py-1.5 text-sm"> <a href="#svms-continued" target="_self" class="inline-block decoration-black/30 dark:decoration-white/30 hover:decoration-black/50 focus-visible:decoration-black/50 dark:hover:decoration-white/50 dark:focus-visible:decoration-white/50 text-current hover:text-black focus-visible:text-black dark:hover:text-white dark:focus-visible:text-white transition-colors duration-300 ease-in-out underline underline-offset-[3px]"> SVMs Continued </a>  </li><li class="list-inside list-disc px-6 py-1.5 text-sm"> <a href="#deriving-the-dual-problem" target="_self" class="inline-block decoration-black/30 dark:decoration-white/30 hover:decoration-black/50 focus-visible:decoration-black/50 dark:hover:decoration-white/50 dark:focus-visible:decoration-white/50 text-current hover:text-black focus-visible:text-black dark:hover:text-white dark:focus-visible:text-white transition-colors duration-300 ease-in-out underline underline-offset-[3px]"> Deriving the Dual Problem </a>  </li><li class="list-inside list-disc px-6 py-1.5 text-sm"> <a href="#gradient-descent-and-variants" target="_self" class="inline-block decoration-black/30 dark:decoration-white/30 hover:decoration-black/50 focus-visible:decoration-black/50 dark:hover:decoration-white/50 dark:focus-visible:decoration-white/50 text-current hover:text-black focus-visible:text-black dark:hover:text-white dark:focus-visible:text-white transition-colors duration-300 ease-in-out underline underline-offset-[3px]"> Gradient Descent and variants </a>  </li><li class="list-inside list-disc px-6 py-1.5 text-sm"> <a href="#k-nearest-neighbors" target="_self" class="inline-block decoration-black/30 dark:decoration-white/30 hover:decoration-black/50 focus-visible:decoration-black/50 dark:hover:decoration-white/50 dark:focus-visible:decoration-white/50 text-current hover:text-black focus-visible:text-black dark:hover:text-white dark:focus-visible:text-white transition-colors duration-300 ease-in-out underline underline-offset-[3px]"> $k$-Nearest Neighbors </a>  </li> </ul> </li> </ul> </li><li class="list-inside list-disc px-6 py-1.5 text-sm"> <a href="#the-regression-task" target="_self" class="inline-block decoration-black/30 dark:decoration-white/30 hover:decoration-black/50 focus-visible:decoration-black/50 dark:hover:decoration-white/50 dark:focus-visible:decoration-white/50 text-current hover:text-black focus-visible:text-black dark:hover:text-white dark:focus-visible:text-white transition-colors duration-300 ease-in-out underline underline-offset-[3px]"> The Regression Task </a>  </li><li class="list-inside list-disc px-6 py-1.5 text-sm"> <a href="#the-regression-learning-problem" target="_self" class="inline-block decoration-black/30 dark:decoration-white/30 hover:decoration-black/50 focus-visible:decoration-black/50 dark:hover:decoration-white/50 dark:focus-visible:decoration-white/50 text-current hover:text-black focus-visible:text-black dark:hover:text-white dark:focus-visible:text-white transition-colors duration-300 ease-in-out underline underline-offset-[3px]"> The Regression Learning Problem </a> <ul class="translate-x-3"> <li class="list-inside list-disc px-6 py-1.5 text-sm"> <a href="#linear-regression" target="_self" class="inline-block decoration-black/30 dark:decoration-white/30 hover:decoration-black/50 focus-visible:decoration-black/50 dark:hover:decoration-white/50 dark:focus-visible:decoration-white/50 text-current hover:text-black focus-visible:text-black dark:hover:text-white dark:focus-visible:text-white transition-colors duration-300 ease-in-out underline underline-offset-[3px]"> Linear Regression </a> <ul class="translate-x-3"> <li class="list-inside list-disc px-6 py-1.5 text-sm"> <a href="#ordinary-least-squares-ols" target="_self" class="inline-block decoration-black/30 dark:decoration-white/30 hover:decoration-black/50 focus-visible:decoration-black/50 dark:hover:decoration-white/50 dark:focus-visible:decoration-white/50 text-current hover:text-black focus-visible:text-black dark:hover:text-white dark:focus-visible:text-white transition-colors duration-300 ease-in-out underline underline-offset-[3px]"> Ordinary Least Squares (OLS) </a>  </li><li class="list-inside list-disc px-6 py-1.5 text-sm"> <a href="#general-ols-derivation" target="_self" class="inline-block decoration-black/30 dark:decoration-white/30 hover:decoration-black/50 focus-visible:decoration-black/50 dark:hover:decoration-white/50 dark:focus-visible:decoration-white/50 text-current hover:text-black focus-visible:text-black dark:hover:text-white dark:focus-visible:text-white transition-colors duration-300 ease-in-out underline underline-offset-[3px]"> General OLS Derivation </a>  </li> </ul> </li> </ul> </li> </ul> </li><li class="list-inside list-disc px-6 py-1.5 text-sm"> <a href="#unsupervised-learning" target="_self" class="inline-block decoration-black/30 dark:decoration-white/30 hover:decoration-black/50 focus-visible:decoration-black/50 dark:hover:decoration-white/50 dark:focus-visible:decoration-white/50 text-current hover:text-black focus-visible:text-black dark:hover:text-white dark:focus-visible:text-white transition-colors duration-300 ease-in-out underline underline-offset-[3px]"> Unsupervised Learning </a>  </li> </ul> </li><li class="list-inside list-disc px-6 py-1.5 text-sm"> <a href="#footnote-label" target="_self" class="inline-block decoration-black/30 dark:decoration-white/30 hover:decoration-black/50 focus-visible:decoration-black/50 dark:hover:decoration-white/50 dark:focus-visible:decoration-white/50 text-current hover:text-black focus-visible:text-black dark:hover:text-white dark:focus-visible:text-white transition-colors duration-300 ease-in-out underline underline-offset-[3px]"> Footnotes </a>  </li> </ul> </nav> </details> <article class="animate"> <p><img src="/images/posts/rezvan_explains/re_header.jpg" alt=""></p>
<p style="font-weight:bold; text-align:center;"> Rezvan Explains: Classical Machine Learning</p>
<p style="font-size:15px; font-weight:italic; text-align:center;"> Veni, disce mecum </p>
<p>As of writing this, last night as I was going to sleep, I was lying in bed and thought about the future.
After some rambling I came up with this (hopefully) series, <strong>Rezvan Explains</strong>. I took a course called <a href="https://www.cityu.edu.hk/catalogue/ug/current/course/CS4487.htm">machine learning</a> during my exchange semester @ CityUHK taught by <a href="https://kedema.org">Kede Ma</a> (wonderful professor and I highly recommend taking the course).
This post is very inspired by his course but, I want to add my touch on the topic.</p>
<p>My goal for this part is to build your <strong>intuition</strong> when it comes to machine learning.
I believe most people getting started with AI nowadays donâ€™t want to understand the foundations modern deep learning is built upon.</p>
<h2 id="preqrequisites-and-notation">Preqrequisites and Notation</h2>
<p>This post will assume that you know about:</p>
<ul>
<li>Linear Algebra</li>
<li>Multivariable and Matrix Calculus</li>
<li>Probability and Statistics</li>
</ul>
<p>If you donâ€™t feel comfortable with these topics, read up and come back when ready.</p>
<p>These are the notations that we will use, there is no need to go through them the first time youâ€™re reading this, itâ€™s meant as a <strong>reference</strong>.</p>





















































<table><thead><tr><th><strong>Symbol</strong></th><th><strong>Meaning</strong></th></tr></thead><tbody><tr><td>$M$</td><td>Number of Examples in Dataset</td></tr><tr><td>$N$</td><td>Number of Features in Training Sample</td></tr><tr><td>$\mathcal{D}$</td><td>Dataset of $M$ Examples</td></tr><tr><td>$\mathbf{x}$</td><td>$N$-dimensional Feature Vector</td></tr><tr><td>$y$</td><td>Class Label</td></tr><tr><td>$\mathbf{x}^{(i)}$</td><td>$i$-th Feature Vector in Dataset in $\mathcal{D}$</td></tr><tr><td>$\mathbf{x}^{(i)}_j$</td><td>$j$-th Feature in $i$-th Feature Vector in $\mathcal{D}$</td></tr><tr><td>$y^{(i)}$</td><td>$i$-th Class Label in Dataset in $\mathcal{D}$ corresponding to $\mathbf{x}^{(i)}$</td></tr><tr><td>$\mathbf{X}$</td><td>Input Space</td></tr><tr><td>$\mathbf{Y}$</td><td>Output Space</td></tr><tr><td>$| \mathbf{Y} |$</td><td>Number of Classes in Output Space</td></tr></tbody></table>
<h2 id="what-why-and-how">What, Why, and How?</h2>
<p>There is one fundamental flaw Iâ€™ve seen with <strong>every</strong> machine learning course Iâ€™ve taken.
Machine learning is a study of <strong>statistical algorithms</strong>, i.e., statistics and machine learning are <em>very</em> closely related fields.
But the distinct difference is in their principal goal.</p>
<h3 id="statistics-vs-machine-learning">Statistics VS. Machine Learning</h3>
<p>Generally in machine learning we want to find <strong>generalizable predictive patterns.</strong> <sup><a href="#user-content-fn-1" id="user-content-fnref-1" data-footnote-ref="" aria-describedby="footnote-label">1</a></sup>
While this might not be exclusive to machine learning (a large part of statistics is also about prediction), in machine learning, it is the <strong>main goal</strong>.</p>
<p>Iâ€™m not going into the history of machine learning as a field and its evolution, but if it is one thing I want you to take away from this post, it is that machine learning <strong>fundamentally relies on data</strong>.
I canâ€™t stress this enough, a lot of my fellow peers never got this intuition at the start of our courses, and therefore everything during the semester seemed like black magic.
But in the end <strong>everything</strong> comes down to <strong>data</strong>.</p>
<h3 id="humble-beginnings">Humble Beginnings</h3>
<p>Okay I lied, a bit of history wonâ€™t hurt.
The name <em>machine learning</em> implies that a machine is learning (duh).
I think the <em>machine</em> part is quite obvious (a computer), but learning is a bit more abstract.</p>
<p>A lot of people have defined <em>learning</em> in varying ways and for different domains, letâ€™s take a look:</p>
<ul>
<li>Behaviorism (Skinner)
<ul>
<li>
<blockquote>
<p>Learning is a long-term change in behavior due to experience. <sup><a href="#user-content-fn-2" id="user-content-fnref-2" data-footnote-ref="" aria-describedby="footnote-label">2</a></sup></p>
</blockquote>
</li>
</ul>
</li>
<li>Cognitivism (Gestalt School)
<ul>
<li>
<blockquote>
<p>Learning is an internal mental process that integrates new information into established mental frameworks and updates those frameworks over time. <sup><a href="#user-content-fn-3" id="user-content-fnref-3" data-footnote-ref="" aria-describedby="footnote-label">3</a></sup></p>
</blockquote>
</li>
</ul>
</li>
<li>Connectionism (Hebbian Learning)
<ul>
<li>
<blockquote>
<p>Learning is a physical process in which neurons join by developing the synapses between them. <sup><a href="#user-content-fn-4" id="user-content-fnref-4" data-footnote-ref="" aria-describedby="footnote-label">4</a></sup></p>
</blockquote>
</li>
</ul>
</li>
</ul>
<p>We can see that in an abstract sense, learning is taking some input and changing some internal state based on that input.
The last one is an outlier, but remember this for later.</p>
<h2 id="different-types-of-learning">Different Types of Learning</h2>
<p>Depending on the <strong>type of data</strong> we have but also <strong>what we want to achieve</strong>, the learning process <em>needs</em> to be different.</p>
<p>In this post, we will focus on <strong>supervised learning</strong> and <strong>unsupervised learning</strong>.</p>
<p>Letâ€™s define supervised learning in mathematical terms.</p>
<h3 id="supervised-learning">Supervised Learning</h3>
<p>In supervised learning, we have a dataset consisting of well-defined input-output pairs.
The task is to find a (good) <strong>generalized mapping</strong> from an arbitrary input to an output.</p>
<p>Mathematically we define this as,</p>
<p>$$
\begin{equation}
f : \mathbf{X} \mapsto \mathbf{Y},
\end{equation}
$$</p>
<p>where $\mathbf{X}$ is the input space and $\mathbf{Y}$ is the output space, we want to find the <em>best</em> function $f$ that maps $\mathbf{X}$ to $\mathbf{Y}$.</p>
<h4 id="the-classification-task">The Classification Task</h4>
<p>The best way to understand supervised learning is through the <strong>classification task</strong> and <em>Fisherâ€™s Iris dataset</em>. <sup><a href="#user-content-fn-5" id="user-content-fnref-5" data-footnote-ref="" aria-describedby="footnote-label">5</a></sup></p>
<p>In Fisherâ€™s Iris dataset we have 150 samples of input-output pairs.
The input is a vector with four <strong>features</strong> â€” sepal length, sepal width, petal length, petal width â€” the output is the <strong>species</strong> of the iris flower.</p>
<p>As described above, our input and output spaces are,</p>
<p>$$
\begin{equation}
\begin{aligned}
\mathbf{X} &#x26; = \{ \text{Sepal Length}, \text{Sepal Width}, \text{Petal Length}, \text{Petal Width} \} \newline
\mathbf{Y} &#x26; = \{ \text{Setosa}, \text{Versicolor}, \text{Virginica} \}
\end{aligned}
\end{equation}
$$</p>
<p>So given a vector with four real numbers (where each number describes a feature of the iris flower), we want to predict a number that corresponds to the species of the iris flower.</p>
<p>Thus, the proper mathematical definition of the classification task is,</p>
<blockquote>
<p>Given a feature vector $\mathbf{x} \in \mathbf{X} = \mathbb{R}^N$ that describes an object that belongs to one of $C$ classes from the set $\mathbf{Y} = \{ 1, 2, \ldots, C \}$, predict the class label $y \in \mathbf{Y}$.</p>
</blockquote>
<h4 id="the-classification-learning-problem">The Classification Learning Problem</h4>
<p>Now that we have defined the classification task, letâ€™s define the classification learning problem,</p>
<blockquote>
<p>Given a dataset of example pairs $\mathcal{D} = \{ (\mathbf{x}^{(i)}, y^{(i)}), i = 1, \ldots, M \}$
where $\mathbf{x}^{(i)} \in \mathbf{X} = \mathbb{R}^N$ is a feature vector and $y^{(i)} \in \mathbf{Y} = \{1, \ldots, C\}$ is the class label,
learn a function $f: \mathbb{R}^N \mapsto \mathbf{Y}$ that accurately predicts the class label $y$ for any feature vector $\mathbf{x}$.</p>
</blockquote>
<h5 id="metrics">Metrics</h5>
<p>To determine how well our function $f$ is doing, we need to define some (primal) metrics.</p>
<p>Firstly, letâ€™s define the <strong>indicator function</strong>,</p>
<p>$$
\begin{equation}
\mathbb{I}[A] = \begin{cases}
1, &#x26; \text{if } A \text{ is true}, \newline
0, &#x26; \text{otherwise}.
\end{cases}
\end{equation}
$$</p>
<p>The <strong>classification error</strong> is then defined as,</p>
<blockquote>
<p>Given a dataset of example pairs $\mathcal{D} = \{ (\mathbf{x}^{(i)}, y^{(i)}), i = 1, \ldots, M \}$
and a function $f: \mathbb{R}^N \mapsto \mathbf{Y}$, the classification error of $f$ on $\mathcal{D}$ is defined as,
$$
\begin{equation}
\text{Error}(f, \mathcal{D}) = \frac{1}{M} \sum_{i=1}^{M} \mathbb{I}[f(\mathbf{x}^{(i)}) \neq y^{(i)}].
\end{equation}
$$</p>
</blockquote>
<p>I.e., the classification error is the fraction of examples in the dataset that are misclassified by the function $f$.</p>
<p>The <strong>classification accuracy</strong> is then defined as,</p>
<blockquote>
<p>Given a dataset of example pairs $\mathcal{D} = \{ (\mathbf{x}^{(i)}, y^{(i)}), i = 1, \ldots, M \}$
and a function $f: \mathbb{R}^N \mapsto \mathbf{Y}$, the classification accuracy of $f$ on $\mathcal{D}$ is defined as,
$$
\begin{equation}
\text{Accuracy}(f, \mathcal{D}) = \frac{1}{M} \sum_{i=1}^{M} \mathbb{I}[f(\mathbf{x}^{(i)}) = y^{(i)}] = 1 - \text{Error}(f, \mathcal{D}).
\end{equation}
$$</p>
</blockquote>
<h4 id="different-approaches">Different Approaches</h4>
<p>But how do we solve the classification learning problem?
We will go through different ways of approaching this problem.</p>
<p>But I want to start of with the <strong>probabilistic approach</strong> first.</p>
<h5 id="generative-models">Generative Models</h5>
<p>We know that our dataset $\mathcal{D}$ consists of input-output pairs $(\mathbf{x}^{(i)}, y^{(i)})$.
In the real dataset, we have a <strong>joint distribution</strong> $p(\mathbf{x}, y)$, this describes the probability of observing the pair $(\mathbf{x}, y)$.</p>
<p>We can learn this joint distribution from the dataset.
We know from <strong>Bayesâ€™ Rule</strong> that,</p>
<p>$$
\begin{equation}
p(\mathbf{x}, y) = p(y) p(\mathbf{x} | y).
\end{equation}
$$</p>
<p>These two terms are very important, letâ€™s define them properly.</p>
<p>The first term $p(y)$ is often called the <strong>prior distribution</strong> of the classes.
It describes how frequently each class occurs in nature (or in the dataset).</p>
<p>The second term $p(\mathbf{x} | y)$ is called the <strong>class-conditional distribution</strong>.
This distribution describes how the features $\mathbf{x}$ are distributed for different classes $y$.</p>
<p>To remind you, the <strong>classification task</strong> is to predict the <strong>class label $y$ given a feature vector $\mathbf{x}$</strong>.</p>
<p>So again, by Bayesâ€™s Rule we know that,</p>
<p>$$
\begin{equation}
p(y | \mathbf{x}) = \frac{p(\mathbf{x}, y)}{p(\mathbf{x})} = \frac{p(y) p(\mathbf{x} | y)}{p(\mathbf{x})}.
\end{equation}
$$</p>
<p>So for the classification task, we want to choose the <strong>best prediction</strong>.</p>
<p>Letâ€™s clarify the difference between the <strong>$\max$</strong> and <strong>$\arg \max$</strong> operators.
The $\max$ returns the maximum <strong>value</strong> of a function, while the $\arg \max$ returns the <strong>argument</strong> that gives the maximum value.</p>
<p>Or in mathematical terms,</p>
<p>$$
\begin{equation}
\max_{\mathbf{x}} f(\mathbf{x}) = \{f(\mathbf{x}) | \mathbf{x} \in \mathcal{D} \land \forall \mathbf{y} \in \mathcal{D}, f(\mathbf{y}) \leq f(\mathbf{x})\}
\end{equation}
$$</p>
<p>$$
\begin{equation}
\underset{\mathbf{x}}{\arg\max} f(\mathbf{x}) = \{\mathbf{x} | \mathbf{x} \in \mathcal{D} \land \forall \mathbf{y} \in \mathcal{D}, f(\mathbf{y}) \leq f(\mathbf{x})\}
\end{equation}
$$</p>
<p>Therefore, the best prediction for the classification task is,</p>
<p>$$
\begin{equation}
\hat{y} = \arg \max_{y \in \mathbf{Y}} p(y | \mathbf{x}) = \arg \max_{y \in \mathbf{Y}} \frac{p(y) p(\mathbf{x} | y)}{p(\mathbf{x})}.
\end{equation}
$$</p>
<p>If we are looking to <strong>maximize the fraction</strong>, we can <strong>ignore the denominator</strong> $p(\mathbf{x})$ since we know that it is <strong>non-negative and class-independent</strong>.</p>
<p>$$
\begin{equation}
\hat{y} = \arg \max_{y \in \mathbf{Y}} p(y) p(\mathbf{x} | y).
\end{equation}
$$</p>
<p>So if we can estimate the <strong>prior distribution</strong> $p(y)$ and the <strong>class-conditional distribution</strong> $p(\mathbf{x} | y)$, we can predict the class label $y$ for <strong>any feature vector</strong> $\mathbf{x}$.</p>
<p>Letâ€™s start with the <strong>prior distribution</strong> $p(y)$, since it is the easiest to learn.
From our dataset $\mathcal{D} = \{ (\mathbf{x}^{(i)}, y^{(i)}), i = 1, \ldots, M \}$, with well-defined input-output pairs we simply count how often each class label $y$ appears,</p>
<p>$$
\begin{equation}
p(y = c) \approx \frac{\sum_{i = 1}^M \mathbb{I}[y^{(i)} = c]}{M}.
\end{equation}
$$</p>
<p><strong>Note</strong>, that this is the simplest case if $y$ only captures one class, it is possible that for a different task that $y$ is a vector of classes (e.g., multi-label classification).</p>
<p>The class-conditional distribution $p(\mathbf{x} | y)$ is a bit more tricky. How do we model this distribution?</p>
<p><img src="/images/posts/rezvan_explains/iris_histogram.svg" alt="">
<strong>Figure 1:</strong> Histogram of the petal length of all three species of iris flowers.</p>
<p>By looking at Figure 1, we see that it is a bit noisy, but we can see <em>some</em> Gaussian structure.
Letâ€™s assume a probability model for the class conditional $p(\mathbf{x} | y)$, in our case <strong>Gaussian</strong>.</p>
<h6 id="bayes-optimal-classifier">Bayes Optimal Classifier</h6>
<p>So, each class is modeled as a <strong>separate Gaussian</strong> distribution <strong>of the feature values</strong>, or in other words,</p>
<p>$$
\begin{equation}
p(\mathbf{x} | y) = \frac{1}{\sqrt{2 \pi \sigma_{c}^2}} e^{-\frac{1}{2 \sigma_{c}^2} \left(x^{(i)} - \mu_{c}\right)^2}
\end{equation}
$$</p>
<p>Each class has its own mean and variance parameters ($\mu_{c}$ and $\sigma_{c}^2$).
But whatâ€™s considered the â€œbestâ€ estimates, and how do we find them?</p>
<h6 id="maximum-likelihood-estimate">Maximum Likelihood Estimate</h6>
<p>We want our model to be as close to the true distribution as possible.
Meaning that <strong>our (already) observed data should be the most probable</strong> under our model.</p>
<p>The <strong>likelihood function</strong> measures how well a model explains the observed data given the model parameters <sup><a href="#user-content-fn-6" id="user-content-fnref-6" data-footnote-ref="" aria-describedby="footnote-label">6</a></sup>.</p>
<p><strong>Maximum Likelihood Estimate (MLE)</strong> is a method for estimating said parameters by maximizing the likelihood function.</p>
<p><strong>Note</strong>, there are more sophisticated methods (e.g., Bayesian estimation, Maximum A Posteriori (MAP) estimation, etc.), but MLE has very nice properties and is good enough for most cases.</p>
<p>In our case, the likelihood function is defined as,</p>
<p>$$
\begin{equation}
L(\mu_c, \sigma_c^2) = \prod_{i=1}^{M_c} \frac{1}{\sqrt{2 \pi \sigma_{c}^2}} e^{-\frac{1}{2 \sigma_{c}^2} \left(x^{(i)} - \mu_{c}\right)^2},
\end{equation}
$$</p>
<p>where <strong>$M_c$ is the number of samples in class $c$</strong>, since the parameters are different for each class.</p>
<p>Thus, our MLE estimates are,</p>
<p>$$
\begin{equation}
(\hat{\mu_c}, \hat{\sigma_c^2}) = \underset{\mu_c, \sigma_c^2}{\arg\max} \prod_{i=1}^{M_c} \frac{1}{\sqrt{2 \pi \sigma_{c}^2}} e^{-\frac{1}{2 \sigma_{c}^2} \left(x^{(i)} - \mu_{c}\right)^2}.
\end{equation}
$$</p>
<p>Letâ€™s use a little trick to avoid the product notation.
The <strong>logarithm</strong> is a <strong>monotonic function</strong>, meaning that the <strong>order of the values doesnâ€™t change</strong>.
In other words, the <strong>maximum value before applying the logarithm is still the maximum value</strong> after applying the logarithm (just the scale changes).</p>
<p>Thus, taking the <strong>MLE of the log-likelihood function is equivalent</strong> to taking the MLE of the likelihood function.</p>
<p>$$
\begin{equation}
(\hat{\mu_c}, \hat{\sigma_c^2}) = \underset{\mu_c, \sigma_c^2}{\arg\max} \log \left[\prod_{i=1}^{M_c} \frac{1}{\sqrt{2 \pi \sigma_{c}^2}} e^{-\frac{1}{2 \sigma_{c}^2} \left(x^{(i)} - \mu_{c}\right)^2}\right].
\end{equation}
$$</p>
<p>Now, the product becomes a sum (since the logarithm of a product is the sum of the logarithms).</p>
<p>$$
\begin{equation}
(\hat{\mu_c}, \hat{\sigma_c^2}) = \underset{\mu_c, \sigma_c^2}{\arg\max} \sum_{i=1}^{M_c} \log \left[\frac{1}{\sqrt{2 \pi \sigma_{c}^2}} e^{-\frac{1}{2 \sigma_{c}^2} \left(x^{(i)} - \mu_{c}\right)^2}\right].
\end{equation}
$$</p>
<p>Now, I am going to simplify the expression step-by-step, at some steps I will have a $\big\rvert \cdot$ to indicate what operation we perform at that step.</p>
<p>$$
\begin{aligned}
\log \left[\frac{1}{\sqrt{2 \pi \sigma_{c}^2}} e^{-\frac{1}{2 \sigma_{c}^2} \left(x^{(i)} - \mu_{c}\right)^2}\right] &#x26;= \log \left[\frac{1}{\sqrt{2 \pi \sigma_{c}^2}}\right] + \log \left[e^{-\frac{1}{2 \sigma_{c}^2} \left(x^{(i)} - \mu_{c}\right)^2}\right] \ \biggr\rvert \log(ab) = \log(a) + \log(b) \newline
&#x26;= \log(1) - \log(\sqrt{2 \pi \sigma_{c}^2}) + \log \left[e^{-\frac{1}{2 \sigma_{c}^2} \left(x^{(i)} - \mu_{c}\right)^2}\right] \ \biggr\rvert \log(a/b) = \log(a) - \log(b) \newline
&#x26;= -\log(\sqrt{2 \pi \sigma_{c}^2}) + \log \left[e^{-\frac{1}{2 \sigma_{c}^2} \left(x^{(i)} - \mu_{c}\right)^2}\right] \ \biggr\rvert \log(1) = 0 \newline
&#x26;= -\log(\sqrt{2 \pi \sigma_{c}^2}) -\frac{1}{2 \sigma_{c}^2} \left(x^{(i)} - \mu_{c}\right)^2 \ \biggr\rvert \log(e^a) = a \newline
\end{aligned}
$$</p>
<p>So, our MLE estimates are,</p>
<p>$$
\begin{equation}
(\hat{\mu_c}, \hat{\sigma_c^2}) = \underset{\mu_c, \sigma_c^2}{\arg\max} \sum_{i=1}^{M_c} \left[-\log(\sqrt{2 \pi \sigma_{c}^2}) -\frac{1}{2 \sigma_{c}^2} \left(x^{(i)} - \mu_{c}\right)^2\right].
\end{equation}
$$</p>
<p>To find the maximum, we need to take the derivative of the expression with respect to $\mu_c$ and $\sigma_c^2$ and set them to zero.</p>
<p>Letâ€™s start with $\mu_c$ since itâ€™s easier.</p>
<p>$$
\begin{equation}
\begin{aligned}
\frac{\partial}{\partial \mu_c} \sum \left[-\log(\sqrt{2 \pi \sigma_c^2}) -\frac{1}{2 \sigma_c^2} \left(x^{(i)} - \mu_c\right)^2\right] &#x26;= 0 \newline
\sum \frac{\partial}{\partial \mu_c} \left[\underbrace{-\log(\sqrt{2 \pi \sigma_c^2})}_0 -\frac{1}{2 \sigma_c^2} \left(x^{(i)} - \mu_c\right)^2\right] &#x26;= 0 \newline
\sum \frac{1}{\sigma_c^2} \left(x^{(i)} - \mu_c\right) &#x26;= 0 \ \biggr\rvert \text{Chain Rule} \newline
\sum \left(x^{(i)} - \mu_c\right) &#x26;= 0 \ \biggr\rvert \cdot \sigma_c^2 \newline
\sum x^{(i)} - \sum \mu_c &#x26;= 0 \newline
\sum x^{(i)} - M_c \mu_c &#x26;= 0 \ \biggr\rvert \text{ Since $\mu_c$ doesnâ€™t depend on $i$} \newline
\hat{\mu_c} &#x26;= \boxed{\frac{1}{M_c} \sum x^{(i)}}
\end{aligned}
\end{equation}
$$</p>
<p>Now, letâ€™s find $\sigma_c^2$.</p>
<p>$$
\begin{equation}
\begin{aligned}
\frac{\partial}{\partial \sigma_c^2} \sum \left[-\log(\sqrt{2 \pi \sigma_c^2}) -\frac{1}{2 \sigma_c^2} \left(x^{(i)} - \mu_c\right)^2\right] &#x26;= 0 \newline
\sum \frac{\partial}{\partial \sigma_c^2} \left[-\log(\sqrt{2 \pi \sigma_c^2}) -\frac{1}{2 \sigma_c^2} \left(x^{(i)} - \mu_c\right)^2\right] &#x26;= 0 \newline
\sum \frac{\partial}{\partial \sigma_c^2} \left[-\log(\left(2 \pi \sigma_c^2\right)^{1/2}) -\frac{1}{2 \sigma_c^2} \left(x^{(i)} - \mu_c\right)^2\right] &#x26;= 0 \ \biggr\rvert \sqrt{a} = a^{1/2} \newline
\sum \frac{\partial}{\partial \sigma_c^2} \left[-\frac{1}{2} \log(2 \pi \sigma_c^2) -\frac{1}{2 \sigma_c^2} \left(x^{(i)} - \mu_c\right)^2\right] &#x26;= 0 \ \biggr\rvert \log(a^b) = b \log(a) \newline
\sum \left[-\frac{1}{2} \frac{1}{2 \pi \sigma_c^2} \cdot 2 \pi + \frac{1}{2 \sigma_c^4} \left(x^{(i)} - \mu_c\right)^2\right] &#x26;= 0 \newline
\sum \left[-\frac{1}{2 \sigma_c^2} + \frac{1}{2 \sigma_c^4} \left(x^{(i)} - \mu_c\right)^2\right] &#x26;= 0 \newline
\sum \left[-1 + \frac{1}{\sigma_c^2} \left(x^{(i)} - \mu_c\right)^2\right] &#x26;= 0 \ \biggr\rvert \cdot 2\sigma_c^2 \newline
-M_c + \sum \frac{1}{\sigma_c^2} \left(x^{(i)} - \mu_c\right)^2 &#x26;= 0 \newline
\sum \frac{1}{\sigma_c^2} \left(x^{(i)} - \mu_c\right)^2 &#x26;= M_c \newline
\frac{1}{\sigma_c^2} \sum \left(x^{(i)} - \mu_c\right)^2 &#x26;= M_c \ \biggr\rvert \text{Since $\sigma_c^2$ doesnâ€™t depend on $i$} \newline
\hat{\sigma_c^2} &#x26;= \boxed{\frac{1}{M_c} \sum \left(x^{(i)} - \hat{\mu_c}\right)^2}
\end{aligned}
\end{equation}
$$</p>
<p>In our example from Figure 1, if we plot the Gaussian estimates, we get the following plot,</p>
<p><img src="/images/posts/rezvan_explains/iris_gaussian.svg" alt="">
<strong>Figure 2</strong>: Histogram of the petal length of all three species of iris flowers and their corresponding Gaussian estimates.</p>
<p>We can see that Figure 2 indeed captures these distributions quite nicely.</p>
<h6 id="bayes-optimal-classifier-summary">Bayes Optimal Classifier Summary</h6>
<p>Letâ€™s summarize what we have learned about Bayes Optimal Classifier and how we can use the Bayesian Decision Rule to classify new data points.</p>
<p>Given an observation $\mathbf{x}$, we want to pick the class $c$ with the <strong>highest posterior probability</strong> $p(y = c | \mathbf{x})$,</p>
<p>$$
\begin{equation}
f_B(\mathbf{x}) = \underset{c \in \mathbf{Y}}{\arg\max} \ p(y = c | \mathbf{x})
\end{equation}
$$</p>
<p>But in most real-world scenarios we donâ€™t have $p(y | \mathbf{x})$ or any reliable way to estimate it, we only $p(y)$ and $p(\mathbf{x} | y)$.</p>
<p>So by using Bayesâ€™ rule, the posterior probability can be expressed as,</p>
<p>$$
\begin{equation}
p(y = c | \mathbf{x}) = \frac{p(\mathbf{x} | y = c) \ p(y = c)}{p(\mathbf{x})}
\end{equation}
$$</p>
<p><img src="/images/posts/rezvan_explains/iris_probabilities.svg" alt="">
<strong>Figure 3:</strong> The class conditional densities and posterior probabilities for the Iris dataset.</p>
<p>We can see that we have a <strong>decision boundary</strong>, or where the posterior probabilities meet.
Weâ€™ll talk more about decision boundaries later.</p>
<p>So, in summary for the Bayes Optimal Classifier,</p>
<ul>
<li><strong>Training</strong>
<ul>
<li>Estimate the class conditional densities $p(x | y = c)$ <strong>for each class $c$</strong> using <strong>MLE</strong> where distribution is assumed to be <strong>Gaussian</strong>.</li>
<li>Estimate the prior probabilities $p(y = c)$ using <strong>MLE</strong>.</li>
</ul>
</li>
<li><strong>Classification</strong>
<ul>
<li>Given a new sample $\mathbf{x}^{\star}$, calculate the probability $p(\mathbf{x}^{\star} | y = c)$ for each class $c$.</li>
<li>Pick the class $c$ with the <strong>largest posterior probability</strong> p(y = c | $\mathbf{x}^{\star}$).
<ul>
<li>Equivalently use $p(\mathbf{x}^{\star} | y = c) p(y = c)$.</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>The Bayes Optimal Classifier is the best classifier in theory, but it is often not practical because it is hard estimating $p(\mathbf{x} | y = c)$.</p>
<h6 id="naive-bayes-classifier">Naive Bayes Classifier</h6>
<p><strong>Technically</strong>, the entire previous section is <strong>wrong in notation</strong>.
Iâ€™ve used $\mathbf{x}$ to denote the feature vector, but the method proposed is for a <strong>single feature</strong>.</p>
<p>If we have multiple features, the joint probability $p(\mathbf{x} | y = c)$ canâ€™t be modeled as a single Gaussian distribution.
So letâ€™s make a <strong>naive assumption</strong> that the features are <strong>statistically independent</strong> given the class label, e.g., in 2D,</p>
<p>$$
\begin{equation}
p(x_1, x_2 | y = c) = p(x_1 | y = c) p(x_2 | y = c)
\end{equation}
$$</p>
<p>The general form for classification is,</p>
<p>$$
\begin{equation}
f_{NB}(\mathbf{x}) = \underset{c}{\arg\max} \ p(y = c) \prod_{j=1}^{N} p(x_j | y = c),
\end{equation}
$$</p>
<p>where $N$ is the number of features.</p>
<p><strong>I will consider the 2D case for visualization and building your intuition</strong>, but everything we discuss can be generalized to $N$ dimensions.</p>
<p>The only difference from the previous section is that we now have parameters $(\mu_{j | c}, \sigma_{j | c}^2)$ instead of $(\mu_{c}, \sigma_{c}^2)$.</p>
<p><strong>TODO</strong></p>
<h6 id="linear-discriminant-analysis-lda">Linear Discriminant Analysis (LDA)</h6>
<p>So far we have only considered <strong>univariate Gaussian distributions</strong>.
Why not extend this to <strong>multivariate Gaussian distributions</strong>?</p>
<p>However, LDA makes one assumption, that the <strong>covariance matrix is the same for all classes</strong>,</p>
<p>$$
\begin{equation}
p(\mathbf{x} | y = c) = \frac{1}{|(2\pi)^N \Sigma|^{1/2}} \exp \left( -\frac{1}{2} (\mathbf{x} - \mu_c)^T \Sigma^{-1} (\mathbf{x} - \mu_c) \right),
\end{equation}
$$</p>
<p>where $\Sigma$ is the covariance matrix.</p>
<p>As with (Naive) Bayes Classifier, these parameters are learned from the data using MLE.</p>
<p>For now, letâ€™s focus on class conditional densities $p(\mathbf{x} | y = c)$.
Letâ€™s look at the log-likelihood function.</p>
<p>$$
\begin{aligned}
(\hat{\mu_c}, \hat{\Sigma}) &#x26; = \underset{\mu_c, \Sigma}{\arg\max} \log \left[\prod \frac{1}{(2\pi)^{N/2} |\Sigma|^{1/2}} \exp \left( -\frac{1}{2} (\mathbf{x}^{(i)} - \mu_c)^T \Sigma^{-1} (\mathbf{x}^{(i)} - \mu_c) \right) \right] \newline
&#x26; = \underset{\mu_c, \Sigma}{\arg\max} \sum \log \left[ \frac{1}{(2\pi)^{N/2} |\Sigma|^{1/2}} \exp \left( -\frac{1}{2} (\mathbf{x}^{(i)} - \mu_c)^T \Sigma^{-1} (\mathbf{x}^{(i)} - \mu_c) \right) \right] \newline
&#x26; = \underset{\mu_c, \Sigma}{\arg\max} \sum \left[ \log \left( \frac{1}{(2\pi)^{N/2} |\Sigma|^{1/2}} \right) + \log \left( \exp \left( -\frac{1}{2} (\mathbf{x}^{(i)} - \mu_c)^T \Sigma^{-1} (\mathbf{x}^{(i)} - \mu_c) \right) \right) \right] \ \biggr\rvert \log(ab) = \log(a) + \log(b) \newline
&#x26; = \underset{\mu_c, \Sigma}{\arg\max} \sum \left[ \underbrace{\log(1)}_0 - \log \left( (2\pi)^{N/2} |\Sigma|^{1/2} \right) + \log \left( \exp \left( -\frac{1}{2} (\mathbf{x}^{(i)} - \mu_c)^T \Sigma^{-1} (\mathbf{x}^{(i)} - \mu_c) \right) \right) \right] \ \biggr\rvert \log(a/b) = \log(a) - \log(b) \newline
&#x26; = \underset{\mu_c, \Sigma}{\arg\max} \sum \left[ -\log \left( (2\pi)^{N/2} |\Sigma|^{1/2} \right) - \frac{1}{2} (\mathbf{x}^{(i)} - \mu_c)^T \Sigma^{-1} (\mathbf{x}^{(i)} - \mu_c) \right] \ \biggr\rvert \log(e^a) = a \newline
&#x26; = \underset{\mu_c, \Sigma}{\arg\max} \sum \left[ -\left(\log\left((2\pi)^{N/2}\right) + \log\left(|\Sigma|^{1/2}\right) \right) - \frac{1}{2} (\mathbf{x}^{(i)} - \mu_c)^T \Sigma^{-1} (\mathbf{x}^{(i)} - \mu_c) \right] \ \biggr\rvert \log(ab) = \log(a) + \log(b) \newline
&#x26; = \underset{\mu_c, \Sigma}{\arg\max} \sum \left[ -\frac{N}{2} \log(2\pi) - \frac{1}{2} \log\left(|\Sigma|\right) - \frac{1}{2} (\mathbf{x}^{(i)} - \mu_c)^T \Sigma^{-1} (\mathbf{x}^{(i)} - \mu_c) \right] \ \biggr\rvert \log(a^b) = b \log(a) \newline
\end{aligned}
$$</p>
<p>Then to find the MLE estimates, we differentiate the log-likelihood function with respect to $\mu_c$ and $\Sigma$ and set them to zero.</p>
<p>Letâ€™s start with $\mu_c$.</p>
<p>$$
\begin{aligned}
\frac{\partial}{\partial \mu_c} \sum \left[ -\frac{N}{2} \log(2\pi) - \frac{1}{2} \log\left(|\Sigma|\right) - \frac{1}{2} (\mathbf{x}^{(i)} - \mu_c)^T \Sigma^{-1} (\mathbf{x}^{(i)} - \mu_c) \right] &#x26; = 0 \newline
\sum \frac{\partial}{\partial \mu_c} \left[ \underbrace{-\frac{N}{2} \log(2\pi)}_0 - \underbrace{\frac{1}{2} \log\left(|\Sigma|\right)}_0 - \frac{1}{2} (\mathbf{x}^{(i)} - \mu_c)^T \Sigma^{-1} (\mathbf{x}^{(i)} - \mu_c) \right] &#x26; = 0 \newline
\sum \frac{\partial}{\partial \mu_c} \left[ -\frac{1}{2} (\mathbf{x}^{(i)} - \mu_c)^T \Sigma^{-1} (\mathbf{x}^{(i)} - \mu_c) \right] &#x26; = 0.
\end{aligned}
$$</p>
<p>Now we need to use the identity $\frac{\partial}{\partial \mathbf{v}} \mathbf{v}^T A \mathbf{v} = 2 A \mathbf{v}$, by letting $\mathbf{v} = \mathbf{x}^{(i)} - \mu_c$ and using the chain rule â€” where the inner product is just $-\mathbf{I}$, we get,</p>
<p>$$
\begin{aligned}
\sum \frac{\partial}{\partial \mu_c} \left[ -\frac{1}{2} (\mathbf{x}^{(i)} - \mu_c)^T \Sigma^{-1} (\mathbf{x}^{(i)} - \mu_c) \right] &#x26; = 0 \newline
\sum \frac{1}{2} 2 \Sigma^{-1} (\mathbf{x}^{(i)} - \mu_c) &#x26; = 0 \newline
\sum \Sigma^{-1} (\mathbf{x}^{(i)} - \mu_c) &#x26; = 0 \newline
\Sigma^{-1} \sum (\mathbf{x}^{(i)} - \mu_c) &#x26; = 0 \newline
\sum (\mathbf{x}^{(i)} - \mu_c) &#x26; = 0 \ \biggr\rvert \Sigma^{-1} \text{ is invertible} \newline
\sum \mathbf{x}^{(i)} - M_c \mu_c &#x26; = 0 \ \biggr\rvert \text{doesnâ€™t depend on sum} \newline
\hat{\mu_c} &#x26; = \boxed{\frac{1}{M_c} \sum \mathbf{x}^{(i)}}.
\end{aligned}
$$</p>
<p>The mean MLE is the same as the MLE for the univariate Gaussian distribution.</p>
<p>Now for the covariance matrix $\Sigma$.</p>
<p>$$
\begin{aligned}
\frac{\partial}{\partial \Sigma} \sum \left[ -\frac{N}{2} \log(2\pi) - \frac{1}{2} \log\left(|\Sigma|\right) - \frac{1}{2} (\mathbf{x}^{(i)} - \mu_c)^T \Sigma^{-1} (\mathbf{x}^{(i)} - \mu_c) \right] &#x26; = 0 \newline
\sum \frac{\partial}{\partial \Sigma} \left[ \underbrace{-\frac{N}{2} \log(2\pi)}_0 - \frac{1}{2} \log\left(|\Sigma|\right) - \frac{1}{2} (\mathbf{x}^{(i)} - \mu_c)^T \Sigma^{-1} (\mathbf{x}^{(i)} - \mu_c) \right] &#x26; = 0,
\end{aligned}
$$</p>
<p>From here we need to use two identities â€” $\frac{\partial}{\partial A} \log|A| = (A^{-1})^T$ and $\frac{\partial}{\partial A} \mathbf{a}^T A^{-1} \mathbf{b} = -A^{-T} \mathbf{a} \mathbf{b}^T A^{-T}$ â€” where the former holds if $A$ is symmetric.</p>
<p>Thus,
$$
\begin{aligned}
\sum \frac{\partial}{\partial \Sigma} \left[ -\frac{1}{2} \log\left(|\Sigma|\right) - \frac{1}{2} (\mathbf{x}^{(i)} - \mu_c)^T \Sigma^{-1} (\mathbf{x}^{(i)} - \mu_c) \right] &#x26; = 0 \newline
\sum -\frac{1}{2} \Sigma^{-1} + \frac{1}{2} \Sigma^{-1} (\mathbf{x}^{(i)} - \mu_c) (\mathbf{x}^{(i)} - \mu_c)^T \Sigma^{-1} &#x26; = 0 \newline
\sum -\Sigma^{-1} + \Sigma^{-1} (\mathbf{x}^{(i)} - \mu_c) (\mathbf{x}^{(i)} - \mu_c)^T \Sigma^{-1} &#x26; = 0 \ \biggr\rvert \cdot 2 \newline
\sum \Sigma^{-1} \left(-\mathbf{I} + (\mathbf{x}^{(i)} - \mu_c) (\mathbf{x}^{(i)} - \mu_c)^T \Sigma^{-1}\right) &#x26; = 0 \ \biggr\rvert \textbf{left } \text{factorize } \Sigma^{-1} \newline
\Sigma^{-1} \sum \left(-\mathbf{I} + (\mathbf{x}^{(i)} - \mu_c) (\mathbf{x}^{(i)} - \mu_c)^T \Sigma^{-1}\right) &#x26; = 0 \ \biggr\rvert \text{doesnâ€™t depend on sum} \newline
\sum \left(-\mathbf{I} + (\mathbf{x}^{(i)} - \mu_c) (\mathbf{x}^{(i)} - \mu_c)^T \Sigma^{-1}\right) &#x26; = 0 \ \biggr\rvert \Sigma^{-1} \text{ is invertible} \newline
-M_c \mathbf{I} + \sum (\mathbf{x}^{(i)} - \mu_c) (\mathbf{x}^{(i)} - \mu_c)^T \Sigma^{-1} &#x26; = 0 \ \biggr\rvert \mathbf{I} \text{ doesnâ€™t depend on sum} \newline
\sum (\mathbf{x}^{(i)} - \mu_c) (\mathbf{x}^{(i)} - \mu_c)^T \Sigma^{-1} &#x26; = M_c \mathbf{I} \newline
\sum (\mathbf{x}^{(i)} - \mu_c) (\mathbf{x}^{(i)} - \mu_c)^T \Sigma^{-1} \Sigma &#x26; = M_c \mathbf{I} \Sigma \ \biggr\rvert \textbf{right } \text{multiply by } \Sigma \newline
\sum (\mathbf{x}^{(i)} - \mu_c) (\mathbf{x}^{(i)} - \mu_c)^T &#x26; = M_c \Sigma \newline
\Sigma &#x26; = \boxed{\frac{1}{M_c} \sum (\mathbf{x}^{(i)} - \mu_c) (\mathbf{x}^{(i)} - \mu_c)^T}.
\end{aligned}
$$</p>
<h5 id="summary-generative-models">Summary Generative Models</h5>
<p><strong>TODO</strong></p>
<p>I want to emphasize that weâ€™ve taken a more <strong>frequentist approach (MLE)</strong> to the problem, but <strong>one can also take a Bayesian approach</strong> <sup><a href="#user-content-fn-7" id="user-content-fnref-7" data-footnote-ref="" aria-describedby="footnote-label">7</a></sup>.</p>
<h5 id="discriminative-models">Discriminative Models</h5>
<p>Weâ€™ve seen that generative models model the joint distribution $p(\mathbf{x}, y)$ â€” more specifically the class-conditional densities $p(\mathbf{x} | y)$ and the prior probabilities $p(y)$ â€” and then use Bayesâ€™ rule to calculate the posterior probabilities $p(y | \mathbf{x})$.</p>
<p>But density estimation is hard and an ill-posed problem (to some extent), letâ€™s take a <strong>discriminative</strong> approach instead, letâ€™s solve for $p(y | \mathbf{x})$ directly.</p>
<h6 id="logistic-regression">Logistic Regression</h6>
<p>Letâ€™s start with the simplest classifier, a <strong>binary linear classifier</strong> from a logistic regression perspective.</p>
<p>So we have the setup that our observation/feature vector $\mathbf{x} \in \mathbb{R}^N$, and we want to predict our class label $y \in \{-1, +1\}$.
<strong>Note</strong>, one can use a zero-indexed class label but using $-1$ and $+1$ yields a nice property that we will see later on.</p>
<p>Our <strong>goal</strong> is to have a linear function depends on $\mathbf{x}$ that,</p>
<p>$$
\begin{equation}
f(\mathbf{x}) = \mathbf{w}^T \mathbf{x} + b = \sum_{j = 1}^N w_j x_j + b,
\end{equation}
$$</p>
<p>where $\mathbf{w} \in \mathbb{R}^N$ is the weight vector used to multiply each feature value and then sum.</p>
<p>From this we decide on a decision rule that is, <strong>if $f(\mathbf{x})$ then predict class $y = 1$</strong>, if $f(\mathbf{x}) &#x3C; 0$ then predict class $y = - 1$.
Equivalently, the decision rule is, $y = \text{sign}(f(\mathbf{x}))$.</p>
<p>This is why we have $-1$ and $+1$ as class labels.</p>
<p>Our linear classifier will separate the feature space into 2 half-spaces</p>
<p><img src="/images/posts/rezvan_explains/linear_halfspace.svg" alt="">
<strong>Figure 4:</strong> Linear Halfspace Example</p>
<p>In a $N$-dimensional feature space $\mathbf{x} \in \mathbb{R}^N$ our parameters are $\mathbf{w} \in \mathbb{R}^N$.</p>
<p>Our equation â€” $\mathbf{w}^T \mathbf{x} + b = 0$ defines an $N - 1$-dimensional (linear) surface.
In general, we call this the <strong>hyperplane</strong>.</p>
<p>But how do we find the parameters $(\mathbf{w}, b)$?</p>
<p>Logistic regression takes a <strong>probabilistic</strong> approach to classification.
But thereâ€™s a problem, to take a probabilistic approach we need a function to map the value of $f(\mathbf{x}) = \mathbf{w}^T \mathbf{x} + b$ to a probability value (between 0 and 1).</p>
<p><img src="/images/posts/rezvan_explains/sigmoid.svg" alt="">
<strong>Figure 5:</strong> Sigmoid function</p>
<p>Luckily, the <strong>sigmoid function</strong> maps any real-value to $[0, 1]$. It is defined as,</p>
<p>$$
\begin{equation}
\sigma(z) = \frac{1}{1 + e^{-z}}, \quad z \in \mathbb{R}
\end{equation}
$$</p>
<p><strong>Exercise</strong>:
What is the derivative of the sigmoid function?</p>
<details>
<summary><b>Answer</b></summary>
<blockquote>
$$
\begin{equation}
\begin{aligned}
\sigma(z) &#x26;= \frac{1}{1 + e^{-z}} \newline
\frac{d}{dz} \sigma(z) &#x26;= \frac{d}{dz} \left(1 + e^{-z}\right)^{-1} \newline
&#x26;= -1 \cdot \left(1 + e^{-z}\right)^{-2} \cdot -e^{-z} \biggr\rvert \text{ Chain rule} \newline
&#x26;= \frac{e^{-z}}{\left(1 + e^{-z}\right)^2} \newline
&#x26;= \frac{1}{1 + e^{-z}} \cdot \frac{e^{-z}}{1 + e^{-z}} \newline
&#x26;= \sigma(z) \cdot \left(1 - \sigma(z)\right)
\end{aligned}
\end{equation}
$$
</blockquote>
</details>
<p>Thus, given a feature vector $\mathbf{x}$ the probability of the classes are,</p>
<p>$$
\begin{equation}
\begin{aligned}
p(y = +1 | \mathbf{x}) &#x26;= \sigma(f(\mathbf{x})) \newline
p(y = -1 | \mathbf{x}) &#x26;= 1 - \sigma(f(\mathbf{x})) = \sigma(-f(\mathbf{x}))
\end{aligned}
\end{equation}
$$</p>
<p>Equivalently, we can write this as,</p>
<p>$$
\begin{equation}
p(y | \mathbf{x}) = \sigma(yf(\mathbf{x}))
\end{equation}
$$</p>
<p><strong>Exercise</strong>:
Can you prove that $1 - \sigma(z) = \sigma(-z)$?</p>
<details>
<summary><b>Proof</b></summary>
<blockquote>
$$
\begin{equation}
\begin{aligned}
1 - \sigma(z) &#x26;= 1 - \frac{1}{1 + e^{-z}} \ \biggr\rvert \cdot 1 + e^{-z} \newline
&#x26;= \frac{1 + e^{-z} - 1}{1 + e^{-z}} \newline
&#x26;= \frac{e^{-z}}{1 + e^{-z}} \ \biggr\rvert \cdot \frac{1}{e^{-z}} \newline
&#x26;= \frac{1}{1 + e^{z}} \newline
&#x26;= \sigma(-z)
\end{aligned}
\end{equation}
$$
</blockquote>
</details>
<p>Thus, we are <strong>directly modeling the class posterior probability</strong> $p(y | \mathbf{x})$.</p>
<p>Just like Naive Bayes and LDA we learn the parameters from the data.</p>
<p>By maximizing the (log) likelihood,</p>
<p>$$
\begin{equation}
\begin{aligned}
(\mathbf{w}^{\star}, b^{\star}) &#x26;= \underset{\mathbf{w}, b}{\arg\max} \prod_{i=1}^{N} p(y^{(i)} | \mathbf{x}^{(i)}; \mathbf{w}, b) \newline
&#x26; = \underset{\mathbf{w}, b}{\arg\max} \prod_{i=1}^{N} \sigma\left(y^{(i)}(\mathbf{w}^T \mathbf{x}^{(i)} + b)\right) \newline
&#x26; = \underset{\mathbf{w}, b}{\arg\max} \sum_{i=1}^{N} \log \sigma\left(y^{(i)}(\mathbf{w}^T \mathbf{x}^{(i)} + b)\right) \ \biggr\rvert \log(\cdot) \newline
\end{aligned}
\end{equation}
$$</p>
<p><strong>However</strong>, this does not have a closed-form solution like our previous models.
For now, we will leave it at this, but we will come back and see how we eventually can solve for these parameters.</p>
<h6 id="support-vector-machines-svms">Support Vector Machines (SVMs)</h6>
<p>So far weâ€™ve only looked at <strong>probabilistic models</strong>, they all use the same probabilistic framework (MLE) to learn how to classify the data.</p>
<p>But when you think about it, a <strong>purely geometric approach</strong> to classification should be possible and easy to understand.
This is what the <strong>Support Vector Machine (SVM)</strong> does, a <strong>purely geometric approach</strong> to classification.</p>
<p>For now, letâ€™s assume that our data is <strong>linearly separable</strong>.</p>
<p><img src="/images/posts/rezvan_explains/iris_linear_separation.svg" alt="">
<strong>Figure 6:</strong> Linearly separable data</p>
<p>If our data is linearly separable, we will have many possible solutions for a hyperplane.
We need somekind of <strong>criterion</strong> to choose the best hyperplane.</p>
<h6 id="maximum-margin-principle">Maximum Margin Principle</h6>
<p>Let us define a naive criterion, the <strong>maximum margin principle</strong>.</p>
<p><img src="/images/posts/rezvan_explains/margin_principle.svg" alt="">
<strong>Figure 7:</strong> Maximum margin principle</p>
<p>We define the <strong>distance between the separating line and the closest point</strong> as the <strong>margin</strong>.
Intuitively, we think of this space as the amount of â€œwiggle roomâ€ for any potential errors in estimating $\mathbf{w}$.</p>
<p>Thus, we say that the <strong>best line is the one that maximizes the margin</strong> (i.e., has the most distance between the closest point(s) and the hyperplane).</p>
<p>By symmetry, there <strong>should be at least one margin point on each side of the hyperplane</strong> (assuming the data is linearly separable).</p>
<p>These points on the margin(s) are called the <strong>support vectors</strong> (these points define the margin).</p>
<h6 id="computing-the-margin">Computing the Margin</h6>
<p>How do we compute the margin from $\mathbf{w}^T \mathbf{x} + b = 0$ to a point $(\mathbf{x}^{(i)}, y^{(i)})$?</p>
<p>We compute the <strong>geometric distance</strong> from the point to the hyperplane,</p>
<p>$$
\begin{equation}
d^{(i)} = \frac{y^{(i)}(\mathbf{w}^T \mathbf{x}^{(i)} + b)}{\Vert \mathbf{w} \Vert_2}
\end{equation}
$$</p>
<p>Then we simply compute this distance and take the minimum of all the distances,</p>
<p>$$
\begin{equation}
d = \min \{d^{(i)}\}_{i=1}^{M} = \underset{(\mathbf{x}, y) \in \mathcal{D}}{\min} \frac{y(\mathbf{w}^T \mathbf{x} + b)}{\Vert \mathbf{w} \Vert_2}
\end{equation}
$$</p>
<p>Thus, the maximum margin is found by solving,</p>
<p>$$
\begin{equation}
\begin{aligned}
\underset{\mathbf{w}, b}{\max} \left(\underset{(\mathbf{x}, y) \in \mathcal{D}}{\min} \frac{y(\mathbf{w}^T \mathbf{x} + b)}{\Vert \mathbf{w} \Vert_2}\right) \newline
\underset{\mathbf{w}, b}{\max} \left(\frac{1}{\Vert \mathbf{w} \Vert_2} \underset{(\mathbf{x}, y) \in \mathcal{D}}{\min} y(\mathbf{w}^T \mathbf{x} + b)\right) \newline
\end{aligned}
\end{equation}
$$</p>
<p><strong>Exercise</strong>:
If we rescale $(\mathbf{w}, b)$ does our objective function change?</p>
<details>
<summary><b>Answer</b></summary>
<blockquote>
No, even if we rescale $\mathbf{w} \to \gamma \mathbf{w}$ and $b \to \gamma b$ the objective function remains the same.
</blockquote>
</details>
<h6 id="why-is-maximize-the-margin-a-good-idea">Why is Maximize the Margin a Good Idea?</h6>
<p>Letâ€™s take a step back and think about why maximizing the margin is a good idea.</p>
<p>Firstly, the <strong>true $\mathbf{w}$ is uncertain</strong> (we only have a finite amount of data), maximizing the margin allows the most uncertainty (wiggle room) for $\mathbf{w}$, while keeping all the points on the correct side of the hyperplane.
Also, the <strong>data is uncertain</strong>, maximizing the margin allows the most uncertainty (wiggle room) for the data, while keeping all the points on the correct side of the hyperplane.</p>
<p>Thus, maximizing the margin is a good idea because it allows the most uncertainty for both the data and the true $\mathbf{w}$.</p>
<h6 id="soft-margin">Soft-Margin</h6>
<p>So far we have assumed that the data is <strong>completely linearly separable</strong>, but this is rarely the case in practice.</p>
<p><img src="/images/posts/rezvan_explains/soft_margin_principle.svg" alt="">
<strong>Figure 8:</strong> Soft-margin</p>
<p>Letâ€™s now imagine that the data is <em>almost</em> linearly separable, but there are a few points that are on the wrong side of the hyperplane.</p>
<p>How should we proceed? We allow <em>some</em> samples to <strong>violate the margin</strong>.</p>
<p>We define the <strong>slack variable</strong> $\xi_i \geq 0$ for each sample $(\mathbf{x}^{(i)}, y^{(i)})$, where $\xi_i = 0$ means that our sample is outside of margin area (no slack) and $\xi_i > 0$ means our sample is inside the margin area (slack).</p>
<h6 id="convex-optimization">(Convex) Optimization</h6>
<p>Before we continue, we need to take a detour and talk about <strong>(convex) optimization</strong>.</p>
<p>A lot of machine learning problems can not be solved analytically and we need to rely on numerical optimization methods to solve them.</p>
<p>But what does this mean? Much of machine learning can be written as an optimization problem,</p>
<p>$$
\begin{equation}
\underset{\mathbf{\theta}}{\min} \ \ell(\mathcal{D}; \mathbf{\theta}) = \underset{\mathbf{\theta}}{\min} \frac{1}{M} \sum_{i = 1}^M \ell(\mathbf{x}^{(i)}, y^{(i)}; \mathbf{\theta})
\end{equation}
$$</p>
<p>where $\mathbf{\theta}$ is our parameter vector to be optimized, $\ell(\cdot)$ is our <strong>loss function</strong>, and $\mathcal{D}$ is our dataset.</p>
<p><strong>Exercise</strong>:
What is the loss function for logistic regression?</p>
<details>
<summary><b>Answer</b></summary>
<blockquote>
$$
\begin{aligned}
\ell(\mathbf{x}^{(i)}, y^{(i)}; \mathbf{w}, b) &#x26; = \log \sigma(y^{(i)}(\mathbf{w}^T \mathbf{x}^{(i)} + b)) \newline
&#x26; = \log \left(\frac{1}{1 + \exp(-y^{(i)}(\mathbf{w}^T \mathbf{x}^{(i)} + b))}\right) \newline
&#x26; = \log(1) - \log(1 + \exp(-y^{(i)}(\mathbf{w}^T \mathbf{x}^{(i)} + b))) \biggr\rvert \log(a/b) = \log(a) - \log(b) \newline
&#x26; = -\log(1 + \exp(-y^{(i)}(\mathbf{w}^T \mathbf{x}^{(i)} + b))) \biggr\rvert \log(1) = 0 \newline
\end{aligned}
$$
</blockquote>
</details>
<p>When solving optimization problems, it is important to know which <em>type</em> of problem we have.</p>
<p><strong>Convex</strong> optimization is the easy case <strong>since we can guarantee to find the optimal solution</strong> (we will prove this later).
<strong>Non-convex</strong> optimization is the hard case <strong>since we can not guarantee to find the optimal solution</strong>.</p>
<p>Understanding (convex) optimization is a huge part of (modern) machine learning.
But I feel like there a lot of good sources on these â€¦ so I will give the brief introduction and explanation, if it is not sufficient find a good source and read about it.</p>
<p>To understand convex optimization, we first need to understand what a <strong>convex set</strong> is.</p>
<p>Recall that a <strong>line segment</strong> between two points $\mathbf{x}^{(1)}$ and $\mathbf{x}^{(2)}$ is defined as,</p>
<p>$$
\begin{equation}
\mathbf{x} = \alpha \mathbf{x}^{(1)} + (1 - \alpha) \mathbf{x}^{(2)}, \quad 0 \leq \alpha \leq 1.
\end{equation}
$$</p>
<p>A <strong>convex set</strong> is a set which contains all line segments between any two points in the set,</p>
<p>$$
\begin{equation}
\mathbf{x}^{(1)}, \mathbf{x}^{(2)} \in \chi, 0 \leq \alpha \leq 1 \Rightarrow \mathbf{x} = \alpha \mathbf{x}^{(1)} + (1 - \alpha) \mathbf{x}^{(2)} \in \chi,
\end{equation}
$$</p>
<p>where $\chi$ is our convex set.</p>
<p><img src="/images/posts/rezvan_explains/convex_sets.svg" alt="">
<strong>Figure 9:</strong> Convex set and line segment.</p>
<p>A function, $f : \mathbb{R}^N \mapsto \mathbb{R}$ is <strong>convex</strong> if $\text{dom}(f)$ is a <em>convex set</em> <strong>and</strong>,</p>
<p>$$
\begin{equation}
f(\alpha \mathbf{x}^{(1)} + (1 - \alpha) \mathbf{x}^{(2)}) \leq \alpha f(\mathbf{x}^{(1)}) + (1 - \alpha) f(\mathbf{x}^{(2)})
\end{equation}
$$</p>
<p><img src="/images/posts/rezvan_explains/convex_functions.svg" alt="">
<strong>Figure 10:</strong> Convex function.</p>
<p>The most simple way one can understand convex functions is, <strong>any line segment between two points lies above the curve</strong>.</p>
<p>As we mentioned earlier, we can guarantee to find the optimal solution for convex optimization problems.
Letâ€™s prove this now, I will use a proof of contradiction.</p>
<blockquote>
<p>Suppose $x$ is a local optimum and $y$ is a global optimum with $f(y) &#x3C; f(x)$.
The local optimum $x$ implies that there is a radius $R > 0$Â such that,
$$
z \in \text{dom}(f), \Vert z - x \Vert_2 \leq R \Rightarrow f(x) \leq f(z).
$$
Now consider $z = \theta y + (1 - \theta)x$ with $\theta = \frac{R}{2 \Vert y - x \Vert_2}$.
First, we note that $\Vert y - x \Vert_2 > R$, due to our assumptions.
Therefore, we have $0 \leq \theta \leq \frac{1}{2}$, which implies that $z$ is a convex combination of $x$ and $y$ and is in the domain of $f$.
Note also that,
$$
\Vert z - x \Vert_2 = \Vert \theta y + (1 - \theta)x - x \Vert_2 = \Vert \theta (y - x) \Vert_2 = \theta \Vert y - x \Vert_2 = \frac{R}{2},
$$
which implies that $f(x) \leq f(z)$.
As $f$ is convex, we have,
$$
f(z) = f(\theta y + (1 - \theta)x) \leq \theta f(y) + (1 - \theta) f(x) &#x3C; \theta f(x) + (1 - \theta) f(x) = f(x),
$$
which is a contradiction, thus any local optimum must be a global optimum.</p>
</blockquote>
<h6 id="standard-form-of-convex-optimization">Standard Form of Convex Optimization</h6>
<p>Convex optimization problems can be written in the following standard form,</p>
<p>$$
\begin{equation}
\begin{aligned}
\underset{\mathbf{x}}{\min} &#x26; \quad f_0(\mathbf{x}) \newline
\text{subject to} &#x26; \quad f_i(\mathbf{x}) \leq 0, \quad i = 1, \ldots, r \newline
&#x26; \quad h_i(\mathbf{x}) = 0, \quad i = 1, \ldots, s
\end{aligned}
\end{equation}
$$</p>
<p>The optimal value is,</p>
<p>$$
\begin{equation}
p^{\star} = \min\{f_0(\mathbf{x}) | f_i(\mathbf{x}) \leq 0, i = 1, \ldots, r, h_i(\mathbf{x}) = 0, i = 1, \ldots,s \}
\end{equation}
$$</p>
<h6 id="duality-and-kkt-conditions">Duality and KKT Conditions</h6>
<p>But, how do we solve these optimization problems?</p>
<p>Letâ€™s first introduce the <strong>Lagrangian</strong> <sup><a href="#user-content-fn-8" id="user-content-fnref-8" data-footnote-ref="" aria-describedby="footnote-label">8</a></sup>.</p>
<p>We have our standard form optimization problem (not necessarily convex),</p>
<p>$$
\begin{equation}
\begin{aligned}
\underset{\mathbf{x}}{\min} &#x26; \quad f_0(\mathbf{x}) \newline
\text{subject to} &#x26; \quad f_i(\mathbf{x}) \leq 0, \quad i = 1, \ldots, r \newline
&#x26; \quad h_i(\mathbf{x}) = 0, \quad i = 1, \ldots, s
\end{aligned}
\end{equation}
$$</p>
<p>With our variable $\mathbf{x} \in \mathbb{R}^N$ and its domain $\chi$ and the optimal value $p^{\star}$.</p>
<p>The <strong>Lagrangian</strong> is defined as,</p>
<p>$$
\begin{equation}
L(\mathbf{x}, \mathbf{\lambda}, \mathbf{\nu}) = f_0(\mathbf{x}) + \sum_{i=1}^{r} \lambda_i f_i(\mathbf{x}) + \sum_{i=1}^{s} \nu_i h_i(\mathbf{x}).
\end{equation}
$$</p>
<p>The domain $\text{dom}(L) = \chi \times \mathbb{R}^r \times \mathbb{R}^s$.
The lagrangian is a weighted sum of the objective function and the constraints.
The coefficients $\lambda_i$ and $\nu_i$ are called the <strong>Lagrange multipliers</strong>.</p>
<p>The <strong>lagrangian dual function</strong> $g : \mathbb{R}^r \times \mathbb{R}^s \mapsto \mathbb{R}$ is defined as,</p>
<p>$$
\begin{equation}
g(\mathbf{\lambda}, \mathbf{\nu}) = \underset{\mathbf{x} \in \chi}{\inf} \ L(\mathbf{x}, \mathbf{\lambda}, \mathbf{\nu}).
\end{equation}
$$</p>
<p>With this we can prove the <strong>lower bound property</strong>,</p>
<blockquote>
<p>If $\mathbf{\lambda} \geq 0$, then $g(\mathbf{\lambda}, \mathbf{\nu}) \leq p^{\star}$.
<strong>Proof</strong>: If $\tilde{x}$ is feasible and $\mathbf{\lambda} \geq 0$, then,
$$
f_0(\tilde{x}) \geq L(\tilde{x}, \mathbf{\lambda}, \mathbf{\nu}) \geq \underset{\mathbf{x} \in \chi}{\inf} L(\mathbf{x}, \mathbf{\lambda}, \mathbf{\nu}) = g(\mathbf{\lambda}, \mathbf{\nu}).
$$
Minimizing over all feasible $\tilde{x}$ gives $p^{\star} \geq g(\mathbf{\lambda}, \mathbf{\nu})$.</p>
</blockquote>
<p><strong>Exercise</strong>:
What is the lower-bound for the following optimization problem?</p>
<p>$$
\begin{equation}
\begin{aligned}
\underset{\mathbf{x}}{\min} &#x26; \quad \mathbf{x}^T \mathbf{x} \newline
\text{subject to} &#x26; \quad \mathbf{A} \mathbf{x} = \mathbf{b}
\end{aligned}
\end{equation}
$$</p>
<details>
<summary><b>Answer</b></summary>
<blockquote>
Firstly, rewrite it to standard form,
<p>$$
\begin{equation}
\begin{aligned}
\underset{\mathbf{x}}{\min} &#x26; \quad \mathbf{x}^T \mathbf{x} \newline
\text{subject to} &#x26; \quad \mathbf{A} \mathbf{x} - \mathbf{b} = 0
\end{aligned}
\end{equation}
$$</p>
<p>Formulate the Lagrangian $L(\mathbf{x}, \mathbf{\nu}) = \mathbf{x}^T \mathbf{x} + \mathbf{\nu}^T (\mathbf{A} \mathbf{x} - \mathbf{b})$
We take gradient of the Lagrangian and set it equal to zero to, $\nabla_{\mathbf{x}} L(\mathbf{x}, \mathbf{\nu}) = 2 \mathbf{x} + \mathbf{A}^T \mathbf{\nu} = 0$.
Solve for $\mathbf{x}$ to get $\mathbf{x} = -\frac{1}{2} \mathbf{A}^T \mathbf{\nu}$.</p>
<p>Substitute this into the dual function to get $g(\mathbf{\nu}) = -\frac{1}{4} \mathbf{\nu}^T \mathbf{A} \mathbf{A}^T \mathbf{\nu} - \mathbf{b}^T \mathbf{\nu}$.
Thus, this is the lower bound for all $\mathbf{\nu}$.</p>
</blockquote>
</details>
<p>Notice how our original problem â€” which we will call the <strong>primal problem</strong> â€” is a minimization problem, while the dual problem is a maximization problem,</p>
<p>$$
\begin{equation}
\begin{aligned}
\underset{\mathbf{\lambda}, \mathbf{\nu}}{\max} &#x26; \quad g(\mathbf{\lambda}, \mathbf{\nu}) \newline
\text{subject to} &#x26; \quad \mathbf{\lambda} \succeq 0
\end{aligned}
\end{equation}
$$</p>
<p>$\mathbf{\lambda}, \mathbf{\nu}$ are (dual) feasible if $\mathbf{\lambda} \succeq 0$ (here $\succeq 0$ means that every $\lambda_i \geq 0$) and $(\mathbf{\lambda}, \mathbf{\nu}) \in \text{dom}(g)$.</p>
<p><strong>The dual problem is always a convex optimization problem, and the optimal value of the dual problem is always a lower bound on the optimal value of the primal problem</strong>.
Yes everything above is in bold because it is important. Really take time to understand why this is important (and powerful).</p>
<p>We denote the optimal value of the dual problem as $d^{\star}$.
We say that we have <strong>weak duality</strong> if $d^{\star} \leq p^{\star}$. This <strong>always holds</strong>, both for convex and non-convex problems.</p>
<p>The interesting case is <strong>strong duality</strong>, or $d^{\star} = p^{\star}$, this usually does not hold in general but <em>usually</em> holds for convex problems (e.g., SVMs, which we will derive later).</p>
<p>Assume that strong duality holds such that $\mathbf{x}^{\star}$ is primal optimal and $(\mathbf{\lambda}^{\star}, \mathbf{\nu}^{\star})$ is dual optimal, then,</p>
<p>$$
\begin{equation}
\begin{aligned}
f(\mathbf{x}^{\star}) = g(\mathbf{\lambda}^{\star}, \mathbf{\nu}^{\star}) &#x26; = \underset{\mathbf{x} \in \chi}{\inf} \left(f_0(\mathbf{x}) + \sum_{i=1}^{r} \lambda_i^{\star} f_i(\mathbf{x}) + \sum_{i=1}^{s} \nu_i^{\star} h_i(\mathbf{x})\right) \newline
&#x26; \leq f_0(\mathbf{x}^{\star}) + \sum_{i=1}^{r} \lambda_i^{\star} f_i(\mathbf{x}^{\star}) + \sum_{i=1}^{s} \nu_i^{\star} h_i(\mathbf{x}^{\star}) \newline
\end{aligned}
\end{equation}
$$</p>
<p>If we let $\lambda_i^{\star} f_i(\mathbf{x}^{\star}) = 0$ for $i = 1, \ldots, r$ â€” which we will call <strong>complementary slackness</strong>) â€” then we have,</p>
<p>$$
\begin{equation}
\begin{aligned}
f(\mathbf{x}^{\star}) = g(\mathbf{\lambda}^{\star}, \mathbf{\nu}^{\star}) &#x26; = \underset{\mathbf{x} \in \chi}{\inf} \left(f_0(\mathbf{x}) + \sum_{i=1}^{r} \lambda_i^{\star} f_i(\mathbf{x}) + \sum_{i=1}^{s} \nu_i^{\star} h_i(\mathbf{x})\right) \newline
&#x26; \leq f_0(\mathbf{x}^{\star}) + \sum_{i=1}^{r} \lambda_i^{\star} f_i(\mathbf{x}^{\star}) + \sum_{i=1}^{s} \nu_i^{\star} h_i(\mathbf{x}^{\star}) \newline
&#x26; \leq f_0(\mathbf{x}^{\star})
\end{aligned}
\end{equation}
$$</p>
<p><strong>The two inequalities hold with equality</strong>. <strong>$\mathbf{x}^{\star}$ not only minimizes $f_0(\mathbf{x})$, but also minimizes $L(\mathbf{x}, \mathbf{\lambda}^{\star}, \mathbf{\nu}^{\star})$.</strong></p>
<p>Weâ€™ve <strong>finally</strong> covered the four KKT (Karush-Kuhn-Tucker) conditions!</p>
<ol>
<li><strong>Primal constraints</strong>: $f_i(\mathbf{x}^{\star}) \leq 0$ for $i = 1, \ldots, r, h_i(\mathbf{x}^{\star}) = 0$ for $i = 1, \ldots, s$.</li>
<li><strong>Dual constraints</strong>: $\mathbf{\lambda}^{\star} \succeq 0$.</li>
<li><strong>Complementary slackness</strong>: $\lambda_i^{\star} f_i(\mathbf{x}^{\star}) = 0$ for $i = 1, \ldots, r$.</li>
<li><strong>Gradient of Lagrangian with respect to $\mathbf{x}$ vanishes</strong>,
$$
\begin{equation}
\nabla_{\mathbf{x}} L(\mathbf{x}^{\star}, \mathbf{\lambda}^{\star}, \mathbf{\nu}^{\star}) = 0
\end{equation}
$$</li>
</ol>
<p>If strong duality holds and $\mathbf{x}^{\star}$ are optimal, then they must satisfy the KKT conditions.</p>
<h6 id="svms-continued">SVMs Continued</h6>
<p>Letâ€™s now write our hard-margin SVM as an optimization problem,</p>
<p>$$
\begin{equation}
\begin{aligned}
\underset{\mathbf{w}, b}{\min} &#x26; \quad \frac{1}{2} \Vert \mathbf{w} \Vert_2^2 \newline
\text{subject to} &#x26; \quad y^{(i)}(\mathbf{w}^T \mathbf{x}^{(i)} + b) \geq 1, \quad i = 1, \ldots, M
\end{aligned}
\end{equation}
$$</p>
<p><strong>Note</strong> that our constraint is from the fact that rescaling $(\mathbf{w}, b)$ does not change the objective function.
Therefore, we set the margin to be $1$,</p>
<p>$$
\begin{equation}
\underset{(\mathbf{x}, y) \in \mathcal{D}}{\min} y(\mathbf{w}^T \mathbf{x} + b) = 1
\end{equation}
$$</p>
<p>For the soft-margin SVM, we introduced the slack variable $\xi_i \geq 0$ for each sample $(\mathbf{x}^{(i)}, y^{(i)})$,</p>
<p>$$
\begin{equation}
\begin{aligned}
\underset{\mathbf{w}, b}{\min} &#x26; \quad \frac{1}{2} \Vert \mathbf{w} \Vert_2^2 + C \sum_{i=1}^{M} \xi_i \newline
\text{subject to} &#x26; \quad y^{(i)}(\mathbf{w}^T \mathbf{x}^{(i)} + b) \geq 1 - \xi_i, \quad i = 1, \ldots, M \newline
&#x26; \quad \xi_i \geq 0, \quad i = 1, \ldots, M
\end{aligned}
\end{equation}
$$</p>
<p>We also introduce a (hyper)parameter $C$ as a penalty for violating the margin (too much slack).
Now that we have both the hard-margin and soft-margin SVMs, letâ€™s derive their respective dual problems.</p>
<h6 id="deriving-the-dual-problem">Deriving the Dual Problem</h6>
<p>Letâ€™s now derive the dual problem for SVMs, since they are so alike, I will derive both â€œat the same timeâ€.
The unique part(s) of the soft-margin SVM will be highlighted in $\colorbox{purple}{\text{purple}}$.</p>
<p>We have the following optimization problem,</p>
<p>$$
\begin{equation}
\begin{aligned}
\underset{\mathbf{w}, b}{\min} &#x26; \quad \frac{1}{2} \Vert \mathbf{w} \Vert_2^2 + \colorbox{purple}{$C \sum_{i=1}^{M} \xi_i$} \newline
\text{subject to} &#x26; \quad y^{(i)}(\mathbf{w}^T \mathbf{x}^{(i)} + b) \geq 1 \colorbox{purple}{$- \xi_i$}, \quad i = 1, \ldots, M \newline
&#x26; \quad \colorbox{purple}{$\xi_i \geq 0 \quad i = 1, \ldots, M$}
\end{aligned}
\end{equation}
$$</p>
<p>Firstly, we write the problem into standard form,</p>
<p>$$
\begin{equation}
\begin{aligned}
\underset{\mathbf{w}, b}{\min} &#x26; \quad \frac{1}{2} \Vert \mathbf{w} \Vert_2^2 + \colorbox{purple}{$C \sum_{i=1}^{M} \xi_i$} \newline
\text{subject to} &#x26; \quad 1 - y^{(i)}(\mathbf{w}^T \mathbf{x}^{(i)} + b) \colorbox{purple}{$+ \xi_i$} \leq 0, \quad i = 1, \ldots, M \newline
&#x26; \quad \colorbox{purple}{$-\xi_i \leq 0 \quad i = 1, \ldots, M$}
\end{aligned}
\end{equation}
$$</p>
<p>Then, we form the Lagrangian,</p>
<p>$$
\begin{equation}
\begin{aligned}
L(\mathbf{w}, b, \mathbf{\lambda}, \colorbox{purple}{$\mathbf{\mu}$}) &#x26; = \frac{1}{2} \Vert \mathbf{w} \Vert_2^2 + \colorbox{purple}{$C \sum_{i=1}^{M} \xi_i$} + \sum_{i = 1}^M \lambda_i (1 - y^{(i)}(\mathbf{w}^T \mathbf{x}^{(i)} + b) \colorbox{purple}{$+ \xi_i$}) - \colorbox{purple}{$\sum_{i=1}^{M} \mu_i \xi_i$} \newline
&#x26; = \frac{1}{2} \Vert \mathbf{w} \Vert_2^2 + \sum_{i = 1}^M \lambda_i - \lambda_i y^{(i)} (\mathbf{w}^T \mathbf{x}^{(i)} + b) + \colorbox{purple}{$\sum_{i=1}^{M} \xi_i (C - \lambda_i - \mu_i)$} \newline
&#x26; = \frac{1}{2} \Vert \mathbf{w} \Vert_2^2 + \sum_{i = 1}^M \lambda_i - \lambda_i y^{(i)} \mathbf{w}^T \mathbf{x}^{(i)} + \lambda_i y^{(i)} b + \colorbox{purple}{$\sum_{i=1}^{M} \xi_i (C - \lambda_i - \mu_i)$} \newline
&#x26; = \frac{1}{2} \Vert \mathbf{w} \Vert_2^2 - \sum_{i = 1}^M \lambda_i y^{(i)} \mathbf{w}^T \mathbf{x}^{(i)} + \sum_{i = 1}^M \lambda_i y^{(i)} b + \sum_{i = 1}^M \lambda_i + \colorbox{purple}{$\sum_{i=1}^{M} \xi_i (C - \lambda_i - \mu_i)$}.
\end{aligned}
\end{equation}
$$</p>
<p>The dual function is defined as,</p>
<p>$$
g(\mathbf{\lambda}, \colorbox{purple}{$\mathbf{\mu}$}) = \underset{\mathbf{w}, b}{\max} \ L(\mathbf{w}, b, \mathbf{\lambda}, \colorbox{purple}{$\mathbf{\mu}$)}.
$$</p>
<p>To maximize $L$ with respect to $\mathbf{w}$, $b$Â $\colorbox{purple}{$\xi_i$}$, we take the partial derivative of $\mathbf{w}$, $b$ and $\colorbox{purple}{$\xi_i$}$ of $L$ and set the expression to zero, respectively.</p>
<p>$$
\begin{equation}
\begin{aligned}
\frac{\partial L(\mathbf{w}, b, \mathbf{\lambda}, \colorbox{purple}{$\xi_i$})}{\partial \mathbf{w}} &#x26; = \frac{\partial}{\partial \mathbf{w}} \left[\frac{1}{2} \Vert \mathbf{w} \Vert_2^2 - \sum_{i = 1}^M \lambda_i y^{(i)} \mathbf{w}^T \mathbf{x}^{(i)} + \sum_{i = 1}^M \lambda_i y^{(i)} b \sum_{i = 1}^M \lambda_i + \colorbox{purple}{$\sum_{i=1}^{M} \xi_i (C - \lambda_i - \mu_i)$} \right] \newline
&#x26; = \mathbf{w} - \sum_{i = 1}^M \lambda_i y^{(i)} \mathbf{x}^{(i)} = 0.
\end{aligned}
\end{equation}
$$</p>
<p>$$
\begin{equation}
\begin{aligned}
\frac{\partial L(\mathbf{w}, b, \mathbf{\lambda}, \colorbox{purple}{$\xi_i$})}{\partial b} &#x26; = \frac{\partial}{\partial b} \left[\frac{1}{2} \Vert \mathbf{w} \Vert_2^2 - \sum_{i = 1}^M \lambda_i y^{(i)} \mathbf{w}^T \mathbf{x}^{(i)} + \sum_{i = 1}^M \lambda_i y^{(i)} b \sum_{i = 1}^M \lambda_i + \colorbox{purple}{$\sum_{i=1}^{M} \xi_i (C - \lambda_i - \mu_i)$} \right] \newline
&#x26; = \sum_{i = 1}^M \lambda_i y^{(i)} = 0.
\end{aligned}
\end{equation}
$$</p>
<p>$$
\begin{equation}
\begin{aligned}
\frac{\partial L(\mathbf{w}, b, \mathbf{\lambda}, \colorbox{purple}{$\xi_i$})}{\colorbox{purple}{$\partial \xi_i$}} &#x26; = \frac{\partial}{\colorbox{purple}{$\partial \xi_i$}} \left[\frac{1}{2} \Vert \mathbf{w} \Vert_2^2 - \sum_{i = 1}^M \lambda_i y^{(i)} \mathbf{w}^T \mathbf{x}^{(i)} + \sum_{i = 1}^M \lambda_i y^{(i)} b \sum_{i = 1}^M \lambda_i + \colorbox{purple}{$\sum_{i=1}^{M} \xi_i (C - \lambda_i - \mu_i)$} \right] \newline
&#x26; = \colorbox{purple}{$C - \lambda_i - \mu_i = 0$}.
\end{aligned}
\end{equation}
$$</p>
<p>Thus, we can solve for $\mathbf{w}$ from the first equation and use the other two as constraints.</p>
<p>$$
\mathbf{w} = \sum_{i = 1}^M \lambda_i y^{(i)} \mathbf{x}^{(i)}.
$$</p>
<p>If we plug back these into our original Lagrangian,</p>
<p>$$
\begin{aligned}
L(\mathbf{w}, b, \mathbf{\lambda}, \colorbox{purple}{$\xi_i$}) &#x26; = \frac{1}{2} \left( \sum_{i = 1}^M \lambda_i y^{(i)} \mathbf{x}^{(i)} \right)^T \left( \sum_{j = 1}^M \lambda_j y^{(j)} \mathbf{x}^{(j)} \right) - \sum_{i = 1}^M \lambda_i y^{(i)} \left( \sum_{j = 1}^M \lambda_j y^{(j)} \mathbf{x}^{(j)} \right) ^T \mathbf{x}^{(i)} + \sum_{i = 1}^M \lambda_i y^{(i)} b + \sum_{i = 1}^M \lambda_i + \colorbox{purple}{$\sum_{i=1}^{M} \xi_i (C - \lambda_i - \mu_i)$}\newline
&#x26; = \sum_{i = 1}^M \lambda_i + \frac{1}{2} \sum_{i = 1}^M \sum_{j = 1}^M y^{(i)} y^{(j)} \lambda_i \lambda_j (\mathbf{x}^{(i)})^T  \mathbf{x}^{(j)} - \sum_{i = 1}^M \sum_{j = 1}^M y^{(i)} y^{(j)} \lambda_i \lambda_j (\mathbf{x}^{(i)})^T \mathbf{x}^{(j)} \newline
&#x26; = \sum_{i = 1}^M \lambda_i - \frac{1}{2} \sum_{i = 1}^M \sum_{j = 1}^M y^{(i)} y^{(j)} \lambda_i \lambda_j (\mathbf{x}^{(i)})^T  \mathbf{x}^{(j)}
\end{aligned}
$$</p>
<p><strong>Note</strong> that I have rewritten $\Vert \mathbf{w} \Vert_{2}^2$ as $\mathbf{w}^T \mathbf{w}$.</p>
<p>So, our dual function is,
$$
g(\mathbf{\lambda}) = \sum_{i = 1}^M \lambda_i - \frac{1}{2} \sum_{i = 1}^M \sum_{j = 1}^M y^{(i)} y^{(j)} \lambda_i \lambda_j (\mathbf{x}^{(i)})^T  \mathbf{x}^{(j)}.
$$</p>
<p>Combining this and our constraints, we get the following dual optimization problem,</p>
<p>$$
\begin{equation}
\begin{aligned}
\underset{\lambda}{\max} &#x26; \quad \sum_{i = 1}^M \lambda_i - \frac{1}{2} \sum_{i = 1}^M \sum_{j = 1}^M y^{(i)} y^{(j)} \lambda_i \lambda_j (\mathbf{x}^{(i)})^T  \mathbf{x}^{(j)}. \newline
\text{subject to} &#x26; \quad \sum_{i = 1}^M \lambda_i y^{(i)} = 0 \newline
&#x26; \quad \colorbox{purple}{$C - \lambda_i - \mu_i = 0$} \quad i = 1, \ldots, M \newline
&#x26; \quad \lambda_i \geq 0, \quad i = 1, \ldots, M \newline
&#x26; \quad \colorbox{purple}{$\mu_i \geq 0$} \quad i = 1, \ldots, M
\end{aligned}
\end{equation}
$$</p>
<p>Which we can easily rewrite as,
$$
\begin{equation}
\begin{aligned}
\underset{\lambda}{\max} &#x26; \quad \sum_{i = 1}^M \lambda_i - \frac{1}{2} \sum_{i = 1}^M \sum_{j = 1}^M y^{(i)} y^{(j)} \lambda_i \lambda_j (\mathbf{x}^{(i)})^T  \mathbf{x}^{(j)}. \newline
\text{subject to} &#x26; \quad \sum_{i = 1}^M \lambda_i y^{(i)} = 0 \newline
&#x26; \quad 0 \leq \lambda_i \colorbox{purple}{$\leq C$} \quad i = 1, \ldots, M
\end{aligned}
\end{equation}
$$</p>
<p>We can see that the only difference lies in the constraint on $\lambda_i$.</p>
<p>In the <strong>hard margin case</strong>, we <strong>do not have an upper-bound</strong>, this is due to the $\xi_i$ term (slackness term), we get the upper-bound $C$.
With hard margins, we assume the data is perfectly separable, i.e., no mistakes in classification.</p>
<p>We can think of the <strong>hard margin case</strong> as a <strong>special case of the soft margin</strong>, if we let $C \to \infty$ we get the hard margin case.</p>
<p>However, I lied earlier, SVMs do not have a <strong>truly closed form solution</strong>, only a quadratic programming/optimization problem <sup><a href="#user-content-fn-10" id="user-content-fnref-10" data-footnote-ref="" aria-describedby="footnote-label">9</a></sup>.
These optimization problems are <strong>well studied and methods to solve them exists</strong> but beyond our scope [^11].</p>
<h6 id="gradient-descent-and-variants">Gradient Descent and variants</h6>
<p>But there is another way to find the best parameters, that we also can use for logistic regression.</p>
<p><strong>Gradient descent</strong> is an optimization algorithm used to minimize some function by iteratively moving in the direction of steepest descent as defined by the negative of the gradient,</p>
<p>$$
\begin{equation}
\mathbf{\theta} = \mathbf{\theta} - \alpha \nabla \ell(\mathbf{\theta}),
\end{equation}
$$</p>
<p>where $\alpha$ is the <strong>learning rate</strong> and $\nabla \ell(\mathbf{\theta})$ is the gradient of the loss function evaluated at $\mathbf{\theta}$.</p>
<p><strong>Figure 11:</strong> Gradient descent.</p>
<p>Gradient descent picks an initial point $\mathbf{\theta}^{(0)}$ and iteratively performs,</p>
<p>$$
\begin{equation}
\begin{aligned}
\mathbf{\theta}^{(t+1)} &#x26; = \mathbf{\theta}^{(t)} - \alpha \nabla \ell(\mathcal{D}; \mathbf{\theta}^{(t)}) \newline
&#x26; = \mathbf{\theta}^{(t)} - \alpha \frac{1}{M} \sum_{i=1}^{M} \nabla \ell(\mathbf{x}^{(i)}, y^{(i)}; \mathbf{\theta}^{(t)}).
\end{aligned}
\end{equation}
$$</p>
<p>But when do we stop?</p>
<p>We can stop when $\Vert \mathbf{\theta}^{(t+1)} - \mathbf{\theta}^{(t)} \Vert_2 \leq \epsilon$ for some small $\epsilon$.
Intuitively, this means that we are not moving much anymore, i.e., we are close to (some) optimum.</p>
<p>Similarly, we can stop if $\Vert \nabla \ell(\mathcal{D}; \mathbf{\theta}^{(t)}) \Vert_2 \leq \epsilon$.
Again, this can intuitively be interpreted as we are not moving much anymore.</p>
<p><strong>Figure 12:</strong> Gradient descent example.</p>
<p>Our initial point matters a lot, as viewed in <strong>Figure 12</strong>.
Therefore, we can run gradient descent multiple times with different initial points and pick the best one.</p>
<p><strong>Figure 13:</strong> Gradient descent example.</p>
<p>Our <em>learning rate</em> matters too of course, if we choose a too big $\alpha$, gradient descent might move too quickly and risk never converging.
If we choose a too small $\alpha$, gradient descent might take too long to converge.</p>
<p>However, there is a drawback to gradient descent, <strong>the computational cost</strong>.
For each iteration, we need to compute the gradient for all samples, this can be very expensive for large datasets.</p>
<p><strong>Stochastic gradient descent</strong> (SGD) is a variant of gradient descent that only uses a (random) single sample to compute the gradient.
At the $t$-th iteration, we randomly sample a single input-output pair and compute the gradient,</p>
<p>$$
\begin{equation}
\mathbf{\theta}^{(t+1)} = \mathbf{\theta}^{(t)} - \alpha \nabla \ell(\mathbf{x}^{(i)}, y^{(i)}; \mathbf{\theta}^{(t)}).
\end{equation}
$$</p>
<p><strong>Figure 14:</strong> Stochastic gradient descent VS. Gradient descent.</p>
<p><strong>Exercise</strong>:
What is the expected value of SGD over all samples?</p>
<details>
<summary><b>Answer</b></summary>
<blockquote>
The expected value of SGD over all samples is the same as the gradient descent,
<p>$$
\begin{equation}
\begin{aligned}
\mathbb{E}[\ell(\mathbf{x}, y; \mathbf{\theta}^{(t+1)})] &#x26; = \frac{1}{M} \sum_{i=1}^{M} \ell(\mathbf{x}^{(i)}, y^{(i)}; \mathbf{\theta}^{(t+1)}) \newline
&#x26; = \nabla \ell(\mathcal{D}; \mathbf{\theta}^{(t)}).
\end{aligned}
\end{equation}
$$</p>
</blockquote>
</details>
<p><strong>Mini-batch gradient descent</strong> is a compromise between gradient descent and SGD.
At the $t$-th iteration, we randomly sample a mini-batch $\mathcal{B} \subset \mathcal{D}$ and compute the gradient,</p>
<p>$$
\begin{equation}
\begin{aligned}
\mathbf{\theta}^{(t+1)} &#x26; = \mathbf{\theta}^{(t)} - \alpha \nabla \ell(\mathcal{B}; \mathbf{\theta}^{(t)}) \newline
&#x26; = \mathbf{\theta}^{(t)} - \alpha \frac{1}{|\mathcal{B}|} \sum_{(\mathbf{x}^{(i)}, y^{(i)}) \in \mathcal{B}} \nabla \ell(\mathbf{x}^{(i)}, y^{(i)}; \mathbf{\theta}^{(t)}).
\end{aligned}
\end{equation}
$$</p>
<p>Letâ€™s now derive the gradient descent update rule for logistic regression.
Remember that the loss function for logistic regression is,</p>
<p>$$
\begin{equation}
\ell(\mathbf{x}, y; \mathbf{w}, b) = -\log(1 + \exp(-y(\mathbf{w}^T \mathbf{x} + b))).
\end{equation}
$$</p>
<p>We can rewrite our MLE problem (which has no closed-form solution) as an optimization problem,</p>
<p>$$
\begin{equation}
\begin{aligned}
\underset{\mathbf{w}, b}{\max} &#x26; \quad \sum_{i=1}^{M} -\log(1 + \exp(-y^{(i)}(\mathbf{w}^T \mathbf{x}^{(i)} + b))) \newline
\underset{\mathbf{w}, b}{\min} &#x26; \quad \sum_{i=1}^{M} \log(1 + \exp(-y^{(i)}(\mathbf{w}^T \mathbf{x}^{(i)} + b))).
\end{aligned}
\end{equation}
$$</p>
<p>Simply using the negative sign to convert the maximization problem to a minimization problem.</p>
<p>Letâ€™s see how the gradient behaves for a single training example $(\mathbf{x}, y)$.
The partial derivative of the loss function with respect to the $j$-th component $w_j$,</p>
<p>$$
\begin{aligned}
\frac{\partial \ell(\mathbf{x}, y; \mathbf{w}, b)}{\partial w_j} &#x26; = \frac{\partial}{\partial w_j} \left[-\log(\sigma(y(\mathbf{w}^T \mathbf{x} + b)))\right] \newline
&#x26; = -\frac{1}{\sigma(y(\mathbf{w}^T \mathbf{x} + b))} \frac{\partial}{\partial w_j} \sigma(y(\mathbf{w}^T \mathbf{x} + b)) \biggr\rvert \text{ Chain rule} \newline
&#x26; = -\frac{1}{\sigma(y(\mathbf{w}^T \mathbf{x} + b))} \sigma(y(\mathbf{w}^T \mathbf{x} + b)) (1 - \sigma(y(\mathbf{w}^T \mathbf{x} + b))) \frac{\partial}{\partial w_j} y(\mathbf{w}^T \mathbf{x} + b) \biggr\rvert \text{ Chain rule} \newline
&#x26; = (\sigma(y(\mathbf{w}^T \mathbf{x} + b)) - 1) \frac{\partial}{\partial w_j} y(\mathbf{w}^T \mathbf{x} + b) \newline
&#x26; = (\sigma(y(\mathbf{w}^T \mathbf{x} + b)) - 1) y \frac{\partial}{\partial w_j} (\mathbf{w}^T \mathbf{x} + b) \newline
&#x26; = (\sigma(y(\mathbf{w}^T \mathbf{x} + b)) - 1) y x_j.
\end{aligned}
$$</p>
<p>The partial derivative of the loss function with respect to $b$,</p>
<p>$$
\begin{aligned}
\frac{\partial \ell(\mathbf{x}, y; \mathbf{w}, b)}{\partial b} &#x26; = \frac{\partial}{\partial b} \left[-\log(\sigma(y(\mathbf{w}^T \mathbf{x} + b)))\right] \newline
&#x26; = -\frac{1}{\sigma(y(\mathbf{w}^T \mathbf{x} + b))} \frac{\partial}{\partial b} \sigma(y(\mathbf{w}^T \mathbf{x} + b)) \text{ Chain rule} \newline
&#x26; = -\frac{1}{\sigma(y(\mathbf{w}^T \mathbf{x} + b))} \sigma(y(\mathbf{w}^T \mathbf{x} + b)) (1 - \sigma(y(\mathbf{w}^T \mathbf{x} + b))) \frac{\partial}{\partial b} y(\mathbf{w}^T \mathbf{x} + b) \text{ Chain rule} \newline
&#x26; = (\sigma(y(\mathbf{w}^T \mathbf{x} + b)) - 1) y \frac{\partial}{\partial b} (\mathbf{w}^T \mathbf{x} + b) \newline
&#x26; = (\sigma(y(\mathbf{w}^T \mathbf{x} + b)) - 1) y.
\end{aligned}
$$</p>
<p>Thus, the (vectorized) gradient descent update rules for logistic regression are,</p>
<p>$$
\begin{equation}
\begin{aligned}
\mathbf{w}^{(t+1)} &#x26; = \mathbf{w}^{(t)} - \alpha \frac{1}{M} \sum_{i=1}^{M} (\sigma(y^{(i)}(\mathbf{w}^{(t)T} \mathbf{x}^{(i)} + b^{(t)}) - 1) y^{(i)} \mathbf{x}^{(i)} \newline
b^{(t+1)} &#x26; = b^{(t)} - \alpha \frac{1}{M} \sum_{i=1}^{M} (\sigma(y^{(i)}(\mathbf{w}^{(t)T} \mathbf{x}^{(i)} + b^{(t)}) - 1) y^{(i)}.
\end{aligned}
\end{equation}
$$</p>
<h6 id="k-nearest-neighbors">$k$-Nearest Neighbors</h6>
<p>Well, this detour to derive the dual problem for SVMs was quite long along with understanding gradient descent has taken quite a bit of time.
But letâ€™s introduce another geometric approach to classification, $k$-Nearest Neighbors (KNN).</p>
<p>The idea is to store all the data $\mathcal{D} = {(\mathbf{x}^{(i)}, y^{(i)})}_{i=1}^{M}$ and when we want to classify a new point $\mathbf{x}$ we use a majority vote over its $k$-nearest neighbors $\mathcal{N}_k(\mathbf{x}) \subset \mathcal{D}$.
KNNs therefore require a distance function $d : \mathcal{X} \times \mathcal{X} \to \mathbb{R}$ and the number of neighbors $k$.</p>
<p>Therefore, the classification function is,</p>
<p>$$
\begin{equation}
f_{\text{KNN}}(\mathbf{x}) = \underset{y \in \mathcal{Y}}{\text{argmax}} \sum_{i \in \mathcal{N}_k(\mathbf{x})} \mathbb{I}[y^{(i)} = y],
\end{equation}
$$</p>
<p>where $\mathbb{I}$ is the indicator function.</p>
<p>(Brute force) KNNs work by computing the distance $d_i = d(\mathbf{x}^{(i)}, \mathbf{x})$ from the target point $\mathbf{x}$ to all other points in the dataset $\mathbf{x}^{(i)}$.
We then sort the distances $\{d_i, i = 1, \ldots, M\}$ and take the $k$-nearest neighbors to create the set $\mathcal{N}_k(\mathbf{x})$.</p>
<h4 id="the-regression-task">The Regression Task</h4>
<p>Okay, we are finally done with classification, but what if our target variable is <strong>continuous</strong>?</p>
<blockquote>
<p>Given a feature vector $\mathbf{x} \in \mathbf{X} = \mathbb{R}^N$, predict its corresponding output value $y \in \mathbf{Y} = \mathbb{R}$.</p>
</blockquote>
<p>Letâ€™s take a moment to think about the difference between classification and regression.</p>
<p>In classification, we need to find a hyperplane that <strong>separates the classes (data) from each other</strong>.
While in regression we need to find a <strong>function that best fits the data</strong>.</p>
<p>While <em>curve fitting</em> is not the same as regression, it is a good analogy.
Given $M$ points from some underlying function (assuming it exists and has negligible noise) our goal is to find this function.</p>
<p><strong>Exercise</strong>:
Here are four questions we need to answer to understand curve fitting (and by extension regression),</p>
<ol>
<li>Does a small subset of points work, or is the more data the better?</li>
<li>Do the locations of the points (on the curve) matter?</li>
<li>Given the same set of $M$ points, is the curve(s) unique?</li>
<li>If (3) is false, how do we measure the quality of the curve(s)?</li>
</ol>
<details>
<summary><b>Answers</b></summary>
<blockquote>
1. More data is better, as it gives us a better approximation of the underlying function.
<ol start="2">
<li>
<p>Yes, the locations of the points matter, as they determine the shape of the curve, i.e., they need to be representative of the underlying function.</p>
</li>
<li>
<p>Estimating a continuous function from a finite set of points is an ill-posed problem and rarely has a unique solution.</p>
</li>
<li>
<p>We can measure the quality of the curve(s) by how well it fits the data, i.e., the error between the predicted and actual values.</p>
</li>
</ol>
</blockquote>
</details>
<h4 id="the-regression-learning-problem">The Regression Learning Problem</h4>
<blockquote>
<p>Given a data set of example pairs $\mathcal{D} = \{(\mathbf{x}^{(i)}, y^{(i)}), i = 1, \ldots, M \}$ where $\mathbf{x}^{(i)} \in \mathbb{R}^{N}$ is a feature vector and $y^{(i)} \in \mathbb{R}$ is the output, learn a function $f : \mathbb{R}^{N} \mapsto \mathbb{R}$ that accurately predicts $y$ for any feature vector $\mathbf{x}$.</p>
</blockquote>
<p>For the error measure, we will use the <strong>mean squared error (MSE)</strong>,</p>
<blockquote>
<p>Given a data set of example pairs $\mathcal{D} = \{(\mathbf{x}^{(i)}, y^{(i)}), i = 1, \ldots, M \}$ and a function $f : \mathbb{R}^{N} \mapsto \mathbb{R}$, the mean squared error of $f$ on $\mathcal{D}$ is,
$$
\text{MSE}(\mathcal{D}, f) = \frac{1}{M} \sum_{i=1}^M (y^{(i)} - f(\mathbf{x}^{(i)}))^2.
$$</p>
</blockquote>
<h5 id="linear-regression">Linear Regression</h5>
<p><strong>Figure 15:</strong> 1D regression example.</p>
<p>I think you are familiar with <strong>linear regression</strong>, in 1D it is simply fitting a line,</p>
<p>$$
\begin{equation}
y = wx + b,
\end{equation}
$$</p>
<p>where $w$ is the slope and $b$ is the intercept. Here we simply have one feature $x$.</p>
<p>In the $N$-dimensional case our $y$ is a linear combination of the $N$ features,</p>
<p>$$
\begin{equation}
y = w_1 x_1 + w_2 x_2 + \ldots + w_N x_N + w_0,
\end{equation}
$$</p>
<p>or equivalently,</p>
<p>$$
\begin{equation}
y = \mathbf{w}^T \mathbf{x} + w_0 = \sum_{j=1}^{N} w_j x_j + w_0 = \sum_{j=0}^{N} w_j x_j,
\end{equation}
$$</p>
<p>with defining $x_0 = 1$.</p>
<h6 id="ordinary-least-squares-ols">Ordinary Least Squares (OLS)</h6>
<p>Just as the classification task, we need to estimate our parameters $(\mathbf{w}, b)$ from the data (remember, machine learning relies on data).</p>
<p>The <strong>ordinary least squares (OLS)</strong> method <strong>minimizes the sum of the squared differences</strong> between the observed values and the predicted values, or in other words, <strong>minimizes the MSE</strong>,</p>
<p>$$
\begin{equation}
\mathbf{w}^{\star}, b^{\star} = \underset{\mathbf{w}, b}{\arg \min} \frac{1}{M} \sum_{i=1}^{M} (y^{(i)} - \mathbf{w}^T \mathbf{x}^{(i)} - b)^2.
\end{equation}
$$</p>
<p>Letâ€™s solve OLS for <strong>one feature</strong> and see how it looks like.</p>
<p>As always, we take the derivative of the objective with respect to $w$ (arbitrarily chosen) and set it to zero,</p>
<p>$$
\begin{equation}
\begin{aligned}
\frac{\partial}{\partial w} \frac{1}{M} \sum_{i=1}^{M} (y^{(i)} - w x^{(i)} - b)^2 &#x26; = 0 \newline
2 \frac{1}{M} \sum_{i=1}^{M} (y^{(i)} - w x^{(i)} - b) (-x^{(i)}) &#x26; = 0 \biggr\rvert \text{ Chain rule} \newline
\left( \sum_{i=1}^{M} (x^{(i)})^2 \right) w + \left( \sum_{i=1}^{M} x^{(i)} \right) b &#x26; = \sum_{i=1}^{M} x^{(i)} y^{(i)}
\end{aligned}
\end{equation}
$$</p>
<p>Equivalently for $b$,</p>
<p>$$
\begin{equation}
\begin{aligned}
\frac{\partial}{\partial b} \frac{1}{M} \sum_{i=1}^{M} (y^{(i)} - w x^{(i)} - b)^2 &#x26; = 0 \newline
2 \frac{1}{M} \sum_{i=1}^{M} (y^{(i)} - w x^{(i)} - b) (-1) &#x26; = 0 \biggr\rvert \text{ Chain rule} \newline
\left( \sum_{i=1}^{M} x^{(i)} \right) w + M b &#x26; = \sum_{i=1}^{M} y^{(i)} \biggr\rvert b \text{ is independent of sum} \newline
\end{aligned}
\end{equation}
$$</p>
<p>Thus, we can write them in matrix form,</p>
<p>$$
\begin{equation}
\begin{bmatrix}
\sum_{i=1}^{M} (x^{(i)})^2 &#x26; \sum_{i=1}^{M} x^{(i)} \newline
\sum_{i=1}^{M} x^{(i)} &#x26; M
\end{bmatrix}
\begin{bmatrix}
w \newline
b
\end{bmatrix} =
\begin{bmatrix}
\sum_{i=1}^{M} x^{(i)} y^{(i)} \newline
\sum_{i=1}^{M} y^{(i)}
\end{bmatrix}.
\end{equation}
$$</p>
<p>Solving for $(w, b)$ yields,</p>
<p>$$
\begin{equation}
\begin{bmatrix}
w \newline
b
\end{bmatrix} =
\begin{bmatrix}
\sum_{i=1}^{M} (x^{(i)})^2 &#x26; \sum_{i=1}^{M} x^{(i)} \newline
\sum_{i=1}^{M} x^{(i)} &#x26; M
\end{bmatrix}^{-1}
\begin{bmatrix}
\sum_{i=1}^{M} x^{(i)} y^{(i)} \newline
\sum_{i=1}^{M} y^{(i)}
\end{bmatrix}.
\end{equation}
$$</p>
<h6 id="general-ols-derivation">General OLS Derivation</h6>
<p>For the general case we need to create a <strong>data matrix</strong>.</p>
<p>Let $\mathbf{x}^{(i)} \in \mathbb{R}^{N + 1}$, where we have defined $x_0^{(i)} = 1$.
Thus, let $\mathbf{X} \in \mathbb{R}^{M \times (N + 1)}$ with rows $\mathbf{x}^{(i)} \in \mathbb{R}^{N + 1}$,</p>
<p>$$
\begin{equation}
\mathbf{X} =
\begin{bmatrix}
â€” &#x26; (\mathbf{x}^{(1)})^T &#x26; â€” \newline
â€” &#x26; (\mathbf{x}^{(2)})^T &#x26; â€” \newline
&#x26; \vdots &#x26; \newline
â€” &#x26; (\mathbf{x}^{(M)})^T &#x26; â€”
\end{bmatrix}.
\end{equation}
$$</p>
<p>Equivalently, let $\mathbf{y} \in \mathbb{R}^{M}$ be a column vector with elements $y^{(i)}$,</p>
<p>$$
\begin{equation}
\mathbf{y} =
\begin{bmatrix}
y^{(1)} \newline
y^{(2)} \newline
\vdots \newline
y^{(M)}
\end{bmatrix}.
\end{equation}
$$</p>
<p>As before $\mathbf{w} \in \mathbb{R}^{N +1}$, where $w_0 = b$.</p>
<p>One can verify that,</p>
<p>$$
\mathbf{y} - \mathbf{X} \mathbf{w} =
\begin{bmatrix}
y^{(1)} \newline
y^{(2)} \newline
\vdots \newline
y^{(M)}
\end{bmatrix} -
\begin{bmatrix}
â€” &#x26; (\mathbf{x}^{(1)})^T &#x26; â€” \newline
â€” &#x26; (\mathbf{x}^{(2)})^T &#x26; â€” \newline
&#x26; \vdots &#x26; \newline
â€” &#x26; (\mathbf{x}^{(M)})^T &#x26; â€”
\end{bmatrix} \mathbf{w} =
\begin{bmatrix}
y^{(1)} \newline
y^{(2)} \newline
\vdots \newline
y^{(M)}
\end{bmatrix} -
\begin{bmatrix}
\mathbf{x}^{(1)T} \mathbf{w} \newline
\mathbf{x}^{(2)T} \mathbf{w} \newline
\vdots \newline
\mathbf{x}^{(M)T} \mathbf{w}
\end{bmatrix} =
\begin{bmatrix}
y^{(1)} - \mathbf{x}^{(1)T} \mathbf{w} \newline
y^{(2)} - \mathbf{x}^{(2)T} \mathbf{w} \newline
\vdots \newline
y^{(M)} - \mathbf{x}^{(M)T} \mathbf{w}
\end{bmatrix}.
$$</p>
<p>Thus, the MSE can be written as,</p>
<p>$$
\begin{equation}
\frac{1}{M} (\mathbf{y} - \mathbf{X} \mathbf{w})^T (\mathbf{y} - \mathbf{X} \mathbf{w}) = \frac{1}{M} \sum_{i=1}^{M} (y^{(i)} - \mathbf{x}^{(i)T} \mathbf{w})^2.
\end{equation}
$$</p>
<p>Therefore,</p>
<p>$$
\begin{equation}
\begin{aligned}
\mathbf{w}^{\star} &#x26; = \underset{\mathbf{w}}{\arg \min} \frac{1}{M} \sum_{i=1}^{M} (y^{(i)} - \mathbf{x}^{(i)T} \mathbf{w})^2 \newline
&#x26; = \underset{\mathbf{w}}{\arg \min} \frac{1}{M} (\mathbf{y} - \mathbf{X} \mathbf{w})^T (\mathbf{y} - \mathbf{X} \mathbf{w}) \newline
\end{aligned}
\end{equation}
$$</p>
<p>Taking the derivative with respect to $\mathbf{w}$ and setting it to zero yields,</p>
<p>$$
\begin{equation}
\begin{aligned}
\nabla_{\mathbf{w}} \frac{1}{M} (\mathbf{y} - \mathbf{X} \mathbf{w})^T (\mathbf{y} - \mathbf{X} \mathbf{w}) &#x26; = 0 \newline
\frac{1}{M} \nabla_{\mathbf{w}} (\mathbf{y}^T \mathbf{y} - \mathbf{y}^T \mathbf{X} \mathbf{w} - \mathbf{w}^T \mathbf{X}^T \mathbf{y} + \mathbf{w}^T \mathbf{X}^T \mathbf{X} \mathbf{w}) &#x26; = 0 \biggr\rvert \text{ Multiply the parenthesis} \newline
\frac{1}{M} \nabla_{\mathbf{w}} (\mathbf{y}^T \mathbf{y} - \mathbf{y}^T \mathbf{X} \mathbf{w} - \mathbf{y}^T \mathbf{X} \mathbf{w} + \mathbf{w}^T \mathbf{X}^T \mathbf{X} \mathbf{w}) &#x26; = 0 \biggr\rvert (AB)^T = B^T A^T \newline
\frac{1}{M} \nabla_{\mathbf{w}} (\mathbf{y}^T \mathbf{y} - 2 \mathbf{y}^T \mathbf{X} \mathbf{w} + \mathbf{w}^T \mathbf{X}^T \mathbf{X} \mathbf{w}) &#x26; = 0 \newline
\frac{1}{M} \nabla_{\mathbf{w}} (\mathbf{w}^T \mathbf{X}^T \mathbf{X} \mathbf{w}- 2 \mathbf{y}^T \mathbf{X} \mathbf{w}) &#x26; = 0 \biggr\rvert \text{ Does not depend on } \mathbf{w} \text{, so we can ignore it} \newline
\frac{2}{M} (\mathbf{X}^T \mathbf{X} \mathbf{w} - \mathbf{X}^T \mathbf{y}) &#x26; = 0 \newline
\end{aligned}
\end{equation}
$$</p>
<p>Here we rely on two identities for the derivative, $\nabla_{\mathbf{w}} \mathbf{w}^T \mathbf{X}^T \mathbf{X} \mathbf{w} = (\mathbf{X}^T \mathbf{X} + (\mathbf{X}^T \mathbf{X})^T) \mathbf{w} = 2 \mathbf{X}^T \mathbf{X} \mathbf{w}$
and
$\nabla_{\mathbf{w}} \mathbf{y}^T \mathbf{X} \mathbf{w} = (\mathbf{y}^T \mathbf{X})^T = \mathbf{X} \mathbf{y}$.</p>
<p>Finally, solving for $\mathbf{w}$ yields,</p>
<p>$$
\begin{equation}
\begin{aligned}
\frac{2}{M} (\mathbf{X}^T \mathbf{X} \mathbf{w} - \mathbf{X}^T \mathbf{y}) &#x26; = 0 \newline
\mathbf{X}^T \mathbf{X} \mathbf{w} &#x26; = \mathbf{X}^T \mathbf{y} \newline
\mathbf{w} &#x26; = (\mathbf{X}^T \mathbf{X})^{-1} \mathbf{X}^T \mathbf{y}.
\end{aligned}
\end{equation}
$$</p>
<p><strong>Exercise</strong>:
Can the same solution be derived from a probabilistic perspective using MLE?</p>
<details>
<summary><b>Answer</b></summary>
<blockquote>
Yes, the same solution can be derived from a probabilistic perspective using MLE.
I will leave the derivation as an exercise for you, but the assumption is that our observation $\mathbf{y}$ is from a conditional Gaussian distribution with mean $\mathbf{X} \mathbf{w}$ and variance $\sigma^2 \mathbf{I}$.
</blockquote>
</details>
<h3 id="unsupervised-learning">Unsupervised Learning</h3>
<section data-footnotes="" class="footnotes"><h2 class="sr-only" id="footnote-label">Footnotes</h2>
<ol>
<li id="user-content-fn-1">
<p><a href="https://en.wikipedia.org/wiki/Machine_learning">Wikipedia, Machine Learning</a> <a href="#user-content-fnref-1" data-footnote-backref="" aria-label="Back to reference 1" class="data-footnote-backref">â†©</a></p>
</li>
<li id="user-content-fn-2">
<p><a href="https://en.wikipedia.org/wiki/Behaviorism">Wikipedia, Behaviorism</a> <a href="#user-content-fnref-2" data-footnote-backref="" aria-label="Back to reference 2" class="data-footnote-backref">â†©</a></p>
</li>
<li id="user-content-fn-3">
<p><a href="https://en.wikipedia.org/wiki/Cognitivism">Wikipedia, Cognitivism</a> <a href="#user-content-fnref-3" data-footnote-backref="" aria-label="Back to reference 3" class="data-footnote-backref">â†©</a></p>
</li>
<li id="user-content-fn-4">
<p><a href="https://en.wikipedia.org/wiki/Connectionism">Wikipedia, Connectionism</a> <a href="#user-content-fnref-4" data-footnote-backref="" aria-label="Back to reference 4" class="data-footnote-backref">â†©</a></p>
</li>
<li id="user-content-fn-5">
<p><a href="https://en.wikipedia.org/wiki/Iris_flower_data_set">Wikipedia, Iris Flower Data Set</a> <a href="#user-content-fnref-5" data-footnote-backref="" aria-label="Back to reference 5" class="data-footnote-backref">â†©</a></p>
</li>
<li id="user-content-fn-6">
<p><a href="https://en.wikipedia.org/wiki/Likelihood_function">Wikipedia, Likelihood function</a> <a href="#user-content-fnref-6" data-footnote-backref="" aria-label="Back to reference 6" class="data-footnote-backref">â†©</a></p>
</li>
<li id="user-content-fn-7">
<p><a href="https://machinelearningmastery.com/bayes-optimal-classifier/">A Gentle Introduction to the Bayes Optimal Classifier</a> <a href="#user-content-fnref-7" data-footnote-backref="" aria-label="Back to reference 7" class="data-footnote-backref">â†©</a></p>
</li>
<li id="user-content-fn-8">
<p><a href="https://en.wikipedia.org/wiki/Lagrangian">Wikipedia, Lagrangian</a> <a href="#user-content-fnref-8" data-footnote-backref="" aria-label="Back to reference 8" class="data-footnote-backref">â†©</a></p>
</li>
<li id="user-content-fn-10">
<p><a href="https://en.wikipedia.org/wiki/Sequential_minimal_optimization">Sequential Minimal Optimization</a> <a href="#user-content-fnref-10" data-footnote-backref="" aria-label="Back to reference 9" class="data-footnote-backref">â†©</a></p>
</li>
</ol>
</section> <div class="mt-24"> <div class="grid grid-cols-2 gap-1.5 sm:gap-3"> <div class="invisible"></div> <a href="/posts/uncertainty" class="group relative flex flex-grow flex-row-reverse flex-nowrap rounded-lg border border-black/15 px-4 py-4 pr-10 no-underline transition-colors duration-300 ease-in-out hover:bg-black/5 hover:text-black focus-visible:bg-black/5 focus-visible:text-black dark:border-white/20 dark:hover:bg-white/5 dark:hover:text-white dark:focus-visible:bg-white/5 dark:focus-visible:text-white"> <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" class="absolute right-2 top-1/2 size-5 -translate-y-1/2 fill-none stroke-current stroke-2"> <line x1="5" y1="12" x2="19" y2="12" class="translate-x-3 scale-x-0 transition-transform duration-300 ease-in-out group-hover:translate-x-0 group-hover:scale-x-100 group-focus-visible:translate-x-0 group-focus-visible:scale-x-100"></line> <polyline points="12 5 19 12 12 19" class="-translate-x-1 transition-transform duration-300 ease-in-out group-hover:translate-x-0 group-focus-visible:translate-x-0"></polyline> </svg> <div class="flex items-center text-sm"> Uncertainty makes the soul </div> </a> </div> </div> <div class="mt-24"> <div class="giscus"></div> <script data-astro-rerun src="https://giscus.app/client.js" data-repo="rezaarezvan/rezvan.xyz" data-repo-id="R_kgDOHvQr3w" data-category="General" data-category-id="DIC_kwDOHvQr384CiWVC" data-mapping="pathname" data-strict="0" data-reactions-enabled="1" data-emit-metadata="0" data-input-position="bottom" data-theme="preferred_color_scheme" data-lang="en" data-loading="lazy" crossorigin="anonymous" async></script> </div> </article> </div>  </main> <footer class="animate"> <div class="mx-auto max-w-screen-sm px-3"> <div class="relative"> <div class="absolute -top-12 right-0"> <button id="back-to-top" class="group relative flex w-fit flex-nowrap rounded border border-black/15 py-1.5 pl-8 pr-3 transition-colors duration-300 ease-in-out hover:bg-black/5 hover:text-black focus-visible:bg-black/5 focus-visible:text-black dark:border-white/20 dark:hover:bg-white/5 dark:hover:text-white dark:focus-visible:bg-white/5 dark:focus-visible:text-white"> <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" class="absolute left-2 top-1/2 size-4 -translate-y-1/2 rotate-90 fill-none stroke-current stroke-2"> <line x1="5" y1="12" x2="19" y2="12" class="translate-x-2 scale-x-0 transition-transform duration-300 ease-in-out group-hover:translate-x-0 group-hover:scale-x-100 group-focus-visible:translate-x-0 group-focus-visible:scale-x-100"></line> <polyline points="12 5 5 12 12 19" class="translate-x-1 transition-transform duration-300 ease-in-out group-hover:translate-x-0 group-focus-visible:translate-x-0"></polyline> </svg> <div class="text-sm">Back to top</div> </button> </div> </div> <div class="flex items-center justify-between"> <div>&copy; 2025 â€¢ rezarezvan.com</div> <div class="flex flex-wrap items-center gap-1.5"></div> </div> </div> </footer> <aside data-pagefind-ignore> <div id="backdrop" class="bg-[rgba(0, 0, 0, 0.5] invisible fixed left-0 top-0 z-50 flex h-screen w-full justify-center p-6 backdrop-blur-sm" data-astro-transition-persist="astro-3snakcvo-2"> <div id="pagefind-container" class="m-0 flex h-fit max-h-[80%] w-full max-w-screen-sm flex-col overflow-auto rounded border border-black/15 bg-neutral-100 p-2 px-4 py-3 shadow-lg dark:border-white/20 dark:bg-neutral-900"> <div id="search" class="pagefind-ui pagefind-init" data-pagefind-ui data-bundle-path="/pagefind/" data-ui-options="{&#34;showImages&#34;:false,&#34;excerptLength&#34;:15,&#34;resetStyles&#34;:false}"></div> <script type="module" src="/_astro/Search.astro_astro_type_script_index_0_lang.C4tRTXsn.js"></script> <div class="mr-2 pb-1 pt-4 text-right text-xs dark:prose-invert">
Press <span class="prose text-xs dark:prose-invert"><kbd class="">Esc</kbd></span> or click anywhere to close
</div> </div> </div> </aside> <script>
  const magnifyingGlass = document.getElementById("magnifying-glass");
  const backdrop = document.getElementById("backdrop");

  function openPagefind() {
    const searchDiv = document.getElementById("search");
    const search = searchDiv.querySelector("input");
    setTimeout(() => {
      search.focus();
    }, 0);
    backdrop?.classList.remove("invisible");
    backdrop?.classList.add("visible");
  }

  function closePagefind() {
    const search = document.getElementById("search");
    search.value = "";
    backdrop?.classList.remove("visible");
    backdrop?.classList.add("invisible");
  }

  // open pagefind
  magnifyingGlass?.addEventListener("click", () => {
    openPagefind();
  });

  document.addEventListener("keydown", (e) => {
    if (e.key === "/") {
      e.preventDefault();
      openPagefind();
    } else if ((e.metaKey || e.ctrlKey) && e.key === "k") {
      e.preventDefault();
      openPagefind();
    }
  });

  // close pagefind
  document.addEventListener("keydown", (e) => {
    if (e.key === "Escape" || e.keyCode === 27) {
      closePagefind();
    }
  });

  // close pagefind when searched result(link) clicked
  document.addEventListener("click", (event) => {
    if (event.target.classList.contains("pagefind-ui__result-link")) {
      closePagefind();
    }
  });

  backdrop?.addEventListener("click", (event) => {
    if (!event.target.closest("#pagefind-container")) {
      closePagefind();
    }
  });

  // prevent form submission
  const form = document.getElementById("form");
  form?.addEventListener("submit", (event) => {
    event.preventDefault();
  });
</script>  </body></html>