<!DOCTYPE html><html lang="en"> <head><!-- Global Metadata --><meta charset="utf-8"><meta name="viewport" content="width=device-width,initial-scale=1"><link rel="icon" type="image/icon" href="/favicon.ico"><meta name="generator" content="Astro v5.0.5"><!-- Canonical URL --><link rel="canonical" href="https://rezvan.xyz/posts/claudeslens/"><!-- Primary Meta Tags --><title>My BSc Thesis, ClaudesLens | rezarezvan.com</title><meta name="title" content="My BSc Thesis, ClaudesLens | rezarezvan.com"><meta name="description"><!-- Open Graph / Facebook --><meta property="og:type" content="website"><meta property="og:url" content="https://rezvan.xyz/posts/claudeslens/"><meta property="og:title" content="My BSc Thesis, ClaudesLens | rezarezvan.com"><meta property="og:description"><meta property="og:image" content="https://rezvan.xyz/favicon.ico"><!-- Twitter --><meta property="twitter:card" content="summary_large_image"><meta property="twitter:url" content="https://rezvan.xyz/posts/claudeslens/"><meta property="twitter:title" content="My BSc Thesis, ClaudesLens | rezarezvan.com"><meta property="twitter:description"><meta property="twitter:image" content="https://rezvan.xyz/favicon.ico"><!-- PageFind --><link href="/pagefind/pagefind-ui.css" rel="stylesheet"><script src="/pagefind/pagefind-ui.js"></script><!-- KaTeX support --><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.15/dist/katex.min.css" integrity="sha384-Htz9HMhiwV8GuQ28Xr9pEs1B4qJiYu/nYLLwlDklR53QibDfmQzi7rYxXhMH/5/u" crossorigin="anonymous"><script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.15/dist/katex.min.js" integrity="sha384-bxmi2jLGCvnsEqMuYLKE/KsVCxV3PqmKeK6Y6+lmNXBry6+luFkEOsmp5vD9I/7+" crossorigin="anonymous"></script><script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.15/dist/contrib/auto-render.min.js" integrity="sha384-hCXGrW6PitJEwbkoStFjeJxv+fSOOQKOPbJxSfM6G5sWZjAyWhXiTIIAmQqnlLlh" crossorigin="anonymous" onload="renderMathInElement(document.body);"></script><!-- inline KaTeX --><script>
    function renderKaTeX() {
        if (typeof renderMathInElement !== "undefined") {
            renderMathInElement(document.body, {
                delimiters: [
                    { left: "$$", right: "$$", display: true },
                    { left: "$", right: "$", display: false },
                ],
            });
        }
    }

    document.addEventListener("DOMContentLoaded", renderKaTeX);
    document.addEventListener("astro:after-swap", renderKaTeX);
</script><meta name="astro-view-transitions-enabled" content="true"><meta name="astro-view-transitions-fallback" content="animate"><script type="module" src="/_astro/ClientRouter.astro_astro_type_script_index_0_lang.BScVxmeO.js"></script><script>
    function init() {
        preloadTheme();
        onScroll();
        animate();
        updateThemeButtons();
        addCopyCodeButtons();
        setGiscusTheme();

        const backToTop = document.getElementById("back-to-top");
        backToTop?.addEventListener("click", (event) => scrollToTop(event));

        const backToPrev = document.getElementById("back-to-prev");
        backToPrev?.addEventListener("click", () => window.history.back());

        const lightThemeButton = document.getElementById("light-theme-button");
        lightThemeButton?.addEventListener("click", () => {
            localStorage.setItem("theme", "light");
            toggleTheme(false);
            updateThemeButtons();
        });

        const darkThemeButton = document.getElementById("dark-theme-button");
        darkThemeButton?.addEventListener("click", () => {
            localStorage.setItem("theme", "dark");
            toggleTheme(true);
            updateThemeButtons();
        });

        const systemThemeButton = document.getElementById(
            "system-theme-button",
        );
        systemThemeButton?.addEventListener("click", () => {
            localStorage.setItem("theme", "system");
            toggleTheme(
                window.matchMedia("(prefers-color-scheme: dark)").matches,
            );
            updateThemeButtons();
        });

        window
            .matchMedia("(prefers-color-scheme: dark)")
            .addEventListener("change", (event) => {
                if (localStorage.theme === "system") {
                    toggleTheme(event.matches);
                }
            });

        document.addEventListener("scroll", onScroll);
    }

    function updateThemeButtons() {
        const theme = localStorage.getItem("theme");
        const lightThemeButton = document.getElementById("light-theme-button");
        const darkThemeButton = document.getElementById("dark-theme-button");
        const systemThemeButton = document.getElementById(
            "system-theme-button",
        );

        function removeActiveButtonTheme(button) {
            button?.classList.remove("bg-black/5");
            button?.classList.remove("dark:bg-white/5");
        }

        function addActiveButtonTheme(button) {
            button?.classList.add("bg-black/5");
            button?.classList.add("dark:bg-white/5");
        }

        removeActiveButtonTheme(lightThemeButton);
        removeActiveButtonTheme(darkThemeButton);
        removeActiveButtonTheme(systemThemeButton);

        if (theme === "light") {
            addActiveButtonTheme(lightThemeButton);
        } else if (theme === "dark") {
            addActiveButtonTheme(darkThemeButton);
        } else {
            addActiveButtonTheme(systemThemeButton);
        }
    }

    function animate() {
        const animateElements = document.querySelectorAll(".animate");

        animateElements.forEach((element, index) => {
            setTimeout(() => {
                element.classList.add("show");
            }, index * 100);
        });
    }

    function onScroll() {
        if (window.scrollY > 0) {
            document.documentElement.classList.add("scrolled");
        } else {
            document.documentElement.classList.remove("scrolled");
        }
    }

    function scrollToTop(event) {
        event.preventDefault();
        window.scrollTo({
            top: 0,
            behavior: "smooth",
        });
    }

    function toggleTheme(dark) {
        const css = document.createElement("style");

        css.appendChild(
            document.createTextNode(
                `* {
             -webkit-transition: none !important;
             -moz-transition: none !important;
             -o-transition: none !important;
             -ms-transition: none !important;
             transition: none !important;
          }
        `,
            ),
        );

        document.head.appendChild(css);

        if (dark) {
            document.documentElement.classList.add("dark");
        } else {
            document.documentElement.classList.remove("dark");
        }

        window.getComputedStyle(css).opacity;
        document.head.removeChild(css);

        setGiscusTheme();
    }

    function preloadTheme() {
        const userTheme = localStorage.theme;

        if (userTheme === "light" || userTheme === "dark") {
            toggleTheme(userTheme === "dark");
        } else {
            toggleTheme(
                window.matchMedia("(prefers-color-scheme: dark)").matches,
            );
        }
    }

    function addCopyCodeButtons() {
        let copyButtonLabel = "📋";
        let codeBlocks = Array.from(document.querySelectorAll("pre"));

        async function copyCode(codeBlock, copyButton) {
            const codeText = codeBlock.innerText;
            const buttonText = copyButton.innerText;
            const textToCopy = codeText.replace(buttonText, "");

            await navigator.clipboard.writeText(textToCopy);
            copyButton.innerText = "✅";

            setTimeout(() => {
                copyButton.innerText = copyButtonLabel;
            }, 2000);
        }

        for (let codeBlock of codeBlocks) {
            const wrapper = document.createElement("div");
            wrapper.style.position = "relative";

            const copyButton = document.createElement("button");
            copyButton.innerText = copyButtonLabel;
            copyButton.classList = "copy-code";

            codeBlock.setAttribute("tabindex", "0");
            codeBlock.appendChild(copyButton);

            codeBlock.parentNode.insertBefore(wrapper, codeBlock);
            wrapper.appendChild(codeBlock);

            copyButton?.addEventListener("click", async () => {
                await copyCode(codeBlock, copyButton);
            });
        }
    }

    const setGiscusTheme = () => {
        const giscus = document.querySelector(".giscus-frame");

        const isDark = document.documentElement.classList.contains("dark");

        if (giscus) {
            const url = new URL(giscus.src);
            url.searchParams.set("theme", isDark ? "dark" : "light");
            giscus.src = url.toString();
        }
    };

    document.addEventListener("DOMContentLoaded", () => init());
    document.addEventListener("astro:after-swap", () => init());
    preloadTheme();
</script><link rel="stylesheet" href="/_astro/_subject_.CbuzD2Qq.css">
<link rel="stylesheet" href="/_astro/index.CFKFE0Zk.css">
<style>summary[data-astro-cid-xvrfupwn]{cursor:pointer;border-top-left-radius:.5rem;border-top-right-radius:.5rem;padding:.375rem .75rem;font-weight:500;transition-property:color,background-color,border-color,text-decoration-color,fill,stroke;transition-timing-function:cubic-bezier(.4,0,.2,1);transition-duration:.15s}summary[data-astro-cid-xvrfupwn]:hover{background-color:#0000000d}summary[data-astro-cid-xvrfupwn]:hover:is(.dark *){background-color:#ffffff0d}details[data-astro-cid-xvrfupwn][open] summary[data-astro-cid-xvrfupwn]{background-color:#0000000d}details[data-astro-cid-xvrfupwn][open] summary[data-astro-cid-xvrfupwn]:is(.dark *){background-color:#ffffff0d}
[data-astro-image]{width:100%;height:auto;-o-object-fit:var(--fit);object-fit:var(--fit);-o-object-position:var(--pos);object-position:var(--pos);aspect-ratio:var(--w) / var(--h)}[data-astro-image=responsive]{max-width:calc(var(--w) * 1px);max-height:calc(var(--h) * 1px)}[data-astro-image=fixed]{width:calc(var(--w) * 1px);height:calc(var(--h) * 1px)}
</style></head> <body> <header data-astro-transition-persist="astro-l7r54iwe-1"> <div class="mx-auto max-w-screen-sm px-3"> <div class="flex flex-wrap justify-between gap-y-4"> <div class="flex flex-col gap-y-2"> <a href="/" target="_self" class="inline-block decoration-black/30 dark:decoration-white/30 hover:decoration-black/50 focus-visible:decoration-black/50 dark:hover:decoration-white/50 dark:focus-visible:decoration-white/50 text-current hover:text-black focus-visible:text-black dark:hover:text-white dark:focus-visible:text-white transition-colors duration-300 ease-in-out">  <div class="font-semibold"> rezarezvan.com </div>  </a> <div class="flex gap-x-2"> <button id="light-theme-button" aria-label="Light theme" class="group flex size-6 items-center justify-center rounded border border-black/15 hover:bg-black/5 focus-visible:bg-black/5 dark:border-white/20 dark:hover:bg-white/5 dark:focus-visible:bg-white/5"> <svg xmlns="http://www.w3.org/2000/svg" width="14" height="14" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="transition-colors duration-300 ease-in-out group-hover:animate-pulse group-hover:stroke-black group-focus-visible:animate-pulse group-focus-visible:stroke-black group-hover:dark:stroke-white dark:group-focus-visible:stroke-white"> <circle cx="12" cy="12" r="5"></circle> <line x1="12" y1="1" x2="12" y2="3"></line> <line x1="12" y1="21" x2="12" y2="23"></line> <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line> <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line> <line x1="1" y1="12" x2="3" y2="12"></line> <line x1="21" y1="12" x2="23" y2="12"></line> <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line> <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line> </svg> </button> <button id="dark-theme-button" aria-label="Dark theme" class="group flex size-6 items-center justify-center rounded border border-black/15 hover:bg-black/5 focus-visible:bg-black/5 dark:border-white/20 dark:hover:bg-white/5 dark:focus-visible:bg-white/5"> <svg xmlns="http://www.w3.org/2000/svg" width="14" height="14" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="transition-colors duration-300 ease-in-out group-hover:animate-pulse group-hover:stroke-black group-focus-visible:animate-pulse group-focus-visible:stroke-black group-hover:dark:stroke-white dark:group-focus-visible:stroke-white"> <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path> </svg> </button> <button id="system-theme-button" aria-label="System theme" class="group flex size-6 items-center justify-center rounded border border-black/15 hover:bg-black/5 focus-visible:bg-black/5 dark:border-white/20 dark:hover:bg-white/5 dark:focus-visible:bg-white/5"> <svg xmlns="http://www.w3.org/2000/svg" width="14" height="14" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="transition-colors duration-300 ease-in-out group-hover:animate-pulse group-hover:stroke-black group-focus-visible:animate-pulse group-focus-visible:stroke-black group-hover:dark:stroke-white dark:group-focus-visible:stroke-white"> <rect x="2" y="3" width="20" height="14" rx="2" ry="2"></rect> <line x1="8" y1="21" x2="16" y2="21"></line> <line x1="12" y1="17" x2="12" y2="21"></line> </svg> </button> </div> </div> <nav class="flex items-center gap-1 text-sm"> <a href="/posts" target="_self" class="inline-block decoration-black/30 dark:decoration-white/30 hover:decoration-black/50 focus-visible:decoration-black/50 dark:hover:decoration-white/50 dark:focus-visible:decoration-white/50 text-current hover:text-black focus-visible:text-black dark:hover:text-white dark:focus-visible:text-white transition-colors duration-300 ease-in-out underline underline-offset-[3px]"> posts </a> <span>/</span> <a href="/chalmers" target="_self" class="inline-block decoration-black/30 dark:decoration-white/30 hover:decoration-black/50 focus-visible:decoration-black/50 dark:hover:decoration-white/50 dark:focus-visible:decoration-white/50 text-current hover:text-black focus-visible:text-black dark:hover:text-white dark:focus-visible:text-white transition-colors duration-300 ease-in-out underline underline-offset-[3px]"> chalmers </a> <span>/</span> <a href="/cityu" target="_self" class="inline-block decoration-black/30 dark:decoration-white/30 hover:decoration-black/50 focus-visible:decoration-black/50 dark:hover:decoration-white/50 dark:focus-visible:decoration-white/50 text-current hover:text-black focus-visible:text-black dark:hover:text-white dark:focus-visible:text-white transition-colors duration-300 ease-in-out underline underline-offset-[3px]"> cityu </a> <span>/</span> <a href="/pdf/cv/cv.pdf" target="_self" class="inline-block decoration-black/30 dark:decoration-white/30 hover:decoration-black/50 focus-visible:decoration-black/50 dark:hover:decoration-white/50 dark:focus-visible:decoration-white/50 text-current hover:text-black focus-visible:text-black dark:hover:text-white dark:focus-visible:text-white transition-colors duration-300 ease-in-out underline underline-offset-[3px]"> cv </a> <span>/</span> <button id="magnifying-glass" aria-label="Search" class="flex items-center rounded border border-black/15 bg-neutral-100 px-2 py-1 text-xs transition-colors duration-300 ease-in-out hover:bg-black/5 hover:text-black focus-visible:bg-black/5 focus-visible:text-black dark:border-white/20 dark:bg-neutral-900 dark:hover:bg-white/5 dark:hover:text-white dark:focus-visible:bg-white/5 dark:focus-visible:text-white"> <svg height="16" stroke-linejoin="round" viewBox="0 0 16 16" width="16" style="color: currentcolor;"> <path fill-rule="evenodd" clip-rule="evenodd" d="M3.5 7C3.5 5.067 5.067 3.5 7 3.5C8.933 3.5 10.5 5.067 10.5 7C10.5 7.88461 10.1718 8.69256 9.63058 9.30876L9.30876 9.63058C8.69256 10.1718 7.88461 10.5 7 10.5C5.067 10.5 3.5 8.933 3.5 7ZM9.96544 11.0261C9.13578 11.6382 8.11014 12 7 12C4.23858 12 2 9.76142 2 7C2 4.23858 4.23858 2 7 2C9.76142 2 12 4.23858 12 7C12 8.11014 11.6382 9.13578 11.0261 9.96544L14.0303 12.9697L14.5607 13.5L13.5 14.5607L12.9697 14.0303L9.96544 11.0261Z" fill="currentColor"></path> </svg>
&nbsp;Search
</button> </nav> </div> </div> </header> <main>  <div class="mx-auto max-w-screen-sm px-3"> <div class="animate grid gap-4"> <a href="/posts" class="not-prose group relative flex w-fit flex-nowrap rounded border border-black/15 py-1.5 pl-7 pr-3 transition-colors duration-300 ease-in-out hover:bg-black/5 hover:text-black focus-visible:bg-black/5 focus-visible:text-black dark:border-white/20 dark:hover:bg-white/5 dark:hover:text-white dark:focus-visible:bg-white/5 dark:focus-visible:text-white"> <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" class="absolute left-2 top-1/2 size-4 -translate-y-1/2 fill-none stroke-current stroke-2"> <line x1="5" y1="12" x2="19" y2="12" class="translate-x-2 scale-x-0 transition-transform duration-300 ease-in-out group-hover:translate-x-0 group-hover:scale-x-100 group-focus-visible:translate-x-0 group-focus-visible:scale-x-100"></line> <polyline points="12 5 5 12 12 19" class="translate-x-1 transition-transform duration-300 ease-in-out group-hover:translate-x-0 group-focus-visible:translate-x-0"></polyline> </svg> <div class="text-sm"> Back to posts </div> </a> <div class="grid grid-cols-2 gap-1.5 sm:gap-3"> <div class="invisible"></div> <div class="invisible"></div> </div> </div> <div class="my-10 space-y-1"> <div class="animate flex items-center gap-1.5"> <div class="font-base text-sm"> <time datetime="2024-06-18T00:00:00.000Z"> June 18, 2024 </time> </div> 
&bull;
<div class="font-base text-sm"> 14 min read </div> </div> <h1 class="animate text-3xl font-semibold text-black dark:text-white"> My BSc Thesis, ClaudesLens </h1> </div> <details open class="animate rounded-lg border border-black/15 dark:border-white/20" data-astro-cid-xvrfupwn> <summary data-astro-cid-xvrfupwn>Table of Contents</summary> <nav class="" data-astro-cid-xvrfupwn> <ul class="py-3" data-astro-cid-xvrfupwn> <li class="list-inside list-disc px-6 py-1.5 text-sm"> <a href="#introduction" target="_self" class="inline-block decoration-black/30 dark:decoration-white/30 hover:decoration-black/50 focus-visible:decoration-black/50 dark:hover:decoration-white/50 dark:focus-visible:decoration-white/50 text-current hover:text-black focus-visible:text-black dark:hover:text-white dark:focus-visible:text-white transition-colors duration-300 ease-in-out underline underline-offset-[3px]"> Introduction </a> <ul class="translate-x-3"> <li class="list-inside list-disc px-6 py-1.5 text-sm"> <a href="#bayeslens" target="_self" class="inline-block decoration-black/30 dark:decoration-white/30 hover:decoration-black/50 focus-visible:decoration-black/50 dark:hover:decoration-white/50 dark:focus-visible:decoration-white/50 text-current hover:text-black focus-visible:text-black dark:hover:text-white dark:focus-visible:text-white transition-colors duration-300 ease-in-out underline underline-offset-[3px]"> BayesLens </a>  </li><li class="list-inside list-disc px-6 py-1.5 text-sm"> <a href="#claudeslens" target="_self" class="inline-block decoration-black/30 dark:decoration-white/30 hover:decoration-black/50 focus-visible:decoration-black/50 dark:hover:decoration-white/50 dark:focus-visible:decoration-white/50 text-current hover:text-black focus-visible:text-black dark:hover:text-white dark:focus-visible:text-white transition-colors duration-300 ease-in-out underline underline-offset-[3px]"> ClaudesLens </a>  </li> </ul> </li><li class="list-inside list-disc px-6 py-1.5 text-sm"> <a href="#neural-networks" target="_self" class="inline-block decoration-black/30 dark:decoration-white/30 hover:decoration-black/50 focus-visible:decoration-black/50 dark:hover:decoration-white/50 dark:focus-visible:decoration-white/50 text-current hover:text-black focus-visible:text-black dark:hover:text-white dark:focus-visible:text-white transition-colors duration-300 ease-in-out underline underline-offset-[3px]"> Neural Networks </a> <ul class="translate-x-3"> <li class="list-inside list-disc px-6 py-1.5 text-sm"> <a href="#the-neuron" target="_self" class="inline-block decoration-black/30 dark:decoration-white/30 hover:decoration-black/50 focus-visible:decoration-black/50 dark:hover:decoration-white/50 dark:focus-visible:decoration-white/50 text-current hover:text-black focus-visible:text-black dark:hover:text-white dark:focus-visible:text-white transition-colors duration-300 ease-in-out underline underline-offset-[3px]"> The Neuron </a>  </li><li class="list-inside list-disc px-6 py-1.5 text-sm"> <a href="#the-network" target="_self" class="inline-block decoration-black/30 dark:decoration-white/30 hover:decoration-black/50 focus-visible:decoration-black/50 dark:hover:decoration-white/50 dark:focus-visible:decoration-white/50 text-current hover:text-black focus-visible:text-black dark:hover:text-white dark:focus-visible:text-white transition-colors duration-300 ease-in-out underline underline-offset-[3px]"> The Network </a>  </li> </ul> </li><li class="list-inside list-disc px-6 py-1.5 text-sm"> <a href="#computer-vision" target="_self" class="inline-block decoration-black/30 dark:decoration-white/30 hover:decoration-black/50 focus-visible:decoration-black/50 dark:hover:decoration-white/50 dark:focus-visible:decoration-white/50 text-current hover:text-black focus-visible:text-black dark:hover:text-white dark:focus-visible:text-white transition-colors duration-300 ease-in-out underline underline-offset-[3px]"> Computer Vision </a> <ul class="translate-x-3"> <li class="list-inside list-disc px-6 py-1.5 text-sm"> <a href="#images" target="_self" class="inline-block decoration-black/30 dark:decoration-white/30 hover:decoration-black/50 focus-visible:decoration-black/50 dark:hover:decoration-white/50 dark:focus-visible:decoration-white/50 text-current hover:text-black focus-visible:text-black dark:hover:text-white dark:focus-visible:text-white transition-colors duration-300 ease-in-out underline underline-offset-[3px]"> Images </a>  </li> </ul> </li><li class="list-inside list-disc px-6 py-1.5 text-sm"> <a href="#entropy" target="_self" class="inline-block decoration-black/30 dark:decoration-white/30 hover:decoration-black/50 focus-visible:decoration-black/50 dark:hover:decoration-white/50 dark:focus-visible:decoration-white/50 text-current hover:text-black focus-visible:text-black dark:hover:text-white dark:focus-visible:text-white transition-colors duration-300 ease-in-out underline underline-offset-[3px]"> Entropy </a> <ul class="translate-x-3"> <li class="list-inside list-disc px-6 py-1.5 text-sm"> <a href="#uncertainty-in-information-theory" target="_self" class="inline-block decoration-black/30 dark:decoration-white/30 hover:decoration-black/50 focus-visible:decoration-black/50 dark:hover:decoration-white/50 dark:focus-visible:decoration-white/50 text-current hover:text-black focus-visible:text-black dark:hover:text-white dark:focus-visible:text-white transition-colors duration-300 ease-in-out underline underline-offset-[3px]"> Uncertainty in Information Theory </a>  </li> </ul> </li><li class="list-inside list-disc px-6 py-1.5 text-sm"> <a href="#entropy-based-uncertainty-quantification-framework" target="_self" class="inline-block decoration-black/30 dark:decoration-white/30 hover:decoration-black/50 focus-visible:decoration-black/50 dark:hover:decoration-white/50 dark:focus-visible:decoration-white/50 text-current hover:text-black focus-visible:text-black dark:hover:text-white dark:focus-visible:text-white transition-colors duration-300 ease-in-out underline underline-offset-[3px]"> Entropy-based Uncertainty Quantification Framework </a> <ul class="translate-x-3"> <li class="list-inside list-disc px-6 py-1.5 text-sm"> <a href="#proposed-metrics" target="_self" class="inline-block decoration-black/30 dark:decoration-white/30 hover:decoration-black/50 focus-visible:decoration-black/50 dark:hover:decoration-white/50 dark:focus-visible:decoration-white/50 text-current hover:text-black focus-visible:text-black dark:hover:text-white dark:focus-visible:text-white transition-colors duration-300 ease-in-out underline underline-offset-[3px]"> Proposed Metrics </a> <ul class="translate-x-3"> <li class="list-inside list-disc px-6 py-1.5 text-sm"> <a href="#pi-perturbation-index" target="_self" class="inline-block decoration-black/30 dark:decoration-white/30 hover:decoration-black/50 focus-visible:decoration-black/50 dark:hover:decoration-white/50 dark:focus-visible:decoration-white/50 text-current hover:text-black focus-visible:text-black dark:hover:text-white dark:focus-visible:text-white transition-colors duration-300 ease-in-out underline underline-offset-[3px]"> PI: Perturbation Index </a>  </li><li class="list-inside list-disc px-6 py-1.5 text-sm"> <a href="#psi-perturbation-stability-index" target="_self" class="inline-block decoration-black/30 dark:decoration-white/30 hover:decoration-black/50 focus-visible:decoration-black/50 dark:hover:decoration-white/50 dark:focus-visible:decoration-white/50 text-current hover:text-black focus-visible:text-black dark:hover:text-white dark:focus-visible:text-white transition-colors duration-300 ease-in-out underline underline-offset-[3px]"> PSI: Perturbation Stability Index </a>  </li> </ul> </li><li class="list-inside list-disc px-6 py-1.5 text-sm"> <a href="#mapping-entropy-categorically" target="_self" class="inline-block decoration-black/30 dark:decoration-white/30 hover:decoration-black/50 focus-visible:decoration-black/50 dark:hover:decoration-white/50 dark:focus-visible:decoration-white/50 text-current hover:text-black focus-visible:text-black dark:hover:text-white dark:focus-visible:text-white transition-colors duration-300 ease-in-out underline underline-offset-[3px]"> Mapping entropy categorically </a>  </li> </ul> </li><li class="list-inside list-disc px-6 py-1.5 text-sm"> <a href="#conclusion" target="_self" class="inline-block decoration-black/30 dark:decoration-white/30 hover:decoration-black/50 focus-visible:decoration-black/50 dark:hover:decoration-white/50 dark:focus-visible:decoration-white/50 text-current hover:text-black focus-visible:text-black dark:hover:text-white dark:focus-visible:text-white transition-colors duration-300 ease-in-out underline underline-offset-[3px]"> Conclusion </a> <ul class="translate-x-3"> <li class="list-inside list-disc px-6 py-1.5 text-sm"> <a href="#footnote-label" target="_self" class="inline-block decoration-black/30 dark:decoration-white/30 hover:decoration-black/50 focus-visible:decoration-black/50 dark:hover:decoration-white/50 dark:focus-visible:decoration-white/50 text-current hover:text-black focus-visible:text-black dark:hover:text-white dark:focus-visible:text-white transition-colors duration-300 ease-in-out underline underline-offset-[3px]"> Footnotes </a>  </li> </ul> </li> </ul> </nav> </details> <article class="animate"> <h1 id="introduction">Introduction</h1>
<p>I have finally finished my undergrad and would like to make a blog post about what I have been working on these past ~6 months.</p>
<p>The tile of our thesis is:</p>
<blockquote>
<p>ClaudesLens: Uncertainty Quantification in Computer Vision Models</p>
</blockquote>
<p>Which you can read <a href="https://arxiv.org/abs/2406.13008">here.</a></p>
<p>However, before I dive into the project and what we did, let me tell you what we <em>wanted</em> to do.</p>
<h3 id="bayeslens">BayesLens</h3>
<p>Originally, we wanted to create “Uncertainty-Aware Attention Mechanisms”.
What we specifically had in mind was to create a transformer model that used Bayesian Neural Networks (BNNs) <sup><a href="#user-content-fn-1" id="user-content-fnref-1" data-footnote-ref="" aria-describedby="footnote-label">1</a></sup>.
Even more ambitiously, apply this to self-driving cars.</p>
<p>Needless to say, this was a bit too ambitious for a BSc thesis, so we had to scale down our project a bit.
We didn’t have the prerequisite knowledge or the compute to do such a task within that time frame.</p>
<p>So about ~1/3 into the project, when our supervisor wanted us to explore the <em>entropy</em> of predictions and got really excited about our results, we got <strong>ClaudesLens</strong>.</p>
<h3 id="claudeslens">ClaudesLens</h3>
<p>From the results using entropy as a measure of uncertainty — which in itself is nothing new — we decided to focus on this instead.
I’ll go into more detail and motivate how this approach works.</p>
<p>Enough about what we <em>wanted</em> to do and what we <em>did</em>.
Let’s start what lies at the heart of this project: <strong>Neural Networks</strong>.</p>
<h1 id="neural-networks">Neural Networks</h1>
<p>There are many ways to explain neural networks, in this post I will use a mathematical approach which will let us view the entire network as a single function.</p>
<h3 id="the-neuron">The Neuron</h3>
<p>At the core of a neural network lies the neuron, which is inspired by the biological neuron <sup><a href="#user-content-fn-2" id="user-content-fnref-2" data-footnote-ref="" aria-describedby="footnote-label">2</a></sup>.</p>
<p>Each neuron takes in one or more scalars $x_j$ as input and outputs a single scalar $y$.
Each input $x_j$ is scaled by an associated weight denoted as $w_j$. The neuron also has a special input called the bias,
$b$.</p>
<p>The neuron has two stages it goes through, <strong>summation</strong> and <strong>activation</strong>.</p>
<p><img src="/images/posts/neuron.png" alt="neuron">
<strong>Figure 1:</strong> A single neuron with <em>n</em> inputs and one output, showcasing the summation and activation components.</p>
<p>The summation stage is where the neuron calculates the <strong>weighted sum</strong> of the inputs and the bias:
$$
\begin{equation}
z = \sum_{j=1}^{n} w_j x_j + b
\end{equation}
$$</p>
<p>The activation function, denoted as $f$, calculates the neuron’s output $y = f(z)$ based on the weighted summation.</p>
<p>Activation functions introduce <strong>non-linearity</strong>, enabling neural networks to approximate complex, non-linear functions.</p>
<p><strong>Exercise</strong>:
Why does the neuron have a bias input?</p>
<details>
<summary><b>Answer</b></summary>
<blockquote>
The bias input allows the neuron to shift the activation function to the left or right, which can be crucial for the learning process.
</blockquote>
</details>
<h3 id="the-network">The Network</h3>
<p>Lets build upon what we now have learned and see how we can extend this.</p>
<p>We can represent the inputs of a neuron as a vector,
$$
\mathbf{x} = \left[x_1, x_2, \ldots, x_n\right],
$$</p>
<p>where each element corresponds to an input to the neuron.</p>
<p>Similarly, we can represent the associated weights as a vector,
$$
\mathbf{w} = \left[w_1, w_2, \ldots, w_n\right],
$$</p>
<p>with this the summation can be simplified to a dot product,
$$
z = \mathbf{w} \cdot \mathbf{x} + b.
$$</p>
<p>But only using one neuron will only get us so far, if we instead have multiple neurons and try to mimic the structure of the brain, we can get something more powerful.</p>
<p>A <em>layer</em> is a collection of neurons, stacked on top of each other.
Very often when we are referring to a layer, are we referring to a <em>fully connected layer</em>, where each neuron in the layer is connected to all the neurons in the previous layer.</p>
<p>In the case of a network, we can now talk about the input layer and the output layer.</p>
<p><img src="/images/posts/nn.png" alt="nn">
<strong>Figure 2:</strong> A simple neural network with one hidden layer.</p>
<p>As we see in the picture, we now have multiple neurons with numerous inter-neuron connections, along with multiple outputs.</p>
<p>The matrix-vector equation,
$$
\mathbf{a} = \mathbf{W_1} \mathbf{x} + \mathbf{b_1} = [a_1, a_2, \ldots, a_m],
$$</p>
<p>yields each output of each neuron in the <em>hidden layer</em> (intermediate layers between the input and output layers).</p>
<p><strong>Note</strong>, I’m <strong>explicitly leaving out</strong> the required transpose operations out of the equations, in reality we need our matrix and vectors to match dimension, but our theory and intuition will still hold.</p>
<p>$\mathbf{W_1}$ is the <em>weight matrix</em> with rows $\mathbf{w_i} = [w_{i, 1}, w_{i, 2}, \ldots, w_{i, n}]$ corresponding to the weights of the $i$-th neuron in the hidden layer.
The bias values are represented by $\mathbf{b_1} = [b_1, b_2, \ldots, b_m]$.</p>
<p>In the case of several layers, we work with multiple weight matrices and bias vectors, which we index as $\mathbf{W_j}$ and $\mathbf{b_j}$, respectively.</p>
<p>So, given an input $\mathbf{x}$, the output of the hidden layer (i.e., Figure 2) is given by,
$$
\mathbf{a} = f.(\mathbf{W_1} \mathbf{x} + \mathbf{b_1}),
$$</p>
<p>where the dot indicates that the activation function $f$ is applied element-wise.</p>
<p>So the final output is therefore,
$$
\mathbf{y} = f.(\mathbf{W_2} \mathbf{a} + \mathbf{b_2}). = f.(\mathbf{W_2} f.(\mathbf{W_1} \mathbf{x} + \mathbf{b_1}) + \mathbf{b_2}).
$$</p>
<p><strong>Exercise</strong>:
Is it necessary to apply the same activation function to all layers in a neural network?</p>
<details>
<summary><b>Answer</b></summary>
<blockquote>
No, it is not necessary to apply the same activation function to all layers.
Different activation functions can be used in different layers, depending on the problem at hand.
</blockquote>
</details>
<p>This is the basic structure of a neural network, I will not go into more detail about the <em>training process</em>, but I will mention that these weights and biases are <em>learned</em> (from the data) through an optimization process called <em>backpropagation</em> <sup><a href="#user-content-fn-3" id="user-content-fnref-3" data-footnote-ref="" aria-describedby="footnote-label">3</a></sup>.</p>
<p>There are a ton of resources to understand these concepts, even we tried to explain these concepts in our thesis.
I highly encourage you to read about it, it is one of the most important concepts of modern deep learning <sup><a href="#user-content-fn-4" id="user-content-fnref-4" data-footnote-ref="" aria-describedby="footnote-label">4</a></sup>.</p>
<h1 id="computer-vision">Computer Vision</h1>
<p>Now that we have a basic understanding of neural networks, we can move on to computer vision.</p>
<p>Computer vision is a field of computer science that focuses on <strong>replicating</strong> parts of the complexity of the <strong>human vision system</strong> and enabling computers to <strong>identify and process objects in images and videos</strong> in the same way that humans do.</p>
<p>The most important thing that we will cover here is how we represent images numerically so we can feed them into as input to neural networks.</p>
<h3 id="images">Images</h3>
<p><img src="https://upload.wikimedia.org/wikipedia/commons/5/56/RGB_channels_separation.png" alt="">
<strong>Figure 3:</strong> An RBG image with its corresponding channels. <a href="https://commons.wikimedia.org/wiki/File:RGB_channels_separation.png">Source</a></p>
<p>Images are represented as a grid of pixels, where each pixel needs to be represented in a numerical way.</p>
<p>For most images, we represent each pixel as a 3-dimensional vector, where each element corresponds to the intensity of the color channels red, green, and blue (RGB). This is called a <em>channel</em>.</p>
<p>So, a single pixel in an image is represented as a vector, therefore a whole image can be represented as a 3-dimensional tensor.</p>
<h1 id="entropy">Entropy</h1>
<p>Now that we have covered the basics of neural networks and computer vision (in our use case that is), we can move on to the main topic of this thesis: <strong>Entropy</strong>.</p>
<h3 id="uncertainty-in-information-theory">Uncertainty in Information Theory</h3>
<p>Now, when we are talking about entropy, we are talking about the <strong>information kind</strong> of entropy.
Thanks to the great work of Claude Shannon, we have a way to quantify the uncertainty of a random variable. <sup><a href="#user-content-fn-5" id="user-content-fnref-5" data-footnote-ref="" aria-describedby="footnote-label">5</a></sup></p>
<p>The entropy of a random variable $X$ is defined as,
$$
H(X) = -\sum_{x \in \chi} p(x) \log p(x),
$$</p>
<p>where $p(x) = P(X = x)$.</p>
<p>If I were to explain Shannon-Entropy in an intuitive way.
If we have no uncertainty or very little, i.e., imagine an unfair coin with 99% probability of landing on heads. You <strong>won’t be surprised</strong> if it lands on heads.</p>
<p>However, if we have a fair coin, if I flip it 100 times and 99 of them are heads, you would be <strong>very surprised</strong>.</p>
<p>This is what Shannon-Entropy captures, how <em>surprised</em> you are about the outcome of a random variable.</p>
<p>There is a more elegant way it is presented (and especially used!) in classical information theory. But I will leave that for yourself to read and discover :).</p>
<p><strong>Exercise</strong>:
Does Shannon-Entropy have a lower and upper bound?</p>
<details>
<summary><b>Answer</b></summary>
<blockquote>
Yes, the lower bound of entropy is 0 and the upper bound is $\log |\chi|$.
Where $|\chi|$ is the cardinality or the number of elements in the set $\chi$.
<details>
<summary><b>Proof</b></summary>
$$
\begin{align*}
&#x26;\textbf{We show } 0 \leq H(X) \leq \log |\chi|. \newline
&#x26;\textbf{Lower Bound (}H(X) \ge 0\textbf): \newline
&#x26;\quad H(X) = -\sum_{x \in \chi} p(x)\,\log p(x). \newline
&#x26;\quad \text{Note that for any } 0 &#x3C; p(x) \le 1,\, -\log p(x) \ge 0,\text{ hence each term } p(x)\,\bigl(-\log p(x)\bigr) \ge 0. \newline
&#x26;\quad \text{Thus } H(X) \;=\; -\sum_{x \in \chi} p(x)\,\log p(x) \;\ge\; 0. \newline
&#x26;\textbf{Upper Bound (}H(X) \le \log |\chi|\textbf): \newline
&#x26;\quad \text{Using the concavity of the } \log \text{ function and by Jensen's inequality, we have} \newline
&#x26;\quad -\sum_{x \in \chi} p(x)\,\log p(x) \;\le\; \log\Bigl(\lvert \chi \rvert \Bigr). \newline \\
&#x26;\quad \text{Alternatively, we can argue that for fixed } \lvert \chi \rvert, \newline
&#x26;\quad \text{the uniform distribution } p(x) = \frac{1}{|\chi|} \text{ maximizes the entropy,} \newline
&#x26;\quad \text{yielding } H(X) = -\sum_{x \in \chi} \frac{1}{|\chi|}\,\log \Bigl(\tfrac{1}{|\chi|}\Bigr) = \log\Bigl(\lvert \chi \rvert\Bigr). \newline \\
&#x26;\text{Hence, combining both bounds, we have } 0 \le H(X) \le \log |\chi|. \newline
\end{align*}
$$
</details>
</blockquote>
</details>
<h1 id="entropy-based-uncertainty-quantification-framework">Entropy-based Uncertainty Quantification Framework</h1>
<p>From what we have seen, we can view a neural network as a <strong>function</strong>.</p>
<p>In our case — since we’re dealing with classification — our function spits out a <strong>probability vector</strong> where each element corresponds to the probability of the input belonging to a specific class.</p>
<p>Therefore, the best prediction is,
$$
\begin{equation}
\hat{y} = \arg\max(\mathcal{F}(\mathbf{x}, \mathbf{W})),
\end{equation}
$$</p>
<p>where the $\arg\max$ function returns the <strong>index</strong> of the <strong>maximum element</strong> in the vector.</p>
<p>$\mathcal{F}$ is our neural network that takes the inputs $\mathbf{x}$ (image) and $\mathbf{W}$ (<strong>final learned</strong> weights).</p>
<p>But this is deterministic, there is no uncertainty (no surprise), given the same input we will <strong>always</strong> get the same output.</p>
<p>So, let us introduce some uncertainty, let’s make our network <strong>stochastic</strong>.</p>
<p>To make the network stochastic, we need to introduce some <strong>randomness somewhere</strong> in the network.</p>
<p>I want to emphasize that you can do this in a lot of different ways and “inject” the randomness at different stages in a neural network.
We chose the most straightforward and primitive ways, adding image on the input image and adding noise to the weights.</p>
<p>So, the perturbed weight matrix is given by,</p>
<p>$$
\begin{equation}
\mathbf{W}_{\sigma} = \mathbf{W} + \sigma \mathbf{N},
\end{equation}
$$</p>
<p>where $N \sim \mathcal{N}(0, 1)$ is a matrix — with the same shape of $\mathbf{W}$ — of random numbers drawn from a normal distribution.
$\sigma$ is a hyperparameter scalar that weights the amount of noise added to the weights.</p>
<p>Now, the output becomes stochastic,</p>
<p>$$
\begin{equation}
\hat{y_{\sigma}} = \arg\max(\mathcal{F}(\mathbf{x}; \mathbf{W}_{\sigma})),
\end{equation}
$$</p>
<p>note the difference from our original equation, we no longer treat $\mathbf{W}$ as an input, but rather a parameter of the function $\mathcal{F}$.</p>
<p>By perturbing the weights and creating a single prediction <strong>constitues a random experiment</strong>.
It is therefore meaningful to examine the <strong>probability distribution</strong> of the random variable $\mathcal{F}(\mathbf{x}; \mathbf{W}_{\sigma})$ for a fixed input.</p>
<p>By repeating the experiment for a fixed input $\mathbf{x}$ and creating samples of $\mathcal{F}(\mathbf{x}; \mathbf{W_{\sigma}})$ but drawing different samples of $\mathbf{W_{\sigma}}^{(i)}, i = 1, \ldots, N$ we can empirically calculate the <strong>entropy</strong> $H_{\sigma}(\mathbf{x})$ <strong>entropy distribution</strong>.</p>
<p>With this framework, we want to search for the <strong>underlying distribution of the model</strong> and the <strong>properties of the distribution</strong>.</p>
<p><strong>Exercise</strong>:
What is the difference between the entropy of the model and the entropy of the prediction?</p>
<details>
<summary><b>Answer</b></summary>
<blockquote>
The entropy of the model is the entropy of <b>multiple predictions</b> given the same fixed input $\mathbf{x}$, whereas the entropy of the prediction is the <b>entropy of the probability vector</b> for a <b>single prediction</b>.
</blockquote>
</details>
<p><strong>Exercise</strong>:
Is there a difference if you add noise to the input image instead of the weights?</p>
<details>
<summary><b>Answer</b></summary>
<blockquote>
Yes and no.
<p>Adding noise to the input image will perturb the image itself, which is different from perturbing the weights.
However, conceptually, the idea is the same.</p>
<p>We can view the noise to the input image as corresponding weights in the first layer of the network.
Meaning that the first layer of the network is now stochastic, instead of all the weights in the network.</p>
</blockquote>
</details>
<h3 id="proposed-metrics">Proposed Metrics</h3>
<p>With this entropy-based uncertainty quantification framework, we propose two metrics to quantify the uncertainty of a neural network model.</p>
<h4 id="pi-perturbation-index">PI: Perturbation Index</h4>
<p>In image classification — one of the most common and fundamental tasks in computer vision — accuracy is a common metric to evaluate the performance of a model.</p>
<p>Accuracy is defined as,</p>
<p>$$
\begin{equation}
\text{Acc}(f) = \frac{1}{N} \sum_{i=1}^{N} \mathbb{I}[y^{(i)} = f(\mathbf{x}^{(i)})],
\end{equation}
$$</p>
<p>where $y^{(i)}$ is the true label of the $i$-th image, $f(\mathbf{x}^{(i)})$ is the predicted label of the $i$-th image and $\mathbb{I}[\cdot]$ is the indicator function defined as,</p>
<p>$$
\begin{equation}
\mathbb{I}[A] = \begin{cases}
1 &#x26; \text{if } A \text{ is true}, \newline
0 &#x26; \text{otherwise}.
\end{cases}
\end{equation}
$$</p>
<p>Simply, accuracy is the fraction of correct predictions over the total number of predictions.</p>
<p>It is therefore natural to imagine that perturbing the weights of a model will affect the accuracy of the model.
However, a robust model should be able to handle these perturbations and still perform well.
The Perturbation Index (PI) is therefore defined as,</p>
<p>$$
\begin{equation}
\pi_{\sigma} = \text{Acc}(\mathcal{F}(\mathbf{x}; \mathbf{W}_{\sigma})) - \text{Acc}(\mathcal{F}(\mathbf{x}, \mathbf{W})).
\end{equation}
$$</p>
<p>$\pi_{\sigma}$ is the difference in accuracy between the perturbed and the original model.</p>
<p><strong>Exercise</strong>:
Should you calculate the PI for a single image, a batch of images, or the entire dataset?</p>
<details>
<summary><b>Answer</b></summary>
<blockquote>
The most meaningful way to calculate the PI is to calculate it for the entire dataset.
</blockquote>
</details>
<h4 id="psi-perturbation-stability-index">PSI: Perturbation Stability Index</h4>
<p>But PI doesn’t tell us anything about the inherent uncertainty of the model.</p>
<p>As we discussed, we can empirically calculate the entropy, in mathematical terms,</p>
<p>$$
\begin{equation}
H_{\sigma}(\mathbf{x}) = \lim_{n \to \infty} - \sum_{c \in \mathcal{C}} p_c^{(n)} \log p_c^{(n)},
\end{equation}
$$</p>
<p>where $p_c^{(n)}$ is the proportion of predictions $\hat{y_{\sigma}}$ equal to the class index $c$ out of all $C$ classes in the $n$ samples of $\hat{y}_{\sigma}$ for a given input $\mathbf{x}$.</p>
<p>If the model generates varying predictions under perturbation, this might suggest uncertainty in the classification.
In simpler terms, there <strong>should be a negative correlation</strong> between <strong>prediction stability</strong> and the <strong>Shannon-Entropy</strong> of the model.</p>
<p>$$
\begin{equation}
\psi_{\sigma} = \text{Acc}(\mathcal{F}(\mathbf{x}; \mathbf{W_{\sigma}})) - \text{Corr}(\mathbb{I}[\hat{y_{\sigma}} = Y], H_{\sigma}(\mathbf{x})).
\end{equation}
$$</p>
<p>Now, this might look confusing at a first glance, but let me break it down.</p>
<p>Across the dataset, do samples with <strong>higher entropy</strong> also have <strong>more errors</strong>?
This is why we calculate the sample-level correlation between them.</p>
<p>Note, that by doing this, we,</p>
<ul>
<li>Reward the model if higher entropy → more errors.</li>
<li>Penalizes it if higher entropy → more correct predictions.</li>
</ul>
<p>Essentially, if the model <strong>“knows when it is uncertain”</strong> (this is very handwavey), it gets a higher PSI.</p>
<p>We also include the accuracy in the calculation, as we want to penalize the model if it is affected by the perturbation.</p>
<h3 id="mapping-entropy-categorically">Mapping entropy categorically</h3>
<p>A very important part of this framework is that the input $\mathbf{x}$ is <strong>fixed</strong>.
Do images (given same perturbation level) with the <strong>same entropy</strong> yield similar predictions?</p>
<p>$$
p_{\sigma} = P(\hat{y_{\sigma}} = Y | H_{\sigma}(\mathbf{x}) = h), \quad \text{ where } h = H(\mathbf{x}).
$$</p>
<p>The function mapping $\mathbf{x}$ to $h$ can be understood as the probability of making a correct prediciton within all draws from the data, which have <strong>the same entropy as $\mathbf{x}$</strong>.</p>
<p>TO BE CONTINUED…</p>
<h1 id="conclusion">Conclusion</h1>
<p>This is a very brief overview of what we did in our thesis, and I hope that I have motivated why we did what we did.
I thought it was a very challenging but fun project, and I learned a lot from it.</p>
<p>Read the paper as well, we basically died writing it.</p>
<section data-footnotes="" class="footnotes"><h2 class="sr-only" id="footnote-label">Footnotes</h2>
<ol>
<li id="user-content-fn-1">
<p><a href="https://link.springer.com/book/10.1007/978-1-4612-0745-0">Radford M. Neal “Bayesian learning for neural networks.”</a> <a href="#user-content-fnref-1" data-footnote-backref="" aria-label="Back to reference 1" class="data-footnote-backref">↩</a></p>
</li>
<li id="user-content-fn-2">
<p><a href="https://www.cs.cmu.edu/~./epxing/Class/10715/reading/Rosenblatt.perceptron.pdf">Frank Rosenblatt. “The perceptron: a probabilistic model for information storage and organization in the brain.”</a> <a href="#user-content-fnref-2" data-footnote-backref="" aria-label="Back to reference 2" class="data-footnote-backref">↩</a></p>
</li>
<li id="user-content-fn-3">
<p><a href="https://www.nature.com/articles/323533a0">David E. Rumelhart, Geoffrey E. Hinton, Ronald J. Williams, “Learning representations by back-propagating errors.”</a> <a href="#user-content-fnref-3" data-footnote-backref="" aria-label="Back to reference 3" class="data-footnote-backref">↩</a></p>
</li>
<li id="user-content-fn-4">
<p><a href="https://karpathy.medium.com/yes-you-should-understand-backprop-e2f06eab496b">Andrej Karpathy, “Yes you should understand backprop.”</a> <a href="#user-content-fnref-4" data-footnote-backref="" aria-label="Back to reference 4" class="data-footnote-backref">↩</a></p>
</li>
<li id="user-content-fn-5">
<p><a href="https://ieeexplore.ieee.org/document/6773024">Claude E. Shannon, “A mathematical theory of communication.”</a> <a href="#user-content-fnref-5" data-footnote-backref="" aria-label="Back to reference 5" class="data-footnote-backref">↩</a></p>
</li>
</ol>
</section> <div class="mt-24"> <div class="grid grid-cols-2 gap-1.5 sm:gap-3"> <div class="invisible"></div> <div class="invisible"></div> </div> </div> <div class="mt-24"> <div class="giscus"></div> <script data-astro-rerun src="https://giscus.app/client.js" data-repo="rezaarezvan/rezvan.xyz" data-repo-id="R_kgDOHvQr3w" data-category="General" data-category-id="DIC_kwDOHvQr384CiWVC" data-mapping="pathname" data-strict="0" data-reactions-enabled="1" data-emit-metadata="0" data-input-position="bottom" data-theme="preferred_color_scheme" data-lang="en" data-loading="lazy" crossorigin="anonymous" async></script> </div> </article> </div>  </main> <footer class="animate"> <div class="mx-auto max-w-screen-sm px-3"> <div class="relative"> <div class="absolute -top-12 right-0"> <button id="back-to-top" class="group relative flex w-fit flex-nowrap rounded border border-black/15 py-1.5 pl-8 pr-3 transition-colors duration-300 ease-in-out hover:bg-black/5 hover:text-black focus-visible:bg-black/5 focus-visible:text-black dark:border-white/20 dark:hover:bg-white/5 dark:hover:text-white dark:focus-visible:bg-white/5 dark:focus-visible:text-white"> <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" class="absolute left-2 top-1/2 size-4 -translate-y-1/2 rotate-90 fill-none stroke-current stroke-2"> <line x1="5" y1="12" x2="19" y2="12" class="translate-x-2 scale-x-0 transition-transform duration-300 ease-in-out group-hover:translate-x-0 group-hover:scale-x-100 group-focus-visible:translate-x-0 group-focus-visible:scale-x-100"></line> <polyline points="12 5 5 12 12 19" class="translate-x-1 transition-transform duration-300 ease-in-out group-hover:translate-x-0 group-focus-visible:translate-x-0"></polyline> </svg> <div class="text-sm">Back to top</div> </button> </div> </div> <div class="flex items-center justify-between"> <div>&copy; 2024 • rezarezvan.com</div> <div class="flex flex-wrap items-center gap-1.5"></div> </div> </div> </footer> <aside data-pagefind-ignore> <div id="backdrop" class="bg-[rgba(0, 0, 0, 0.5] invisible fixed left-0 top-0 z-50 flex h-screen w-full justify-center p-6 backdrop-blur-sm" data-astro-transition-persist="astro-3snakcvo-2"> <div id="pagefind-container" class="m-0 flex h-fit max-h-[80%] w-full max-w-screen-sm flex-col overflow-auto rounded border border-black/15 bg-neutral-100 p-2 px-4 py-3 shadow-lg dark:border-white/20 dark:bg-neutral-900"> <div id="search" class="pagefind-ui pagefind-init" data-pagefind-ui data-bundle-path="/pagefind/" data-ui-options="{&#34;showImages&#34;:false,&#34;excerptLength&#34;:15,&#34;resetStyles&#34;:false}"></div> <script type="module" src="/_astro/Search.astro_astro_type_script_index_0_lang.BoThSDgl.js"></script> <div class="mr-2 pb-1 pt-4 text-right text-xs dark:prose-invert">
Press <span class="prose text-xs dark:prose-invert"><kbd class="">Esc</kbd></span> or click anywhere to close
</div> </div> </div> </aside> <script>
  const magnifyingGlass = document.getElementById("magnifying-glass");
  const backdrop = document.getElementById("backdrop");

  function openPagefind() {
    const searchDiv = document.getElementById("search");
    const search = searchDiv.querySelector("input");
    setTimeout(() => {
      search.focus();
    }, 0);
    backdrop?.classList.remove("invisible");
    backdrop?.classList.add("visible");
  }

  function closePagefind() {
    const search = document.getElementById("search");
    search.value = "";
    backdrop?.classList.remove("visible");
    backdrop?.classList.add("invisible");
  }

  // open pagefind
  magnifyingGlass?.addEventListener("click", () => {
    openPagefind();
  });

  document.addEventListener("keydown", (e) => {
    if (e.key === "/") {
      e.preventDefault();
      openPagefind();
    } else if ((e.metaKey || e.ctrlKey) && e.key === "k") {
      e.preventDefault();
      openPagefind();
    }
  });

  // close pagefind
  document.addEventListener("keydown", (e) => {
    if (e.key === "Escape" || e.keyCode === 27) {
      closePagefind();
    }
  });

  // close pagefind when searched result(link) clicked
  document.addEventListener("click", (event) => {
    if (event.target.classList.contains("pagefind-ui__result-link")) {
      closePagefind();
    }
  });

  backdrop?.addEventListener("click", (event) => {
    if (!event.target.closest("#pagefind-container")) {
      closePagefind();
    }
  });

  // prevent form submission
  const form = document.getElementById("form");
  form?.addEventListener("submit", (event) => {
    event.preventDefault();
  });
</script>  </body></html>