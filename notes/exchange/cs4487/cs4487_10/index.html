<!DOCTYPE html><html class="bg-background text-foreground" lang="en"> <head><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes"><meta name="generator" content="Astro v5.13.5"><meta name="robots" content="index, follow"><meta name="HandheldFriendly" content="True"><meta name="mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="format-detection" content="telephone=no,date=no,address=no,email=no,url=no"><meta name="theme-color" content="#121212" media="(prefers-color-scheme: dark)"><meta name="theme-color" content="#121212" media="(prefers-color-scheme: light)"><link rel="sitemap" href="/sitemap-index.xml"><link rel="manifest" href="/site.webmanifest"><link rel="alternate" type="application/rss+xml" title="rezarezvan.com" href="https://rezarezvan.com/rss.xml"><!-- PageFind --><link href="/pagefind/pagefind-ui.css" rel="stylesheet"><script src="/pagefind/pagefind-ui.js"></script><!-- KaTeX support --><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.22/dist/katex.min.css" integrity="sha384-5TcZemv2l/9On385z///+d7MSYlvIEw9FuZTIdZ14vJLqWphw7e7ZPuOiCHJcFCP" crossorigin="anonymous"><script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.22/dist/katex.min.js" integrity="sha384-cMkvdD8LoxVzGF/RPUKAcvmm49FQ0oxwDF3BGKtDXcEc+T1b2N+teh/OJfpU0jr6" crossorigin="anonymous"></script><script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.22/dist/contrib/auto-render.min.js" integrity="sha384-hCXGrW6PitJEwbkoStFjeJxv+fSOOQKOPbJxSfM6G5sWZjAyWhXiTIIAmQqnlLlh" crossorigin="anonymous" onload="renderMathInElement(document.body);"></script><!-- inline KaTeX --><script>
    function renderKaTeX() {
      if (typeof renderMathInElement !== 'undefined') {
        renderMathInElement(document.body, {
          delimiters: [
            { left: '$$', right: '$$', display: true },
            { left: '$', right: '$', display: false },
          ],
        })
      }
    }

    document.addEventListener('DOMContentLoaded', renderKaTeX)
    document.addEventListener('astro:after-swap', renderKaTeX)
  </script><link rel="icon" type="image/png" href="/favicon-96x96.png" sizes="96x96"><link rel="icon" type="image/svg+xml" href="/favicon.ico"><link rel="shortcut icon" href="/favicon.ico"><link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png"><meta name="apple-mobile-web-app-title" content="rezvan-blog"><link rel="manifest" href="/site.webmanifest"><meta name="astro-view-transitions-enabled" content="true"><meta name="astro-view-transitions-fallback" content="animate"><script type="module" src="/_astro/ClientRouter.astro_astro_type_script_index_0_lang.DZnDNxNb.js"></script><script>
    function init() {
      setGiscusTheme()
    }

    const setGiscusTheme = () => {
      const giscus = document.querySelector('.giscus-frame')

      const isDark = document.documentElement.classList.contains('dark')

      if (giscus) {
        const url = new URL(giscus.src)
        url.searchParams.set('theme', isDark ? 'dark' : 'light')
        giscus.src = url.toString()
      }
    }

    document.addEventListener('DOMContentLoaded', () => init())
    document.addEventListener('astro:after-swap', () => init())
  </script><title>Part 10 - Neural Networks and Deep Learning Part 2 | rezarezvan.com</title><meta name="title" content="Part 10 - Neural Networks and Deep Learning Part 2 | rezarezvan.com"><meta name="description" content="Personal website and course notes repository"><link rel="canonical" href="https://rezarezvan.com"><meta name="robots" content="noindex"><meta property="og:title" content="Part 10 - Neural Networks and Deep Learning Part 2"><meta property="og:description" content="Personal website and course notes repository"><meta property="og:image" content="https://rezarezvan.com/static/1200x630.png"><meta property="og:image:alt" content="Part 10 - Neural Networks and Deep Learning Part 2"><meta property="og:type" content="website"><meta property="og:locale" content="en"><meta property="og:site_name" content="rezarezvan.com"><meta property="og:url" content="https://rezarezvan.com/notes/exchange/cs4487/cs4487_10/"><meta name="twitter:title" content="Part 10 - Neural Networks and Deep Learning Part 2"><meta name="twitter:description" content="Personal website and course notes repository"><meta property="twitter:image" content="https://rezarezvan.com/static/1200x630.png"><meta name="twitter:image:alt" content="Part 10 - Neural Networks and Deep Learning Part 2"><meta name="twitter:card" content="summary_large_image"><link rel="stylesheet" href="/_astro/_slug_.uFZ5-K9L.css"></head><body> <div class="flex h-fit min-h-screen flex-col gap-y-6 font-sans"> <div class="bg-background/50 sticky top-0 z-50 divide-y backdrop-blur-sm xl:divide-none"> <header data-astro-transition-persist="astro-l7r54iwe-1"> <div class="mx-auto flex max-w-3xl items-center justify-between gap-4 px-4 py-3"> <a href="/" target="_self" class="transition-colors duration-300 ease-in-out flex shrink-0 items-center justify-center gap-3">  <span class="hidden h-full text-lg font-medium min-[300px]:block">rezarezvan.com</span>  </a> <div class="flex items-center sm:gap-4"> <nav class="hidden items-center gap-4 text-sm sm:flex sm:gap-6"> <a href="/blog" target="_self" class="inline-block duration-300 ease-in-out hover:text-foreground/30 transition-colors"> blog<span>/</span>  </a><a href="/notes" target="_self" class="inline-block duration-300 ease-in-out hover:text-foreground/30 transition-colors"> notes<span>/</span>  </a><a href="/dump" target="_self" class="inline-block duration-300 ease-in-out hover:text-foreground/30 transition-colors"> dump<span>/</span>  </a><a href="/research" target="_self" class="inline-block duration-300 ease-in-out hover:text-foreground/30 transition-colors"> research<span>/</span>  </a><a href="/about" target="_self" class="inline-block duration-300 ease-in-out hover:text-foreground/30 transition-colors"> about<span>/</span>  </a> </nav> <button id="magnifying-glass" aria-label="Search" class="flex items-center px-2 text-sm transition-colors duration-300 ease-in-out hover:rounded hover:bg-black/5 hover:text-black focus-visible:bg-black/5 focus-visible:text-black dark:hover:bg-white/5 dark:hover:text-white dark:focus-visible:bg-white/5 dark:focus-visible:text-white"> <svg height="16" stroke-linejoin="round" viewBox="0 0 16 16" width="16" style="color: currentcolor;"> <path fill-rule="evenodd" clip-rule="evenodd" d="M3.5 7C3.5 5.067 5.067 3.5 7 3.5C8.933 3.5 10.5 5.067 10.5 7C10.5 7.88461 10.1718 8.69256 9.63058 9.30876L9.30876 9.63058C8.69256 10.1718 7.88461 10.5 7 10.5C5.067 10.5 3.5 8.933 3.5 7ZM9.96544 11.0261C9.13578 11.6382 8.11014 12 7 12C4.23858 12 2 9.76142 2 7C2 4.23858 4.23858 2 7 2C9.76142 2 12 4.23858 12 7C12 8.11014 11.6382 9.13578 11.0261 9.96544L14.0303 12.9697L14.5607 13.5L13.5 14.5607L12.9697 14.0303L9.96544 11.0261Z" fill="currentColor"></path> </svg>
&nbsp;Search
</button> <style>astro-island,astro-slot,astro-static-slot{display:contents}</style><script>(()=>{var e=async t=>{await(await t())()};(self.Astro||(self.Astro={})).load=e;window.dispatchEvent(new Event("astro:load"));})();</script><script>(()=>{var A=Object.defineProperty;var g=(i,o,a)=>o in i?A(i,o,{enumerable:!0,configurable:!0,writable:!0,value:a}):i[o]=a;var d=(i,o,a)=>g(i,typeof o!="symbol"?o+"":o,a);{let i={0:t=>m(t),1:t=>a(t),2:t=>new RegExp(t),3:t=>new Date(t),4:t=>new Map(a(t)),5:t=>new Set(a(t)),6:t=>BigInt(t),7:t=>new URL(t),8:t=>new Uint8Array(t),9:t=>new Uint16Array(t),10:t=>new Uint32Array(t),11:t=>1/0*t},o=t=>{let[l,e]=t;return l in i?i[l](e):void 0},a=t=>t.map(o),m=t=>typeof t!="object"||t===null?t:Object.fromEntries(Object.entries(t).map(([l,e])=>[l,o(e)]));class y extends HTMLElement{constructor(){super(...arguments);d(this,"Component");d(this,"hydrator");d(this,"hydrate",async()=>{var b;if(!this.hydrator||!this.isConnected)return;let e=(b=this.parentElement)==null?void 0:b.closest("astro-island[ssr]");if(e){e.addEventListener("astro:hydrate",this.hydrate,{once:!0});return}let c=this.querySelectorAll("astro-slot"),n={},h=this.querySelectorAll("template[data-astro-template]");for(let r of h){let s=r.closest(this.tagName);s!=null&&s.isSameNode(this)&&(n[r.getAttribute("data-astro-template")||"default"]=r.innerHTML,r.remove())}for(let r of c){let s=r.closest(this.tagName);s!=null&&s.isSameNode(this)&&(n[r.getAttribute("name")||"default"]=r.innerHTML)}let p;try{p=this.hasAttribute("props")?m(JSON.parse(this.getAttribute("props"))):{}}catch(r){let s=this.getAttribute("component-url")||"<unknown>",v=this.getAttribute("component-export");throw v&&(s+=` (export ${v})`),console.error(`[hydrate] Error parsing props for component ${s}`,this.getAttribute("props"),r),r}let u;await this.hydrator(this)(this.Component,p,n,{client:this.getAttribute("client")}),this.removeAttribute("ssr"),this.dispatchEvent(new CustomEvent("astro:hydrate"))});d(this,"unmount",()=>{this.isConnected||this.dispatchEvent(new CustomEvent("astro:unmount"))})}disconnectedCallback(){document.removeEventListener("astro:after-swap",this.unmount),document.addEventListener("astro:after-swap",this.unmount,{once:!0})}connectedCallback(){if(!this.hasAttribute("await-children")||document.readyState==="interactive"||document.readyState==="complete")this.childrenConnectedCallback();else{let e=()=>{document.removeEventListener("DOMContentLoaded",e),c.disconnect(),this.childrenConnectedCallback()},c=new MutationObserver(()=>{var n;((n=this.lastChild)==null?void 0:n.nodeType)===Node.COMMENT_NODE&&this.lastChild.nodeValue==="astro:end"&&(this.lastChild.remove(),e())});c.observe(this,{childList:!0}),document.addEventListener("DOMContentLoaded",e)}}async childrenConnectedCallback(){let e=this.getAttribute("before-hydration-url");e&&await import(e),this.start()}async start(){let e=JSON.parse(this.getAttribute("opts")),c=this.getAttribute("client");if(Astro[c]===void 0){window.addEventListener(`astro:${c}`,()=>this.start(),{once:!0});return}try{await Astro[c](async()=>{let n=this.getAttribute("renderer-url"),[h,{default:p}]=await Promise.all([import(this.getAttribute("component-url")),n?import(n):()=>()=>{}]),u=this.getAttribute("component-export")||"default";if(!u.includes("."))this.Component=h[u];else{this.Component=h;for(let f of u.split("."))this.Component=this.Component[f]}return this.hydrator=p,this.hydrate},e,this)}catch(n){console.error(`[astro-island] Error hydrating ${this.getAttribute("component-url")}`,n)}}attributeChangedCallback(){this.hydrate()}}d(y,"observedAttributes",["props"]),customElements.get("astro-island")||customElements.define("astro-island",y)}})();</script><astro-island uid="Z1H5Gng" prefix="r19" component-url="/_astro/mobile-menu.BeUb9wJC.js" component-export="default" renderer-url="/_astro/client.CVI9NSBG.js" props="{&quot;data-astro-transition-persist&quot;:[0,&quot;astro-iq5tym4z-2&quot;]}" ssr client="load" opts="{&quot;name&quot;:&quot;MobileMenu&quot;,&quot;value&quot;:true}" data-astro-transition-persist="astro-iq5tym4z-2" await-children><button data-slot="dropdown-menu-trigger" class="inline-flex items-center justify-center gap-2 whitespace-nowrap rounded-md text-sm font-medium transition-all disabled:pointer-events-none disabled:opacity-50 [&amp;_svg]:pointer-events-none [&amp;_svg:not([class*=&#x27;size-&#x27;])]:size-4 shrink-0 [&amp;_svg]:shrink-0 outline-none focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:ring-[3px] aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive hover:bg-accent hover:text-accent-foreground dark:hover:bg-accent/50 size-9 md:hidden" title="Menu" type="button" id="radix-:r19R0:" aria-haspopup="menu" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-menu h-5 w-5"><line x1="4" x2="20" y1="12" y2="12"></line><line x1="4" x2="20" y1="6" y2="6"></line><line x1="4" x2="20" y1="18" y2="18"></line></svg><span class="sr-only">Toggle menu</span></button><!--astro:end--></astro-island> <button data-slot="button" class="inline-flex items-center justify-center gap-2 whitespace-nowrap rounded-md text-sm font-medium transition-all disabled:pointer-events-none disabled:opacity-50 [&amp;_svg]:pointer-events-none [&amp;_svg:not([class*=&#x27;size-&#x27;])]:size-4 shrink-0 [&amp;_svg]:shrink-0 outline-none focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:ring-[3px] aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive hover:bg-accent hover:text-accent-foreground dark:hover:bg-accent/50 size-9" id="theme-toggle" title="Toggle theme"> <svg width="1em" height="1em" class="size-4 scale-100 rotate-0 transition-all dark:scale-0 dark:-rotate-90" data-icon="lucide:sun">   <symbol id="ai:lucide:sun" viewBox="0 0 24 24"><g fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2"><circle cx="12" cy="12" r="4"/><path d="M12 2v2m0 16v2M4.93 4.93l1.41 1.41m11.32 11.32l1.41 1.41M2 12h2m16 0h2M6.34 17.66l-1.41 1.41M19.07 4.93l-1.41 1.41"/></g></symbol><use href="#ai:lucide:sun"></use>  </svg> <svg width="1em" height="1em" class="absolute size-4 scale-0 rotate-90 transition-all dark:scale-100 dark:rotate-0" data-icon="lucide:moon">   <symbol id="ai:lucide:moon" viewBox="0 0 24 24"><path fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M20.985 12.486a9 9 0 1 1-9.473-9.472c.405-.022.617.46.402.803a6 6 0 0 0 8.268 8.268c.344-.215.825-.004.803.401"/></symbol><use href="#ai:lucide:moon"></use>  </svg> <span class="sr-only">Toggle theme</span> </button> <script data-astro-rerun>
  const theme = (() => {
    const localStorageTheme = localStorage?.getItem('theme') ?? ''
    if (['dark', 'light'].includes(localStorageTheme)) {
      return localStorageTheme
    }
    if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
      return 'dark'
    }
    return 'light'
  })()

  document.documentElement.setAttribute('data-theme', theme)
  document.documentElement.classList.add(
    theme === 'dark' ? 'scheme-dark' : 'scheme-light',
  )
  window.localStorage.setItem('theme', theme)
</script> <script type="module">function a(){const e=document.documentElement,n=e.getAttribute("data-theme")==="dark"?"light":"dark";e.classList.add("[&_*]:transition-none"),e.setAttribute("data-theme",n),e.classList.remove("scheme-dark","scheme-light"),e.classList.add(n==="dark"?"scheme-dark":"scheme-light"),window.getComputedStyle(e).getPropertyValue("opacity"),requestAnimationFrame(()=>{e.classList.remove("[&_*]:transition-none")}),localStorage.setItem("theme",n)}function s(){const e=document.getElementById("theme-toggle");e&&e.addEventListener("click",a)}s();document.addEventListener("astro:after-swap",()=>{const e=localStorage.getItem("theme")||"light",t=document.documentElement;t.classList.add("[&_*]:transition-none"),window.getComputedStyle(t).getPropertyValue("opacity"),t.setAttribute("data-theme",e),t.classList.remove("scheme-dark","scheme-light"),t.classList.add(e==="dark"?"scheme-dark":"scheme-light"),requestAnimationFrame(()=>{t.classList.remove("[&_*]:transition-none")}),s()});</script> </div> </div> </header> <div id="mobile-toc-container" class="w-full xl:hidden"><details class="group"><summary class="flex w-full cursor-pointer items-center justify-between"><div class="mx-auto flex w-full max-w-3xl items-center px-4 py-3"><div class="relative mr-2 size-4"><svg class="h-4 w-4" viewBox="0 0 24 24"><circle class="text-primary/20" cx="12" cy="12" r="10" fill="none" stroke="currentColor" stroke-width="2"></circle><circle id="mobile-toc-progress-circle" class="text-primary" cx="12" cy="12" r="10" fill="none" stroke="currentColor" stroke-width="2" stroke-dasharray="62.83" stroke-dashoffset="62.83" transform="rotate(-90 12 12)"></circle></svg></div><span id="mobile-toc-current-section" class="text-muted-foreground flex-grow truncate text-sm">
Overview
</span><span class="text-muted-foreground ml-2"><svg width="1em" height="1em" class="h-4 w-4 transition-transform duration-200 group-open:rotate-180" data-icon="lucide:chevron-down">   <symbol id="ai:lucide:chevron-down" viewBox="0 0 24 24"><path fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="m6 9l6 6l6-6"/></symbol><use href="#ai:lucide:chevron-down"></use>  </svg></span></div></summary><astro-island uid="1ipBT7" prefix="r31" component-url="/_astro/scroll-area.IQqQpc_6.js" component-export="ScrollArea" renderer-url="/_astro/client.CVI9NSBG.js" props="{&quot;className&quot;:[0,&quot;mx-auto max-w-3xl&quot;],&quot;data-toc-header-scroll&quot;:[0,true]}" ssr client="load" opts="{&quot;name&quot;:&quot;ScrollArea&quot;,&quot;value&quot;:true}" await-children><div dir="ltr" data-slot="scroll-area" class="relative mx-auto max-w-3xl" data-toc-header-scroll="true" style="position:relative;--radix-scroll-area-corner-width:0px;--radix-scroll-area-corner-height:0px"><style>[data-radix-scroll-area-viewport]{scrollbar-width:none;-ms-overflow-style:none;-webkit-overflow-scrolling:touch;}[data-radix-scroll-area-viewport]::-webkit-scrollbar{display:none}</style><div data-radix-scroll-area-viewport="" data-slot="scroll-area-viewport" class="ring-ring/10 dark:ring-ring/20 dark:outline-ring/40 outline-ring/50 size-full rounded-[inherit] transition-[color,box-shadow] focus-visible:ring-4 focus-visible:outline-1" style="overflow-x:hidden;overflow-y:hidden"><div style="min-width:100%;display:table"><astro-slot><div class="max-h-[30vh]"><ul class="flex list-none flex-col gap-y-2 px-4 pb-4" id="mobile-table-of-contents"><li class="px-4 text-sm ml-4 text-foreground/60"><a href="#training-deep-neural-networks" class="mobile-toc-item underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit" data-heading-id="training-deep-neural-networks">Training Deep Neural Networks</a></li><li class="px-4 text-sm ml-8 text-foreground/60"><a href="#gradient-descent-gd" class="mobile-toc-item underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit" data-heading-id="gradient-descent-gd">Gradient Descent (GD)</a></li><li class="px-4 text-sm ml-8 text-foreground/60"><a href="#stochastic-gradient-descent-sgd" class="mobile-toc-item underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit" data-heading-id="stochastic-gradient-descent-sgd">Stochastic Gradient Descent (SGD)</a></li><li class="px-4 text-sm ml-4 text-foreground/60"><a href="#optimization-techniques" class="mobile-toc-item underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit" data-heading-id="optimization-techniques">Optimization Techniques</a></li><li class="px-4 text-sm ml-8 text-foreground/60"><a href="#more-problems-with-sgd" class="mobile-toc-item underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit" data-heading-id="more-problems-with-sgd">More Problems with SGD</a></li><li class="px-4 text-sm ml-8 text-foreground/60"><a href="#momentum" class="mobile-toc-item underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit" data-heading-id="momentum">Momentum</a></li><li class="px-4 text-sm ml-12 text-foreground/60"><a href="#sgd-with-momentum" class="mobile-toc-item underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit" data-heading-id="sgd-with-momentum">SGD with Momentum</a></li><li class="px-4 text-sm ml-8 text-foreground/60"><a href="#nesterov-momentum" class="mobile-toc-item underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit" data-heading-id="nesterov-momentum">Nesterov Momentum</a></li><li class="px-4 text-sm ml-12 text-foreground/60"><a href="#sgd-with-nesterov-momentum" class="mobile-toc-item underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit" data-heading-id="sgd-with-nesterov-momentum">SGD with Nesterov Momentum</a></li><li class="px-4 text-sm ml-8 text-foreground/60"><a href="#adaptive-learning-rate-methods" class="mobile-toc-item underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit" data-heading-id="adaptive-learning-rate-methods">Adaptive Learning Rate Methods</a></li><li class="px-4 text-sm ml-12 text-foreground/60"><a href="#adagrad" class="mobile-toc-item underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit" data-heading-id="adagrad">AdaGrad</a></li><li class="px-4 text-sm ml-8 text-foreground/60"><a href="#rmsprop-leaky-adagrad" class="mobile-toc-item underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit" data-heading-id="rmsprop-leaky-adagrad">RMSProp: “Leaky AdaGrad”</a></li><li class="px-4 text-sm ml-8 text-foreground/60"><a href="#adam-adaptive-moments" class="mobile-toc-item underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit" data-heading-id="adam-adaptive-moments">Adam: ADAptive Moments</a></li><li class="px-4 text-sm ml-8 text-foreground/60"><a href="#adamw-adaptive-moments-with-weight-decay" class="mobile-toc-item underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit" data-heading-id="adamw-adaptive-moments-with-weight-decay">AdamW: ADAptive Moments with Weight Decay</a></li><li class="px-4 text-sm ml-8 text-foreground/60"><a href="#other-emerging-optimization-techniques" class="mobile-toc-item underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit" data-heading-id="other-emerging-optimization-techniques">Other Emerging Optimization Techniques</a></li><li class="px-4 text-sm ml-4 text-foreground/60"><a href="#regularization" class="mobile-toc-item underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit" data-heading-id="regularization">Regularization</a></li><li class="px-4 text-sm ml-8 text-foreground/60"><a href="#data-augmentation" class="mobile-toc-item underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit" data-heading-id="data-augmentation">Data Augmentation</a></li><li class="px-4 text-sm ml-8 text-foreground/60"><a href="#emerging-data-augmentation-techniques" class="mobile-toc-item underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit" data-heading-id="emerging-data-augmentation-techniques">Emerging Data Augmentation Techniques</a></li><li class="px-4 text-sm ml-8 text-foreground/60"><a href="#other-regularization-techniques" class="mobile-toc-item underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit" data-heading-id="other-regularization-techniques">Other Regularization Techniques</a></li><li class="px-4 text-sm ml-12 text-foreground/60"><a href="#early-stopping" class="mobile-toc-item underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit" data-heading-id="early-stopping">Early Stopping</a></li><li class="px-4 text-sm ml-12 text-foreground/60"><a href="#dropout" class="mobile-toc-item underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit" data-heading-id="dropout">Dropout</a></li><li class="px-4 text-sm ml-12 text-foreground/60"><a href="#dropout-at-test-time" class="mobile-toc-item underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit" data-heading-id="dropout-at-test-time">Dropout at Test Time</a></li><li class="px-4 text-sm ml-8 text-foreground/60"><a href="#stochastic-depth" class="mobile-toc-item underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit" data-heading-id="stochastic-depth">Stochastic Depth</a></li><li class="px-4 text-sm ml-8 text-foreground/60"><a href="#batch-normalization" class="mobile-toc-item underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit" data-heading-id="batch-normalization">Batch Normalization</a></li><li class="px-4 text-sm ml-12 text-foreground/60"><a href="#batch-normalization-at-test-time" class="mobile-toc-item underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit" data-heading-id="batch-normalization-at-test-time">Batch Normalization at Test Time</a></li><li class="px-4 text-sm ml-8 text-foreground/60"><a href="#layer-normalization" class="mobile-toc-item underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit" data-heading-id="layer-normalization">Layer Normalization</a></li><li class="px-4 text-sm ml-8 text-foreground/60"><a href="#group-normalization" class="mobile-toc-item underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit" data-heading-id="group-normalization">Group Normalization</a></li><li class="px-4 text-sm ml-4 text-foreground/60"><a href="#practical-tricks--tips" class="mobile-toc-item underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit" data-heading-id="practical-tricks--tips">Practical Tricks &amp; Tips</a></li><li class="px-4 text-sm ml-8 text-foreground/60"><a href="#data--pre-procesing" class="mobile-toc-item underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit" data-heading-id="data--pre-procesing">Data  Pre-Procesing</a></li><li class="px-4 text-sm ml-12 text-foreground/60"><a href="#pca-as-whitening" class="mobile-toc-item underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit" data-heading-id="pca-as-whitening">PCA as Whitening</a></li><li class="px-4 text-sm ml-8 text-foreground/60"><a href="#weight-initialization" class="mobile-toc-item underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit" data-heading-id="weight-initialization">Weight Initialization</a></li><li class="px-4 text-sm ml-8 text-foreground/60"><a href="#learning-rate-decay" class="mobile-toc-item underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit" data-heading-id="learning-rate-decay">Learning Rate Decay</a></li><li class="px-4 text-sm ml-8 text-foreground/60"><a href="#transfer-learning" class="mobile-toc-item underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit" data-heading-id="transfer-learning">Transfer Learning</a></li><li class="px-4 text-sm ml-8 text-foreground/60"><a href="#choosing-hyperparameters" class="mobile-toc-item underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit" data-heading-id="choosing-hyperparameters">Choosing Hyperparameters</a></li><li class="px-4 text-sm ml-4 text-foreground/60"><a href="#summary" class="mobile-toc-item underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit" data-heading-id="summary">Summary</a></li></ul></div></astro-slot></div></div></div><!--astro:end--></astro-island></details></div><script type="module" src="/_astro/TOCHeader.astro_astro_type_script_index_0_lang.CKMLAwWj.js"></script>   </div> <main class="grow"> <div class="mx-auto flex grow flex-col gap-y-6 px-4">   <section class="grid grid-cols-[minmax(0px,1fr)_min(calc(var(--breakpoint-md)-2rem),100%)_minmax(0px,1fr)] gap-y-6"> <div class="col-start-2"> <nav aria-label="breadcrumb" data-slot="breadcrumb"> <ol data-slot="breadcrumb-list" class="text-muted-foreground flex flex-wrap items-center gap-1.5 text-sm break-words sm:gap-2.5"> <li data-slot="breadcrumb-item" class="inline-flex items-center gap-1.5"> <a data-slot="breadcrumb-link" class="hover:text-foreground transition-colors" href="/"> <svg width="1em" height="1em" class="size-4 shrink-0" data-icon="lucide:home">   <symbol id="ai:lucide:home" viewBox="0 0 24 24"><g fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2"><path d="M15 21v-8a1 1 0 0 0-1-1h-4a1 1 0 0 0-1 1v8"/><path d="M3 10a2 2 0 0 1 .709-1.528l7-5.999a2 2 0 0 1 2.582 0l7 5.999A2 2 0 0 1 21 10v9a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2z"/></g></symbol><use href="#ai:lucide:home"></use>  </svg> </a> </li>  <li data-slot="breadcrumb-separator" role="presentation" aria-hidden="true" class="[&amp;&gt;svg]:size-3.5"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-chevron-right"><path d="m9 18 6-6-6-6"></path></svg></li> <li data-slot="breadcrumb-item" class="inline-flex items-center gap-1.5"><a data-slot="breadcrumb-link" class="hover:text-foreground transition-colors" href="/notes/"> <span class="flex items-center gap-x-2"> <svg width="1em" height="1em" class="size-4" data-icon="lucide:graduation-cap">   <symbol id="ai:lucide:graduation-cap" viewBox="0 0 24 24"><g fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2"><path d="M21.42 10.922a1 1 0 0 0-.019-1.838L12.83 5.18a2 2 0 0 0-1.66 0L2.6 9.08a1 1 0 0 0 0 1.832l8.57 3.908a2 2 0 0 0 1.66 0zM22 10v6"/><path d="M6 12.5V16a6 3 0 0 0 12 0v-3.5"/></g></symbol><use href="#ai:lucide:graduation-cap"></use>  </svg> Exchange </span> </a></li>  <li data-slot="breadcrumb-separator" role="presentation" aria-hidden="true" class="[&amp;&gt;svg]:size-3.5"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-chevron-right"><path d="m9 18 6-6-6-6"></path></svg></li> <li data-slot="breadcrumb-item" class="inline-flex items-center gap-1.5"><a data-slot="breadcrumb-link" class="hover:text-foreground transition-colors" href="/notes/exchange/cs4487"> <span class="flex items-center gap-x-2"> <svg width="1em" height="1em" class="size-4" data-icon="lucide:book-open">   <symbol id="ai:lucide:book-open" viewBox="0 0 24 24"><path fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M12 7v14m-9-3a1 1 0 0 1-1-1V4a1 1 0 0 1 1-1h5a4 4 0 0 1 4 4a4 4 0 0 1 4-4h5a1 1 0 0 1 1 1v13a1 1 0 0 1-1 1h-6a3 3 0 0 0-3 3a3 3 0 0 0-3-3z"/></symbol><use href="#ai:lucide:book-open"></use>  </svg> Machine Learning </span> </a></li>  <li data-slot="breadcrumb-separator" role="presentation" aria-hidden="true" class="[&amp;&gt;svg]:size-3.5"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-chevron-right"><path d="m9 18 6-6-6-6"></path></svg></li> <li data-slot="breadcrumb-item" class="inline-flex items-center gap-1.5"><span data-slot="breadcrumb-page" role="link" aria-disabled="true" aria-current="page" class="text-foreground font-normal"> <span class="flex items-center gap-x-2"> <svg width="1em" height="1em" class="size-4 shrink-0" data-icon="lucide:file-text">   <symbol id="ai:lucide:file-text" viewBox="0 0 24 24"><g fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2"><path d="M15 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V7Z"/><path d="M14 2v4a2 2 0 0 0 2 2h4M10 9H8m8 4H8m8 4H8"/></g></symbol><use href="#ai:lucide:file-text"></use>  </svg> <span>Part 10 - Neural Networks and Deep Learning Part 2</span> </span> </span></li> </ol> </nav> </div>  <section class="col-start-2 flex flex-col gap-y-6 text-center"> <div class="flex flex-col"> <h1 class="mb-2 scroll-mt-31 text-4xl leading-tight font-medium text-pretty" id="post-title"> Part 10 - Neural Networks and Deep Learning Part 2 </h1> <div class="text-muted-foreground mb-4 flex flex-wrap items-center justify-center gap-2 text-sm"> <div class="flex items-center gap-2"> <span data-slot="badge" class="inline-flex items-center justify-center rounded-md border px-2 py-0.5 text-xs font-medium w-fit whitespace-nowrap shrink-0 [&amp;&gt;svg]:size-3 gap-1 [&amp;&gt;svg]:pointer-events-none focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:ring-[3px] aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive transition-[color,box-shadow] overflow-hidden text-foreground [a&amp;]:hover:bg-accent [a&amp;]:hover:text-accent-foreground">CS4487</span> <div data-orientation="vertical" role="none" data-slot="separator-root" class="bg-border red shrink-0 data-[orientation=horizontal]:h-px data-[orientation=horizontal]:w-full data-[orientation=vertical]:h-full data-[orientation=vertical]:w-px h-4!"></div> <span>Date: November 13, 2024</span> <div data-orientation="vertical" role="none" data-slot="separator-root" class="bg-border red shrink-0 data-[orientation=horizontal]:h-px data-[orientation=horizontal]:w-full data-[orientation=vertical]:h-full data-[orientation=vertical]:w-px h-4!"></div>  <div class="font-base text-sm">
Last modified: July 10, 2025 </div>  <div data-orientation="vertical" role="none" data-slot="separator-root" class="bg-border red shrink-0 data-[orientation=horizontal]:h-px data-[orientation=horizontal]:w-full data-[orientation=vertical]:h-full data-[orientation=vertical]:w-px h-4!"></div> <span>21 min read</span> </div> </div> </div> <nav class="col-start-2 grid grid-cols-1 gap-4 sm:grid-cols-2"> <a href="/notes/exchange/cs4487/cs4487_9" target="_self" class="duration-300 ease-in-out gap-2 whitespace-nowrap text-sm font-medium transition-all disabled:pointer-events-none disabled:opacity-50 [&#38;_svg]:pointer-events-none [&#38;_svg:not([class*='size-'])]:size-4 shrink-0 [&#38;_svg]:shrink-0 outline-none focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:ring-[3px] aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive border bg-background shadow-xs hover:bg-accent hover:text-accent-foreground dark:bg-input/30 dark:border-input dark:hover:bg-input/50 px-4 py-2 has-[>svg]:px-3 rounded-lg group flex items-center justify-start size-full" aria-disabled="false">  <svg width="1em" height="1em" class="mr-2 size-4 transition-transform group-hover:-translate-x-1" data-icon="lucide:arrow-left">   <symbol id="ai:lucide:arrow-left" viewBox="0 0 24 24"><path fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="m12 19l-7-7l7-7m7 7H5"/></symbol><use href="#ai:lucide:arrow-left"></use>  </svg> <div class="flex flex-col items-start overflow-hidden text-wrap"> <span class="text-muted-foreground text-left text-xs"> Previous Post </span> <span class="w-full text-left text-sm text-balance text-ellipsis"> Part 9 - Neural Networks and Deep Learning </span> </div>  </a>  <a href="/notes/exchange/cs4487/cs4487_11" target="_self" class="duration-300 ease-in-out gap-2 whitespace-nowrap text-sm font-medium transition-all disabled:pointer-events-none disabled:opacity-50 [&#38;_svg]:pointer-events-none [&#38;_svg:not([class*='size-'])]:size-4 shrink-0 [&#38;_svg]:shrink-0 outline-none focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:ring-[3px] aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive border bg-background shadow-xs hover:bg-accent hover:text-accent-foreground dark:bg-input/30 dark:border-input dark:hover:bg-input/50 px-4 py-2 has-[>svg]:px-3 rounded-lg group flex items-center justify-end size-full" aria-disabled="false">  <div class="flex flex-col items-end overflow-hidden text-wrap"> <span class="text-muted-foreground text-right text-xs"> Next Post </span> <span class="w-full text-right text-sm text-balance text-ellipsis"> Part 11 - High-Level and Low-Level Vision Applications </span> </div> <svg width="1em" height="1em" class="ml-2 size-4 transition-transform group-hover:translate-x-1" data-icon="lucide:arrow-right">   <symbol id="ai:lucide:arrow-right" viewBox="0 0 24 24"><path fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M5 12h14m-7-7l7 7l-7 7"/></symbol><use href="#ai:lucide:arrow-right"></use>  </svg>  </a> </nav> </section> <div id="toc-sidebar-container" class="sticky top-20 col-start-1 row-span-1 mr-8 ml-auto hidden h-[calc(100vh-5rem)] max-w-md xl:block"><astro-island uid="1wShvc" prefix="r21" component-url="/_astro/scroll-area.IQqQpc_6.js" component-export="ScrollArea" renderer-url="/_astro/client.CVI9NSBG.js" props="{&quot;className&quot;:[0,&quot;flex max-h-[calc(100vh-8rem)] flex-col overflow-y-auto&quot;],&quot;type&quot;:[0,&quot;hover&quot;],&quot;data-toc-scroll-area&quot;:[0,true]}" ssr client="load" opts="{&quot;name&quot;:&quot;ScrollArea&quot;,&quot;value&quot;:true}" await-children><div dir="ltr" data-slot="scroll-area" class="relative flex max-h-[calc(100vh-8rem)] flex-col overflow-y-auto" data-toc-scroll-area="true" style="position:relative;--radix-scroll-area-corner-width:0px;--radix-scroll-area-corner-height:0px"><style>[data-radix-scroll-area-viewport]{scrollbar-width:none;-ms-overflow-style:none;-webkit-overflow-scrolling:touch;}[data-radix-scroll-area-viewport]::-webkit-scrollbar{display:none}</style><div data-radix-scroll-area-viewport="" data-slot="scroll-area-viewport" class="ring-ring/10 dark:ring-ring/20 dark:outline-ring/40 outline-ring/50 size-full rounded-[inherit] transition-[color,box-shadow] focus-visible:ring-4 focus-visible:outline-1" style="overflow-x:hidden;overflow-y:hidden"><div style="min-width:100%;display:table"><astro-slot><div class="flex flex-col gap-2 px-4"><span class="text-lg font-medium">Table of Contents</span><ul class="flex list-none flex-col gap-y-2"><li class="text-sm ml-4 text-foreground/60"><a href="#training-deep-neural-networks" class="marker:text-foreground/30 list-none underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit" data-heading-link="training-deep-neural-networks">Training Deep Neural Networks</a></li><li class="text-sm ml-8 text-foreground/60"><a href="#gradient-descent-gd" class="marker:text-foreground/30 list-none underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit" data-heading-link="gradient-descent-gd">Gradient Descent (GD)</a></li><li class="text-sm ml-8 text-foreground/60"><a href="#stochastic-gradient-descent-sgd" class="marker:text-foreground/30 list-none underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit" data-heading-link="stochastic-gradient-descent-sgd">Stochastic Gradient Descent (SGD)</a></li><li class="text-sm ml-4 text-foreground/60"><a href="#optimization-techniques" class="marker:text-foreground/30 list-none underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit" data-heading-link="optimization-techniques">Optimization Techniques</a></li><li class="text-sm ml-8 text-foreground/60"><a href="#more-problems-with-sgd" class="marker:text-foreground/30 list-none underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit" data-heading-link="more-problems-with-sgd">More Problems with SGD</a></li><li class="text-sm ml-8 text-foreground/60"><a href="#momentum" class="marker:text-foreground/30 list-none underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit" data-heading-link="momentum">Momentum</a></li><li class="text-sm ml-12 text-foreground/60"><a href="#sgd-with-momentum" class="marker:text-foreground/30 list-none underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit" data-heading-link="sgd-with-momentum">SGD with Momentum</a></li><li class="text-sm ml-8 text-foreground/60"><a href="#nesterov-momentum" class="marker:text-foreground/30 list-none underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit" data-heading-link="nesterov-momentum">Nesterov Momentum</a></li><li class="text-sm ml-12 text-foreground/60"><a href="#sgd-with-nesterov-momentum" class="marker:text-foreground/30 list-none underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit" data-heading-link="sgd-with-nesterov-momentum">SGD with Nesterov Momentum</a></li><li class="text-sm ml-8 text-foreground/60"><a href="#adaptive-learning-rate-methods" class="marker:text-foreground/30 list-none underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit" data-heading-link="adaptive-learning-rate-methods">Adaptive Learning Rate Methods</a></li><li class="text-sm ml-12 text-foreground/60"><a href="#adagrad" class="marker:text-foreground/30 list-none underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit" data-heading-link="adagrad">AdaGrad</a></li><li class="text-sm ml-8 text-foreground/60"><a href="#rmsprop-leaky-adagrad" class="marker:text-foreground/30 list-none underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit" data-heading-link="rmsprop-leaky-adagrad">RMSProp: “Leaky AdaGrad”</a></li><li class="text-sm ml-8 text-foreground/60"><a href="#adam-adaptive-moments" class="marker:text-foreground/30 list-none underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit" data-heading-link="adam-adaptive-moments">Adam: ADAptive Moments</a></li><li class="text-sm ml-8 text-foreground/60"><a href="#adamw-adaptive-moments-with-weight-decay" class="marker:text-foreground/30 list-none underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit" data-heading-link="adamw-adaptive-moments-with-weight-decay">AdamW: ADAptive Moments with Weight Decay</a></li><li class="text-sm ml-8 text-foreground/60"><a href="#other-emerging-optimization-techniques" class="marker:text-foreground/30 list-none underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit" data-heading-link="other-emerging-optimization-techniques">Other Emerging Optimization Techniques</a></li><li class="text-sm ml-4 text-foreground/60"><a href="#regularization" class="marker:text-foreground/30 list-none underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit" data-heading-link="regularization">Regularization</a></li><li class="text-sm ml-8 text-foreground/60"><a href="#data-augmentation" class="marker:text-foreground/30 list-none underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit" data-heading-link="data-augmentation">Data Augmentation</a></li><li class="text-sm ml-8 text-foreground/60"><a href="#emerging-data-augmentation-techniques" class="marker:text-foreground/30 list-none underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit" data-heading-link="emerging-data-augmentation-techniques">Emerging Data Augmentation Techniques</a></li><li class="text-sm ml-8 text-foreground/60"><a href="#other-regularization-techniques" class="marker:text-foreground/30 list-none underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit" data-heading-link="other-regularization-techniques">Other Regularization Techniques</a></li><li class="text-sm ml-12 text-foreground/60"><a href="#early-stopping" class="marker:text-foreground/30 list-none underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit" data-heading-link="early-stopping">Early Stopping</a></li><li class="text-sm ml-12 text-foreground/60"><a href="#dropout" class="marker:text-foreground/30 list-none underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit" data-heading-link="dropout">Dropout</a></li><li class="text-sm ml-12 text-foreground/60"><a href="#dropout-at-test-time" class="marker:text-foreground/30 list-none underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit" data-heading-link="dropout-at-test-time">Dropout at Test Time</a></li><li class="text-sm ml-8 text-foreground/60"><a href="#stochastic-depth" class="marker:text-foreground/30 list-none underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit" data-heading-link="stochastic-depth">Stochastic Depth</a></li><li class="text-sm ml-8 text-foreground/60"><a href="#batch-normalization" class="marker:text-foreground/30 list-none underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit" data-heading-link="batch-normalization">Batch Normalization</a></li><li class="text-sm ml-12 text-foreground/60"><a href="#batch-normalization-at-test-time" class="marker:text-foreground/30 list-none underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit" data-heading-link="batch-normalization-at-test-time">Batch Normalization at Test Time</a></li><li class="text-sm ml-8 text-foreground/60"><a href="#layer-normalization" class="marker:text-foreground/30 list-none underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit" data-heading-link="layer-normalization">Layer Normalization</a></li><li class="text-sm ml-8 text-foreground/60"><a href="#group-normalization" class="marker:text-foreground/30 list-none underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit" data-heading-link="group-normalization">Group Normalization</a></li><li class="text-sm ml-4 text-foreground/60"><a href="#practical-tricks--tips" class="marker:text-foreground/30 list-none underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit" data-heading-link="practical-tricks--tips">Practical Tricks &amp; Tips</a></li><li class="text-sm ml-8 text-foreground/60"><a href="#data--pre-procesing" class="marker:text-foreground/30 list-none underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit" data-heading-link="data--pre-procesing">Data  Pre-Procesing</a></li><li class="text-sm ml-12 text-foreground/60"><a href="#pca-as-whitening" class="marker:text-foreground/30 list-none underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit" data-heading-link="pca-as-whitening">PCA as Whitening</a></li><li class="text-sm ml-8 text-foreground/60"><a href="#weight-initialization" class="marker:text-foreground/30 list-none underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit" data-heading-link="weight-initialization">Weight Initialization</a></li><li class="text-sm ml-8 text-foreground/60"><a href="#learning-rate-decay" class="marker:text-foreground/30 list-none underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit" data-heading-link="learning-rate-decay">Learning Rate Decay</a></li><li class="text-sm ml-8 text-foreground/60"><a href="#transfer-learning" class="marker:text-foreground/30 list-none underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit" data-heading-link="transfer-learning">Transfer Learning</a></li><li class="text-sm ml-8 text-foreground/60"><a href="#choosing-hyperparameters" class="marker:text-foreground/30 list-none underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit" data-heading-link="choosing-hyperparameters">Choosing Hyperparameters</a></li><li class="text-sm ml-4 text-foreground/60"><a href="#summary" class="marker:text-foreground/30 list-none underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit" data-heading-link="summary">Summary</a></li></ul></div></astro-slot></div></div></div><!--astro:end--></astro-island></div><script type="module">class f{links=document.querySelectorAll("[data-heading-link]");activeIds=[];headings=[];regions=[];scrollArea=null;tocScrollArea=null;reset(){this.links=document.querySelectorAll("#toc-sidebar-container [data-heading-link]"),this.activeIds=[],this.headings=[],this.regions=[];const t=document.getElementById("toc-sidebar-container");this.scrollArea=t?.querySelector("[data-radix-scroll-area-viewport]")||null,this.tocScrollArea=t?.querySelector("[data-toc-scroll-area]")||null}}const e=new f;class c{static build(){if(e.headings=Array.from(document.querySelectorAll(".prose h2, .prose h3, .prose h4, .prose h5, .prose h6")),e.headings.length===0){e.regions=[];return}e.regions=e.headings.map((t,o)=>{const i=e.headings[o+1];return{id:t.id,start:t.offsetTop,end:i?i.offsetTop:document.body.scrollHeight}})}static getVisibleIds(){if(e.headings.length===0)return[];const t=window.scrollY+80,o=window.scrollY+window.innerHeight,i=new Set,l=(s,r)=>s>=t&&s<=o||r>=t&&r<=o||s<=t&&r>=o;return e.headings.forEach(s=>{const r=s.offsetTop+s.offsetHeight;l(s.offsetTop,r)&&i.add(s.id)}),e.regions.forEach(s=>{if(s.start<=o&&s.end>=t){const r=document.getElementById(s.id);if(r){const a=r.offsetTop+r.offsetHeight;s.end>a&&(a<o||t<s.end)&&i.add(s.id)}}}),Array.from(i)}}class h{static update(){if(!e.scrollArea||!e.tocScrollArea)return;const{scrollTop:t,scrollHeight:o,clientHeight:i}=e.scrollArea,l=5,s=t<=l,r=t>=o-i-l;e.tocScrollArea.classList.toggle("mask-t-from-90%",!s),e.tocScrollArea.classList.toggle("mask-b-from-90%",!r)}}class g{static update(t){e.links.forEach(o=>{o.classList.remove("text-foreground")}),t.forEach(o=>{if(o){const i=document.querySelector(`#toc-sidebar-container [data-heading-link="${o}"]`);i&&i.classList.add("text-foreground")}}),this.scrollToActive(t)}static scrollToActive(t){if(!e.scrollArea||!t.length)return;const o=document.querySelector(`#toc-sidebar-container [data-heading-link="${t[0]}"]`);if(!o)return;const{top:i,height:l}=e.scrollArea.getBoundingClientRect(),{top:s,height:r}=o.getBoundingClientRect(),a=s-i+e.scrollArea.scrollTop,u=Math.max(0,Math.min(a-(l-r)/2,e.scrollArea.scrollHeight-e.scrollArea.clientHeight));Math.abs(u-e.scrollArea.scrollTop)>5&&(e.scrollArea.scrollTop=u)}}class d{static handleScroll(){const t=c.getVisibleIds();JSON.stringify(t)!==JSON.stringify(e.activeIds)&&(e.activeIds=t,g.update(e.activeIds))}static handleTOCScroll=()=>h.update();static handleResize(){c.build();const t=c.getVisibleIds();JSON.stringify(t)!==JSON.stringify(e.activeIds)&&(e.activeIds=t,g.update(e.activeIds)),h.update()}static init(){if(e.reset(),c.build(),e.headings.length===0){g.update([]);return}this.handleScroll(),setTimeout(h.update,100);const t={passive:!0};window.addEventListener("scroll",this.handleScroll,t),window.addEventListener("resize",this.handleResize,t),e.scrollArea?.addEventListener("scroll",this.handleTOCScroll,t)}static cleanup(){window.removeEventListener("scroll",this.handleScroll),window.removeEventListener("resize",this.handleResize),e.scrollArea?.removeEventListener("scroll",this.handleTOCScroll),Object.assign(e,{activeIds:[],headings:[],regions:[],scrollArea:null,tocScrollArea:null})}}document.addEventListener("astro:page-load",()=>d.init());document.addEventListener("astro:after-swap",()=>{d.cleanup(),d.init()});document.addEventListener("astro:before-swap",()=>d.cleanup());</script> <article class="prose col-start-2 max-w-none"> <!doctype html><html lang="en"><head></head><body>


<meta charset="utf-8">
<title>CS4487_10</title>
<meta content="width=device-width, initial-scale=1" name="viewport">
<link href="https://cdn.jsdelivr.net/npm/katex@0.16.21/dist/katex.min.css" rel="stylesheet">

<svg xmlns="http://www.w3.org/2000/svg" style="display:none"><defs>
        <symbol id="info" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
          <path d="M13 16h-1v-4h-1m1-4h.01M21 12a9 9 0 11-18 0 9 9 0 0118 0z"></path>
        </symbol>
        <symbol id="lightbulb" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
          <path d="M9.663 17h4.673M12 3v1m6.364 1.636l-.707.707M21 12h-1M4 12H3m3.343-5.657l-.707-.707m2.828 9.9a5 5 0 117.072 0l-.548.547A3.374 3.374 0 0014 18.469V19a2 2 0 11-4 0v-.531c0-.895-.356-1.754-.988-2.386l-.548-.547z"></path>
        </symbol>
        <symbol id="alert-triangle" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
          <path d="M12 9v2m0 4h.01m-6.938 4h13.856c1.54 0 2.502-1.667 1.732-3L13.732 4c-.77-1.333-2.694-1.333-3.464 0L3.34 16c-.77 1.333.192 3 1.732 3z"></path>
        </symbol>
        <symbol id="shield-alert" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
          <path d="M20.618 5.984A11.955 11.955 0 0112 2.944a11.955 11.955 0 01-8.618 3.04A12.02 12.02 0 003 9c0 5.591 3.824 10.29 9 11.622 5.176-1.332 9-6.03 9-11.622 0-1.042-.133-2.052-.382-3.016zM12 9v2m0 4h.01"></path>
        </symbol>
        <symbol id="message-square-warning" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
          <path d="M21 15a2 2 0 01-2 2H7l-4 4V5a2 2 0 012-2h14a2 2 0 012 2zM12 8v4m0 4h.01"></path>
        </symbol>
        <symbol id="book-open" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
          <path d="M12 6.253v13m0-13C10.832 5.477 9.246 5 7.5 5S4.168 5.477 3 6.253v13C4.168 18.477 5.754 18 7.5 18s3.332.477 4.5 1.253m0-13C13.168 5.477 14.754 5 16.5 5c1.747 0 3.332.477 4.5 1.253v13C19.832 18.477 18.247 18 16.5 18c-1.746 0-3.332.477-4.5 1.253"></path>
        </symbol>
        <symbol id="anchor" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
          <path d="M8 12h.01M12 12h.01M16 12h.01M21 12a9 9 0 11-18 0 9 9 0 0118 0z"></path>
        </symbol>
        <symbol id="pen-tool" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
          <path d="M12 19l7-7 3 3-7 7-3-3z"></path>
        </symbol>
        <symbol id="check-circle" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
          <path d="M9 12l2 2 4-4m6 2a9 9 0 11-18 0 9 9 0 0118 0z"></path>
        </symbol>
        <symbol id="puzzle" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
          <path d="M11 4a2 2 0 114 0v1a1 1 0 001 1h3a1 1 0 011 1v3a1 1 0 01-1 1h-1a2 2 0 100 4h1a1 1 0 011 1v3a1 1 0 01-1 1h-3a1 1 0 01-1-1v-1a2 2 0 10-4 0v1a1 1 0 01-1 1H7a1 1 0 01-1-1v-3a1 1 0 00-1-1H4a2 2 0 110-4h1a1 1 0 001-1V7a1 1 0 011-1h3a1 1 0 001-1V4z"></path>
        </symbol>
        <symbol id="git-branch" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
          <path d="M3 3v12h12M8 8l8 8"></path>
        </symbol>
        <symbol id="file-text" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
          <path d="M9 12h6m-6 4h6m2 5H7a2 2 0 01-2-2V5a2 2 0 012-2h5.586a1 1 0 01.707.293l5.414 5.414a1 1 0 01.293.707V19a2 2 0 01-2 2z"></path>
        </symbol>
        <symbol id="help-circle" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
          <path d="M18.364 5.636l-3.536 3.536m0 5.656l3.536 3.536M9.172 9.172L5.636 5.636m3.536 9.192l-3.536 3.536M21 12a9 9 0 11-18 0 9 9 0 0118 0zm-5 0a4 4 0 11-8 0 4 4 0 018 0z"></path>
        </symbol>
        <symbol id="check-square" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
          <path d="M9 5H7a2 2 0 00-2 2v12a2 2 0 002 2h10a2 2 0 002-2V7a2 2 0 00-2-2h-2M9 5a2 2 0 002 2h2a2 2 0 002-2M9 5a2 2 0 012-2h2a2 2 0 012 2m-6 9l2 2 4-4"></path>
        </symbol>
        <symbol id="message-circle" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
          <path d="M8 12h.01M12 12h.01M16 12h.01M21 12c0 4.418-4.03 8-9 8a9.863 9.863 0 01-4.255-.949L3 20l1.395-3.72C3.512 15.042 3 13.574 3 12c0-4.418 4.03-8 9-8s9 3.582 9 8z"></path>
        </symbol>
        <symbol id="rotate-ccw" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
          <path d="M3 2v6h6M3 8a9 9 0 015.168 1.637c.773.516 2.21 1.756 3.005 2.318.942.665 2.253.788 3.295.16.9-.545 1.553-1.723 2.592-2.605A9 9 0 018.709 21.5L7.5 20.295"></path>
        </symbol>
        <symbol id="code" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
          <path d="M10 20l4-16m4 4l4 4-4 4M6 16l-4-4 4-4"></path>
        </symbol>
        <symbol id="dumbbell" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
          <path d="M6.5 6.5h11m-11 11h11M5 20a2 2 0 100-4 2 2 0 000 4zM19 20a2 2 0 100-4 2 2 0 000 4zM5 10a2 2 0 100-4 2 2 0 000 4zM19 10a2 2 0 100-4 2 2 0 000 4z"></path>
        </symbol>
        <symbol id="alert-circle" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
          <path d="M12 8v4m0 4h.01M21 12a9 9 0 11-18 0 9 9 0 0118 0z"></path>
        </symbol>
        <symbol id="check" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
          <path d="M5 13l4 4L19 7"></path>
        </symbol>
        <symbol id="check-circle-2" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
          <path d="M9 12l2 2 4-4m6 2a9 9 0 11-18 0 9 9 0 0118 0z"></path>
        </symbol>
        <symbol id="list" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
          <path d="M9 5H7a2 2 0 00-2 2v12a2 2 0 002 2h10a2 2 0 002-2V7a2 2 0 00-2-2h-2M9 5a2 2 0 002 2h2a2 2 0 002-2M9 5a2 2 0 012-2h2a2 2 0 012 2m-3 7h3m-3 4h3m-6-4h.01M9 16h.01"></path>
        </symbol>
        <symbol id="chevron-down" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
          <path d="M19 9l-7 7-7-7"></path>
        </symbol></defs></svg>
<h3 id="training-deep-neural-networks">Training Deep Neural Networks</h3>
<p>As we discussed last time, training neural networks is a highly non-convex optimization problem in high dimensional space.
In the loss landscape, we will have lots of plateaus, saddle points and local optimas that can hinder our training process.</p>
<p>So far, we have learned about Gradient Descent (GD) and Stochastic Gradient Descent (SGD, along with its mini-batch version) as optimization techniques.</p>
<h4 id="gradient-descent-gd">Gradient Descent (GD)</h4>
<p>Recall the algorithm for (batch) Gradient Descent:</p>
<ol>
<li><strong>Require</strong>: Learning Rate $\alpha^{(t)}$</li>
<li><strong>Require</strong>: Initial Parameter $\mathbf{\theta}^{(0)}$</li>
<li><strong>while</strong> stopping criterion not met <strong>do</strong></li>
<li>$\quad$ Compute gradient estimate over $M$ examples:</li>
<li>$\quad$ $\mathbf{g}^{(t)} = \nabla_{\mathbf{\theta}} \frac{1}{M} \sum_{i=1}^{M} \ell(f(\mathbf{x}^{(i)}; \mathbf{\theta}), y^{(i)})$</li>
<li>$\quad$ Apply update: $\mathbf{\theta}^{(t+1)} = \mathbf{\theta}^{(t)} - \alpha^{(t)} \mathbf{g}^{(t)}$</li>
<li>$\quad$ $t = t + 1$</li>
<li><strong>end while</strong></li>
</ol>
<ul>
<li>Pros: Gradient estimates are stable</li>
<li>Cons: Need to compute gradients over the entire training set for one update.</li>
</ul>
<h4 id="stochastic-gradient-descent-sgd">Stochastic Gradient Descent (SGD)</h4>
<p>Recall the algorithm for Stochastic Gradient Descent:</p>
<ol>
<li><strong>Require</strong>: Learning Rate $\alpha^{(t)}$</li>
<li><strong>Require</strong>: Initial Parameter $\mathbf{\theta}^{(0)}$</li>
<li><strong>while</strong> stopping criterion not met <strong>do</strong></li>
<li>$\quad$ Sample example $(\mathbf{x}^{(i)}, y^{(i)})$ from the training set.</li>
<li>$\quad$ Compute gradient estimate:</li>
<li>$\quad$ $\mathbf{g}^{(t)} = \nabla_{\mathbf{\theta}} \ell(f(\mathbf{x}^{(i)}; \mathbf{\theta}), y^{(i)})$</li>
<li>$\quad$ Apply update: $\mathbf{\theta}^{(t+1)} = \mathbf{\theta}^{(t)} - \alpha^{(t)} \mathbf{g}^{(t)}$</li>
<li>$\quad$ $t = t + 1$</li>
<li><strong>end while</strong></li>
</ol>
<ul>
<li>Pros: Computation time per update does not depend on $M$, allowing convergence on extremely large datasets.</li>
<li>Cons: Gradient estimates can be noisy, use mini-batches to mitigate this.</li>
</ul>
<h3 id="optimization-techniques">Optimization Techniques</h3>
<p>We will discuss other optimization techniques that can help us train deep neural networks more effectively.</p>
<h4 id="more-problems-with-sgd">More Problems with SGD</h4>
<p>What if the loss changes quickly in one direction and slowly in another (i.e., error surface has high curvature)?
SGD will have a hard time converging in this case.</p>
<p>As we know, gradient descent gains very slow progress along a shallow direction and starts to jitter along steep direction.</p>
<h4 id="momentum">Momentum</h4>
<p>How do we solve this problem? One way is to use <strong>momentum</strong>.</p>
<p>We introduce a new variable $\mathbf{v}$, the velocity.</p>
<p>We think of $\mathbf{v}$ as the direction and speed by which the parameters move as the learning dynamics progress.</p>
<p>The velocity is an <strong>exponentially decaying moving average</strong> of the negative gradients,</p>
<p>$$
\mathbf{v}^{(t + 1)} = \rho \mathbf{v}^{(t)} - \alpha^{(t)} \nabla_{\mathbf{\theta}} \ell(f(\mathbf{x}^{(i)}; \mathbf{\theta}), y^{(i)})
$$</p>
<p>where $\rho \in [0, 1)$.</p>
<p>Update rule: $\mathbf{\theta}^{(t+1)} = \mathbf{\theta}^{(t)} + \mathbf{v}^{(t+1)}$</p>
<p>Let’s take a closer look at the velocity term,</p>
<p>$$
\mathbf{v}^{(t + 1)} = \rho \mathbf{v}^{(t)} - \alpha^{(t)} \nabla_{\mathbf{\theta}} \ell(f(\mathbf{x}^{(i)}; \mathbf{\theta}), y^{(i)})
$$</p>
<p>We can see that the velocity <strong>accumulates</strong> the previous gradients.</p>
<p>But, what is the role of $rho$?</p>
<p>If $rho$ is larger than $\alpha^{(t)}$, the current update is more affected by the previous gradients.</p>
<p>We usually set $rho$ to a high value, e.g., 0.9.</p>
<h5 id="sgd-with-momentum">SGD with Momentum</h5>
<ol>
<li><strong>Require</strong>: Learning Rate $\alpha^{(t)}$</li>
<li><strong>Require</strong>: Momentum $\rho$</li>
<li><strong>Require</strong>: Initial Parameter $\mathbf{\theta}^{(0)}$</li>
<li><strong>Require</strong>: Initial Velocity $\mathbf{v}^{(0)}$</li>
<li><strong>while</strong> stopping criterion not met <strong>do</strong></li>
<li>$\quad$ Sample example $(\mathbf{x}^{(i)}, y^{(i)})$ from the training set.</li>
<li>$\quad$ Compute gradient estimate: $\mathbf{g}^{(t)} = \nabla_{\mathbf{\theta}} \ell(f(\mathbf{x}^{(i)}; \mathbf{\theta}), y^{(i)})$</li>
<li>$\quad$ Update velocity: $\mathbf{v}^{(t+1)} = \rho \mathbf{v}^{(t)} - \alpha^{(t)} \mathbf{g}^{(t)}$</li>
<li>$\quad$ Apply update: $\mathbf{\theta}^{(t+1)} = \mathbf{\theta}^{(t)} + \mathbf{v}^{(t+1)}$</li>
<li>$\quad$ $t = t + 1$</li>
<li><strong>end while</strong></li>
</ol>
<h4 id="nesterov-momentum">Nesterov Momentum</h4>
<p>Another approach that we can take, is to use <strong>Nesterov Momentum</strong>.</p>
<p>First take a step in the direction of the accumulated gradient, then calculate the gradient and make a correction.</p>
<p>Let’s write it out.</p>
<p>Recall the velocity term in the momentum update,</p>
<p>$$
\mathbf{v}^{(t + 1)} = \rho \mathbf{v}^{(t)} - \alpha^{(t)} \nabla_{\mathbf{\theta}} \ell(f(\mathbf{x}^{(i)}; \mathbf{\theta}), y^{(i)})
$$</p>
<p>Nesterov Momentum changes the update rule to,</p>
<p>$$
\begin{align*}
\tilde{\mathbf{\theta}} = \mathbf{\theta}^{(t)} + \rho \mathbf{v}^{(t)} \newline
\mathbf{v}^{(t + 1)} = \rho \mathbf{v}^{(t)} - \alpha^{(t)} \nabla_{\mathbf{\theta}} \ell(f(\mathbf{x}^{(i)}; \tilde{\mathbf{\theta}}), y^{(i)}) \newline
\end{align*}
$$</p>
<p>Update: $\mathbf{\theta}^{(t+1)} = \mathbf{\theta}^{(t)} + \mathbf{v}^{(t+1)}$</p>
<h5 id="sgd-with-nesterov-momentum">SGD with Nesterov Momentum</h5>
<ol>
<li><strong>Require</strong>: Learning Rate $\alpha^{(t)}$</li>
<li><strong>Require</strong>: Momentum $\rho$</li>
<li><strong>Require</strong>: Initial Parameter $\mathbf{\theta}^{(0)}$</li>
<li><strong>Require</strong>: Initial Velocity $\mathbf{v}^{(0)}$</li>
<li><strong>while</strong> stopping criterion not met <strong>do</strong></li>
<li>$\quad$ Sample example $(\mathbf{x}^{(i)}, y^{(i)})$ from the training set.</li>
<li>$\quad$ Update: $\tilde{\mathbf{\theta}} = \mathbf{\theta}^{(t)} + \rho \mathbf{v}^{(t)}$</li>
<li>$\quad$ Compute gradient estimate: $\mathbf{g}^{(t)} = \nabla_{\mathbf{\theta}} \ell(f(\mathbf{x}^{(i)}; \tilde{\mathbf{\theta}}), y^{(i)})$</li>
<li>$\quad$ Update velocity: $\mathbf{v}^{(t+1)} = \rho \mathbf{v}^{(t)} - \alpha^{(t)} \mathbf{g}^{(t)}$</li>
<li>$\quad$ Apply update: $\mathbf{\theta}^{(t+1)} = \mathbf{\theta}^{(t)} + \mathbf{v}^{(t+1)}$</li>
<li>$\quad$ $t = t + 1$</li>
<li><strong>end while</strong></li>
</ol>
<h4 id="adaptive-learning-rate-methods">Adaptive Learning Rate Methods</h4>
<p>Till now we have assigned the same learning rate to all parameters $\theta_j$‘s.</p>
<p>But, if $\theta_j$‘s vary in importance and convergence speed, is this really a good idea?</p>
<p>Probably not.</p>
<h5 id="adagrad">AdaGrad</h5>
<p>One way to address this issue is to use <strong>AdaGrad</strong>.</p>
<p>Idea: Scale the gradient of a model parameter by the square root of sum of squares of all its historical values.</p>
<p>Or in other words, progress along “steep” directions (with large partial derivatives) are damped.</p>
<p>Progress along “flat” directions (with small partial derivatives) are accelerated.</p>
<p>Here is a conceptual question that is quite important.</p>
<p>What will happen to the gradient magnitude over a long time?</p>
<p>It will decay to zero.</p>
<ol>
<li><strong>Require</strong>: Initial Learning Rate $\alpha$</li>
<li><strong>Require</strong>: Initial Parameter $\mathbf{\theta}^{(0)}$</li>
<li>Initialize $\mathbf{r}^{(0)} = 0$</li>
<li><strong>while</strong> stopping criterion not met <strong>do</strong></li>
<li>$\quad$ Sample example $(\mathbf{x}^{(i)}, y^{(i)})$ from the training set.</li>
<li>$\quad$ Compute gradient estimate: $\mathbf{g}^{(t)} = \nabla_{\mathbf{\theta}} \ell(f(\mathbf{x}^{(i)}; \mathbf{\theta}), y^{(i)})$</li>
<li>$\quad$ Accumulate: $\mathbf{r}^{(t+1)} = \mathbf{r}^{(t)} + \mathbf{g}^{(t)} \odot \mathbf{g}^{(t)}$</li>
<li>$\quad$ Compute update: $\Delta \mathbf{\theta} = -\frac{\alpha}{\epsilon + \sqrt{\mathbf{r}^{(t+1)}}} \odot \mathbf{g}^{(t)}$</li>
<li>$\quad$ Apply update: $\mathbf{\theta}^{(t+1)} = \mathbf{\theta}^{(t)} + \Delta \mathbf{\theta}$</li>
<li>$\quad$ $t = t + 1$</li>
<li><strong>end while</strong></li>
</ol>
<h4 id="rmsprop-leaky-adagrad">RMSProp: “Leaky AdaGrad”</h4>
<p>AdaGrad is good when the objective is convex, however, it may not be the best choice for non-convex problems.</p>
<p>AdaGrad might shrink the learning rate too aggressievly sometimes as well, but we can overcome these problems.</p>
<p>We can adapt it to perform better in non-convex settings by accumulating an exponentially decaying average of the gradient.
This is an idea that we will see time and time again in deep learning.</p>
<ol>
<li><strong>Require</strong>: Global Learning Rate $\alpha$</li>
<li><strong>Require</strong>: Decay Rate $\rho$</li>
<li><strong>Require</strong>: Initial Parameter $\mathbf{\theta}^{(0)}$</li>
<li>Initialize $\mathbf{r}^{(0)} = 0$</li>
<li><strong>while</strong> stopping criterion not met <strong>do</strong></li>
<li>$\quad$ Sample example $(\mathbf{x}^{(i)}, y^{(i)})$ from the training set.</li>
<li>$\quad$ Compute gradient estimate: $\mathbf{g}^{(t)} = \nabla_{\mathbf{\theta}} \ell(f(\mathbf{x}^{(i)}; \mathbf{\theta}), y^{(i)})$</li>
<li>$\quad$ Accumulate: $\mathbf{r}^{(t+1)} = \rho \mathbf{r}^{(t)} + (1 - \rho) \mathbf{g}^{(t)} \odot \mathbf{g}^{(t)}$</li>
<li>$\quad$ Compute update: $\Delta \mathbf{\theta} = -\frac{\alpha}{\epsilon + \sqrt{\mathbf{r}^{(t+1)}}} \odot \mathbf{g}^{(t)}$</li>
<li>$\quad$ Apply update: $\mathbf{\theta}^{(t+1)} = \mathbf{\theta}^{(t)} + \Delta \mathbf{\theta}$</li>
<li>$\quad$ $t = t + 1$</li>
<li><strong>end while</strong></li>
</ol>
<h4 id="adam-adaptive-moments">Adam: ADAptive Moments</h4>
<p>Adam is currently <strong>the</strong> default optimization algorithm for training deep neural networks.</p>
<p>Adam is like RMSProp with momentum but with bias correction terms for the first (mean) and second (uncentered variance) moments.</p>
<ol>
<li><strong>Require</strong>: Global Learning Rate $\alpha$</li>
<li><strong>Require</strong>: Decay Rates $\rho_1, \rho_2$</li>
<li><strong>Require</strong>: Initial Parameter $\mathbf{\theta}^{(0)}$</li>
<li>Initialize moment variables $\mathbf{s}^{(0)} = 0$, $\mathbf{r}^{(0)} = 0$</li>
<li><strong>while</strong> stopping criterion not met <strong>do</strong></li>
<li>$\quad$ Sample example $(\mathbf{x}^{(i)}, y^{(i)})$ from the training set.</li>
<li>$\quad$ Compute gradient estimate: $\mathbf{g}^{(t)} = \nabla_{\mathbf{\theta}} \ell(f(\mathbf{x}^{(i)}; \mathbf{\theta}), y^{(i)})$</li>
<li>$\quad$ Update: $\mathbf{s}^{(t+1)} = \rho_1 \mathbf{s}^{(t)} + (1 - \rho_1) \mathbf{g}^{(t)}$</li>
<li>$\quad$ Update: $\mathbf{r}^{(t+1)} = \rho_2 \mathbf{r}^{(t)} + (1 - \rho_2) \mathbf{g}^{(t)} \odot \mathbf{g}^{(t)}$</li>
<li>$\quad$ Correct biases: $\hat{\mathbf{s}} = \frac{\mathbf{s}^{(t+1)}}{1 - \rho_1^{t+1}}$, $\hat{\mathbf{r}} = \frac{\mathbf{r}^{(t+1)}}{1 - \rho_2^{t+1}}$</li>
<li>$\quad$ Compute and apply update: $\Delta \mathbf{\theta} = -\frac{\hat{\mathbf{s}}}{\delta + \sqrt{\hat{\mathbf{r}}}}, \mathbf{\theta}^{(t+1)} = \mathbf{\theta}^{(t)} + \Delta \mathbf{\theta}$</li>
<li>$\quad$ $t = t + 1$</li>
<li><strong>end while</strong></li>
</ol>
<h4 id="adamw-adaptive-moments-with-weight-decay">AdamW: ADAptive Moments with Weight Decay</h4>
<p>AdamW is an extension of Adam, and has gained popularity, especially in training transformer-based deep models.</p>
<p>Weight decay (which is just a fancy word for $\ell_2$-regularization and ridge regularization) is a regularization technique to prevent ovefitting.
It is just adding a $\Vert \mathbf{\theta} \Vert_2^2$ term to the loss function.</p>
<p>AdamW applies weight decay as a separate regularization term during the update step, decoupling it from the adaptive learning rate mechanism.</p>
<p>AdamW addresses the issue of large weights being incorrectly penalized by weight decay.</p>
<p>It also provides improved regularization and better generalization compared to original Adam.</p>
<p>$\colorbox{pink}{\text{Adam}}$ VS. $\colorbox{lime}{\text{AdamW}}$</p>
<ol>
<li><strong>Require</strong>: Global Learning Rate $\alpha$</li>
<li><strong>Require</strong>: Decay Rates $\rho_1, \rho_2$</li>
<li><strong>Require</strong>: Weight Decay $\lambda$</li>
<li><strong>Require</strong>: Initial Parameter $\mathbf{\theta}^{(0)}$</li>
<li>Initialize moment variables $\mathbf{s}^{(0)} = 0$, $\mathbf{r}^{(0)} = 0$</li>
<li><strong>while</strong> stopping criterion not met <strong>do</strong></li>
<li>$\quad$ Sample example $(\mathbf{x}^{(i)}, y^{(i)})$ from the training set.</li>
<li>$\quad$ Compute gradient estimate: $\mathbf{g}^{(t)} = \nabla_{\mathbf{\theta}} \ell(f(\mathbf{x}^{(i)}; \mathbf{\theta}), y^{(i)}) \colorbox{pink}{$+ \lambda \mathbf{\theta}^{(t)}$}$</li>
<li>$\quad$ Update: $\mathbf{s}^{(t+1)} = \rho_1 \mathbf{s}^{(t)} + (1 - \rho_1) \mathbf{g}^{(t)}$</li>
<li>$\quad$ Update: $\mathbf{r}^{(t+1)} = \rho_2 \mathbf{r}^{(t)} + (1 - \rho_2) \mathbf{g}^{(t)} \odot \mathbf{g}^{(t)}$</li>
<li>$\quad$ Correct biases: $\hat{\mathbf{s}} = \frac{\mathbf{s}^{(t+1)}}{1 - \rho_1^{t+1}}$, $\hat{\mathbf{r}} = \frac{\mathbf{r}^{(t+1)}}{1 - \rho_2^{t+1}}$</li>
<li>$\quad$ Compute and apply update: $\Delta \mathbf{\theta} = -\frac{\hat{\mathbf{s}}}{\delta + \sqrt{\hat{\mathbf{r}}}} \colorbox{lime}{$- \lambda \mathbf{\theta}^{(t)}$}$, $\mathbf{\theta}^{(t+1)} = \mathbf{\theta}^{(t)} + \Delta \mathbf{\theta}$</li>
<li>$\quad$ $t = t + 1$</li>
<li><strong>end while</strong></li>
</ol>
<h4 id="other-emerging-optimization-techniques">Other Emerging Optimization Techniques</h4>
<ul>
<li>AdaBelief, unlike Adam, AdaBelief divides by the exponentially decaying moving average of variance of the gradients.</li>
</ul>
<p>In Adam: $\mathbf{r}^{(t+1)} = \rho_2 \mathbf{r}^{(t)} + (1 - \rho_2) \mathbf{g}^{(t)} \odot \mathbf{g}^{(t)}$
In AdaBelief: $\mathbf{r}^{(t+1)} = \rho_2 \mathbf{r}^{(t)} + (1 - \rho_2) (\mathbf{g}^{(t)} - \mathbf{m}^{(t)}) \odot (\mathbf{g}^{(t)} - \mathbf{s}^{(t + 1)})^2$</p>
<ul>
<li>AdaHessian: Second-order optimization technique that incorporates the curvature of the loss function via adaptive estimates of the Hessian diagonals
Since calculating the Hessian is a computationally expensive operation, it can be approximated with a Hessian vector product.</li>
</ul>
<h3 id="regularization">Regularization</h3>
<p>We’ve discussed regularization before, but this has mostly been in the loss function.
However, when it comes to preventing overfit for models, we can apply regularization elsewhere, for example, in the data.</p>
<h4 id="data-augmentation">Data Augmentation</h4>
<p>If we artificially permute the data to increase the dataset size, we will have more data to train on!</p>
<p>Common ways to do this are,</p>
<ul>
<li>Horizontal flipping
<ul>
<li>As the name suggests, we flip the image horizontally.</li>
</ul>
</li>
<li>Random crops and scales.
<ul>
<li><strong>Training</strong>: Sample random crops/scales (given that the input resolution is $512 \times 512$).
<ol>
<li>Pick random $L$ in range $[256, 480]$.</li>
<li>Resize training image short side to $L$.</li>
<li>Sample random $224 \times 224$ patch.</li>
</ol>
</li>
<li><strong>Testing</strong>: Average a fixed set of crops.
<ol>
<li>Resize image at 5 scales, $\{224, 256, 384, 480, 640\}$.</li>
<li>For each size, use 10 $224 \times 224$ crops, 4 corners + center + flips.</li>
</ol>
</li>
</ul>
</li>
<li>Color jittering
<ul>
<li>Randomly change the brightness, contrast, saturation, and hue of the image.</li>
</ul>
</li>
<li>And so on…
<ul>
<li>Random mix of:
<ul>
<li>Translation</li>
<li>Rotation</li>
<li>Stretching</li>
<li>Shearing</li>
<li>Lens distortion</li>
<li>Add noise to pixels</li>
<li>$\ldots$</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>But we have to be careful about the transformation we choose, it has to be <strong>label preserving</strong>.</p>
<p>For example, if we are dealing with text, we simply can not flip the characters, a ‘b’ will become a ‘d’.
If we are working with the MNIST dataset, we can not perform a 180$^\circ$ rotation, a ‘6’ will become a ‘9’.</p>
<h4 id="emerging-data-augmentation-techniques">Emerging Data Augmentation Techniques</h4>
<p>There are a few emerging data augmentation techniques that are worth mentioning.</p>
<ul>
<li>Cutout
<ul>
<li>Idea: Randomly remove a square region of pixels in an image during training.
<ul>
<li>Pros: Can remove noise, e.g., irrelevant background.</li>
<li>Cons: Can remove important information.</li>
</ul>
</li>
</ul>
</li>
<li>Mixup
<ul>
<li>Idea: Linearly mix two random images and their labels during training.
<ul>
<li>Pros: Increase diversity in the training data.</li>
<li>Cons: Can create blurred images (which can be a pro sometimes!), especially for images with complex textures.</li>
</ul>
</li>
</ul>
</li>
<li>Cutmix
<ul>
<li>Idea: Randomly select two images during training, cut a random patch of pixels from one image and paste it to the other, and then mix their labels proportionally to the area of the patch.
<ul>
<li>Pros: Increase diversity in the training data.</li>
<li>Cons: Can create unrealistic images, can also remove important features.</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="other-regularization-techniques">Other Regularization Techniques</h4>
<p>We can also apply regularization to the training process itself. Here are a few examples.</p>
<h5 id="early-stopping">Early Stopping</h5>
<p>As the name suggests, we do not want to train a network to have a too small training error.</p>
<p>Recall that overfitting, with a large and complex model, means that it is easier to (over)fit the training samples into them.</p>
<p>To prevent this, we use the validation error to decide when to stop training.</p>
<p>We can think of early stopping as a type of regularization, why?</p>
<p>The <strong>effective</strong> complexity of the network starts out small, as the weights are initialized small</p>
<p>The effect complexity grows during training, as the weights get larger and larger.</p>
<p>Early stopping then represents a way of limiting the effective network complexity.</p>
<p>In practice, when we are training we also output the validation error, to get a sense of both.</p>
<p>Every time the validation error improves, we want to save this checkpoint.</p>
<p>When the validation error plateaus for some time (or starts to increase for some time), we should stop.</p>
<p>The number of training steps (i.e., epochs) is also a hyperparameter that we can tune.</p>
<h5 id="dropout">Dropout</h5>
<p>Dropout is a regularization technique that is applied to the network itself.</p>
<p>In each update step, randomly sample a different <strong>binary</strong> mask to all the input and hidden units.</p>
<p>Multiply the mask with the units and do the update as usual, typical dropout probabilities are 0.8/0.5 for input/hidden units.</p>
<p>This is especially useful for fully connected layers, less so for convolutional layers.</p>
<p>But why is this even a good idea, don’t we want more units and parameters to represent the data?</p>
<p>This is true, but we want <strong>representative</strong> parameters, this forces the network to avoid having <strong>redundant</strong> or <strong>dependent</strong> representations.
I.e., prevents co-adaptation of features, in which a feature is only helpful in the context/presence of several other specific features (although, this can be useful in some cases).</p>
<p>We also train a large ensemble of models (that share parameters), each binary mask corresponds to one model.</p>
<p>But how do we make a final decision?</p>
<p>At test time all the neurons are active always (usually).
We scale the activations so that for each neuron, the output at test time = <em>expected</em> output at training time.</p>
<p>We can also use mask sampling (not as common).
We randomly sample some (typically, 10-20) masks, for each mask, we apply it to the trained model to get a prediction, then we take the majority vote (i.e., average) over the predicitons.</p>
<h5 id="dropout-at-test-time">Dropout at Test Time</h5>
<p>So, as we can see, dropout makes our output random!</p>
<p>$$
\mathbf{y} = f_{\mathbf{W}} (\mathbf{x}, \mathbf{z})
$$</p>
<p>where $\mathbf{z}$ is the random mask.</p>
<p>We want to “average out” the randomness at test time.</p>
<p>$$
\mathbf{y} = f_W (\mathbf{x}) = \mathbb{E}_z [f_W (\mathbf{x}, \mathbf{z})] = \int_z f_W (\mathbf{x}, \mathbf{z}) p(\mathbf{z}) d\mathbf{z}
$$</p>
<p>Consider a single neuron, $a = w_1 x_1 + w_2 x_2$.</p>
<p>At test time, we have $\mathbb{E}[a] = w_1 x_1 + w_2 x_2$.</p>
<p>At training time (with a dropout probability of 0.5), we have,</p>
<p>$$
\begin{align*}
\mathbb{E}[a] &#x26;= \frac{1}{4}(w_1 x_1 + w_2 x_2) + \frac{1}{4}(w_1 x_1 + w_2 0) \newline
&#x26;+ \frac{1}{4}(w_1 0 + w_2 x_2) + \frac{1}{4}(w_1 0 + w_2 0) \newline
&#x26;= \frac{1}{2}(w_1 x_1 + w_2 x_2)
\end{align*}
$$</p>
<p>At test time, we multiply by the dropout probability to get the expected value.</p>
<p>However, this is quite tedious, as we need to change the test time.</p>
<p>A more common way is the “inverted dropout”, where we instead scale the activations at training time.</p>
<p>Thus, the test time remains the same.</p>
<h4 id="stochastic-depth">Stochastic Depth</h4>
<p>Similar to Droput, in each iteration, Stochastic Depth randomly drops a subset of <em>layers</em> with some survival probabilities and bypasses them with the identity function.</p>
<p>At test time, all layers are activated and re-calibrated by multiplying the corresponding survival probabilities.</p>
<p>This reduces training time substantially and improves generalization as an implicit model ensemble.</p>
<h4 id="batch-normalization">Batch Normalization</h4>
<p>The idea of batch normalization is to adjust activations to lie within a desired operating range, while maintaining their relative values.</p>
<p>Given a mini-batch $\mathcal{B} = \{(\mathbf{x}^{(i)}, y^{(i)}, i = 1, \ldots, M\}$.</p>
<p>We compute the per-channel (i.e., feature) mean, $\mu_j = \frac{1}{M} \sum_{i = 1}^M x_j^{(i)}$ and,</p>
<p>compute the per-channel variance, $\sigma_j^2 = \frac{1}{M} \sum_{i = 1}^M (x_j^{(i)} - \mu_j)^2$.</p>
<p>Normalize $\mathbf{x}^{(i)}$ across the channel/feature, $\hat{x}_j^{(i)} = \frac{x_j^{(i)} - \mu_j}{\sqrt{\sigma_j^2 + \epsilon}}$.</p>
<p>But we have a issue, what if a zero mean and unit variance are too hard of a constraint?</p>
<p>The answer is more learnable parameters (as usual), we incorporate learnable scale and shift parameters $\gamma$ and $\beta$ such that,</p>
<p>$$
z_j^{(i)} = \gamma_j \hat{x}_j^{(i)} + \beta_j
$$</p>
<h5 id="batch-normalization-at-test-time">Batch Normalization at Test Time</h5>
<p>Mean and variance estimates depend on mini-batch at train time, but we can not do this at test time.</p>
<p>What’s the solution? We keep exponentially decaying the moving average of values seen during training and use them for testing.</p>
<p>During testing, batch normalization becomes a linear operator, which means it can be fused with the previous (convolutional) layer.</p>
<p>We usually use batch normalization after convolutional layers and before nonlinearity.</p>
<p>So remember, it behaves <strong>differently</strong> during training and testing, this can be a source for lots of pesky bugs.</p>
<h4 id="layer-normalization">Layer Normalization</h4>
<p>Layer normalization is similar to batch normalization, but it normalizes across the feature dimension.</p>
<p>Since we are normalizing across the channel dimension, we get the same behavior at training and testing time.</p>
<p>Layer normalization for convolutional layers normalizes along both channel and spatial dimensions.</p>
<h4 id="group-normalization">Group Normalization</h4>
<p>Group normalization is a compromise between batch and layer normalization.</p>
<p>It divides the channels into groups and computes the mean and variance within each group.</p>
<p>Group normalization is more stable than batch normalization when the batch size is small.</p>
<h3 id="practical-tricks--tips">Practical Tricks &#x26; Tips</h3>
<p>We will discuss some practical tips and tricks that can help you train deep neural networks more effectively.</p>
<h4 id="data--pre-procesing">Data  Pre-Procesing</h4>
<p>Data pre-processing is a crucial step in training deep neural networks.</p>
<p>Assume $\mathbf{X} \in \mathbb{R}^{M \times N}$ is the data matrix (each example in a row).</p>
<p>We can make the data zero-centered by subtracting the mean of each feature,</p>
<p>$$
\mathbf{X} = \mathbf{X} - \mathbf{1} \mu
$$</p>
<p>where $\mu = \frac{1}{M} \mathbf{X}^T \mathbf{1}$.</p>
<p>We can also normalize the data by dividing by the standard deviation of each feature,</p>
<p>$$
\mathbf{X} = \mathbf{X} \oslash \sigma
$$</p>
<p>where $\sigma = \sqrt{\frac{1}{M} \mathbf{X}^T \mathbf{X}}$.</p>
<p>In practice, we may also want to PCA (Principal Component Analysis) the data.</p>
<p>The data is first centered, then projected into the eigenbasis, followed by divding every dimension by the corresponding eigenvalue.</p>
<p>We call the first step for decorrelation and the second step for whitening.</p>
<h5 id="pca-as-whitening">PCA as Whitening</h5>
<p>Recall the eigendeomposition,</p>
<p>$$
\mathbf{C} = \frac{1}{M} \mathbf{X}^T \mathbf{X} = \frac{1}{M} \sum_{i = 1}^M \mathbf{x}^{(i)} (\mathbf{x}^{(i)})^T = \mathbf{U} \mathbf{\Sigma}^2 \mathbf{U}^T
$$</p>
<p>Defining $\hat{\mathbf{x}^{(i)}} = \mathbf{\Sigma}^{-1} \mathbf{U}^T \mathbf{x}^{(i)}$, we have,</p>
<p>$$
\begin{align*}
\hat{\mathbf{C}} &#x26;= \frac{1}{M} \sum_{i = 1}^M \hat{\mathbf{x}^{(i)}} (\hat{\mathbf{x}^{(i)}})^T \newline
&#x26;= \frac{1}{M} \sum_{i = 1}^M \mathbf{\Sigma}^{-1} \mathbf{U}^T \mathbf{x}^{(i)} (\mathbf{x}^{(i)})^T \mathbf{U} \mathbf{\Sigma}^{-1} \newline
&#x26;= \mathbf{\Sigma}^{-1} \mathbf{U}^T \left( \frac{1}{M} \sum_{i = 1}^M \mathbf{x}^{(i)} (\mathbf{x}^{(i)})^T \right) \mathbf{U} \mathbf{\Sigma}^{-1} \newline
&#x26;= \mathbf{\Sigma}^{-1} \mathbf{U}^T \mathbf{U} \mathbf{\Sigma}^2 \mathbf{U}^T \mathbf{U} \mathbf{\Sigma}^{-1} \newline
&#x26;= \mathbf{I}
\end{align*}
$$</p>
<p>In practice, for color (RGB) images, we only do this for the center, it is not common to do PCA whitening for the entire image.</p>
<p>But, we can three variants.</p>
<ul>
<li>Subtract the mean image.
<ul>
<li>Mean image = [3, height, width] array.</li>
</ul>
</li>
<li>Subtract per-channel mean.
<ul>
<li>Mean along each channel = 3 numbers.</li>
</ul>
</li>
<li>Subtract per-channel mean and divide by per-channel std.
<ul>
<li>Mean and std along each channel = $2 \times 3$ numbers.</li>
</ul>
</li>
</ul>
<p>As we lightly discussed earlier, we typically train our network several times on the entire dataset, one complete pass through the data is calle an <em>epoch</em>.</p>
<p>Also, never forget to <strong>shuffle</strong> your training data per epoch, since otherwise the training sequence can introduce bias.</p>
<h4 id="weight-initialization">Weight Initialization</h4>
<p>Weight initialization is another crucial step in training deep neural networks.</p>
<p>Constant (including all zero) initialization is a bad idea and wrong.</p>
<p>Why? If every neuron in the netwrok computes the same output, then all of them will also compute the same gradients during backpropagation and undergo the exact same parameter updates.</p>
<p>Small random initialization is a good idea, but we have to be careful.
It works okay for small networks, but for deeper and more complex networks this doesn’t work well.</p>
<p>The current recommendation for initializing CNNs with ReLU, for example is,</p>
<p>$$
w = np.random.randn(n) \times \sqrt{\frac{2}{n}}
$$</p>
<p>where <code>randn</code> is Gaussian and $n$ is the number of input channels.</p>
<p>Proper initialization is an active research area, and there are many other initialization techniques.</p>
<h4 id="learning-rate-decay">Learning Rate Decay</h4>
<p>SGD, AdaGrad, RMSProp, and Adam all have learning rate as a hyperparameter, but which learning rate should we choose?</p>
<ul>
<li>If we have a very high learning rate, our loss will diverge.</li>
<li>If we have a high learning rate, our loss will quickly drop then plateau.</li>
<li>If we have a low learning rate, our loss will slowly drop, but we may get stuck in a local minima.</li>
</ul>
<p>Which one should we choose? All of them, we first start with a high learning rate and decay it over time.</p>
<p>We can do this stepwise, i.e., we reduce the learning rate at a few fixed points, for example, multiply $\alpha$ by 0.1 after every 30 epochs.</p>
<p>There are also some other common <em>schedulers</em> for learning rate decay.</p>
<ul>
<li>Cosine: $\alpha^{(t)} = \frac{1}{2} \alpha^{(0)} \left(1 + \cos \left(\frac{t}{T} \pi \right) \right)$</li>
<li>Linear: $\alpha^{(t)} = \alpha^{(0)} \left(1 - \frac{t}{T} \right)$</li>
</ul>
<p>where $t$ is the epoch index and $T$ is the total number of epochs.</p>
<h4 id="transfer-learning">Transfer Learning</h4>
<p>Transfer learning is a technique where we use a pre-trained model on a different task as a starting point for training a new model.</p>
<p>Deep features are fairly transferable, and open source pre-trained models are everywhere, so this is a common practice</p>




















<table><thead><tr><th></th><th>Very Similar Dataset</th><th>Very Different Dataset</th></tr></thead><tbody><tr><td>Very Little Data</td><td>Use Linear classifier on top layer</td><td>You’re in trouble… Try linear classifier from different stages</td></tr><tr><td>Quite a lot of data</td><td>Finetune a few layers</td><td>Finetune a large number of layers</td></tr></tbody></table>
<h4 id="choosing-hyperparameters">Choosing Hyperparameters</h4>
<p>Choosing hyperparameters is a crucial step in training deep neural networks.</p>
<ol>
<li>Check initial loss.
<ul>
<li>Turn off weight decay and sanity check loss at initialization.
<ul>
<li>E.g. $\log(C)$ for softmax with $C$ classes.</li>
</ul>
</li>
</ul>
</li>
<li>Overfit a small sample.
<ul>
<li>Try to train to 100% training accuracy on a small sample of training data (5-10 mini-batches).
<ul>
<li>Fiddle with the architechture, learning rate, weight initialization, etc.</li>
</ul>
</li>
<li>Loss not going down?
<ul>
<li>Learning rate too low, bad initialization, etc.</li>
</ul>
</li>
<li>Loss explodes to Inf or NaN?
<ul>
<li>Learning rate too high, bad initialization, etc.</li>
</ul>
</li>
</ul>
</li>
<li>Find learning rate that mkaes loss go down.
<ul>
<li>Use the architecture from the previous step, use all training data, turn on small weight decay, find a learning rate that mkaes the loss drop significantly within ~100 iterations.</li>
<li>Good learning rates to usually start off with are, $1e^{-1}, 1e^{-2}, 1e^{-3}, 1e^{-4}$.</li>
</ul>
</li>
<li>Coarse grid, train for 1-5 epochs.
<ul>
<li>Choose a few values of learning rate and weight decay around what worked from (3) and train a few models for 1-5 epochs.</li>
<li>Good weight decay to usually start off with are, $1e^{-4}, 1e^{-5}, 0$.</li>
</ul>
</li>
<li>Refine grid and train longer.
<ul>
<li>Pick the best model(s) from (4) and train them for longer (10-20 epochs) without learning rate decay.</li>
</ul>
</li>
<li>Look at loss curves.
<ul>
<li>Losses may be noisy
<ul>
<li>Use a scatter plot</li>
<li>Also plot exponentially decaying moving average to see trends better.</li>
</ul>
</li>
</ul>
</li>
<li>Go to (5)</li>
</ol>
<h3 id="summary">Summary</h3>
<ul>
<li>Improve your training error
<ul>
<li>Network architectures</li>
<li>Initializations</li>
<li>Optimizers</li>
<li>Learning rate schedulers</li>
</ul>
</li>
<li>Improve your test error
<ul>
<li>Regularization</li>
<li>Choosing Hyperparameters</li>
</ul>
</li>
</ul>


</body></html> </article>  <nav class="col-start-2 grid grid-cols-1 gap-4 sm:grid-cols-2"> <a href="/notes/exchange/cs4487/cs4487_9" target="_self" class="duration-300 ease-in-out gap-2 whitespace-nowrap text-sm font-medium transition-all disabled:pointer-events-none disabled:opacity-50 [&#38;_svg]:pointer-events-none [&#38;_svg:not([class*='size-'])]:size-4 shrink-0 [&#38;_svg]:shrink-0 outline-none focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:ring-[3px] aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive border bg-background shadow-xs hover:bg-accent hover:text-accent-foreground dark:bg-input/30 dark:border-input dark:hover:bg-input/50 px-4 py-2 has-[>svg]:px-3 rounded-lg group flex items-center justify-start size-full" aria-disabled="false">  <svg width="1em" height="1em" viewBox="0 0 24 24" class="mr-2 size-4 transition-transform group-hover:-translate-x-1" data-icon="lucide:arrow-left">   <use href="#ai:lucide:arrow-left"></use>  </svg> <div class="flex flex-col items-start overflow-hidden text-wrap"> <span class="text-muted-foreground text-left text-xs"> Previous Post </span> <span class="w-full text-left text-sm text-balance text-ellipsis"> Part 9 - Neural Networks and Deep Learning </span> </div>  </a>  <a href="/notes/exchange/cs4487/cs4487_11" target="_self" class="duration-300 ease-in-out gap-2 whitespace-nowrap text-sm font-medium transition-all disabled:pointer-events-none disabled:opacity-50 [&#38;_svg]:pointer-events-none [&#38;_svg:not([class*='size-'])]:size-4 shrink-0 [&#38;_svg]:shrink-0 outline-none focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:ring-[3px] aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive border bg-background shadow-xs hover:bg-accent hover:text-accent-foreground dark:bg-input/30 dark:border-input dark:hover:bg-input/50 px-4 py-2 has-[>svg]:px-3 rounded-lg group flex items-center justify-end size-full" aria-disabled="false">  <div class="flex flex-col items-end overflow-hidden text-wrap"> <span class="text-muted-foreground text-right text-xs"> Next Post </span> <span class="w-full text-right text-sm text-balance text-ellipsis"> Part 11 - High-Level and Low-Level Vision Applications </span> </div> <svg width="1em" height="1em" viewBox="0 0 24 24" class="ml-2 size-4 transition-transform group-hover:translate-x-1" data-icon="lucide:arrow-right">   <use href="#ai:lucide:arrow-right"></use>  </svg>  </a> </nav> <div class="col-start-2"> <section class="mx-auto mt-12"> <script data-astro-rerun src="https://giscus.app/client.js" data-repo="rezaarezvan/rezarezvan.com" data-repo-id="R_kgDOHvQr3w" data-category="General" data-category-id="DIC_kwDOHvQr384CiWVC" data-mapping="og:title" data-strict="0" data-reactions-enabled="1" data-emit-metadata="0" data-input-position="bottom" data-theme="preferred_color_scheme" data-lang="en" data-loading="lazy" crossorigin="anonymous" async></script> </section> <script>
  function updateGiscusTheme() {
    const element = document.documentElement
    const theme = element.getAttribute('data-theme')
    const iframe = document.querySelector('iframe.giscus-frame')
    if (!iframe) return
    iframe.contentWindow.postMessage(
      { giscus: { setConfig: { theme } } },
      'https://giscus.app',
    )
  }

  const observer = new MutationObserver(updateGiscusTheme)
  observer.observe(document.documentElement, {
    attributes: true,
    attributeFilter: ['class'],
  })

  window.onload = () => {
    updateGiscusTheme()
  }
</script> </div> </section> <button data-slot="button" class="items-center justify-center gap-2 whitespace-nowrap rounded-md text-sm font-medium transition-all disabled:pointer-events-none disabled:opacity-50 [&amp;_svg]:pointer-events-none [&amp;_svg:not([class*=&#x27;size-&#x27;])]:size-4 shrink-0 [&amp;_svg]:shrink-0 outline-none focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:ring-[3px] aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive border bg-background shadow-xs hover:bg-accent hover:text-accent-foreground dark:bg-input/30 dark:border-input dark:hover:bg-input/50 size-9 group fixed right-8 bottom-8 z-50 hidden" id="scroll-to-top" title="Scroll to top" aria-label="Scroll to top"> <svg width="1em" height="1em" class="mx-auto size-4 transition-all group-hover:-translate-y-0.5" data-icon="lucide:arrow-up">   <symbol id="ai:lucide:arrow-up" viewBox="0 0 24 24"><path fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="m5 12l7-7l7 7m-7 7V5"/></symbol><use href="#ai:lucide:arrow-up"></use>  </svg> </button> <script type="module">document.addEventListener("astro:page-load",()=>{const o=document.getElementById("scroll-to-top"),t=document.querySelector("footer");o&&t&&(o.addEventListener("click",()=>{window.scrollTo({top:0,behavior:"smooth"})}),window.addEventListener("scroll",()=>{const e=t.getBoundingClientRect().top<=window.innerHeight;o.classList.toggle("hidden",window.scrollY<=300||e)}))});</script>  </div> </main> <footer class="py-4"> <div class="mx-auto flex max-w-3xl flex-col items-center justify-center gap-y-2 px-4 sm:flex-row sm:justify-between"> <div class="flex flex-wrap items-center justify-center gap-x-2 text-center"> <span class="text-muted-foreground text-sm">
&copy; 2025 • rezarezvan.com </span> </div> </div> </footer> <div id="backdrop" class="invisible fixed top-0 left-0 z-50 flex h-screen w-full justify-center bg-[rgba(0,0,0,0.5)] p-6 backdrop-blur-sm" data-astro-transition-persist="astro-t6dxx5el-4"> <div id="pagefind-container" class="m-0 flex h-fit max-h-[80%] w-full max-w-screen-sm flex-col overflow-auto rounded border border-black/15 bg-neutral-100 p-2 px-4 py-3 shadow-lg dark:border-white/20 dark:bg-neutral-900"> <div id="search" class="pagefind-ui pagefind-init" data-pagefind-ui data-bundle-path="/pagefind/" data-ui-options="{&#34;showImages&#34;:false,&#34;excerptLength&#34;:15,&#34;resetStyles&#34;:false}"></div> <script type="module" src="/_astro/Search.astro_astro_type_script_index_0_lang.tZYucdM2.js"></script> <div class="dark:prose-invert mr-2 pt-4 pb-1 text-right text-xs">
Press <span class="prose dark:prose-invert text-xs"><kbd class="">Esc</kbd></span> or click anywhere to close
</div> </div> </div> <script>
  document.addEventListener('DOMContentLoaded', () => {
    const magnifyingGlass = document.getElementById('magnifying-glass')
    const backdrop = document.getElementById('backdrop')

    function openPagefind() {
      const searchDiv = document.getElementById('search')
      const search = searchDiv.querySelector('input')
      setTimeout(() => {
        search.focus()
      }, 0)
      backdrop?.classList.remove('invisible')
      backdrop?.classList.add('visible')
    }

    function closePagefind() {
      const searchDiv = document.getElementById('search')
      const search = searchDiv.querySelector('input')
      if (search) {
        search.value = ''
      }
      backdrop?.classList.remove('visible')
      backdrop?.classList.add('invisible')
    }

    // open pagefind
    magnifyingGlass?.addEventListener('click', () => {
      openPagefind()
    })

    document.addEventListener('keydown', (e) => {
      if (e.key === 'Escape') {
        closePagefind()
      }
    })

    // close pagefind when searched result(link) clicked
    document.addEventListener('click', (event) => {
      if (event.target.classList.contains('pagefind-ui__result-link')) {
        closePagefind()
      }
    })

    backdrop?.addEventListener('click', (event) => {
      if (!event.target.closest('#pagefind-container')) {
        closePagefind()
      }
    })

    // prevent form submission
    const form = document.getElementById('form')
    form?.addEventListener('submit', (event) => {
      event.preventDefault()
    })
  })
</script>  </div> </body></html>