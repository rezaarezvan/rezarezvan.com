<!DOCTYPE html><html class="bg-background text-foreground" lang="en"> <head><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes"><meta name="generator" content="Astro v5.16.1"><meta name="robots" content="index, follow"><meta name="HandheldFriendly" content="True"><meta name="mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="format-detection" content="telephone=no,date=no,address=no,email=no,url=no"><meta name="theme-color" content="#121212" media="(prefers-color-scheme: dark)"><meta name="theme-color" content="#121212" media="(prefers-color-scheme: light)"><link rel="sitemap" href="/sitemap-index.xml"><link rel="manifest" href="/site.webmanifest"><link rel="alternate" type="application/rss+xml" title="rezarezvan.com" href="https://rezarezvan.com/rss.xml"><!-- PageFind --><link href="/pagefind/pagefind-ui.css" rel="stylesheet"><script src="/pagefind/pagefind-ui.js"></script><!-- KaTeX support --><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.22/dist/katex.min.css" integrity="sha384-5TcZemv2l/9On385z///+d7MSYlvIEw9FuZTIdZ14vJLqWphw7e7ZPuOiCHJcFCP" crossorigin="anonymous"><script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.22/dist/katex.min.js" integrity="sha384-cMkvdD8LoxVzGF/RPUKAcvmm49FQ0oxwDF3BGKtDXcEc+T1b2N+teh/OJfpU0jr6" crossorigin="anonymous"></script><script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.22/dist/contrib/auto-render.min.js" integrity="sha384-hCXGrW6PitJEwbkoStFjeJxv+fSOOQKOPbJxSfM6G5sWZjAyWhXiTIIAmQqnlLlh" crossorigin="anonymous" onload="renderMathInElement(document.body);"></script><!-- inline KaTeX --><script>
    function renderKaTeX() {
      if (typeof renderMathInElement !== 'undefined') {
        renderMathInElement(document.body, {
          delimiters: [
            { left: '$$', right: '$$', display: true },
            { left: '$', right: '$', display: false },
          ],
        })
      }
    }

    document.addEventListener('DOMContentLoaded', renderKaTeX)
    document.addEventListener('astro:after-swap', renderKaTeX)
  </script><link rel="icon" type="image/png" href="/favicon-96x96.png" sizes="96x96"><link rel="icon" type="image/svg+xml" href="/favicon.ico"><link rel="shortcut icon" href="/favicon.ico"><link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png"><meta name="apple-mobile-web-app-title" content="rezvan-blog"><link rel="manifest" href="/site.webmanifest"><meta name="astro-view-transitions-enabled" content="true"><meta name="astro-view-transitions-fallback" content="animate"><script type="module" src="/_astro/ClientRouter.astro_astro_type_script_index_0_lang.QW52Ox2j.js"></script><script>
    function init() {
      setGiscusTheme()
    }

    const setGiscusTheme = () => {
      const giscus = document.querySelector('.giscus-frame')

      const isDark = document.documentElement.classList.contains('dark')

      if (giscus) {
        const url = new URL(giscus.src)
        url.searchParams.set('theme', isDark ? 'dark' : 'light')
        giscus.src = url.toString()
      }
    }

    document.addEventListener('DOMContentLoaded', () => init())
    document.addEventListener('astro:after-swap', () => init())
  </script><title>Part 2 &amp; 3 - Bayesian Linear Regression | rezarezvan.com</title><meta name="title" content="Part 2 &#38; 3 - Bayesian Linear Regression | rezarezvan.com"><meta name="description" content="Personal website and course notes repository"><link rel="canonical" href="https://rezarezvan.com"><meta name="robots" content="noindex"><meta property="og:title" content="Part 2 &#38; 3 - Bayesian Linear Regression"><meta property="og:description" content="Personal website and course notes repository"><meta property="og:image" content="https://rezarezvan.com/static/1200x630.png"><meta property="og:image:alt" content="Part 2 &#38; 3 - Bayesian Linear Regression"><meta property="og:type" content="website"><meta property="og:locale" content="en"><meta property="og:site_name" content="rezarezvan.com"><meta property="og:url" content="https://rezarezvan.com/notes/master/ssy316/ssy316_2/"><meta name="twitter:title" content="Part 2 &#38; 3 - Bayesian Linear Regression"><meta name="twitter:description" content="Personal website and course notes repository"><meta property="twitter:image" content="https://rezarezvan.com/static/1200x630.png"><meta name="twitter:image:alt" content="Part 2 &#38; 3 - Bayesian Linear Regression"><meta name="twitter:card" content="summary_large_image"><link rel="stylesheet" href="/_astro/_slug_.B1jzn1J1.css"></head><body> <div class="flex h-fit min-h-screen flex-col gap-y-6 font-sans"> <div class="bg-background/50 sticky top-0 z-50 divide-y backdrop-blur-sm xl:divide-none"> <header data-astro-transition-persist="astro-l7r54iwe-1"> <div class="mx-auto flex max-w-3xl items-center justify-between gap-4 px-4 py-3"> <a href="/" target="_self" class="transition-colors duration-300 ease-in-out flex shrink-0 items-center justify-center gap-3">  <span class="hidden h-full text-lg font-medium min-[300px]:block">rezarezvan.com</span>  </a> <div class="flex items-center sm:gap-4"> <nav class="hidden items-center gap-4 text-sm sm:flex sm:gap-6"> <a href="/blog" target="_self" class="inline-block duration-300 ease-in-out hover:text-foreground/30 transition-colors"> blog<span>/</span>  </a><a href="/notes" target="_self" class="inline-block duration-300 ease-in-out hover:text-foreground/30 transition-colors"> notes<span>/</span>  </a><a href="/dump" target="_self" class="inline-block duration-300 ease-in-out hover:text-foreground/30 transition-colors"> dump<span>/</span>  </a><a href="/research" target="_self" class="inline-block duration-300 ease-in-out hover:text-foreground/30 transition-colors"> research<span>/</span>  </a> </nav> <button id="magnifying-glass" aria-label="Search" class="flex items-center px-2 text-sm transition-colors duration-300 ease-in-out hover:rounded hover:bg-black/5 hover:text-black focus-visible:bg-black/5 focus-visible:text-black dark:hover:bg-white/5 dark:hover:text-white dark:focus-visible:bg-white/5 dark:focus-visible:text-white"> <svg height="16" stroke-linejoin="round" viewBox="0 0 16 16" width="16" style="color: currentcolor;"> <path fill-rule="evenodd" clip-rule="evenodd" d="M3.5 7C3.5 5.067 5.067 3.5 7 3.5C8.933 3.5 10.5 5.067 10.5 7C10.5 7.88461 10.1718 8.69256 9.63058 9.30876L9.30876 9.63058C8.69256 10.1718 7.88461 10.5 7 10.5C5.067 10.5 3.5 8.933 3.5 7ZM9.96544 11.0261C9.13578 11.6382 8.11014 12 7 12C4.23858 12 2 9.76142 2 7C2 4.23858 4.23858 2 7 2C9.76142 2 12 4.23858 12 7C12 8.11014 11.6382 9.13578 11.0261 9.96544L14.0303 12.9697L14.5607 13.5L13.5 14.5607L12.9697 14.0303L9.96544 11.0261Z" fill="currentColor"></path> </svg>
&nbsp;Search
</button> <style>astro-island,astro-slot,astro-static-slot{display:contents}</style><script>(()=>{var e=async t=>{await(await t())()};(self.Astro||(self.Astro={})).load=e;window.dispatchEvent(new Event("astro:load"));})();</script><script>(()=>{var A=Object.defineProperty;var g=(i,o,a)=>o in i?A(i,o,{enumerable:!0,configurable:!0,writable:!0,value:a}):i[o]=a;var d=(i,o,a)=>g(i,typeof o!="symbol"?o+"":o,a);{let i={0:t=>m(t),1:t=>a(t),2:t=>new RegExp(t),3:t=>new Date(t),4:t=>new Map(a(t)),5:t=>new Set(a(t)),6:t=>BigInt(t),7:t=>new URL(t),8:t=>new Uint8Array(t),9:t=>new Uint16Array(t),10:t=>new Uint32Array(t),11:t=>1/0*t},o=t=>{let[l,e]=t;return l in i?i[l](e):void 0},a=t=>t.map(o),m=t=>typeof t!="object"||t===null?t:Object.fromEntries(Object.entries(t).map(([l,e])=>[l,o(e)]));class y extends HTMLElement{constructor(){super(...arguments);d(this,"Component");d(this,"hydrator");d(this,"hydrate",async()=>{var b;if(!this.hydrator||!this.isConnected)return;let e=(b=this.parentElement)==null?void 0:b.closest("astro-island[ssr]");if(e){e.addEventListener("astro:hydrate",this.hydrate,{once:!0});return}let c=this.querySelectorAll("astro-slot"),n={},h=this.querySelectorAll("template[data-astro-template]");for(let r of h){let s=r.closest(this.tagName);s!=null&&s.isSameNode(this)&&(n[r.getAttribute("data-astro-template")||"default"]=r.innerHTML,r.remove())}for(let r of c){let s=r.closest(this.tagName);s!=null&&s.isSameNode(this)&&(n[r.getAttribute("name")||"default"]=r.innerHTML)}let p;try{p=this.hasAttribute("props")?m(JSON.parse(this.getAttribute("props"))):{}}catch(r){let s=this.getAttribute("component-url")||"<unknown>",v=this.getAttribute("component-export");throw v&&(s+=` (export ${v})`),console.error(`[hydrate] Error parsing props for component ${s}`,this.getAttribute("props"),r),r}let u;await this.hydrator(this)(this.Component,p,n,{client:this.getAttribute("client")}),this.removeAttribute("ssr"),this.dispatchEvent(new CustomEvent("astro:hydrate"))});d(this,"unmount",()=>{this.isConnected||this.dispatchEvent(new CustomEvent("astro:unmount"))})}disconnectedCallback(){document.removeEventListener("astro:after-swap",this.unmount),document.addEventListener("astro:after-swap",this.unmount,{once:!0})}connectedCallback(){if(!this.hasAttribute("await-children")||document.readyState==="interactive"||document.readyState==="complete")this.childrenConnectedCallback();else{let e=()=>{document.removeEventListener("DOMContentLoaded",e),c.disconnect(),this.childrenConnectedCallback()},c=new MutationObserver(()=>{var n;((n=this.lastChild)==null?void 0:n.nodeType)===Node.COMMENT_NODE&&this.lastChild.nodeValue==="astro:end"&&(this.lastChild.remove(),e())});c.observe(this,{childList:!0}),document.addEventListener("DOMContentLoaded",e)}}async childrenConnectedCallback(){let e=this.getAttribute("before-hydration-url");e&&await import(e),this.start()}async start(){let e=JSON.parse(this.getAttribute("opts")),c=this.getAttribute("client");if(Astro[c]===void 0){window.addEventListener(`astro:${c}`,()=>this.start(),{once:!0});return}try{await Astro[c](async()=>{let n=this.getAttribute("renderer-url"),[h,{default:p}]=await Promise.all([import(this.getAttribute("component-url")),n?import(n):()=>()=>{}]),u=this.getAttribute("component-export")||"default";if(!u.includes("."))this.Component=h[u];else{this.Component=h;for(let f of u.split("."))this.Component=this.Component[f]}return this.hydrator=p,this.hydrate},e,this)}catch(n){console.error(`[astro-island] Error hydrating ${this.getAttribute("component-url")}`,n)}}attributeChangedCallback(){this.hydrate()}}d(y,"observedAttributes",["props"]),customElements.get("astro-island")||customElements.define("astro-island",y)}})();</script><astro-island uid="1cdVI1" prefix="r28" component-url="/_astro/mobile-menu.DvFCA0M9.js" component-export="default" renderer-url="/_astro/client.DXIZDqlh.js" props="{&quot;data-astro-transition-persist&quot;:[0,&quot;astro-iq5tym4z-2&quot;]}" ssr client="load" opts="{&quot;name&quot;:&quot;MobileMenu&quot;,&quot;value&quot;:true}" data-astro-transition-persist="astro-iq5tym4z-2" await-children><button data-slot="dropdown-menu-trigger" class="inline-flex items-center justify-center gap-2 whitespace-nowrap rounded-md text-sm font-medium transition-all disabled:pointer-events-none disabled:opacity-50 [&amp;_svg]:pointer-events-none [&amp;_svg:not([class*=&#x27;size-&#x27;])]:size-4 shrink-0 [&amp;_svg]:shrink-0 outline-none focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:ring-[3px] aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive hover:bg-accent hover:text-accent-foreground dark:hover:bg-accent/50 size-9 md:hidden" title="Menu" type="button" id="radix-:r28R0:" aria-haspopup="menu" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-menu h-5 w-5"><line x1="4" x2="20" y1="12" y2="12"></line><line x1="4" x2="20" y1="6" y2="6"></line><line x1="4" x2="20" y1="18" y2="18"></line></svg><span class="sr-only">Toggle menu</span></button><!--astro:end--></astro-island> <button data-slot="button" class="inline-flex items-center justify-center gap-2 whitespace-nowrap rounded-md text-sm font-medium transition-all disabled:pointer-events-none disabled:opacity-50 [&amp;_svg]:pointer-events-none [&amp;_svg:not([class*=&#x27;size-&#x27;])]:size-4 shrink-0 [&amp;_svg]:shrink-0 outline-none focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:ring-[3px] aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive hover:bg-accent hover:text-accent-foreground dark:hover:bg-accent/50 size-9" id="theme-toggle" title="Toggle theme"> <svg width="1em" height="1em" class="size-4 scale-100 rotate-0 transition-all dark:scale-0 dark:-rotate-90" data-icon="lucide:sun">   <symbol id="ai:lucide:sun" viewBox="0 0 24 24"><g fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2"><circle cx="12" cy="12" r="4"/><path d="M12 2v2m0 16v2M4.93 4.93l1.41 1.41m11.32 11.32l1.41 1.41M2 12h2m16 0h2M6.34 17.66l-1.41 1.41M19.07 4.93l-1.41 1.41"/></g></symbol><use href="#ai:lucide:sun"></use>  </svg> <svg width="1em" height="1em" class="absolute size-4 scale-0 rotate-90 transition-all dark:scale-100 dark:rotate-0" data-icon="lucide:moon">   <symbol id="ai:lucide:moon" viewBox="0 0 24 24"><path fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M20.985 12.486a9 9 0 1 1-9.473-9.472c.405-.022.617.46.402.803a6 6 0 0 0 8.268 8.268c.344-.215.825-.004.803.401"/></symbol><use href="#ai:lucide:moon"></use>  </svg> <span class="sr-only">Toggle theme</span> </button> <script data-astro-rerun>
  const theme = (() => {
    const localStorageTheme = localStorage?.getItem('theme') ?? ''
    if (['dark', 'light'].includes(localStorageTheme)) {
      return localStorageTheme
    }
    if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
      return 'dark'
    }
    return 'light'
  })()

  document.documentElement.setAttribute('data-theme', theme)
  document.documentElement.classList.add(
    theme === 'dark' ? 'scheme-dark' : 'scheme-light',
  )
  window.localStorage.setItem('theme', theme)
</script> <script type="module">function a(){const e=document.documentElement,n=e.getAttribute("data-theme")==="dark"?"light":"dark";e.classList.add("[&_*]:transition-none"),e.setAttribute("data-theme",n),e.classList.remove("scheme-dark","scheme-light"),e.classList.add(n==="dark"?"scheme-dark":"scheme-light"),window.getComputedStyle(e).getPropertyValue("opacity"),requestAnimationFrame(()=>{e.classList.remove("[&_*]:transition-none")}),localStorage.setItem("theme",n)}function s(){const e=document.getElementById("theme-toggle");e&&e.addEventListener("click",a)}s();document.addEventListener("astro:after-swap",()=>{const e=localStorage.getItem("theme")||"light",t=document.documentElement;t.classList.add("[&_*]:transition-none"),window.getComputedStyle(t).getPropertyValue("opacity"),t.setAttribute("data-theme",e),t.classList.remove("scheme-dark","scheme-light"),t.classList.add(e==="dark"?"scheme-dark":"scheme-light"),requestAnimationFrame(()=>{t.classList.remove("[&_*]:transition-none")}),s()});</script> </div> </div> </header> <div id="mobile-toc-container" class="w-full xl:hidden"><details class="group"><summary class="flex w-full cursor-pointer items-center justify-between"><div class="mx-auto flex w-full max-w-3xl items-center px-4 py-3"><div class="relative mr-2 size-4"><svg class="h-4 w-4" viewBox="0 0 24 24"><circle class="text-primary/20" cx="12" cy="12" r="10" fill="none" stroke="currentColor" stroke-width="2"></circle><circle id="mobile-toc-progress-circle" class="text-primary" cx="12" cy="12" r="10" fill="none" stroke="currentColor" stroke-width="2" stroke-dasharray="62.83" stroke-dashoffset="62.83" transform="rotate(-90 12 12)"></circle></svg></div><span id="mobile-toc-current-section" class="text-muted-foreground flex-grow truncate text-sm">
Overview
</span><span class="text-muted-foreground ml-2"><svg width="1em" height="1em" class="h-4 w-4 transition-transform duration-200 group-open:rotate-180" data-icon="lucide:chevron-down">   <symbol id="ai:lucide:chevron-down" viewBox="0 0 24 24"><path fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="m6 9l6 6l6-6"/></symbol><use href="#ai:lucide:chevron-down"></use>  </svg></span></div></summary><astro-island uid="ZMgccP" prefix="r22" component-url="/_astro/scroll-area.BdR3V4Yj.js" component-export="ScrollArea" renderer-url="/_astro/client.DXIZDqlh.js" props="{&quot;className&quot;:[0,&quot;mx-auto max-w-3xl&quot;],&quot;data-toc-header-scroll&quot;:[0,true]}" ssr client="load" opts="{&quot;name&quot;:&quot;ScrollArea&quot;,&quot;value&quot;:true}" await-children><div dir="ltr" data-slot="scroll-area" class="relative mx-auto max-w-3xl" data-toc-header-scroll="true" style="position:relative;--radix-scroll-area-corner-width:0px;--radix-scroll-area-corner-height:0px"><style>[data-radix-scroll-area-viewport]{scrollbar-width:none;-ms-overflow-style:none;-webkit-overflow-scrolling:touch;}[data-radix-scroll-area-viewport]::-webkit-scrollbar{display:none}</style><div data-radix-scroll-area-viewport="" data-slot="scroll-area-viewport" class="ring-ring/10 dark:ring-ring/20 dark:outline-ring/40 outline-ring/50 size-full rounded-[inherit] transition-[color,box-shadow] focus-visible:ring-4 focus-visible:outline-1" style="overflow-x:hidden;overflow-y:hidden"><div style="min-width:100%;display:table"><astro-slot><div class="max-h-[30vh]"><ul class="flex list-none flex-col gap-y-2 px-4 pb-4" id="mobile-table-of-contents"><li class="px-4 text-sm text-foreground/60"><a href="#introduction" class="mobile-toc-item underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit" data-heading-id="introduction">Introduction</a></li><li class="px-4 text-sm text-foreground/60"><a href="#supervised-machine-learning" class="mobile-toc-item underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit" data-heading-id="supervised-machine-learning">Supervised Machine Learning</a></li><li class="px-4 text-sm ml-4 text-foreground/60"><a href="#the-inference-problem" class="mobile-toc-item underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit" data-heading-id="the-inference-problem">The Inference Problem</a></li><li class="px-4 text-sm ml-4 text-foreground/60"><a href="#frequentist-approach" class="mobile-toc-item underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit" data-heading-id="frequentist-approach">Frequentist Approach</a></li><li class="px-4 text-sm text-foreground/60"><a href="#linear-regression-problem-setting" class="mobile-toc-item underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit" data-heading-id="linear-regression-problem-setting">Linear Regression: Problem Setting</a></li><li class="px-4 text-sm ml-4 text-foreground/60"><a href="#probabilistic-modeling" class="mobile-toc-item underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit" data-heading-id="probabilistic-modeling">Probabilistic Modeling</a></li><li class="px-4 text-sm ml-4 text-foreground/60"><a href="#discriminative-vs-generative-probabilistic-models" class="mobile-toc-item underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit" data-heading-id="discriminative-vs-generative-probabilistic-models">Discriminative VS. Generative Probabilistic Models</a></li><li class="px-4 text-sm text-foreground/60"><a href="#learning-the-model-parameters" class="mobile-toc-item underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit" data-heading-id="learning-the-model-parameters">Learning the Model Parameters</a></li><li class="px-4 text-sm ml-4 text-foreground/60"><a href="#maximum-likelihood-estimation" class="mobile-toc-item underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit" data-heading-id="maximum-likelihood-estimation">Maximum Likelihood Estimation</a></li><li class="px-4 text-sm ml-4 text-foreground/60"><a href="#training-generalization-loss-bias-and-estimation-error" class="mobile-toc-item underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit" data-heading-id="training-generalization-loss-bias-and-estimation-error">Training, Generalization Loss, Bias, and Estimation Error</a></li><li class="px-4 text-sm ml-4 text-foreground/60"><a href="#learning-and-validation" class="mobile-toc-item underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit" data-heading-id="learning-and-validation">Learning and Validation</a></li><li class="px-4 text-sm text-foreground/60"><a href="#maximum-a-posteriori-learning" class="mobile-toc-item underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit" data-heading-id="maximum-a-posteriori-learning">Maximum A Posteriori Learning</a></li><li class="px-4 text-sm ml-4 text-foreground/60"><a href="#how-do-we-choose-the-prior-distribution" class="mobile-toc-item underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit" data-heading-id="how-do-we-choose-the-prior-distribution">How do we choose the prior distribution?</a></li><li class="px-4 text-sm text-foreground/60"><a href="#maximum-a-posteriori-learning-continued" class="mobile-toc-item underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit" data-heading-id="maximum-a-posteriori-learning-continued">Maximum A Posteriori Learning: Continued</a></li><li class="px-4 text-sm text-foreground/60"><a href="#footnote-label" class="mobile-toc-item underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit" data-heading-id="footnote-label">Footnotes</a></li></ul></div></astro-slot></div></div></div><!--astro:end--></astro-island></details></div><script type="module" src="/_astro/TOCHeader.astro_astro_type_script_index_0_lang.CKMLAwWj.js"></script> <div id="mobile-margin-notes-container" class="w-full xl:hidden"><details class="group"><summary class="flex w-full cursor-pointer items-center justify-between"><div class="mx-auto flex w-full max-w-3xl items-center px-4 py-3"><div class="relative mr-2 size-4"><svg width="1em" height="1em" class="size-4 flex-shrink-0" aria-hidden="true" data-icon="lucide:pencil-line">   <symbol id="ai:lucide:pencil-line" viewBox="0 0 24 24"><path fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M13 21h8M15 5l4 4m2.174-2.188a1 1 0 0 0-3.986-3.987L3.842 16.174a2 2 0 0 0-.5.83l-1.321 4.352a.5.5 0 0 0 .623.622l4.353-1.32a2 2 0 0 0 .83-.497z"/></symbol><use href="#ai:lucide:pencil-line"></use>  </svg></div><div class="flex flex-grow flex-col truncate text-sm"><span id="mobile-margin-current-note" class="text-muted-foreground truncate">
Margin Notes (1)
</span></div><span class="text-muted-foreground ml-2"><svg width="1em" height="1em" viewBox="0 0 24 24" class="h-4 w-4 transition-transform duration-200 group-open:rotate-180" data-icon="lucide:chevron-down">   <use href="#ai:lucide:chevron-down"></use>  </svg></span></div></summary><astro-island uid="Z1L4LdW" prefix="r23" component-url="/_astro/scroll-area.BdR3V4Yj.js" component-export="ScrollArea" renderer-url="/_astro/client.DXIZDqlh.js" props="{&quot;className&quot;:[0,&quot;mx-auto max-w-3xl&quot;],&quot;data-marginnotes-header-scroll&quot;:[0,true]}" ssr client="load" opts="{&quot;name&quot;:&quot;ScrollArea&quot;,&quot;value&quot;:true}" await-children><div dir="ltr" data-slot="scroll-area" class="relative mx-auto max-w-3xl" data-marginnotes-header-scroll="true" style="position:relative;--radix-scroll-area-corner-width:0px;--radix-scroll-area-corner-height:0px"><style>[data-radix-scroll-area-viewport]{scrollbar-width:none;-ms-overflow-style:none;-webkit-overflow-scrolling:touch;}[data-radix-scroll-area-viewport]::-webkit-scrollbar{display:none}</style><div data-radix-scroll-area-viewport="" data-slot="scroll-area-viewport" class="ring-ring/10 dark:ring-ring/20 dark:outline-ring/40 outline-ring/50 size-full rounded-[inherit] transition-[color,box-shadow] focus-visible:ring-4 focus-visible:outline-1" style="overflow-x:hidden;overflow-y:hidden"><div style="min-width:100%;display:table"><astro-slot><div class="max-h-[30vh]"><ul class="flex list-none flex-col gap-y-1 px-4 pb-4"><li><a href="#mn-1" data-note-id="mn-1" class="mobile-margin-note-item hover:text-foreground text-muted-foreground hover:bg-muted/50 flex items-start gap-2 rounded-md px-2 py-1.5 text-sm transition-colors"><span class="text-primary bg-primary/10 shrink-0 rounded px-1.5 py-0.5 font-mono text-xs">1</span><div class="flex flex-col"><span class="line-clamp-2 text-left">since $\log(\cdot)$ is a monotonic function and does not change the location of the maximum</span></div></a></li></ul></div></astro-slot></div></div></div><!--astro:end--></astro-island></details></div><script type="module">function m(){const e=document.getElementById("mobile-margin-notes-container");if(!e)return;const i=e.querySelector("details"),s=e.querySelectorAll(".mobile-margin-note-item"),c=document.getElementById("mobile-margin-current-note");s.forEach(n=>{n.addEventListener("click",a=>{a.preventDefault();const l=n.dataset.noteId,o=document.getElementById(l);if(o){const r=o.getBoundingClientRect().top+window.scrollY-120;if(window.scrollTo({top:r,behavior:"smooth"}),document.querySelectorAll(".margin-anchor").forEach(t=>{t.classList.remove("active")}),o.classList.add("active"),c){const t=n.querySelector("span:last-child")?.textContent?.trim();t&&(c.textContent=t.length>30?t.substring(0,30)+"...":t)}}i&&(i.open=!1)})});const u=new IntersectionObserver(n=>{n.forEach(a=>{const l=a.target.id,o=e.querySelector(`.mobile-margin-note-item[data-note-id="${l}"]`);if(a.isIntersecting&&o&&c){e.querySelectorAll(".mobile-margin-note-item").forEach(t=>{t.classList.remove("active")}),o.classList.add("active");const r=o.querySelector("span:last-child")?.textContent?.trim();r&&(c.textContent=r.length>30?r.substring(0,30)+"...":r)}})},{rootMargin:"-120px 0px -70% 0px",threshold:.1});document.querySelectorAll(".margin-anchor").forEach(n=>{u.observe(n)})}function d(){document.querySelectorAll(".mobile-margin-note-item").forEach(i=>{i.classList.remove("active")});const e=document.getElementById("mobile-margin-current-note");if(e){const s=document.getElementById("mobile-margin-notes-container")?.querySelectorAll(".mobile-margin-note-item").length||0;e.textContent=`Margin Notes (${s})`}}document.addEventListener("astro:page-load",m);document.addEventListener("astro:after-swap",()=>{d(),m()});document.addEventListener("astro:before-swap",d);</script>  </div> <main class="grow"> <div class="mx-auto flex grow flex-col gap-y-6 px-4">   <section class="grid grid-cols-[minmax(0px,1fr)_min(calc(var(--breakpoint-md)-2rem),100%)_minmax(0px,1fr)] gap-y-6"> <div class="col-start-2"> <nav aria-label="breadcrumb" data-slot="breadcrumb"> <ol data-slot="breadcrumb-list" class="text-muted-foreground flex flex-wrap items-center gap-1.5 text-sm break-words sm:gap-2.5"> <li data-slot="breadcrumb-item" class="inline-flex items-center gap-1.5"> <a data-slot="breadcrumb-link" class="hover:text-foreground transition-colors" href="/"> <svg width="1em" height="1em" class="size-4 shrink-0" data-icon="lucide:home">   <symbol id="ai:lucide:home" viewBox="0 0 24 24"><g fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2"><path d="M15 21v-8a1 1 0 0 0-1-1h-4a1 1 0 0 0-1 1v8"/><path d="M3 10a2 2 0 0 1 .709-1.528l7-6a2 2 0 0 1 2.582 0l7 6A2 2 0 0 1 21 10v9a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2z"/></g></symbol><use href="#ai:lucide:home"></use>  </svg> </a> </li>  <li data-slot="breadcrumb-separator" role="presentation" aria-hidden="true" class="[&amp;&gt;svg]:size-3.5"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-chevron-right"><path d="m9 18 6-6-6-6"></path></svg></li> <li data-slot="breadcrumb-item" class="inline-flex items-center gap-1.5"><a data-slot="breadcrumb-link" class="hover:text-foreground transition-colors" href="/notes/"> <span class="flex items-center gap-x-2"> <svg width="1em" height="1em" class="size-4" data-icon="lucide:graduation-cap">   <symbol id="ai:lucide:graduation-cap" viewBox="0 0 24 24"><g fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2"><path d="M21.42 10.922a1 1 0 0 0-.019-1.838L12.83 5.18a2 2 0 0 0-1.66 0L2.6 9.08a1 1 0 0 0 0 1.832l8.57 3.908a2 2 0 0 0 1.66 0zM22 10v6"/><path d="M6 12.5V16a6 3 0 0 0 12 0v-3.5"/></g></symbol><use href="#ai:lucide:graduation-cap"></use>  </svg> Master </span> </a></li>  <li data-slot="breadcrumb-separator" role="presentation" aria-hidden="true" class="[&amp;&gt;svg]:size-3.5"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-chevron-right"><path d="m9 18 6-6-6-6"></path></svg></li> <li data-slot="breadcrumb-item" class="inline-flex items-center gap-1.5"><a data-slot="breadcrumb-link" class="hover:text-foreground transition-colors" href="/notes/master/ssy316"> <span class="flex items-center gap-x-2"> <svg width="1em" height="1em" class="size-4" data-icon="lucide:book-open">   <symbol id="ai:lucide:book-open" viewBox="0 0 24 24"><path fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M12 7v14m-9-3a1 1 0 0 1-1-1V4a1 1 0 0 1 1-1h5a4 4 0 0 1 4 4a4 4 0 0 1 4-4h5a1 1 0 0 1 1 1v13a1 1 0 0 1-1 1h-6a3 3 0 0 0-3 3a3 3 0 0 0-3-3z"/></symbol><use href="#ai:lucide:book-open"></use>  </svg> Advanced Probabilistic Machine Learning </span> </a></li>  <li data-slot="breadcrumb-separator" role="presentation" aria-hidden="true" class="[&amp;&gt;svg]:size-3.5"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-chevron-right"><path d="m9 18 6-6-6-6"></path></svg></li> <li data-slot="breadcrumb-item" class="inline-flex items-center gap-1.5"><span data-slot="breadcrumb-page" role="link" aria-disabled="true" aria-current="page" class="text-foreground font-normal"> <span class="flex items-center gap-x-2"> <svg width="1em" height="1em" class="size-4 shrink-0" data-icon="lucide:file-text">   <symbol id="ai:lucide:file-text" viewBox="0 0 24 24"><g fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2"><path d="M6 22a2 2 0 0 1-2-2V4a2 2 0 0 1 2-2h8a2.4 2.4 0 0 1 1.704.706l3.588 3.588A2.4 2.4 0 0 1 20 8v12a2 2 0 0 1-2 2z"/><path d="M14 2v5a1 1 0 0 0 1 1h5M10 9H8m8 4H8m8 4H8"/></g></symbol><use href="#ai:lucide:file-text"></use>  </svg> <span>Part 2 &amp; 3 - Bayesian Linear Regression</span> </span> </span></li> </ol> </nav> </div>  <section class="col-start-2 flex flex-col gap-y-6 text-center"> <div class="flex flex-col"> <h1 class="mb-2 scroll-mt-31 text-4xl leading-tight font-medium text-pretty" id="post-title"> Part 2 &amp; 3 - Bayesian Linear Regression </h1> <div class="text-muted-foreground mb-4 flex flex-wrap items-center justify-center gap-2 text-sm"> <div class="flex items-center gap-2"> <span data-slot="badge" class="inline-flex items-center justify-center rounded-md border px-2 py-0.5 text-xs font-medium w-fit whitespace-nowrap shrink-0 [&amp;&gt;svg]:size-3 gap-1 [&amp;&gt;svg]:pointer-events-none focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:ring-[3px] aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive transition-[color,box-shadow] overflow-hidden text-foreground [a&amp;]:hover:bg-accent [a&amp;]:hover:text-accent-foreground">SSY316</span> <div data-orientation="vertical" role="none" data-slot="separator-root" class="bg-border red shrink-0 data-[orientation=horizontal]:h-px data-[orientation=horizontal]:w-full data-[orientation=vertical]:h-full data-[orientation=vertical]:w-px h-4!"></div> <span>Date: November 6, 2025</span> <div data-orientation="vertical" role="none" data-slot="separator-root" class="bg-border red shrink-0 data-[orientation=horizontal]:h-px data-[orientation=horizontal]:w-full data-[orientation=vertical]:h-full data-[orientation=vertical]:w-px h-4!"></div>  <div class="font-base text-sm">
Last modified: November 10, 2025 </div>  <div data-orientation="vertical" role="none" data-slot="separator-root" class="bg-border red shrink-0 data-[orientation=horizontal]:h-px data-[orientation=horizontal]:w-full data-[orientation=vertical]:h-full data-[orientation=vertical]:w-px h-4!"></div> <span>17 min read</span> </div> </div> </div> <nav class="col-start-2 grid grid-cols-1 gap-4 sm:grid-cols-2"> <a href="/notes/master/ssy316/ssy316" target="_self" class="duration-300 ease-in-out gap-2 whitespace-nowrap text-sm font-medium transition-all disabled:pointer-events-none disabled:opacity-50 [&#38;_svg]:pointer-events-none [&#38;_svg:not([class*='size-'])]:size-4 shrink-0 [&#38;_svg]:shrink-0 outline-none focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:ring-[3px] aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive border bg-background shadow-xs hover:bg-accent hover:text-accent-foreground dark:bg-input/30 dark:border-input dark:hover:bg-input/50 px-4 py-2 has-[>svg]:px-3 rounded-lg group flex items-center justify-start size-full" aria-disabled="false">  <svg width="1em" height="1em" class="mr-2 size-4 transition-transform group-hover:-translate-x-1" data-icon="lucide:arrow-left">   <symbol id="ai:lucide:arrow-left" viewBox="0 0 24 24"><path fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="m12 19l-7-7l7-7m7 7H5"/></symbol><use href="#ai:lucide:arrow-left"></use>  </svg> <div class="flex flex-col items-start overflow-hidden text-wrap"> <span class="text-muted-foreground text-left text-xs"> Previous Post </span> <span class="w-full text-left text-sm text-balance text-ellipsis"> Part 1 - Introduction </span> </div>  </a>  <a href="/notes/master/ssy316/ssy316_3" target="_self" class="duration-300 ease-in-out gap-2 whitespace-nowrap text-sm font-medium transition-all disabled:pointer-events-none disabled:opacity-50 [&#38;_svg]:pointer-events-none [&#38;_svg:not([class*='size-'])]:size-4 shrink-0 [&#38;_svg]:shrink-0 outline-none focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:ring-[3px] aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive border bg-background shadow-xs hover:bg-accent hover:text-accent-foreground dark:bg-input/30 dark:border-input dark:hover:bg-input/50 px-4 py-2 has-[>svg]:px-3 rounded-lg group flex items-center justify-end size-full" aria-disabled="false">  <div class="flex flex-col items-end overflow-hidden text-wrap"> <span class="text-muted-foreground text-right text-xs"> Next Post </span> <span class="w-full text-right text-sm text-balance text-ellipsis"> Part 4 &amp; 5 - Linear Models for Classification </span> </div> <svg width="1em" height="1em" class="ml-2 size-4 transition-transform group-hover:translate-x-1" data-icon="lucide:arrow-right">   <symbol id="ai:lucide:arrow-right" viewBox="0 0 24 24"><path fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M5 12h14m-7-7l7 7l-7 7"/></symbol><use href="#ai:lucide:arrow-right"></use>  </svg>  </a> </nav> </section> <div id="toc-sidebar-container" class="sticky top-20 col-start-1 row-span-1 mr-8 ml-auto hidden h-[calc(100vh-5rem)] max-w-md xl:block"><astro-island uid="Z3tzIG" prefix="r24" component-url="/_astro/scroll-area.BdR3V4Yj.js" component-export="ScrollArea" renderer-url="/_astro/client.DXIZDqlh.js" props="{&quot;className&quot;:[0,&quot;flex max-h-[calc(100vh-8rem)] flex-col overflow-y-auto&quot;],&quot;type&quot;:[0,&quot;hover&quot;],&quot;data-toc-scroll-area&quot;:[0,true]}" ssr client="load" opts="{&quot;name&quot;:&quot;ScrollArea&quot;,&quot;value&quot;:true}" await-children><div dir="ltr" data-slot="scroll-area" class="relative flex max-h-[calc(100vh-8rem)] flex-col overflow-y-auto" data-toc-scroll-area="true" style="position:relative;--radix-scroll-area-corner-width:0px;--radix-scroll-area-corner-height:0px"><style>[data-radix-scroll-area-viewport]{scrollbar-width:none;-ms-overflow-style:none;-webkit-overflow-scrolling:touch;}[data-radix-scroll-area-viewport]::-webkit-scrollbar{display:none}</style><div data-radix-scroll-area-viewport="" data-slot="scroll-area-viewport" class="ring-ring/10 dark:ring-ring/20 dark:outline-ring/40 outline-ring/50 size-full rounded-[inherit] transition-[color,box-shadow] focus-visible:ring-4 focus-visible:outline-1" style="overflow-x:hidden;overflow-y:hidden"><div style="min-width:100%;display:table"><astro-slot><div class="flex flex-col gap-2 px-4"><span class="text-lg font-medium">Table of Contents</span><ul class="flex list-none flex-col gap-y-2"><li class="text-sm text-foreground/60"><a href="#introduction" class="marker:text-foreground/30 list-none underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit" data-heading-link="introduction">Introduction</a></li><li class="text-sm text-foreground/60"><a href="#supervised-machine-learning" class="marker:text-foreground/30 list-none underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit" data-heading-link="supervised-machine-learning">Supervised Machine Learning</a></li><li class="text-sm ml-4 text-foreground/60"><a href="#the-inference-problem" class="marker:text-foreground/30 list-none underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit" data-heading-link="the-inference-problem">The Inference Problem</a></li><li class="text-sm ml-4 text-foreground/60"><a href="#frequentist-approach" class="marker:text-foreground/30 list-none underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit" data-heading-link="frequentist-approach">Frequentist Approach</a></li><li class="text-sm text-foreground/60"><a href="#linear-regression-problem-setting" class="marker:text-foreground/30 list-none underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit" data-heading-link="linear-regression-problem-setting">Linear Regression: Problem Setting</a></li><li class="text-sm ml-4 text-foreground/60"><a href="#probabilistic-modeling" class="marker:text-foreground/30 list-none underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit" data-heading-link="probabilistic-modeling">Probabilistic Modeling</a></li><li class="text-sm ml-4 text-foreground/60"><a href="#discriminative-vs-generative-probabilistic-models" class="marker:text-foreground/30 list-none underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit" data-heading-link="discriminative-vs-generative-probabilistic-models">Discriminative VS. Generative Probabilistic Models</a></li><li class="text-sm text-foreground/60"><a href="#learning-the-model-parameters" class="marker:text-foreground/30 list-none underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit" data-heading-link="learning-the-model-parameters">Learning the Model Parameters</a></li><li class="text-sm ml-4 text-foreground/60"><a href="#maximum-likelihood-estimation" class="marker:text-foreground/30 list-none underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit" data-heading-link="maximum-likelihood-estimation">Maximum Likelihood Estimation</a></li><li class="text-sm ml-4 text-foreground/60"><a href="#training-generalization-loss-bias-and-estimation-error" class="marker:text-foreground/30 list-none underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit" data-heading-link="training-generalization-loss-bias-and-estimation-error">Training, Generalization Loss, Bias, and Estimation Error</a></li><li class="text-sm ml-4 text-foreground/60"><a href="#learning-and-validation" class="marker:text-foreground/30 list-none underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit" data-heading-link="learning-and-validation">Learning and Validation</a></li><li class="text-sm text-foreground/60"><a href="#maximum-a-posteriori-learning" class="marker:text-foreground/30 list-none underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit" data-heading-link="maximum-a-posteriori-learning">Maximum A Posteriori Learning</a></li><li class="text-sm ml-4 text-foreground/60"><a href="#how-do-we-choose-the-prior-distribution" class="marker:text-foreground/30 list-none underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit" data-heading-link="how-do-we-choose-the-prior-distribution">How do we choose the prior distribution?</a></li><li class="text-sm text-foreground/60"><a href="#maximum-a-posteriori-learning-continued" class="marker:text-foreground/30 list-none underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit" data-heading-link="maximum-a-posteriori-learning-continued">Maximum A Posteriori Learning: Continued</a></li><li class="text-sm text-foreground/60"><a href="#footnote-label" class="marker:text-foreground/30 list-none underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit" data-heading-link="footnote-label">Footnotes</a></li></ul></div></astro-slot></div></div></div><!--astro:end--></astro-island></div><script type="module">class f{links=document.querySelectorAll("[data-heading-link]");activeIds=[];headings=[];regions=[];scrollArea=null;tocScrollArea=null;reset(){this.links=document.querySelectorAll("#toc-sidebar-container [data-heading-link]"),this.activeIds=[],this.headings=[],this.regions=[];const t=document.getElementById("toc-sidebar-container");this.scrollArea=t?.querySelector("[data-radix-scroll-area-viewport]")||null,this.tocScrollArea=t?.querySelector("[data-toc-scroll-area]")||null}}const e=new f;class c{static build(){if(e.headings=Array.from(document.querySelectorAll(".prose h2, .prose h3, .prose h4, .prose h5, .prose h6")),e.headings.length===0){e.regions=[];return}e.regions=e.headings.map((t,o)=>{const i=e.headings[o+1];return{id:t.id,start:t.offsetTop,end:i?i.offsetTop:document.body.scrollHeight}})}static getVisibleIds(){if(e.headings.length===0)return[];const t=window.scrollY+80,o=window.scrollY+window.innerHeight,i=new Set,l=(s,r)=>s>=t&&s<=o||r>=t&&r<=o||s<=t&&r>=o;return e.headings.forEach(s=>{const r=s.offsetTop+s.offsetHeight;l(s.offsetTop,r)&&i.add(s.id)}),e.regions.forEach(s=>{if(s.start<=o&&s.end>=t){const r=document.getElementById(s.id);if(r){const a=r.offsetTop+r.offsetHeight;s.end>a&&(a<o||t<s.end)&&i.add(s.id)}}}),Array.from(i)}}class h{static update(){if(!e.scrollArea||!e.tocScrollArea)return;const{scrollTop:t,scrollHeight:o,clientHeight:i}=e.scrollArea,l=5,s=t<=l,r=t>=o-i-l;e.tocScrollArea.classList.toggle("mask-t-from-90%",!s),e.tocScrollArea.classList.toggle("mask-b-from-90%",!r)}}class g{static update(t){e.links.forEach(o=>{o.classList.remove("text-foreground")}),t.forEach(o=>{if(o){const i=document.querySelector(`#toc-sidebar-container [data-heading-link="${o}"]`);i&&i.classList.add("text-foreground")}}),this.scrollToActive(t)}static scrollToActive(t){if(!e.scrollArea||!t.length)return;const o=document.querySelector(`#toc-sidebar-container [data-heading-link="${t[0]}"]`);if(!o)return;const{top:i,height:l}=e.scrollArea.getBoundingClientRect(),{top:s,height:r}=o.getBoundingClientRect(),a=s-i+e.scrollArea.scrollTop,u=Math.max(0,Math.min(a-(l-r)/2,e.scrollArea.scrollHeight-e.scrollArea.clientHeight));Math.abs(u-e.scrollArea.scrollTop)>5&&(e.scrollArea.scrollTop=u)}}class d{static handleScroll(){const t=c.getVisibleIds();JSON.stringify(t)!==JSON.stringify(e.activeIds)&&(e.activeIds=t,g.update(e.activeIds))}static handleTOCScroll=()=>h.update();static handleResize(){c.build();const t=c.getVisibleIds();JSON.stringify(t)!==JSON.stringify(e.activeIds)&&(e.activeIds=t,g.update(e.activeIds)),h.update()}static init(){if(e.reset(),c.build(),e.headings.length===0){g.update([]);return}this.handleScroll(),setTimeout(h.update,100);const t={passive:!0};window.addEventListener("scroll",this.handleScroll,t),window.addEventListener("resize",this.handleResize,t),e.scrollArea?.addEventListener("scroll",this.handleTOCScroll,t)}static cleanup(){window.removeEventListener("scroll",this.handleScroll),window.removeEventListener("resize",this.handleResize),e.scrollArea?.removeEventListener("scroll",this.handleTOCScroll),Object.assign(e,{activeIds:[],headings:[],regions:[],scrollArea:null,tocScrollArea:null})}}document.addEventListener("astro:page-load",()=>d.init());document.addEventListener("astro:after-swap",()=>{d.cleanup(),d.init()});document.addEventListener("astro:before-swap",()=>d.cleanup());</script> <article class="prose col-start-2 max-w-none"> <!doctype html><html lang="en"><head></head><body>


<meta charset="utf-8">
<title>SSY316_2</title>
<meta content="width=device-width, initial-scale=1" name="viewport">
<link href="https://cdn.jsdelivr.net/npm/katex@0.16.21/dist/katex.min.css" rel="stylesheet">

<svg xmlns="http://www.w3.org/2000/svg" style="display:none"><defs>
        <symbol id="info" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
          <circle cx="12" cy="12" r="10"></circle><path d="M12 16v-4"></path><path d="M12 8h.01"></path>
        </symbol>
        <symbol id="lightbulb" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
          <path d="M15 14c.2-1 .7-1.7 1.5-2.5 1-.9 1.5-2.2 1.5-3.5A6 6 0 0 0 6 8c0 1 .2 2.2 1.5 3.5.7.7 1.3 1.5 1.5 2.5"></path><path d="M9 18h6"></path><path d="M10 22h4"></path>
        </symbol>
        <symbol id="alert-triangle" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
          <path d="m21.73 18-8-14a2 2 0 0 0-3.48 0l-8 14A2 2 0 0 0 4 21h16a2 2 0 0 0 1.73-3"></path><path d="M12 9v4"></path><path d="m12 17h.01"></path>
        </symbol>
        <symbol id="shield-alert" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
          <path d="M20 13c0 5-3.5 7.5-7.66 8.95a1 1 0 0 1-.67-.01C7.5 20.5 4 18 4 13V6a1 1 0 0 1 1-1c2 0 4.5-1.2 6.24-2.72a1.17 1.17 0 0 1 1.52 0C14.51 3.81 17 5 19 5a1 1 0 0 1 1 1z"></path><path d="M12 8v4"></path><path d="M12 16h.01"></path>
        </symbol>
        <symbol id="message-square-warning" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
          <path d="M22 17a2 2 0 0 1-2 2H6.828a2 2 0 0 0-1.414.586l-2.202 2.202A.71.71 0 0 1 2 21.286V5a2 2 0 0 1 2-2h16a2 2 0 0 1 2 2z"></path><path d="M12 15h.01"></path><path d="m12 17v4"></path>
        </symbol>
        <symbol id="book-open" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
          <path d="M12 7v14"></path><path d="M3 18a1 1 0 0 1-1-1V4a1 1 0 0 1 1-1h5a4 4 0 0 1 4 4 4 4 0 0 1 4-4h5a1 1 0 0 1 1 1v13a1 1 0 0 1-1 1h-6a3 3 0 0 0-3 3 3 3 0 0 0-3-3z"></path>
        </symbol>
        <symbol id="anchor" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
          <path d="M12 22V8"></path><path d="M5 12H2a10 10 0 0 0 20 0h-3"></path><circle cx="12" cy="5" r="3"></circle>
        </symbol>
        <symbol id="pen-tool" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
          <path d="M15.707 21.293a1 1 0 0 1-1.414 0l-1.586-1.586a1 1 0 0 1 0-1.414l5.586-5.586a1 1 0 0 1 1.414 0l1.586 1.586a1 1 0 0 1 0 1.414z"></path><path d="m18 13-1.375-6.874a1 1 0 0 0-.746-.776L3.235 2.028a1 1 0 0 0-1.207 1.207L5.35 15.879a1 1 0 0 0 .776.746L13 18"></path><path d="m2.3 2.3 7.286 7.286"></path><circle cx="11" cy="11" r="2"></circle>
        </symbol>
        <symbol id="check-circle" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
          <circle cx="12" cy="12" r="10"></circle><path d="m9 12 2 2 4-4"></path>
        </symbol>
        <symbol id="puzzle" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
          <path d="M15.39 4.39a1 1 0 0 0 1.68-.474 2.5 2.5 0 1 1 3.014 3.015 1 1 0 0 0-.474 1.68l1.683 1.682a2.414 2.414 0 0 1 0 3.414L19.61 15.39a1 1 0 0 1-1.68-.474 2.5 2.5 0 1 0-3.014 3.015 1 1 0 0 1 .474 1.68l-1.683 1.682a2.414 2.414 0 0 1-3.414 0L8.61 19.61a1 1 0 0 0-1.68.474 2.5 2.5 0 1 1-3.014-3.015 1 1 0 0 0 .474-1.68l-1.683-1.682a2.414 2.414 0 0 1 0-3.414L4.39 8.61a1 1 0 0 1 1.68.474 2.5 2.5 0 1 0 3.014-3.015 1 1 0 0 1-.474-1.68l1.683-1.682a2.414 2.414 0 0 1 3.414 0z"></path>
        </symbol>
        <symbol id="git-branch" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
          <line x1="6" x2="6" y1="3" y2="15"></line><circle cx="18" cy="6" r="3"></circle><circle cx="6" cy="18" r="3"></circle><path d="M18 9a9 9 0 0 1-9 9"></path>
        </symbol>
        <symbol id="file-text" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
          <path d="M15 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V7z"></path><path d="M14 2v4a2 2 0 0 0 2 2h4"></path><path d="M10 9H8"></path><path d="M16 13H8"></path><path d="M16 17H8"></path>
        </symbol>
        <symbol id="help-circle" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
          <circle cx="12" cy="12" r="10"></circle><path d="M9.09 9a3 3 0 0 1 5.83 1c0 2-3 3-3 3"></path><path d="M12 17h.01"></path>
        </symbol>
        <symbol id="check-square" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
          <rect width="18" height="18" x="3" y="3" rx="2"></rect><path d="m9 12 2 2 4-4"></path>
        </symbol>
        <symbol id="message-circle" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
          <path d="M2.992 16.342a2 2 0 0 1 .094 1.167l-1.065 3.29a1 1 0 0 0 1.236 1.168l3.413-.998a2 2 0 0 1 1.099.092 10 10 0 1 0-4.777-4.719"></path>
        </symbol>
        <symbol id="rotate-ccw" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
          <path d="M3 12a9 9 0 1 0 9-9 9.75 9.75 0 0 0-6.74 2.74L3 8"></path><path d="M3 3v5h5"></path>
        </symbol>
        <symbol id="code" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
          <path d="m16 18 6-6-6-6"></path><path d="m8 6-6 6 6 6"></path>
        </symbol>
        <symbol id="dumbbell" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
          <path d="M17.596 12.768a2 2 0 1 0 2.829-2.829l-1.768-1.767a2 2 0 0 0 2.828-2.829l-2.828-2.828a2 2 0 0 0-2.829 2.828l-1.767-1.768a2 2 0 1 0-2.829 2.829z"></path><path d="m2.5 21.5 1.4-1.4"></path><path d="m20.1 3.9 1.4-1.4"></path><path d="M5.343 21.485a2 2 0 1 0 2.829-2.828l1.767 1.768a2 2 0 1 0 2.829-2.829l-6.364-6.364a2 2 0 1 0-2.829 2.829l1.768 1.767a2 2 0 0 0-2.828 2.829z"></path><path d="m9.6 14.4 4.8-4.8"></path>
        </symbol>
        <symbol id="alert-circle" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
          <circle cx="12" cy="12" r="10"></circle><line x1="12" x2="12" y1="8" y2="12"></line><line x1="12" x2="12.01" y1="16" y2="16"></line>
        </symbol>
        <symbol id="check" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
          <path d="M20 6 9 17l-5-5"></path>
        </symbol>
        <symbol id="check-circle-2" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
          <path d="m9 12 2 2 4-4"></path><circle cx="12" cy="12" r="9"></circle>
        </symbol>
        <symbol id="list" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
          <path d="M3 5h.01"></path><path d="M3 12h.01"></path><path d="M3 19h.01"></path><path d="M8 5h13"></path><path d="M8 12h13"></path><path d="M8 19h13"></path>
        </symbol>
        <symbol id="chevron-down" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
          <path d="m6 9 6 6 6-6"></path>
        </symbol>
        <symbol id="cpu" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
          <path d="M12 20v2"></path><path d="M12 2v2"></path><path d="M17 20v2"></path><path d="M17 2v2"></path><path d="M2 12h2"></path><path d="M2 17h2"></path><path d="M2 7h2"></path><path d="M20 12h2"></path><path d="M20 17h2"></path><path d="M20 7h2"></path><path d="M7 20v2"></path><path d="M7 2v2"></path><rect x="4" y="4" width="16" height="16" rx="2"></rect><rect x="8" y="8" width="8" height="8" rx="1"></rect>
        </symbol></defs></svg>
<h2 id="introduction">Introduction</h2>
<p>In this part, we will explore Bayesian linear regression, a probabilistic approach to linear regression that incorporates uncertainty in the model parameters.
Firstly, we will recap supervised machine learning, inference, and the problem setting for linear regression.</p>
<h2 id="supervised-machine-learning">Supervised Machine Learning</h2>
<details class="group relative px-4 py-3 my-6 border-l-4 text-base border-teal-600 dark:bg-teal-950/10" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-teal-700 dark:text-teal-400" data-lucide="book-open" viewBox="0 0 24 24"><use href="#book-open"></use></svg>Definition: Supervised Machine Learning<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-teal-700 dark:text-teal-400" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>Given a training set $\mathcal{D} = \{(\mathbf{x}_i, y_i)\}_{i=1}^{N}$, where $\mathbf{x}_i$ are free variables (features, covariates, domain points, explanatory variables, etc.) and $y_i$ are the target variables, dependant on $\mathbf{x}_i$ (dependent variables, labels, responses, etc.), the goal of supervised machine learning is to identify an algorithm to predict the label $y$ for a new (yet unseen) input $\mathbf{x}$.
In other words, learning a model from label data and predicting outputs of new data based on the learned model.w</p><p>However, this task is impossible if there is no information about the mechanism relating $\mathbf{x}$ and $y$.
Thus, we may assume that $\mathbf{x}$ and $y$ are related via a function $y = \tilde{f}(\mathbf{x})$.</p><p>Thus, the goal is to find the best possible approximation of $\tilde{f}(\mathbf{x})$, $f(\mathbf{x})$ (prediction model), and predict the outcome $y$ for $\mathbf{x}$ as $\hat{y} = f(\mathbf{x})$.</p><p>Again, in more general temrs, we want to identify a predictive algorithm that minimizes the error in the prediction of a new label $y$ for an unobserved input $\mathbf{x}$ (generalization loss).</p><p>As we discussed last time, we have two main approaches, the frequentist and the Bayesian approach.
We will rephrase the supervised machine learning problem as a Bayesian inference problem.</p></div>
</details>
<h3 id="the-inference-problem">The Inference Problem</h3>
<details class="group relative px-4 py-3 my-6 border-l-4 text-base border-teal-600 dark:bg-teal-950/10" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-teal-700 dark:text-teal-400" data-lucide="book-open" viewBox="0 0 24 24"><use href="#book-open"></use></svg>Definition: The Inference Problem<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-teal-700 dark:text-teal-400" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>From learning, we know that we need to treat $\mathbf{x}$ and $y$ as random variables. Thus, our objective is predict $y$ given the (random) observation of $\mathbf{x}$ under the assumption that the joint distribution $p(\mathbf{x}, y)$ is known.</p><p>We define the loss function $\ell(y, \hat{y})$ as the cost (loss or risk) incurred when the correct value is $y$ while the estimated value is $\hat{y}$.
For example, the quadratic loss function is defined as,
$$
\ell(y, \hat{y}) \coloneqq (y - \hat{y})^2.
$$
We say there is a optimal prediction $\hat{y}^{\star}(\mathbf{x})$ that minimizes the generalization loss (or, generalization error),
$$
L_p(\hat{y}) \coloneqq \mathbb{E}_{\mathsf{\mathbf{x}}, \mathsf{y} \sim p(\mathbf{x}, y)}[\ell(\mathsf{y}, \hat{y}(\mathsf{\mathbf{x}}))].
$$
The solution is simply,
$$
\begin{align*}
\hat{y}^{\star}(\mathbf{x}) &#x26; = \underset{\hat{y}}{\arg\min} \ L_p(\hat{y}) \newline
&#x26; = \underset{\hat{y}}{\arg\min} \ \mathbb{E}_{\mathsf{x}, \mathsf{y} \sim p(\mathbf{x}, y)}[\ell(\mathsf{y}, \hat{y}(\mathsf{\mathbf{x}}))] \newline
&#x26; = \underset{\hat{y}}{\arg\min} \ \mathbb{E}_{\mathsf{x} \sim p(\mathbf{x})} \left[ \mathbb{E}_{\mathsf{y} \sim p(y \mid \mathsf{\mathbf{x}})}[\ell(\mathsf{y}, \hat{y}(\mathsf{\mathbf{x}}))] \right] \newline
&#x26; = \underset{\hat{y}}{\arg\min} \ \mathbb{E}_{\mathsf{y} \sim p(y \mid \mathbf{x})}[\ell(\mathsf{y}, \hat{y}(\mathbf{x}))]
\end{align*}
$$
Thus, the optimal prediction is a function of $p(y \mid \mathbf{x})$ and the loss function $\ell(y, \hat{y})$.</p><p>For the loss function, $\ell(y, \hat{y}) = (y - \hat{y})^2$,
$$
\hat{y}^{\star}(\mathbf{x}) = \mathbb{E}_{\mathsf{y} \sim \mathbf{x}}[\mathsf{y} \mid \mathbf{x}]
$$
i.e., the optimal prediction is the conditional mean of $y$ given $\mathbf{x}$.</p><p>However, in most scenarios, the joint distribution $p(\mathbf{x}, y)$ is unknown.</p><p>Finally, lets restate the supervised machine learning problem as an inference problem.</p><p>The goal is to obtain a predictor $\hat{y}(\mathbf{x})$ that performs close to optimal predictor $\hat{y}^{\star}(\mathbf{x})$ based only on the training set $\mathcal{D}$ (without knowledge of $p(\mathbf{x}, y)$).
Where closeness is measured as,
$$
L_p(\hat{y}) - L_p(\hat{y}^{\star}).
$$
where $L_p(\hat{y})$ is the generalization loss of the trained predictor $\hat{y}(\mathbf{x})$ and $L_p(\hat{y}^{\star})$ is the minimum generalization loss (optimal predictor).</p></div>
</details>
<h3 id="frequentist-approach">Frequentist Approach</h3>
<details class="group relative px-4 py-3 my-6 border-l-4 text-base border-sky-300 dark:bg-sky-950/10" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-sky-500 dark:text-sky-200" data-lucide="lightbulb" viewBox="0 0 24 24"><use href="#lightbulb"></use></svg>Intuition: Frequentist Approach<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-sky-500 dark:text-sky-200" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>Our training data points $(\mathbf{x}_i, \mathsf{y}_i) \in \mathcal{D}$ are i.i.d random variables drawn from a true (but unknown) distribution $p(\mathbf{x}, y)$,
$$
(\mathbf{x}_i, \mathsf{y}_i) \sim_{\text{i.i.d}} p(\mathbf{x}, y), \quad i = 1, \ldots, N.
$$
Since $p(\mathbf{x}, y)$ is unknown, we cannot find the optimal predictor via,
$$
\hat{y}^{\star}(\mathbf{x}) = \underset{\hat{y}}{\arg\min} \ \mathbb{E}_{\mathsf{y} \mid \mathbf{x}}[\ell(\mathsf{y}, \hat{y}) \mid \mathbf{x}].
$$
The solution however, is to separate learning inference. If we can learn an approximation of $p(y \mid \mathbf{x})$ based on $\mathcal{D}(p_{\mathcal{D}}(y \mid \mathbf{x}))$, and use it in,
$$
\hat{y}^{\star}(\mathbf{x}) = \underset{\hat{y}}{\arg\min} \ \mathbb{E}_{\mathsf{y} \mid \mathbf{x}}[\ell(\mathsf{y}, \hat{y}) \mid \mathbf{x}].
$$
we can obtain,
$$
\hat{y}_{\mathcal{D}}(\mathbf{x}) = \underset{\hat{y}}{\arg\min} \ \mathbb{E}_{\mathsf{y} \sim p_{\mathcal{D}}(y \mid \mathbf{x})}[\ell(\mathsf{y}, \hat{y}) \mid \mathbf{x}].
$$
Further, we can perform direct inference via empirical risk minimization (ERM). If we directly learn an approximation of the optimal decision rule ($\hat{y}_{\mathcal{D}}(\cdot)$) by minimizing an empirical estimate of the generalization loss,
$$
\hat{y}_{\mathcal{D}} \coloneqq \underset{\hat{y}}{\arg\min} \ L_{\mathcal{D}}(\hat{y}) = \underset{\hat{y}}{\arg\min} \ \frac{1}{N} \sum_{i=1}^{N} \ell(\mathsf{y}_i, \hat{y}(\mathbf{x}_i)).
$$
But, how do we learn an approximation of $p_{\mathcal{D}}(y \mid \mathbf{x})$ of $p(\mathsf{y} \mid \mathbf{x})$ based on $\mathcal{D}$?
If we can select a family of parametric probabilistic models (i.e., hypothesis classes), we can learn the model parameters to fit $\mathcal{D}$.</p></div>
</details>
<h2 id="linear-regression-problem-setting">Linear Regression: Problem Setting</h2>
<details class="group relative px-4 py-3 my-6 border-l-4 text-base border-teal-600 dark:bg-teal-950/10" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-teal-700 dark:text-teal-400" data-lucide="book-open" viewBox="0 0 24 24"><use href="#book-open"></use></svg>Definition: Linear Regression Problem Setting<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-teal-700 dark:text-teal-400" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>In linear regression, we are interested in values of a fucntion $y(\mathbf{x}): \mathbb{R}^d \to \mathbb{R}$, where $\mathbf{x} = (x_1, \ldots, x_d)^T$.
We have some observations of this mapping, precisely $\mathcal{D} = \{(\mathbf{x}_i, y_i)\}_{i=1}^{N}$.</p><p>Thus, the goal is to predict $y$ for a new input $\mathbf{x}$, i.e., learn an accurate prediction function $\hat{y}(\mathbf{x})$ (also called regression function) from $\mathcal{D}$.
Further, in linear regression, we assume that the relationship between $\mathbf{x}$ and $y$ is linear,
$$
\begin{align*}
t(\mathbf{x}) &#x26; = w_0 + w_1 x_1 + \ldots + w_d x_d \newline
&#x26; = \mu(\mathbf{x}, \mathbf{w})
\end{align*}
$$
We can extend this to a setting where we allow linear combinations of fixed nonlinear functions of the input variables,
$$
\mu(\mathbf{x}, \mathbf{w}) = w_0 + \sum_{j=1}^{M-1} w_j \phi_j(\mathbf{x})
$$
where $\phi_j(\mathbf{x})$ are basis functions, $w_0$ is called the bias (allows for any fixed offset).
Further, conveniently, we define the dummy basis function $\phi_0(\mathbf{x}) \coloneqq 1$ so that,
$$
\mu(\mathbf{x}, \mathbf{w}) = \sum_{j=0}^{M-1} w_j \phi_j(\mathbf{x}) = \mathbf{w}^T \boldsymbol{\phi}(\mathbf{x})
$$
where $\mathbf{w} = (w_0, w_1, \ldots, w_{M-1})^T$ and $\boldsymbol{\phi}(\mathbf{x}) = (\phi_0(\mathbf{x}), \phi_1(\mathbf{x}), \ldots, \phi_{M-1}(\mathbf{x}))^T$.</p><details class="group relative px-4 py-3 my-6 border-l-4 text-base border-sky-500 dark:bg-sky-950/10" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-sky-600 dark:text-sky-300" data-lucide="code" viewBox="0 0 24 24"><use href="#code"></use></svg>Example: Basis Functions<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-sky-600 dark:text-sky-300" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>Some common basis functions are,</p><ul>
<li>
<p>Polynomial Linear Regression,
$$
\mu(x, \mathbf{w}) = \sum_{j=0}^{M} w_j x^j = \mathbf{w}^T \boldsymbol{\phi}(x),
$$
where $\mathbf{w} = (w_0, w_1, \ldots, w_{M-1})^T$ and $\boldsymbol{\phi}(x) = (1, x, x^2, \ldots, x^M)^T$.</p>
</li>
<li>
<p>Gaussian Basis Functions,
$$
\phi_j(x) = \exp \left( -\frac{(x - \alpha_j)^2}{2 s^2} \right).
$$</p>
</li>
<li>
<p>Sigmoidal Basis Functions,
$$
\phi_j(x) = \sigma \left( \frac{x - \alpha_j}{s} \right),
$$
where,
$$
\sigma(a) = \frac{1}{1 + \exp(-a)}.
$$</p>
</li>
</ul></div>
</details></div>
</details>
<h3 id="probabilistic-modeling">Probabilistic Modeling</h3>
<details class="group relative px-4 py-3 my-6 border-l-4 text-base border-sky-300 dark:bg-sky-950/10" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-sky-500 dark:text-sky-200" data-lucide="lightbulb" viewBox="0 0 24 24"><use href="#lightbulb"></use></svg>Intuition: Probabilistic Modeling<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-sky-500 dark:text-sky-200" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>We can (again) further extend our framework by expressing our uncertainty over the value of $\mu(\mathbf{x}, \mathbf{w})$ as,
$$
y(\mathbf{x}, \mathbf{w}) = \mathbf{w}^T \boldsymbol{\phi}(\mathbf{x}) + \epsilon = \mu(\mathbf{x}, \mathbf{w}) + \epsilon, \quad \epsilon \sim \mathcal{N}(0, \beta^{-1}).
$$
Thus, given $\mathbf{x}$, $y$ can be modeled by a probabilistic model,
$$
\mathsf{y} \mid \mathbf{x} = \mathbf{x} \sim \mathcal{N}(\mu(\mathbf{x}, \mathbf{w}), \beta^{-1}),
$$
or, equivalently,
$$
p(\mathsf{y} \mid \mathbf{x}, \mathbf{w}, \beta) = p(\mathsf{y} \mid \mathbf{x}, \boldsymbol{\theta}) = \mathcal{N}(\mathsf{y} \mid \mu(\mathbf{x}, \mathbf{w}), \beta^{-1}),
$$
where $\boldsymbol{\theta} = (\mathbf{w}, \beta)$.</p></div>
</details>
<h3 id="discriminative-vs-generative-probabilistic-models">Discriminative VS. Generative Probabilistic Models</h3>
<p>In machine learning, there is a concept of discriminative and generative models <sup><a href="#user-content-fn-1" id="user-content-fnref-1" data-footnote-ref="" aria-describedby="footnote-label">1</a></sup> <sup><a href="#user-content-fn-2" id="user-content-fnref-2" data-footnote-ref="" aria-describedby="footnote-label">2</a></sup>.</p>
<details class="group relative px-4 py-3 my-6 border-l-4 text-base border-teal-600 dark:bg-teal-950/10" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-teal-700 dark:text-teal-400" data-lucide="book-open" viewBox="0 0 24 24"><use href="#book-open"></use></svg>Definition: Discriminative Models<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-teal-700 dark:text-teal-400" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>In discriminative models, our posterior (predictive) distribution $p(y \mid \mathbf{x})$ is assumed to belong to a hypothesis class parameterized by $\boldsymbol{\theta}$, i.e., $p(y \mid \mathbf{x}, \boldsymbol{\theta})$.
We learn the parameters $\boldsymbol{\theta}$ directly from the training data $\mathcal{D}$.</p><p>Thus, once the model is learned, we can compute,
$$
\hat{y}_{\mathcal{D}}(\mathbf{x}) = \underset{\hat{y}}{\arg\min} \ \mathbb{E}_{\mathsf{y} \sim p_{\mathcal{D}}(y \mid \mathbf{x})}[\ell(\mathsf{y}, \hat{y}) \mid \mathbf{x}].
$$</p><details class="group relative px-4 py-3 my-6 border-l-4 text-base border-sky-500 dark:bg-sky-950/10" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-sky-600 dark:text-sky-300" data-lucide="code" viewBox="0 0 24 24"><use href="#code"></use></svg>Example: Linear Regression<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-sky-600 dark:text-sky-300" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>We first learn $\boldsymbol{\theta} = (\mathbf{w}, \beta)$ based on $\mathcal{D}$.
Then, we can find the optimal prediction for a new input $\mathbf{x}$ as (under a quadratic loss function),
$$
\hat{y}_{\mathcal{D}}(\mathbf{x}) = \mathbb{E}_{\mathsf{y} \sim p(y \mid \mathbf{x}, \boldsymbol{\theta}^{\star}_{\mathcal{D}})}[\mathsf{y} \mid \mathbf{x}]
$$
i.e.,
$$
\hat{y}_{\mathcal{D}}(\mathbf{x}) = \mu(\mathbf{x}, \mathbf{w}^{\star}_{\mathcal{D}})
$$</p></div>
</details></div>
</details>
<details class="group relative px-4 py-3 my-6 border-l-4 text-base border-teal-600 dark:bg-teal-950/10" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-teal-700 dark:text-teal-400" data-lucide="book-open" viewBox="0 0 24 24"><use href="#book-open"></use></svg>Definition: Generative Models<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-teal-700 dark:text-teal-400" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>In generative models, we see the models $p(\mathbf{x}, y)$ as being part of a parametric family $p(\mathbf{x}, y \mid \boldsymbol{\theta})$.
This means we from these models, can find $p(\mathbf{x})$.</p><p>This is the generative ascpet of these models. We have the capacity to generate a realization of $\mathbf{x}$ by using the marginal $p(\mathbf{x} \mid \boldsymbol{\theta})$.
Thus, once the model is learned, we can obtain $p(y \mid \mathbf{x}, \boldsymbol{\theta})$ via Bayes theorem and computing,
$$
\hat{y}_{\mathcal{D}}(\mathbf{x}) = \underset{\hat{y}}{\arg\min} \ \mathbb{E}_{\mathsf{y} \sim p_{\mathcal{D}}(y \mid \mathbf{x})}[\ell(\mathsf{y}, \hat{y}) \mid \mathbf{x}].
$$</p><details class="group relative px-4 py-3 my-6 border-l-4 text-base border-blue-500 dark:bg-blue-950/5" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-blue-700 dark:text-blue-300" data-lucide="info" viewBox="0 0 24 24"><use href="#info"></use></svg>Note<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-blue-700 dark:text-blue-300" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>By making stronger assumptions, it (might) lead to more (significant) biases.
However, in this setting we also have the ability to deal with missing data or latent variables (semi-supervised learning).</p></div>
</details></div>
</details>
<h2 id="learning-the-model-parameters">Learning the Model Parameters</h2>
<p>We have clearly defined our problem setting and the overall goal.
However, we have not stated how we actually learn/estimate the model parameters.
As we discussed in the last part, we have two main approaches, the frequentist and the Bayesian approach.</p>
<h3 id="maximum-likelihood-estimation">Maximum Likelihood Estimation</h3>
<details class="group relative px-4 py-3 my-6 border-l-4 text-base border-sky-300 dark:bg-sky-950/10" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-sky-500 dark:text-sky-200" data-lucide="lightbulb" viewBox="0 0 24 24"><use href="#lightbulb"></use></svg>Intuition: Maximum Likelihood Estimation<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-sky-500 dark:text-sky-200" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>From what we have seen so far, we have stated that our models can be from a hypothesis class $p(y \mid \mathbf{x}, \boldsymbol{\theta}) = \mathcal{N}(\mu(\mathbf{x}, \mathbf{w}), \beta^{-1})$.
For example, this can define the polynomial degree $M$ (i.e., edfines the capacity of the class).</p><p>While a specific model $p(y \mid \mathbf{x}, \boldsymbol{\theta})$ is defined by the selection of the parameters $\boldsymbol{\theta} = (\mathbf{w}, \beta)$ (learned from $\mathcal{D}$).</p><p>As we discussed in the last part, one approach is Maximum Likelihood (ML) learning. Select $\boldsymbol{\theta}$ such that $\mathcal{D}$ has maximum probability of being observed,
$$
\begin{align*}
p(y_{\mathcal{D}} \mid x_{\mathcal{D}}, \mathbf{w}, \beta) &#x26; = \prod_{i=1}^{N} p(y_i \mid \mathbf{x}_i, \mathbf{w}, \beta) \newline
&#x26; = \prod_{i=1}^{N} \mathcal{N}(y_i \mid \mu(\mathbf{x}_i, \mathbf{w}), \beta^{-1})
\end{align*}
$$
We know that maximizing the likelihood is equivalent to maximizing the log-likelihood <sup id="mn-1" class="margin-anchor" data-note-id="mn-1" data-note-text="since $\log(\cdot)$ is a monotonic function and does not change the location of the maximum" style="cursor: pointer; margin-left: 0.25rem;">1</sup>,
$$
\begin{align*}
\log p(y_{\mathcal{D}} \mid x_{\mathcal{D}}, \mathbf{w}, \beta) &#x26; = \sum_{i=1}^{N} \log \ p(y_i \mid \mathbf{x}_i, \mathbf{w}, \beta) \newline
&#x26; = -\frac{\beta}{2} \sum_{i=1}^{N} (y_i - \mu(\mathbf{x}_i, \mathbf{w}))^2 + \frac{N}{2} \log \frac{\beta}{2 \pi}
\end{align*}
$$
The ML criterion (cross-entropy or log-loss) is then,
$$
\begin{align*}
(\mathbf{w}_{\text{ML}}, \beta_{\text{ML}}) &#x26; = \underset{\mathbf{w}, \beta}{\arg\max} \ p(y_{\mathcal{D}} \mid x_{\mathcal{D}}, \mathbf{w}, \beta) \newline
&#x26; = \underset{\mathbf{w}, \beta}{\arg\max} \ \frac{1}{N} \log p(y_{\mathcal{D}} \mid x_{\mathcal{D}}, \mathbf{w}, \beta) \newline
&#x26; = \underset{\mathbf{w}, \beta}{\arg\min} \ -\frac{1}{N} \log p(y_{\mathcal{D}} \mid x_{\mathcal{D}}, \mathbf{w}, \beta) \newline
&#x26; = \underset{\mathbf{w}, \beta}{\arg\min} \ \frac{\beta}{2N} \sum_{i=1}^{N} (y_i - \mu(\mathbf{x}_i, \mathbf{w}))^2 - \frac{1}{2} \log \frac{\beta}{2 \pi}
\end{align*}
$$</p><details class="group relative px-4 py-3 my-6 border-l-4 text-base border-blue-500 dark:bg-blue-950/5" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-blue-700 dark:text-blue-300" data-lucide="info" viewBox="0 0 24 24"><use href="#info"></use></svg>Note<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-blue-700 dark:text-blue-300" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>If we are only interested in learning the mean,
$$
\begin{align*}
\mathbf{w}_{\text{ML}} &#x26; = \underset{\mathbf{w}}{\arg\min} \ \frac{\beta}{2N} \sum_{i=1}^{N} (y_i - \mu(\mathbf{x}_i, \mathbf{w}))^2 \newline
&#x26; = \underset{\mathbf{w}}{\arg\min} \ \frac{1}{N} \sum_{i=1}^{N} (y_i - \mu(\mathbf{x}_i, \mathbf{w}))^2 \newline
&#x26; = \underset{\mathbf{w}}{\arg\min} \ L_{\mathcal{D}}(\mathbf{w})
\end{align*}
$$
Thus, the criterion coincides with the direct inference via the empirical risk minimization if we parametrize the predictor as $\hat{y}(\mathbf{x}) = \mu(\mathbf{x}, \mathbf{w})$.
Further, minimizing $L_{\mathcal{D}}(\mathbf{w})$ can be solved in closed form $\mathbf{w}_{\text{ML}} = (\boldsymbol{\Phi}^T \boldsymbol{\Phi})^{-1} \boldsymbol{\Phi}^T \mathbf{y}$, where $\boldsymbol{\Phi} = (\phi(\mathbf{x}_1), \ldots, \phi(\mathbf{x}_N))^T$.</p></div>
</details></div>
</details>
<figure><img alt="ML Learning Example" loading="lazy" decoding="async" fetchpriority="auto" width="553" height="420" src="/_astro/ml_learning_example.BhMqmU2J_Z1wM5JA.svg" ><figcaption>ML Learning Example</figcaption></figure>
<h3 id="training-generalization-loss-bias-and-estimation-error">Training, Generalization Loss, Bias, and Estimation Error</h3>
<p>As the number of data points increases, overfitting is avoided. When $\mathcal{D}$ is big compared to the number of parameters in $\boldsymbol{\theta}$,
$$
L_{\mathcal{D}}(\mathbf{w}) \simeq L_p(\mathbf{w}).
$$</p>
<p>Thus, for large $N$,
$$
\mathbf{w}_{\text{ML}} \Rightarrow \mathbf{w}^{\star} = \underset{\mathbf{w}}{\arg\min} \ L_p(\mathbf{w}).
$$</p>
<details class="group relative px-4 py-3 my-6 border-l-4 text-base border-teal-600 dark:bg-teal-950/10" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-teal-700 dark:text-teal-400" data-lucide="book-open" viewBox="0 0 24 24"><use href="#book-open"></use></svg>Definition: Estimation Error and Bias<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-teal-700 dark:text-teal-400" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>$$
L_p(\mathbf{w}_{\text{ML}}) = L_p(\hat{y}^{\star}) + \underbrace{(L_p(\mathbf{w}^{\star}) - L_p(\hat{y}^{\star}))}_{\text{Bias}} + \underbrace{(L_p(\mathbf{w}_{\text{ML}}) - L_p(\mathbf{w}^{\star}))}_{\text{Estimation Error}}.
$$
where $L_p(\hat{y}^{\star})$ is generalization loss of the optimal predictor (minimum loss achievable), $L_p(\mathbf{w}^{\star})$ is the generalization loss for optimal $\mathbf{w}$ for the given hypothesis class (e.g., fixing $M$).</p><p>The bias (approximation error) is caused by our choice of the hypothesis class (model misspecification) and the estimation error (generalization gap) is caused byt the fact that $N$ is not large enough.</p></div>
</details>
<h3 id="learning-and-validation">Learning and Validation</h3>
<p>So, we would like to choose a model (hyperparameters and parameters) such that the generalization error $L_p(\hat{y}) = \mathbb{E}_{\mathbf{x}, \mathsf{y} \sim p(\mathbf{x}, y)}[\ell(\mathsf{y}, \hat{y}(\mathbf{x}))]$ is minimized.
However, it depends on $p(\mathbf{x}, y)$, which is unknown.</p>
<details class="group relative px-4 py-3 my-6 border-l-4 text-base border-sky-300 dark:bg-sky-950/10" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-sky-500 dark:text-sky-200" data-lucide="lightbulb" viewBox="0 0 24 24"><use href="#lightbulb"></use></svg>Intuition: Validation<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-sky-500 dark:text-sky-200" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>We can divide our available data into three sets.</p><ul>
<li>
<p>Training set $\mathcal{D}$ to fit the model parameters.</p>
</li>
<li>
<p>Validation set $\mathcal{V}$ to choose hypothesis class via evaluation of approximation of the generalization error,
$$
L_p(\mathbf{w}) \approx \frac{1}{N_{\mathcal{V}}} \sum_{i=1}^{N_{\mathcal{V}}} \ell(\mathsf{y}_i, \mu(\mathbf{x}_i, \mathbf{w})),
$$
for the selected hypothesis class, retrain $\mathbf{w}$ based on $\mathcal{D} \cup \mathcal{V}$.</p>
</li>
<li>
<p>Test set $\mathcal{T}$ to produce the estimate generalization error obtained with the final model.</p>
</li>
</ul><p>However, there is a pitfall with this approach, parts of the available data are not used for training!
Validation is suitable when we have plently of data.
However, when data is scarce, we can use cross-validation (CV) techniques.</p></div>
</details>
<details class="group relative px-4 py-3 my-6 border-l-4 text-base border-emerald-600 dark:bg-emerald-950/10" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-emerald-700 dark:text-emerald-300" data-lucide="cpu" viewBox="0 0 24 24"><use href="#cpu"></use></svg>Algorithm: $k$-Fold Cross-Validation<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-emerald-700 dark:text-emerald-300" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><ol>
<li>
<p>Randomly partition data points into $k$ partitions (folds)</p>
</li>
<li>
<p>For each $\kappa \in \{1, \ldots, k\}$, train model over all other $k -1$ partitions.</p>
</li>
<li>
<p>Compute generalization error on the $\kappa$-th partition,</p>
</li>
<li>
<p>Generalization error estimated as average over all partitions.</p>
</li>
<li>
<p>Choose hypothesis class that minimizes the estimate of the generalization error in Step 4.</p>
</li>
</ol></div>
</details>
<h2 id="maximum-a-posteriori-learning">Maximum A Posteriori Learning</h2>
<details class="group relative px-4 py-3 my-6 border-l-4 text-base border-sky-300 dark:bg-sky-950/10" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-sky-500 dark:text-sky-200" data-lucide="lightbulb" viewBox="0 0 24 24"><use href="#lightbulb"></use></svg>Intuition: Maximum A Posteriori Learning<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-sky-500 dark:text-sky-200" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>In the Bayesian approach, we instead treat the parameters $\mathbf{w}$ as unknown random variables (instead of unknown but deterministic quantities).
MAP enables a finer control of the bias and estimation error.</p><p>The key idea is to leverage prior information available on the behavior of parameters in the absence, or presence, of overfitting.</p><details class="group relative px-4 py-3 my-6 border-l-4 text-base border-blue-500 dark:bg-blue-950/5" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-blue-700 dark:text-blue-300" data-lucide="info" viewBox="0 0 24 24"><use href="#info"></use></svg>Note<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-blue-700 dark:text-blue-300" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>A large value of $\Vert \mathbf{w} \Vert_1$ a manifestation of overfitting $\Rightarrow$ introduce a prior on $\mathbf{w}$ that gives lower probability to larger values,
$$
\mathbf{w} \sim \mathcal{N}(0, \alpha^{-1} \mathbf{I}).
$$
i.e., $p(\mathbf{w}) = \mathcal{N}(\mathbf{w} \mid 0, \alpha^{-1} \mathbf{I}) = \left(\frac{\alpha}{2 \pi}\right)^{(M + 1) / 2} \exp \left(- \frac{\alpha}{2} \mathbf{w}^T \mathbf{w} \right)$</p></div>
</details></div>
</details>
<h3 id="how-do-we-choose-the-prior-distribution">How do we choose the prior distribution?</h3>
<p>But, how do we choose the prior distribution?
A common approach is to choose a conjugate prior (if present) to the likelihood function.</p>
<p>For example, exponential of a quadratic function of $\mathbf{w} \Rightarrow$ Conjugate given by a Gaussian distribution of the form,
$$
p(\mathbf{w}) = \mathcal{N}(\mathbf{w} \mid \mathbf{m}_0, \mathbf{S}_0).
$$</p>
<h2 id="maximum-a-posteriori-learning-continued">Maximum A Posteriori Learning: Continued</h2>
<details class="group relative px-4 py-3 my-6 border-l-4 text-base border-teal-600 dark:bg-teal-950/10" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-teal-700 dark:text-teal-400" data-lucide="book-open" viewBox="0 0 24 24"><use href="#book-open"></use></svg>Definition: MAP Criterion<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-teal-700 dark:text-teal-400" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>$$
\begin{align*}
(\mathbf{w}_{\text{MAP}}, \beta) &#x26; = \underset{\mathbf{w}, \beta}{\arg\max} \ p(y_{\mathcal{D}}, \mathbf{w} \mid x_{\mathcal{D}}, \beta) \newline
&#x26; = \underset{\mathbf{w}, \beta}{\arg\max} \ p(\mathbf{w}) \prod_{i=1}^{N} p(y_i \mid \mathbf{x}_i, \mathbf{w}, \beta) \newline
\end{align*}
$$
or, equivalently,
$$
(\mathbf{w}_{\text{MAP}}, \beta) = \underset{\mathbf{w}, \beta}{\arg\min} -\sum_{i=1}^{N} \log p(y_i \mid \mathbf{x}_i, \mathbf{w}, \beta) - \log p(\mathbf{w}).
$$
If $\beta$ is a known constant,
$$
\mathbf{w}_{\text{MAP}} = \underset{\mathbf{w}}{\arg\min} \ -\sum_{i=1}^{N} \log p(y_i \mid \mathbf{x}_i, \mathbf{w}, \beta) - \log p(\mathbf{w}).
$$</p><details class="group relative px-4 py-3 my-6 border-l-4 text-base border-blue-500 dark:bg-blue-950/5" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-blue-700 dark:text-blue-300" data-lucide="info" viewBox="0 0 24 24"><use href="#info"></use></svg>Note<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-blue-700 dark:text-blue-300" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>MAP is equivalent to maximizing the posterior distribution of $\mathbf{w}$ given the available data.</p></div>
</details></div>
</details>
<details class="group relative px-4 py-3 my-6 border-l-4 text-base border-sky-500 dark:bg-sky-950/10" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-sky-600 dark:text-sky-300" data-lucide="code" viewBox="0 0 24 24"><use href="#code"></use></svg>Example: MAP Learning with Gaussian Prior<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-sky-600 dark:text-sky-300" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>Assuming $\mathbf{w} \sim \mathcal{N}(0, \alpha^{-1} \mathbf{I})$, i.e., $p(\mathbf{w}) = \mathcal{N}(\mathbf{w} \mid 0, \alpha^{-1} \mathbf{I}) = \left(\frac{\alpha}{2 \pi}\right)^{(M + 1) / 2} \exp \left(- \frac{\alpha}{2} \mathbf{w}^T \mathbf{w} \right)$,
$$
\begin{align*}
\mathbf{w}_{\text{MAP}} &#x26; = \underset{\mathbf{w}}{\arg\min} \ -\sum_{i=1}^{N} \log p(y_i \mid \mathbf{x}_i, \mathbf{w}, \beta) - \log p(\mathbf{w}) \newline
&#x26; = \underset{\mathbf{w}}{\arg\min} - \left( -\frac{\beta}{2} \sum_{i=1}^{N} \left(\mu(\mathbf{x}_i, \mathbf{w}) - y_i \right)^2 + \frac{N}{2} \log \frac{\beta}{2 \pi} \right) - \log p(\mathbf{w}) \newline
&#x26; = \underset{\mathbf{w}}{\arg\min} \ \frac{\beta}{2} \sum_{i=1}^{N} \left(\mu(\mathbf{x}_i, \mathbf{w}) - y_i \right)^2 - \log p(\mathbf{w}) \newline
&#x26; = \underset{\mathbf{w}}{\arg\min} \ \frac{1}{N} \sum_{i=1}^{N} \left(\mu(\mathbf{x}_i, \mathbf{w}) - y_i \right)^2 - \frac{2}{N \beta} \log p(\mathbf{w}) \newline
&#x26; = \underset{\mathbf{w}}{\arg\min} \ \frac{1}{N} \sum_{i=1}^{N} \left(\mu(\mathbf{x}_i, \mathbf{w}) - y_i \right)^2 + \frac{\alpha}{\beta} \mathbf{w}^T \mathbf{w} \newline
&#x26; = \underset{\mathbf{w}}{\arg\min} \ L_{\mathcal{D}}(\mathbf{w}) + \frac{\lambda}{N} \Vert \mathbf{w} \Vert^2 \Rightarrow \mathbf{w}_{\text{MAP}} = (\lambda \mathbf{I} + \boldsymbol{\Phi}^T \boldsymbol{\Phi})^{-1} \boldsymbol{\Phi}^T \mathbf{y}_{\mathcal{D}}
\end{align*}
$$</p><details class="group relative px-4 py-3 my-6 border-l-4 text-base border-blue-500 dark:bg-blue-950/5" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-blue-700 dark:text-blue-300" data-lucide="info" viewBox="0 0 24 24"><use href="#info"></use></svg>Note<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-blue-700 dark:text-blue-300" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>Note that, as $N \to \infty$, the influence of the prior diminishes, and MAP converges to ML.
The MAP criterion (also called ridge regression <sup><a href="#user-content-fn-3" id="user-content-fnref-3" data-footnote-ref="" aria-describedby="footnote-label">3</a></sup>), modifies the ML criterion by adding the quadratic (or Tikhonov) regularization function $R(\mathbf{w}) = \Vert \mathbf{w} \Vert^2$.</p></div>
</details><p>Thus, consider $p(\mathbf{w} \mid \hat{y}_{\mathcal{D}}, x_{\mathcal{D}}, \beta)$. Due to conjugate Gaussian prior distribution, the posterior also Gaussian,
$$
p(\mathbf{w} \mid y_{\mathcal{D}}, x_{\mathcal{D}}, \beta) = \mathcal{N}(\mathbf{w} \mid \mathbf{m}_N, \mathbf{S}_N),
$$
where,
$$
\begin{align*}
\mathbf{m}_N &#x26; = \mathbf{S}_N (\mathbf{S}_0^{-1} \mathbf{m}_0 + \beta \boldsymbol{\Phi}^T \mathbf{y}_{\mathcal{D}}) \newline
\mathbf{S}_N^{-1} &#x26; = \mathbf{S}_0^{-1} + \beta \boldsymbol{\Phi}^T \boldsymbol{\Phi} \newline
\end{align*}
$$
We assume $\mathbf{w} \sim \mathcal{N}(0, \alpha^{-1} \mathbf{I})$,
$$
\begin{align*}
\mathbf{m}_N &#x26; = \beta \mathbf{S}_N \boldsymbol{\Phi}^T \mathbf{y}_{\mathcal{D}} \newline
\mathbf{S}_N^{-1} &#x26; = \alpha \mathbf{I} + \beta \boldsymbol{\Phi}^T \boldsymbol{\Phi} \newline
\end{align*}
$$</p></div>
</details>
<details class="group relative px-4 py-3 my-6 border-l-4 text-base border-sky-300 dark:bg-sky-950/10" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-sky-500 dark:text-sky-200" data-lucide="lightbulb" viewBox="0 0 24 24"><use href="#lightbulb"></use></svg>Intuition: Bayes Theorem for Prediction<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-sky-500 dark:text-sky-200" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>Applying Bayes,
$$
\begin{align*}
p(\mathbf{w} \mid y_{\mathcal{D}}, x_{\mathcal{D}}, \beta) &#x26; = \frac{p(y_{\mathcal{D}} \mid x_{\mathcal{D}}, \mathbf{w}, \beta) p(\mathbf{w})}{p(y_{\mathcal{D}} \mid x_{\mathcal{D}}, \beta)} \newline
&#x26; \propto p(y_{\mathcal{D}} \mid x_{\mathcal{D}}, \mathbf{w}, \beta) p(\mathbf{w}) \newline
&#x26; = p(\mathbf{w}) \prod_{i=1}^{N} p(y_i \mid \mathbf{x}_i, \mathbf{w}, \beta)
\end{align*}
$$</p><ul>
<li>
<p>$p(\mathbf{w})$ is our knowledge about $\mathbf{w}$ before observing any data.</p>
</li>
<li>
<p>$p(y_{\mathcal{D}} \mid \mathbf{w})$ is how likely the observed data is for a particular parameter value.</p>
</li>
<li>
<p>$p(\mathbf{w} \mid y_{\mathcal{D}})$ knowledge about $\mathbf{w}$ from the observed data and the model.</p>
</li>
</ul></div>
</details>
<figure><img alt="MAP Learning Example" loading="lazy" decoding="async" fetchpriority="auto" width="582" height="433" src="/_astro/map_learning_example.DUw8MwrH_1NqA16.svg" ><figcaption>MAP Learning Example</figcaption></figure>
<details class="group relative px-4 py-3 my-6 border-l-4 text-base border-emerald-600 dark:bg-emerald-950/10" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-emerald-700 dark:text-emerald-300" data-lucide="list" viewBox="0 0 24 24"><use href="#list"></use></svg>Summary: Bayesian Linear Regression<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-emerald-700 dark:text-emerald-300" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>In this part, we have seen that the frequentist approach, aims at identifying a specific value for $\boldsymbol{\theta}$ of a probabilistic model to derive a predictor,
$$
\hat{y}^{\star}(\mathbf{x}) = \underset{\hat{y}}{\arg\min} \ \mathbb{E}_{\mathsf{y} \mid \mathbf{x}}[\ell(\mathsf{y}, \hat{y}) \mid \mathbf{x}].
$$</p><ul>
<li>
<p>ML: Chooses $\boldsymbol{\theta}$ that maximizes probability of training data.</p>
</li>
<li>
<p>MAP: Includes also prior information about parameter vector.
In contrast, the Bayesian approach assumes that $\boldsymbol{\theta}$ is jointly distributed with data $\Rightarrow$ Does not commit to a single value of $\boldsymbol{\theta}$ but considers explanations provided by all possible values of $\boldsymbol{\theta}$, each weighted according to data-dependent belief.</p>
</li>
</ul><p>Bayesian Linear Regression Model,
$$
y(\mathbf{x}, \mathbf{w}) = \mathbf{w}^T \boldsymbol{\phi}(\mathbf{x}) + \epsilon = \mu(\mathbf{x}, \mathbf{w}) + \epsilon, \quad \epsilon \sim \mathcal{N}(0, \beta^{-1}) \newline
$$
where $\mathbf{w} \sim p(\mathbf{w})$</p><p>Probabilistic Model,
$$
\begin{align*}
p(\mathsf{y} \mid \mathbf{x}, \mathbf{w}, \beta) &#x26; = \prod_{i=1}^{N} \mathcal{N}(\mathsf{y} \mid \mu(\mathbf{x}, \mathbf{w}), \beta^{-1}) \quad \text{likelihood} \newline
p(\mathbf{w}) &#x26; = \mathcal{N}(\mathbf{w} \mid \mathbf{0}, \mathbf{S}_0) \quad \text{prior} \newline
\end{align*}
$$
Thus, the end goal is making predictions of $y$ for new values of $\mathbf{x}$ $\Rightarrow$ We can directly evalute the posterior distribution $p(y \mid y_{\mathcal{D}}, x_{\mathcal{D}}, \mathbf{x}, \beta)$.
A fully Bayesian solution returns the entire posterior $p(y \mid \mathcal{D}, \mathbf{x}, \beta)$ $\Rightarrow$ which provides more information about unobserved label $y$.</p><p>Finally, one last note on predictive distribution.
We obtain,
$$
p(y \mid \mathcal{D}, \mathbf{x}, \beta) = \int \underbrace{p(\mathbf{w} \mid \mathcal{D}, \beta)}_{\text{posterior dist. of } \mathbf{w}} p(y \mid \mathbf{x}, \mathbf{w}, \beta) \ d\mathbf{w}.
$$
With the Bayesian approach, $p(y \mid \mathbf{x}, \mathbf{w}, \beta)$ is associated with each value of $\mathbf{w}$ weighted by the posterior belief,
$$
p(\mathbf{w} \mid \mathcal{D}, \beta) = \frac{p(\mathbf{w}) p(y_{\mathcal{D}} \mid x_{\mathcal{D}}, \mathbf{w}, \beta)}{p(y_{\mathcal{D}} \mid x_{\mathcal{D}}, \beta)}.
$$
Computing $p(\mathbf{w} \mid \mathcal{D}, \beta)$ and $p(y \mid \mathcal{D}, \mathbf{x}, \beta)$ is difficult.</p><p>For our Bayesian linear regression problem with $\mathbf{w} \sim \mathcal{N}(0, \alpha^{-1} \mathbf{I})$,
$$
\begin{align*}
p(y \mid \mathbf{x}, \mathbf{w}, \beta) &#x26; = \mathcal{N}(y \mid \mu(\mathbf{x}, \mathbf{w}), \beta^{-1}) \newline
p(\mathbf{w} \mid \mathcal{D}, \beta) &#x26; = \mathcal{N}(\mathbf{w} \mid \mathbf{m}_N, \mathbf{S}_N) \newline
\end{align*}
$$
where $\mathbf{m}_N$ and $\mathbf{S}_N$ are defined as before.</p><p>Thus, we can obtain,
$$
p(y \mid \mathcal{x}, \mathcal{D}, \beta) = \mathcal{N}(y \mid \mu(\mathbf{x}, \mathbf{w}_{\text{MAP}}), \sigma^2_N(\mathbf{x})),
$$
where,
$$
\begin{align*}
\mu(\mathbf{x}, \mathbf{w}_{\text{MAP}}) &#x26; = \mathbf{w}_{\text{MAP}}^T \boldsymbol{\phi}(\mathbf{x}) = \mathbf{m}_N^T \boldsymbol{\phi}(\mathbf{x}) \newline
\sigma^2_N(\mathbf{x}) &#x26; = \frac{1}{\beta} + \frac{1}{\beta} \left( \boldsymbol{\phi}(\mathbf{x})^T \left( \alpha \mathbf{I} + \boldsymbol{\Phi}^T \boldsymbol{\Phi} \right)^{-1} \boldsymbol{\phi}(\mathbf{x}) \right) \newline
\end{align*}
$$</p></div>
</details>
<section data-footnotes="" class="footnotes"><h2 class="sr-only" id="footnote-label">Footnotes</h2>
<ol>
<li id="user-content-fn-1">
<p><a href="https://en.wikipedia.org/wiki/Discriminative_model" rel="nofollow noreferrer noopener" target="_blank">Wikipedia: Discriminative model</a> <a href="#user-content-fnref-1" data-footnote-backref="" aria-label="Back to reference 1" class="data-footnote-backref"></a></p>
</li>
<li id="user-content-fn-2">
<p><a href="https://en.wikipedia.org/wiki/Generative_model" rel="nofollow noreferrer noopener" target="_blank">Wikipedia: Generative model</a> <a href="#user-content-fnref-2" data-footnote-backref="" aria-label="Back to reference 2" class="data-footnote-backref"></a></p>
</li>
<li id="user-content-fn-3">
<p><a href="https://en.wikipedia.org/wiki/Ridge_regression" rel="nofollow noreferrer noopener" target="_blank">Ridge Regression</a> <a href="#user-content-fnref-3" data-footnote-backref="" aria-label="Back to reference 3" class="data-footnote-backref"></a></p>
</li>
</ol>
</section>


</body></html> </article> <div data-margin-sidebar class="sticky top-20 col-start-3 row-span-1 mr-auto ml-8 hidden h-[calc(100vh-5rem)] max-w-fit xl:block"> <astro-island uid="Z1Go3a0" prefix="r31" component-url="/_astro/scroll-area.BdR3V4Yj.js" component-export="ScrollArea" renderer-url="/_astro/client.DXIZDqlh.js" props="{&quot;type&quot;:[0,&quot;always&quot;]}" ssr client="load" opts="{&quot;name&quot;:&quot;ScrollArea&quot;,&quot;value&quot;:true}" await-children><div dir="ltr" data-slot="scroll-area" class="relative" style="position:relative;--radix-scroll-area-corner-width:0px;--radix-scroll-area-corner-height:0px"><style>[data-radix-scroll-area-viewport]{scrollbar-width:none;-ms-overflow-style:none;-webkit-overflow-scrolling:touch;}[data-radix-scroll-area-viewport]::-webkit-scrollbar{display:none}</style><div data-radix-scroll-area-viewport="" data-slot="scroll-area-viewport" class="ring-ring/10 dark:ring-ring/20 dark:outline-ring/40 outline-ring/50 size-full rounded-[inherit] transition-[color,box-shadow] focus-visible:ring-4 focus-visible:outline-1" style="overflow-x:hidden;overflow-y:hidden"><div style="min-width:100%;display:table"><astro-slot> <div class="px-4"> <h3 class="mb-3 text-xl font-medium">Margin Notes</h3> <ul class="space-y-2"> <li> <a href="#mn-1" data-note-id="mn-1" class="margin-note-link group hover:border-border hover:bg-muted/50 block rounded-lg border border-transparent p-3 transition-all duration-200"> <div class="flex items-start gap-2"> <span class="text-primary bg-primary/10 shrink-0 rounded px-1.5 py-0.5 font-mono text-xs"> 1 </span> <p class="text-muted-foreground group-hover:text-foreground line-clamp-3 text-sm leading-relaxed"> since $\log(\cdot)$ is a monotonic function and does not change the location of the maximum </p> </div> </a> </li> </ul> </div> </astro-slot></div></div><div data-orientation="vertical" data-slot="scroll-area-scrollbar" class="flex touch-none p-px transition-colors select-none h-full w-2.5 border-l border-l-transparent" style="position:absolute;top:0;right:0;bottom:var(--radix-scroll-area-corner-height);--radix-scroll-area-thumb-height:18px"></div></div><!--astro:end--></astro-island> </div> <script type="module">function i(){document.querySelectorAll(".margin-anchor").forEach(t=>{t.addEventListener("click",o=>{o.preventDefault();const c=t.id,e=document.querySelector(`.margin-note-link[data-note-id="${c}"]`);e&&(document.querySelectorAll(".margin-note-link").forEach(n=>{n.classList.remove("active")}),e.classList.add("active"),e.scrollIntoView({behavior:"smooth",block:"center"}))})}),document.querySelectorAll(".margin-note-link").forEach(t=>{t.addEventListener("click",o=>{o.preventDefault();const c=t.dataset.noteId,e=document.getElementById(c);if(e){const r=e.getBoundingClientRect().top+window.scrollY-120;window.scrollTo({top:r,behavior:"smooth"}),document.querySelectorAll(".margin-anchor").forEach(l=>{l.classList.remove("active")}),e.classList.add("active")}const n=document.querySelector("#mobile-notes-container details");n&&(n.open=!1)})});const a=new IntersectionObserver(t=>{t.forEach(o=>{const c=o.target.id,e=document.querySelector(`.margin-note-link[data-note-id="${c}"]`),n=o.target;o.isIntersecting&&(document.querySelectorAll(".margin-note-link").forEach(r=>{r.classList.remove("active")}),document.querySelectorAll(".margin-anchor").forEach(r=>{r.classList.remove("active")}),e&&e.classList.add("active"),n&&n.classList.add("active"))})},{rootMargin:"-120px 0px -70% 0px",threshold:.1});document.querySelectorAll(".margin-anchor").forEach(t=>{a.observe(t)})}function s(){document.querySelectorAll(".margin-note-link, .margin-anchor").forEach(a=>{a.classList.remove("active")})}document.addEventListener("DOMContentLoaded",i);document.addEventListener("astro:after-swap",()=>{s(),i()});document.addEventListener("astro:before-swap",s);</script> <nav class="col-start-2 grid grid-cols-1 gap-4 sm:grid-cols-2"> <a href="/notes/master/ssy316/ssy316" target="_self" class="duration-300 ease-in-out gap-2 whitespace-nowrap text-sm font-medium transition-all disabled:pointer-events-none disabled:opacity-50 [&#38;_svg]:pointer-events-none [&#38;_svg:not([class*='size-'])]:size-4 shrink-0 [&#38;_svg]:shrink-0 outline-none focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:ring-[3px] aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive border bg-background shadow-xs hover:bg-accent hover:text-accent-foreground dark:bg-input/30 dark:border-input dark:hover:bg-input/50 px-4 py-2 has-[>svg]:px-3 rounded-lg group flex items-center justify-start size-full" aria-disabled="false">  <svg width="1em" height="1em" viewBox="0 0 24 24" class="mr-2 size-4 transition-transform group-hover:-translate-x-1" data-icon="lucide:arrow-left">   <use href="#ai:lucide:arrow-left"></use>  </svg> <div class="flex flex-col items-start overflow-hidden text-wrap"> <span class="text-muted-foreground text-left text-xs"> Previous Post </span> <span class="w-full text-left text-sm text-balance text-ellipsis"> Part 1 - Introduction </span> </div>  </a>  <a href="/notes/master/ssy316/ssy316_3" target="_self" class="duration-300 ease-in-out gap-2 whitespace-nowrap text-sm font-medium transition-all disabled:pointer-events-none disabled:opacity-50 [&#38;_svg]:pointer-events-none [&#38;_svg:not([class*='size-'])]:size-4 shrink-0 [&#38;_svg]:shrink-0 outline-none focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:ring-[3px] aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive border bg-background shadow-xs hover:bg-accent hover:text-accent-foreground dark:bg-input/30 dark:border-input dark:hover:bg-input/50 px-4 py-2 has-[>svg]:px-3 rounded-lg group flex items-center justify-end size-full" aria-disabled="false">  <div class="flex flex-col items-end overflow-hidden text-wrap"> <span class="text-muted-foreground text-right text-xs"> Next Post </span> <span class="w-full text-right text-sm text-balance text-ellipsis"> Part 4 &amp; 5 - Linear Models for Classification </span> </div> <svg width="1em" height="1em" viewBox="0 0 24 24" class="ml-2 size-4 transition-transform group-hover:translate-x-1" data-icon="lucide:arrow-right">   <use href="#ai:lucide:arrow-right"></use>  </svg>  </a> </nav> <div class="col-start-2"> <section class="mx-auto mt-12"> <script data-astro-rerun src="https://giscus.app/client.js" data-repo="rezaarezvan/rezarezvan.com" data-repo-id="R_kgDOHvQr3w" data-category="General" data-category-id="DIC_kwDOHvQr384CiWVC" data-mapping="og:title" data-strict="0" data-reactions-enabled="1" data-emit-metadata="0" data-input-position="bottom" data-theme="preferred_color_scheme" data-lang="en" data-loading="lazy" crossorigin="anonymous" async></script> </section> <script>
  function updateGiscusTheme() {
    const element = document.documentElement
    const theme = element.getAttribute('data-theme')
    const iframe = document.querySelector('iframe.giscus-frame')
    if (!iframe) return
    iframe.contentWindow.postMessage(
      { giscus: { setConfig: { theme } } },
      'https://giscus.app',
    )
  }

  const observer = new MutationObserver(updateGiscusTheme)
  observer.observe(document.documentElement, {
    attributes: true,
    attributeFilter: ['class'],
  })

  window.onload = () => {
    updateGiscusTheme()
  }
</script> </div> </section> <button data-slot="button" class="items-center justify-center gap-2 whitespace-nowrap rounded-md text-sm font-medium transition-all disabled:pointer-events-none disabled:opacity-50 [&amp;_svg]:pointer-events-none [&amp;_svg:not([class*=&#x27;size-&#x27;])]:size-4 shrink-0 [&amp;_svg]:shrink-0 outline-none focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:ring-[3px] aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive border bg-background shadow-xs hover:bg-accent hover:text-accent-foreground dark:bg-input/30 dark:border-input dark:hover:bg-input/50 size-9 group fixed right-8 bottom-8 z-50 hidden" id="scroll-to-top" title="Scroll to top" aria-label="Scroll to top"> <svg width="1em" height="1em" class="mx-auto size-4 transition-all group-hover:-translate-y-0.5" data-icon="lucide:arrow-up">   <symbol id="ai:lucide:arrow-up" viewBox="0 0 24 24"><path fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="m5 12l7-7l7 7m-7 7V5"/></symbol><use href="#ai:lucide:arrow-up"></use>  </svg> </button> <script type="module">document.addEventListener("astro:page-load",()=>{const o=document.getElementById("scroll-to-top"),t=document.querySelector("footer");o&&t&&(o.addEventListener("click",()=>{window.scrollTo({top:0,behavior:"smooth"})}),window.addEventListener("scroll",()=>{const e=t.getBoundingClientRect().top<=window.innerHeight;o.classList.toggle("hidden",window.scrollY<=300||e)}))});</script>  </div> </main> <footer class="py-4"> <div class="mx-auto flex max-w-3xl flex-col items-center justify-center gap-y-2 px-4 sm:flex-row sm:justify-between"> <div class="flex flex-wrap items-center justify-center gap-x-2 text-center"> <span class="text-muted-foreground text-sm">
&copy; 2025  rezarezvan.com </span> </div> </div> </footer> <div id="backdrop" class="invisible fixed top-0 left-0 z-50 flex h-screen w-full justify-center bg-[rgba(0,0,0,0.5)] p-6 backdrop-blur-sm" data-astro-transition-persist="astro-t6dxx5el-4"> <div id="pagefind-container" class="m-0 flex h-fit max-h-[80%] w-full max-w-screen-sm flex-col overflow-auto rounded border border-black/15 bg-neutral-100 p-2 px-4 py-3 shadow-lg dark:border-white/20 dark:bg-neutral-900"> <div id="search" class="pagefind-ui pagefind-init" data-pagefind-ui data-bundle-path="/pagefind/" data-ui-options="{&#34;showImages&#34;:false,&#34;excerptLength&#34;:15,&#34;resetStyles&#34;:false}"></div> <script type="module" src="/_astro/Search.astro_astro_type_script_index_0_lang.tZYucdM2.js"></script> <div class="dark:prose-invert mr-2 pt-4 pb-1 text-right text-xs">
Press <span class="prose dark:prose-invert text-xs"><kbd class="">Esc</kbd></span> or click anywhere to close
</div> </div> </div> <script>
  document.addEventListener('DOMContentLoaded', () => {
    const magnifyingGlass = document.getElementById('magnifying-glass')
    const backdrop = document.getElementById('backdrop')

    function openPagefind() {
      const searchDiv = document.getElementById('search')
      const search = searchDiv.querySelector('input')
      setTimeout(() => {
        search.focus()
      }, 0)
      backdrop?.classList.remove('invisible')
      backdrop?.classList.add('visible')
    }

    function closePagefind() {
      const searchDiv = document.getElementById('search')
      const search = searchDiv.querySelector('input')
      if (search) {
        search.value = ''
      }
      backdrop?.classList.remove('visible')
      backdrop?.classList.add('invisible')
    }

    // open pagefind
    magnifyingGlass?.addEventListener('click', () => {
      openPagefind()
    })

    document.addEventListener('keydown', (e) => {
      if (e.key === 'Escape') {
        closePagefind()
      }
    })

    // close pagefind when searched result(link) clicked
    document.addEventListener('click', (event) => {
      if (event.target.classList.contains('pagefind-ui__result-link')) {
        closePagefind()
      }
    })

    backdrop?.addEventListener('click', (event) => {
      if (!event.target.closest('#pagefind-container')) {
        closePagefind()
      }
    })

    // prevent form submission
    const form = document.getElementById('form')
    form?.addEventListener('submit', (event) => {
      event.preventDefault()
    })
  })
</script>  </div> </body></html>