<!DOCTYPE html><html class="bg-background text-foreground" lang="en"> <head><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes"><meta name="generator" content="Astro v5.16.6"><meta name="robots" content="index, follow"><meta name="HandheldFriendly" content="True"><meta name="mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="format-detection" content="telephone=no,date=no,address=no,email=no,url=no"><meta name="theme-color" content="#121212" media="(prefers-color-scheme: dark)"><meta name="theme-color" content="#121212" media="(prefers-color-scheme: light)"><link rel="sitemap" href="/sitemap-index.xml"><link rel="manifest" href="/site.webmanifest"><link rel="alternate" type="application/rss+xml" title="rezarezvan.com" href="https://rezarezvan.com/rss.xml"><!-- PageFind --><link href="/pagefind/pagefind-ui.css" rel="stylesheet"><script src="/pagefind/pagefind-ui.js"></script><!-- KaTeX support --><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.22/dist/katex.min.css" integrity="sha384-5TcZemv2l/9On385z///+d7MSYlvIEw9FuZTIdZ14vJLqWphw7e7ZPuOiCHJcFCP" crossorigin="anonymous"><script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.22/dist/katex.min.js" integrity="sha384-cMkvdD8LoxVzGF/RPUKAcvmm49FQ0oxwDF3BGKtDXcEc+T1b2N+teh/OJfpU0jr6" crossorigin="anonymous"></script><script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.22/dist/contrib/auto-render.min.js" integrity="sha384-hCXGrW6PitJEwbkoStFjeJxv+fSOOQKOPbJxSfM6G5sWZjAyWhXiTIIAmQqnlLlh" crossorigin="anonymous" onload="renderMathInElement(document.body);"></script><!-- inline KaTeX --><script>
    function renderKaTeX() {
      if (typeof renderMathInElement !== 'undefined') {
        renderMathInElement(document.body, {
          delimiters: [
            { left: '$$', right: '$$', display: true },
            { left: '$', right: '$', display: false },
          ],
        })
      }
    }

    document.addEventListener('DOMContentLoaded', renderKaTeX)
    document.addEventListener('astro:after-swap', renderKaTeX)
  </script><link rel="icon" type="image/png" href="/favicon-96x96.png" sizes="96x96"><link rel="icon" type="image/svg+xml" href="/favicon.ico"><link rel="shortcut icon" href="/favicon.ico"><link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png"><meta name="apple-mobile-web-app-title" content="rezvan-blog"><link rel="manifest" href="/site.webmanifest"><meta name="astro-view-transitions-enabled" content="true"><meta name="astro-view-transitions-fallback" content="animate"><script type="module" src="/_astro/ClientRouter.astro_astro_type_script_index_0_lang.QW52Ox2j.js"></script><script>
    function init() {
      setGiscusTheme()
    }

    const setGiscusTheme = () => {
      const giscus = document.querySelector('.giscus-frame')

      const isDark = document.documentElement.classList.contains('dark')

      if (giscus) {
        const url = new URL(giscus.src)
        url.searchParams.set('theme', isDark ? 'dark' : 'light')
        giscus.src = url.toString()
      }
    }

    document.addEventListener('DOMContentLoaded', () => init())
    document.addEventListener('astro:after-swap', () => init())
  </script><title>Part 16 - Summary | rezarezvan.com</title><meta name="title" content="Part 16 - Summary | rezarezvan.com"><meta name="description" content="Personal website and course notes repository"><link rel="canonical" href="https://rezarezvan.com"><meta name="robots" content="noindex"><meta property="og:title" content="Part 16 - Summary"><meta property="og:description" content="Personal website and course notes repository"><meta property="og:image" content="https://rezarezvan.com/static/1200x630.png"><meta property="og:image:alt" content="Part 16 - Summary"><meta property="og:type" content="website"><meta property="og:locale" content="en"><meta property="og:site_name" content="rezarezvan.com"><meta property="og:url" content="https://rezarezvan.com/notes/master/mve550/mve550_16/"><meta name="twitter:title" content="Part 16 - Summary"><meta name="twitter:description" content="Personal website and course notes repository"><meta property="twitter:image" content="https://rezarezvan.com/static/1200x630.png"><meta name="twitter:image:alt" content="Part 16 - Summary"><meta name="twitter:card" content="summary_large_image"><link rel="stylesheet" href="/_astro/_slug_.CAsPNc9o.css"></head><body> <div class="flex h-fit min-h-screen flex-col gap-y-6 font-sans"> <div class="bg-background/50 sticky top-0 z-50 divide-y backdrop-blur-sm xl:divide-none"> <header data-astro-transition-persist="astro-l7r54iwe-1"> <div class="mx-auto flex max-w-3xl items-center justify-between gap-4 px-4 py-3"> <a href="/" target="_self" class="transition-colors duration-300 ease-in-out flex shrink-0 items-center justify-center gap-3">  <span class="hidden h-full text-lg font-medium min-[300px]:block">rezarezvan.com</span>  </a> <div class="flex items-center sm:gap-4"> <nav class="hidden items-center gap-4 text-sm sm:flex sm:gap-6"> <a href="/blog" target="_self" class="inline-block duration-300 ease-in-out hover:text-foreground/30 transition-colors"> blog<span>/</span>  </a><a href="/notes" target="_self" class="inline-block duration-300 ease-in-out hover:text-foreground/30 transition-colors"> notes<span>/</span>  </a><a href="/dump" target="_self" class="inline-block duration-300 ease-in-out hover:text-foreground/30 transition-colors"> dump<span>/</span>  </a><a href="/research" target="_self" class="inline-block duration-300 ease-in-out hover:text-foreground/30 transition-colors"> research<span>/</span>  </a> </nav> <button id="magnifying-glass" aria-label="Search" class="flex items-center px-2 text-sm transition-colors duration-300 ease-in-out hover:rounded hover:bg-black/5 hover:text-black focus-visible:bg-black/5 focus-visible:text-black dark:hover:bg-white/5 dark:hover:text-white dark:focus-visible:bg-white/5 dark:focus-visible:text-white"> <svg height="16" stroke-linejoin="round" viewBox="0 0 16 16" width="16" style="color: currentcolor;"> <path fill-rule="evenodd" clip-rule="evenodd" d="M3.5 7C3.5 5.067 5.067 3.5 7 3.5C8.933 3.5 10.5 5.067 10.5 7C10.5 7.88461 10.1718 8.69256 9.63058 9.30876L9.30876 9.63058C8.69256 10.1718 7.88461 10.5 7 10.5C5.067 10.5 3.5 8.933 3.5 7ZM9.96544 11.0261C9.13578 11.6382 8.11014 12 7 12C4.23858 12 2 9.76142 2 7C2 4.23858 4.23858 2 7 2C9.76142 2 12 4.23858 12 7C12 8.11014 11.6382 9.13578 11.0261 9.96544L14.0303 12.9697L14.5607 13.5L13.5 14.5607L12.9697 14.0303L9.96544 11.0261Z" fill="currentColor"></path> </svg>
&nbsp;Search
</button> <style>astro-island,astro-slot,astro-static-slot{display:contents}</style><script>(()=>{var e=async t=>{await(await t())()};(self.Astro||(self.Astro={})).load=e;window.dispatchEvent(new Event("astro:load"));})();</script><script>(()=>{var A=Object.defineProperty;var g=(i,o,a)=>o in i?A(i,o,{enumerable:!0,configurable:!0,writable:!0,value:a}):i[o]=a;var d=(i,o,a)=>g(i,typeof o!="symbol"?o+"":o,a);{let i={0:t=>m(t),1:t=>a(t),2:t=>new RegExp(t),3:t=>new Date(t),4:t=>new Map(a(t)),5:t=>new Set(a(t)),6:t=>BigInt(t),7:t=>new URL(t),8:t=>new Uint8Array(t),9:t=>new Uint16Array(t),10:t=>new Uint32Array(t),11:t=>1/0*t},o=t=>{let[l,e]=t;return l in i?i[l](e):void 0},a=t=>t.map(o),m=t=>typeof t!="object"||t===null?t:Object.fromEntries(Object.entries(t).map(([l,e])=>[l,o(e)]));class y extends HTMLElement{constructor(){super(...arguments);d(this,"Component");d(this,"hydrator");d(this,"hydrate",async()=>{var b;if(!this.hydrator||!this.isConnected)return;let e=(b=this.parentElement)==null?void 0:b.closest("astro-island[ssr]");if(e){e.addEventListener("astro:hydrate",this.hydrate,{once:!0});return}let c=this.querySelectorAll("astro-slot"),n={},h=this.querySelectorAll("template[data-astro-template]");for(let r of h){let s=r.closest(this.tagName);s!=null&&s.isSameNode(this)&&(n[r.getAttribute("data-astro-template")||"default"]=r.innerHTML,r.remove())}for(let r of c){let s=r.closest(this.tagName);s!=null&&s.isSameNode(this)&&(n[r.getAttribute("name")||"default"]=r.innerHTML)}let p;try{p=this.hasAttribute("props")?m(JSON.parse(this.getAttribute("props"))):{}}catch(r){let s=this.getAttribute("component-url")||"<unknown>",v=this.getAttribute("component-export");throw v&&(s+=` (export ${v})`),console.error(`[hydrate] Error parsing props for component ${s}`,this.getAttribute("props"),r),r}let u;await this.hydrator(this)(this.Component,p,n,{client:this.getAttribute("client")}),this.removeAttribute("ssr"),this.dispatchEvent(new CustomEvent("astro:hydrate"))});d(this,"unmount",()=>{this.isConnected||this.dispatchEvent(new CustomEvent("astro:unmount"))})}disconnectedCallback(){document.removeEventListener("astro:after-swap",this.unmount),document.addEventListener("astro:after-swap",this.unmount,{once:!0})}connectedCallback(){if(!this.hasAttribute("await-children")||document.readyState==="interactive"||document.readyState==="complete")this.childrenConnectedCallback();else{let e=()=>{document.removeEventListener("DOMContentLoaded",e),c.disconnect(),this.childrenConnectedCallback()},c=new MutationObserver(()=>{var n;((n=this.lastChild)==null?void 0:n.nodeType)===Node.COMMENT_NODE&&this.lastChild.nodeValue==="astro:end"&&(this.lastChild.remove(),e())});c.observe(this,{childList:!0}),document.addEventListener("DOMContentLoaded",e)}}async childrenConnectedCallback(){let e=this.getAttribute("before-hydration-url");e&&await import(e),this.start()}async start(){let e=JSON.parse(this.getAttribute("opts")),c=this.getAttribute("client");if(Astro[c]===void 0){window.addEventListener(`astro:${c}`,()=>this.start(),{once:!0});return}try{await Astro[c](async()=>{let n=this.getAttribute("renderer-url"),[h,{default:p}]=await Promise.all([import(this.getAttribute("component-url")),n?import(n):()=>()=>{}]),u=this.getAttribute("component-export")||"default";if(!u.includes("."))this.Component=h[u];else{this.Component=h;for(let f of u.split("."))this.Component=this.Component[f]}return this.hydrator=p,this.hydrate},e,this)}catch(n){console.error(`[astro-island] Error hydrating ${this.getAttribute("component-url")}`,n)}}attributeChangedCallback(){this.hydrate()}}d(y,"observedAttributes",["props"]),customElements.get("astro-island")||customElements.define("astro-island",y)}})();</script><astro-island uid="ZRRmSm" prefix="r17" component-url="/_astro/mobile-menu.Dz9dgoI_.js" component-export="default" renderer-url="/_astro/client.DXIZDqlh.js" props="{&quot;data-astro-transition-persist&quot;:[0,&quot;astro-iq5tym4z-2&quot;]}" ssr client="load" opts="{&quot;name&quot;:&quot;MobileMenu&quot;,&quot;value&quot;:true}" data-astro-transition-persist="astro-iq5tym4z-2" await-children><button data-slot="dropdown-menu-trigger" class="inline-flex items-center justify-center gap-2 whitespace-nowrap rounded-md text-sm font-medium transition-all disabled:pointer-events-none disabled:opacity-50 [&amp;_svg]:pointer-events-none [&amp;_svg:not([class*=&#x27;size-&#x27;])]:size-4 shrink-0 [&amp;_svg]:shrink-0 outline-none focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:ring-[3px] aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive hover:bg-accent hover:text-accent-foreground dark:hover:bg-accent/50 size-9 md:hidden" title="Menu" type="button" id="radix-:r17R0:" aria-haspopup="menu" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-menu h-5 w-5"><line x1="4" x2="20" y1="12" y2="12"></line><line x1="4" x2="20" y1="6" y2="6"></line><line x1="4" x2="20" y1="18" y2="18"></line></svg><span class="sr-only">Toggle menu</span></button><!--astro:end--></astro-island> <button data-slot="button" class="inline-flex items-center justify-center gap-2 whitespace-nowrap rounded-md text-sm font-medium transition-all disabled:pointer-events-none disabled:opacity-50 [&amp;_svg]:pointer-events-none [&amp;_svg:not([class*=&#x27;size-&#x27;])]:size-4 shrink-0 [&amp;_svg]:shrink-0 outline-none focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:ring-[3px] aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive hover:bg-accent hover:text-accent-foreground dark:hover:bg-accent/50 size-9" id="theme-toggle" title="Toggle theme"> <svg width="1em" height="1em" class="size-4 scale-100 rotate-0 transition-all dark:scale-0 dark:-rotate-90" data-icon="lucide:sun">   <symbol id="ai:lucide:sun" viewBox="0 0 24 24"><g fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2"><circle cx="12" cy="12" r="4"/><path d="M12 2v2m0 16v2M4.93 4.93l1.41 1.41m11.32 11.32l1.41 1.41M2 12h2m16 0h2M6.34 17.66l-1.41 1.41M19.07 4.93l-1.41 1.41"/></g></symbol><use href="#ai:lucide:sun"></use>  </svg> <svg width="1em" height="1em" class="absolute size-4 scale-0 rotate-90 transition-all dark:scale-100 dark:rotate-0" data-icon="lucide:moon">   <symbol id="ai:lucide:moon" viewBox="0 0 24 24"><path fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M20.985 12.486a9 9 0 1 1-9.473-9.472c.405-.022.617.46.402.803a6 6 0 0 0 8.268 8.268c.344-.215.825-.004.803.401"/></symbol><use href="#ai:lucide:moon"></use>  </svg> <span class="sr-only">Toggle theme</span> </button> <script data-astro-rerun>
  const theme = (() => {
    const localStorageTheme = localStorage?.getItem('theme') ?? ''
    if (['dark', 'light'].includes(localStorageTheme)) {
      return localStorageTheme
    }
    if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
      return 'dark'
    }
    return 'light'
  })()

  document.documentElement.setAttribute('data-theme', theme)
  document.documentElement.classList.add(
    theme === 'dark' ? 'scheme-dark' : 'scheme-light',
  )
  window.localStorage.setItem('theme', theme)
</script> <script type="module">function a(){const e=document.documentElement,n=e.getAttribute("data-theme")==="dark"?"light":"dark";e.classList.add("[&_*]:transition-none"),e.setAttribute("data-theme",n),e.classList.remove("scheme-dark","scheme-light"),e.classList.add(n==="dark"?"scheme-dark":"scheme-light"),window.getComputedStyle(e).getPropertyValue("opacity"),requestAnimationFrame(()=>{e.classList.remove("[&_*]:transition-none")}),localStorage.setItem("theme",n)}function s(){const e=document.getElementById("theme-toggle");e&&e.addEventListener("click",a)}s();document.addEventListener("astro:after-swap",()=>{const e=localStorage.getItem("theme")||"light",t=document.documentElement;t.classList.add("[&_*]:transition-none"),window.getComputedStyle(t).getPropertyValue("opacity"),t.setAttribute("data-theme",e),t.classList.remove("scheme-dark","scheme-light"),t.classList.add(e==="dark"?"scheme-dark":"scheme-light"),requestAnimationFrame(()=>{t.classList.remove("[&_*]:transition-none")}),s()});</script> </div> </div> </header> <div id="mobile-toc-container" class="w-full xl:hidden"><details class="group"><summary class="flex w-full cursor-pointer items-center justify-between"><div class="mx-auto flex w-full max-w-3xl items-center px-4 py-3"><div class="relative mr-2 size-4"><svg class="h-4 w-4" viewBox="0 0 24 24"><circle class="text-primary/20" cx="12" cy="12" r="10" fill="none" stroke="currentColor" stroke-width="2"></circle><circle id="mobile-toc-progress-circle" class="text-primary" cx="12" cy="12" r="10" fill="none" stroke="currentColor" stroke-width="2" stroke-dasharray="62.83" stroke-dashoffset="62.83" transform="rotate(-90 12 12)"></circle></svg></div><span id="mobile-toc-current-section" class="text-muted-foreground flex-grow truncate text-sm">
Overview
</span><span class="text-muted-foreground ml-2"><svg width="1em" height="1em" class="h-4 w-4 transition-transform duration-200 group-open:rotate-180" data-icon="lucide:chevron-down">   <symbol id="ai:lucide:chevron-down" viewBox="0 0 24 24"><path fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="m6 9l6 6l6-6"/></symbol><use href="#ai:lucide:chevron-down"></use>  </svg></span></div></summary><astro-island uid="Z1hNOsY" prefix="r25" component-url="/_astro/scroll-area.BdR3V4Yj.js" component-export="ScrollArea" renderer-url="/_astro/client.DXIZDqlh.js" props="{&quot;className&quot;:[0,&quot;mx-auto max-w-3xl&quot;],&quot;data-toc-header-scroll&quot;:[0,true]}" ssr client="load" opts="{&quot;name&quot;:&quot;ScrollArea&quot;,&quot;value&quot;:true}" await-children><div dir="ltr" data-slot="scroll-area" class="relative mx-auto max-w-3xl" data-toc-header-scroll="true" style="position:relative;--radix-scroll-area-corner-width:0px;--radix-scroll-area-corner-height:0px"><style>[data-radix-scroll-area-viewport]{scrollbar-width:none;-ms-overflow-style:none;-webkit-overflow-scrolling:touch;}[data-radix-scroll-area-viewport]::-webkit-scrollbar{display:none}</style><div data-radix-scroll-area-viewport="" data-slot="scroll-area-viewport" class="ring-ring/10 dark:ring-ring/20 dark:outline-ring/40 outline-ring/50 size-full rounded-[inherit] transition-[color,box-shadow] focus-visible:ring-4 focus-visible:outline-1" style="overflow-x:hidden;overflow-y:hidden"><div style="min-width:100%;display:table"><astro-slot><div class="max-h-[30vh]"><ul class="flex list-none flex-col gap-y-2 px-4 pb-4" id="mobile-table-of-contents"><li class="px-4 text-sm ml-4 text-foreground/60"><a href="#theory" class="mobile-toc-item underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit" data-heading-id="theory">Theory</a></li><li class="px-4 text-sm ml-4 text-foreground/60"><a href="#examples" class="mobile-toc-item underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit" data-heading-id="examples">Examples</a></li><li class="px-4 text-sm text-foreground/60"><a href="#footnote-label" class="mobile-toc-item underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit" data-heading-id="footnote-label">Footnotes</a></li></ul></div></astro-slot></div></div></div><!--astro:end--></astro-island></details></div><script type="module" src="/_astro/TOCHeader.astro_astro_type_script_index_0_lang.CKMLAwWj.js"></script>  </div> <main class="grow"> <div class="mx-auto flex grow flex-col gap-y-6 px-4">   <section class="grid grid-cols-[minmax(0px,1fr)_min(calc(var(--breakpoint-md)-2rem),100%)_minmax(0px,1fr)] gap-y-6"> <div class="col-start-2"> <nav aria-label="breadcrumb" data-slot="breadcrumb"> <ol data-slot="breadcrumb-list" class="text-muted-foreground flex flex-wrap items-center gap-1.5 text-sm break-words sm:gap-2.5"> <li data-slot="breadcrumb-item" class="inline-flex items-center gap-1.5"> <a data-slot="breadcrumb-link" class="hover:text-foreground transition-colors" href="/"> <svg width="1em" height="1em" class="size-4 shrink-0" data-icon="lucide:home">   <symbol id="ai:lucide:home" viewBox="0 0 24 24"><g fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2"><path d="M15 21v-8a1 1 0 0 0-1-1h-4a1 1 0 0 0-1 1v8"/><path d="M3 10a2 2 0 0 1 .709-1.528l7-6a2 2 0 0 1 2.582 0l7 6A2 2 0 0 1 21 10v9a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2z"/></g></symbol><use href="#ai:lucide:home"></use>  </svg> </a> </li>  <li data-slot="breadcrumb-separator" role="presentation" aria-hidden="true" class="[&amp;&gt;svg]:size-3.5"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-chevron-right"><path d="m9 18 6-6-6-6"></path></svg></li> <li data-slot="breadcrumb-item" class="inline-flex items-center gap-1.5"><a data-slot="breadcrumb-link" class="hover:text-foreground transition-colors" href="/notes/"> <span class="flex items-center gap-x-2"> <svg width="1em" height="1em" class="size-4" data-icon="lucide:graduation-cap">   <symbol id="ai:lucide:graduation-cap" viewBox="0 0 24 24"><g fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2"><path d="M21.42 10.922a1 1 0 0 0-.019-1.838L12.83 5.18a2 2 0 0 0-1.66 0L2.6 9.08a1 1 0 0 0 0 1.832l8.57 3.908a2 2 0 0 0 1.66 0zM22 10v6"/><path d="M6 12.5V16a6 3 0 0 0 12 0v-3.5"/></g></symbol><use href="#ai:lucide:graduation-cap"></use>  </svg> Master </span> </a></li>  <li data-slot="breadcrumb-separator" role="presentation" aria-hidden="true" class="[&amp;&gt;svg]:size-3.5"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-chevron-right"><path d="m9 18 6-6-6-6"></path></svg></li> <li data-slot="breadcrumb-item" class="inline-flex items-center gap-1.5"><a data-slot="breadcrumb-link" class="hover:text-foreground transition-colors" href="/notes/master/mve550"> <span class="flex items-center gap-x-2"> <svg width="1em" height="1em" class="size-4" data-icon="lucide:book-open">   <symbol id="ai:lucide:book-open" viewBox="0 0 24 24"><path fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M12 7v14m-9-3a1 1 0 0 1-1-1V4a1 1 0 0 1 1-1h5a4 4 0 0 1 4 4a4 4 0 0 1 4-4h5a1 1 0 0 1 1 1v13a1 1 0 0 1-1 1h-6a3 3 0 0 0-3 3a3 3 0 0 0-3-3z"/></symbol><use href="#ai:lucide:book-open"></use>  </svg> Stochastic Processes And Bayesian Inference </span> </a></li>  <li data-slot="breadcrumb-separator" role="presentation" aria-hidden="true" class="[&amp;&gt;svg]:size-3.5"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-chevron-right"><path d="m9 18 6-6-6-6"></path></svg></li> <li data-slot="breadcrumb-item" class="inline-flex items-center gap-1.5"><span data-slot="breadcrumb-page" role="link" aria-disabled="true" aria-current="page" class="text-foreground font-normal"> <span class="flex items-center gap-x-2"> <svg width="1em" height="1em" class="size-4 shrink-0" data-icon="lucide:file-text">   <symbol id="ai:lucide:file-text" viewBox="0 0 24 24"><g fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2"><path d="M6 22a2 2 0 0 1-2-2V4a2 2 0 0 1 2-2h8a2.4 2.4 0 0 1 1.704.706l3.588 3.588A2.4 2.4 0 0 1 20 8v12a2 2 0 0 1-2 2z"/><path d="M14 2v5a1 1 0 0 0 1 1h5M10 9H8m8 4H8m8 4H8"/></g></symbol><use href="#ai:lucide:file-text"></use>  </svg> <span>Part 16 - Summary</span> </span> </span></li> </ol> </nav> </div>  <section class="col-start-2 flex flex-col gap-y-6 text-center"> <div class="flex flex-col"> <h1 class="mb-2 scroll-mt-31 text-4xl leading-tight font-medium text-pretty" id="post-title"> Part 16 - Summary </h1> <div class="text-muted-foreground mb-4 flex flex-wrap items-center justify-center gap-2 text-sm"> <div class="flex items-center gap-2"> <span data-slot="badge" class="inline-flex items-center justify-center rounded-md border px-2 py-0.5 text-xs font-medium w-fit whitespace-nowrap shrink-0 [&amp;&gt;svg]:size-3 gap-1 [&amp;&gt;svg]:pointer-events-none focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:ring-[3px] aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive transition-[color,box-shadow] overflow-hidden text-foreground [a&amp;]:hover:bg-accent [a&amp;]:hover:text-accent-foreground">MVE550</span> <div data-orientation="vertical" role="none" data-slot="separator-root" class="bg-border red shrink-0 data-[orientation=horizontal]:h-px data-[orientation=horizontal]:w-full data-[orientation=vertical]:h-full data-[orientation=vertical]:w-px h-4!"></div> <span>Date: January 5, 2026</span> <div data-orientation="vertical" role="none" data-slot="separator-root" class="bg-border red shrink-0 data-[orientation=horizontal]:h-px data-[orientation=horizontal]:w-full data-[orientation=vertical]:h-full data-[orientation=vertical]:w-px h-4!"></div>  <div class="font-base text-sm">
Last modified: January 8, 2026 </div>  <div data-orientation="vertical" role="none" data-slot="separator-root" class="bg-border red shrink-0 data-[orientation=horizontal]:h-px data-[orientation=horizontal]:w-full data-[orientation=vertical]:h-full data-[orientation=vertical]:w-px h-4!"></div> <span>75 min read</span> </div> </div> </div> <nav class="col-start-2 grid grid-cols-1 gap-4 sm:grid-cols-2"> <a href="/notes/master/mve550/mve550_15" target="_self" class="duration-300 ease-in-out gap-2 whitespace-nowrap text-sm font-medium transition-all disabled:pointer-events-none disabled:opacity-50 [&#38;_svg]:pointer-events-none [&#38;_svg:not([class*='size-'])]:size-4 shrink-0 [&#38;_svg]:shrink-0 outline-none focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:ring-[3px] aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive border bg-background shadow-xs hover:bg-accent hover:text-accent-foreground dark:bg-input/30 dark:border-input dark:hover:bg-input/50 px-4 py-2 has-[>svg]:px-3 rounded-lg group flex items-center justify-start size-full" aria-disabled="false">  <svg width="1em" height="1em" class="mr-2 size-4 transition-transform group-hover:-translate-x-1" data-icon="lucide:arrow-left">   <symbol id="ai:lucide:arrow-left" viewBox="0 0 24 24"><path fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="m12 19l-7-7l7-7m7 7H5"/></symbol><use href="#ai:lucide:arrow-left"></use>  </svg> <div class="flex flex-col items-start overflow-hidden text-wrap"> <span class="text-muted-foreground text-left text-xs"> Previous Post </span> <span class="w-full text-left text-sm text-balance text-ellipsis"> Part 15 - Brownian Motion and Gaussian Processes III </span> </div>  </a>  <a href="#" target="_self" class="duration-300 ease-in-out gap-2 whitespace-nowrap text-sm font-medium transition-all disabled:pointer-events-none disabled:opacity-50 [&#38;_svg]:pointer-events-none [&#38;_svg:not([class*='size-'])]:size-4 shrink-0 [&#38;_svg]:shrink-0 outline-none focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:ring-[3px] aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive border bg-background shadow-xs hover:bg-accent hover:text-accent-foreground dark:bg-input/30 dark:border-input dark:hover:bg-input/50 px-4 py-2 has-[>svg]:px-3 rounded-lg group flex items-center justify-end size-full pointer-events-none opacity-50 cursor-not-allowed" aria-disabled="true">  <div class="flex flex-col items-end overflow-hidden text-wrap"> <span class="text-muted-foreground text-right text-xs"> Next Post </span> <span class="w-full text-right text-sm text-balance text-ellipsis"> You&#39;re at the newest post! </span> </div> <svg width="1em" height="1em" class="ml-2 size-4 transition-transform group-hover:translate-x-1" data-icon="lucide:arrow-right">   <symbol id="ai:lucide:arrow-right" viewBox="0 0 24 24"><path fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M5 12h14m-7-7l7 7l-7 7"/></symbol><use href="#ai:lucide:arrow-right"></use>  </svg>  </a> </nav> </section> <div id="toc-sidebar-container" class="sticky top-20 col-start-1 row-span-1 mr-8 ml-auto hidden h-[calc(100vh-5rem)] max-w-md xl:block"><astro-island uid="ZMzY46" prefix="r26" component-url="/_astro/scroll-area.BdR3V4Yj.js" component-export="ScrollArea" renderer-url="/_astro/client.DXIZDqlh.js" props="{&quot;className&quot;:[0,&quot;flex max-h-[calc(100vh-8rem)] flex-col overflow-y-auto&quot;],&quot;type&quot;:[0,&quot;hover&quot;],&quot;data-toc-scroll-area&quot;:[0,true]}" ssr client="load" opts="{&quot;name&quot;:&quot;ScrollArea&quot;,&quot;value&quot;:true}" await-children><div dir="ltr" data-slot="scroll-area" class="relative flex max-h-[calc(100vh-8rem)] flex-col overflow-y-auto" data-toc-scroll-area="true" style="position:relative;--radix-scroll-area-corner-width:0px;--radix-scroll-area-corner-height:0px"><style>[data-radix-scroll-area-viewport]{scrollbar-width:none;-ms-overflow-style:none;-webkit-overflow-scrolling:touch;}[data-radix-scroll-area-viewport]::-webkit-scrollbar{display:none}</style><div data-radix-scroll-area-viewport="" data-slot="scroll-area-viewport" class="ring-ring/10 dark:ring-ring/20 dark:outline-ring/40 outline-ring/50 size-full rounded-[inherit] transition-[color,box-shadow] focus-visible:ring-4 focus-visible:outline-1" style="overflow-x:hidden;overflow-y:hidden"><div style="min-width:100%;display:table"><astro-slot><div class="flex flex-col gap-2 px-4"><span class="text-lg font-medium">Table of Contents</span><ul class="flex list-none flex-col gap-y-2"><li class="text-sm ml-4 text-foreground/60"><a href="#theory" class="marker:text-foreground/30 list-none underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit" data-heading-link="theory">Theory</a></li><li class="text-sm ml-4 text-foreground/60"><a href="#examples" class="marker:text-foreground/30 list-none underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit" data-heading-link="examples">Examples</a></li><li class="text-sm text-foreground/60"><a href="#footnote-label" class="marker:text-foreground/30 list-none underline decoration-transparent underline-offset-[3px] transition-colors duration-200 hover:decoration-inherit" data-heading-link="footnote-label">Footnotes</a></li></ul></div></astro-slot></div></div></div><!--astro:end--></astro-island></div><script type="module">class f{links=document.querySelectorAll("[data-heading-link]");activeIds=[];headings=[];regions=[];scrollArea=null;tocScrollArea=null;reset(){this.links=document.querySelectorAll("#toc-sidebar-container [data-heading-link]"),this.activeIds=[],this.headings=[],this.regions=[];const t=document.getElementById("toc-sidebar-container");this.scrollArea=t?.querySelector("[data-radix-scroll-area-viewport]")||null,this.tocScrollArea=t?.querySelector("[data-toc-scroll-area]")||null}}const e=new f;class c{static build(){if(e.headings=Array.from(document.querySelectorAll(".prose h2, .prose h3, .prose h4, .prose h5, .prose h6")),e.headings.length===0){e.regions=[];return}e.regions=e.headings.map((t,o)=>{const i=e.headings[o+1];return{id:t.id,start:t.offsetTop,end:i?i.offsetTop:document.body.scrollHeight}})}static getVisibleIds(){if(e.headings.length===0)return[];const t=window.scrollY+80,o=window.scrollY+window.innerHeight,i=new Set,l=(s,r)=>s>=t&&s<=o||r>=t&&r<=o||s<=t&&r>=o;return e.headings.forEach(s=>{const r=s.offsetTop+s.offsetHeight;l(s.offsetTop,r)&&i.add(s.id)}),e.regions.forEach(s=>{if(s.start<=o&&s.end>=t){const r=document.getElementById(s.id);if(r){const a=r.offsetTop+r.offsetHeight;s.end>a&&(a<o||t<s.end)&&i.add(s.id)}}}),Array.from(i)}}class h{static update(){if(!e.scrollArea||!e.tocScrollArea)return;const{scrollTop:t,scrollHeight:o,clientHeight:i}=e.scrollArea,l=5,s=t<=l,r=t>=o-i-l;e.tocScrollArea.classList.toggle("mask-t-from-90%",!s),e.tocScrollArea.classList.toggle("mask-b-from-90%",!r)}}class g{static update(t){e.links.forEach(o=>{o.classList.remove("text-foreground")}),t.forEach(o=>{if(o){const i=document.querySelector(`#toc-sidebar-container [data-heading-link="${o}"]`);i&&i.classList.add("text-foreground")}}),this.scrollToActive(t)}static scrollToActive(t){if(!e.scrollArea||!t.length)return;const o=document.querySelector(`#toc-sidebar-container [data-heading-link="${t[0]}"]`);if(!o)return;const{top:i,height:l}=e.scrollArea.getBoundingClientRect(),{top:s,height:r}=o.getBoundingClientRect(),a=s-i+e.scrollArea.scrollTop,u=Math.max(0,Math.min(a-(l-r)/2,e.scrollArea.scrollHeight-e.scrollArea.clientHeight));Math.abs(u-e.scrollArea.scrollTop)>5&&(e.scrollArea.scrollTop=u)}}class d{static handleScroll(){const t=c.getVisibleIds();JSON.stringify(t)!==JSON.stringify(e.activeIds)&&(e.activeIds=t,g.update(e.activeIds))}static handleTOCScroll=()=>h.update();static handleResize(){c.build();const t=c.getVisibleIds();JSON.stringify(t)!==JSON.stringify(e.activeIds)&&(e.activeIds=t,g.update(e.activeIds)),h.update()}static init(){if(e.reset(),c.build(),e.headings.length===0){g.update([]);return}this.handleScroll(),setTimeout(h.update,100);const t={passive:!0};window.addEventListener("scroll",this.handleScroll,t),window.addEventListener("resize",this.handleResize,t),e.scrollArea?.addEventListener("scroll",this.handleTOCScroll,t)}static cleanup(){window.removeEventListener("scroll",this.handleScroll),window.removeEventListener("resize",this.handleResize),e.scrollArea?.removeEventListener("scroll",this.handleTOCScroll),Object.assign(e,{activeIds:[],headings:[],regions:[],scrollArea:null,tocScrollArea:null})}}document.addEventListener("astro:page-load",()=>d.init());document.addEventListener("astro:after-swap",()=>{d.cleanup(),d.init()});document.addEventListener("astro:before-swap",()=>d.cleanup());</script> <article class="prose col-start-2 max-w-none"> <!doctype html><html lang="en"><head></head><body>


<meta charset="utf-8">
<title>MVE550_16</title>
<meta content="width=device-width, initial-scale=1" name="viewport">
<link href="https://cdn.jsdelivr.net/npm/katex@0.16.21/dist/katex.min.css" rel="stylesheet">

<svg xmlns="http://www.w3.org/2000/svg" style="display:none"><defs>
        <symbol id="info" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
          <circle cx="12" cy="12" r="10"></circle><path d="M12 16v-4"></path><path d="M12 8h.01"></path>
        </symbol>
        <symbol id="lightbulb" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
          <path d="M15 14c.2-1 .7-1.7 1.5-2.5 1-.9 1.5-2.2 1.5-3.5A6 6 0 0 0 6 8c0 1 .2 2.2 1.5 3.5.7.7 1.3 1.5 1.5 2.5"></path><path d="M9 18h6"></path><path d="M10 22h4"></path>
        </symbol>
        <symbol id="alert-triangle" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
          <path d="m21.73 18-8-14a2 2 0 0 0-3.48 0l-8 14A2 2 0 0 0 4 21h16a2 2 0 0 0 1.73-3"></path><path d="M12 9v4"></path><path d="m12 17h.01"></path>
        </symbol>
        <symbol id="shield-alert" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
          <path d="M20 13c0 5-3.5 7.5-7.66 8.95a1 1 0 0 1-.67-.01C7.5 20.5 4 18 4 13V6a1 1 0 0 1 1-1c2 0 4.5-1.2 6.24-2.72a1.17 1.17 0 0 1 1.52 0C14.51 3.81 17 5 19 5a1 1 0 0 1 1 1z"></path><path d="M12 8v4"></path><path d="M12 16h.01"></path>
        </symbol>
        <symbol id="message-square-warning" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
          <path d="M22 17a2 2 0 0 1-2 2H6.828a2 2 0 0 0-1.414.586l-2.202 2.202A.71.71 0 0 1 2 21.286V5a2 2 0 0 1 2-2h16a2 2 0 0 1 2 2z"></path><path d="M12 15h.01"></path><path d="m12 17v4"></path>
        </symbol>
        <symbol id="book-open" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
          <path d="M12 7v14"></path><path d="M3 18a1 1 0 0 1-1-1V4a1 1 0 0 1 1-1h5a4 4 0 0 1 4 4 4 4 0 0 1 4-4h5a1 1 0 0 1 1 1v13a1 1 0 0 1-1 1h-6a3 3 0 0 0-3 3 3 3 0 0 0-3-3z"></path>
        </symbol>
        <symbol id="anchor" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
          <path d="M12 22V8"></path><path d="M5 12H2a10 10 0 0 0 20 0h-3"></path><circle cx="12" cy="5" r="3"></circle>
        </symbol>
        <symbol id="pen-tool" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
          <path d="M15.707 21.293a1 1 0 0 1-1.414 0l-1.586-1.586a1 1 0 0 1 0-1.414l5.586-5.586a1 1 0 0 1 1.414 0l1.586 1.586a1 1 0 0 1 0 1.414z"></path><path d="m18 13-1.375-6.874a1 1 0 0 0-.746-.776L3.235 2.028a1 1 0 0 0-1.207 1.207L5.35 15.879a1 1 0 0 0 .776.746L13 18"></path><path d="m2.3 2.3 7.286 7.286"></path><circle cx="11" cy="11" r="2"></circle>
        </symbol>
        <symbol id="check-circle" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
          <circle cx="12" cy="12" r="10"></circle><path d="m9 12 2 2 4-4"></path>
        </symbol>
        <symbol id="puzzle" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
          <path d="M15.39 4.39a1 1 0 0 0 1.68-.474 2.5 2.5 0 1 1 3.014 3.015 1 1 0 0 0-.474 1.68l1.683 1.682a2.414 2.414 0 0 1 0 3.414L19.61 15.39a1 1 0 0 1-1.68-.474 2.5 2.5 0 1 0-3.014 3.015 1 1 0 0 1 .474 1.68l-1.683 1.682a2.414 2.414 0 0 1-3.414 0L8.61 19.61a1 1 0 0 0-1.68.474 2.5 2.5 0 1 1-3.014-3.015 1 1 0 0 0 .474-1.68l-1.683-1.682a2.414 2.414 0 0 1 0-3.414L4.39 8.61a1 1 0 0 1 1.68.474 2.5 2.5 0 1 0 3.014-3.015 1 1 0 0 1-.474-1.68l1.683-1.682a2.414 2.414 0 0 1 3.414 0z"></path>
        </symbol>
        <symbol id="git-branch" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
          <line x1="6" x2="6" y1="3" y2="15"></line><circle cx="18" cy="6" r="3"></circle><circle cx="6" cy="18" r="3"></circle><path d="M18 9a9 9 0 0 1-9 9"></path>
        </symbol>
        <symbol id="file-text" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
          <path d="M15 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V7z"></path><path d="M14 2v4a2 2 0 0 0 2 2h4"></path><path d="M10 9H8"></path><path d="M16 13H8"></path><path d="M16 17H8"></path>
        </symbol>
        <symbol id="help-circle" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
          <circle cx="12" cy="12" r="10"></circle><path d="M9.09 9a3 3 0 0 1 5.83 1c0 2-3 3-3 3"></path><path d="M12 17h.01"></path>
        </symbol>
        <symbol id="check-square" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
          <rect width="18" height="18" x="3" y="3" rx="2"></rect><path d="m9 12 2 2 4-4"></path>
        </symbol>
        <symbol id="message-circle" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
          <path d="M2.992 16.342a2 2 0 0 1 .094 1.167l-1.065 3.29a1 1 0 0 0 1.236 1.168l3.413-.998a2 2 0 0 1 1.099.092 10 10 0 1 0-4.777-4.719"></path>
        </symbol>
        <symbol id="rotate-ccw" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
          <path d="M3 12a9 9 0 1 0 9-9 9.75 9.75 0 0 0-6.74 2.74L3 8"></path><path d="M3 3v5h5"></path>
        </symbol>
        <symbol id="code" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
          <path d="m16 18 6-6-6-6"></path><path d="m8 6-6 6 6 6"></path>
        </symbol>
        <symbol id="dumbbell" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
          <path d="M17.596 12.768a2 2 0 1 0 2.829-2.829l-1.768-1.767a2 2 0 0 0 2.828-2.829l-2.828-2.828a2 2 0 0 0-2.829 2.828l-1.767-1.768a2 2 0 1 0-2.829 2.829z"></path><path d="m2.5 21.5 1.4-1.4"></path><path d="m20.1 3.9 1.4-1.4"></path><path d="M5.343 21.485a2 2 0 1 0 2.829-2.828l1.767 1.768a2 2 0 1 0 2.829-2.829l-6.364-6.364a2 2 0 1 0-2.829 2.829l1.768 1.767a2 2 0 0 0-2.828 2.829z"></path><path d="m9.6 14.4 4.8-4.8"></path>
        </symbol>
        <symbol id="alert-circle" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
          <circle cx="12" cy="12" r="10"></circle><line x1="12" x2="12" y1="8" y2="12"></line><line x1="12" x2="12.01" y1="16" y2="16"></line>
        </symbol>
        <symbol id="check" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
          <path d="M20 6 9 17l-5-5"></path>
        </symbol>
        <symbol id="check-circle-2" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
          <path d="m9 12 2 2 4-4"></path><circle cx="12" cy="12" r="9"></circle>
        </symbol>
        <symbol id="list" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
          <path d="M3 5h.01"></path><path d="M3 12h.01"></path><path d="M3 19h.01"></path><path d="M8 5h13"></path><path d="M8 12h13"></path><path d="M8 19h13"></path>
        </symbol>
        <symbol id="chevron-down" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
          <path d="m6 9 6 6 6-6"></path>
        </symbol>
        <symbol id="cpu" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
          <path d="M12 20v2"></path><path d="M12 2v2"></path><path d="M17 20v2"></path><path d="M17 2v2"></path><path d="M2 12h2"></path><path d="M2 17h2"></path><path d="M2 7h2"></path><path d="M20 12h2"></path><path d="M20 17h2"></path><path d="M20 7h2"></path><path d="M7 20v2"></path><path d="M7 2v2"></path><rect x="4" y="4" width="16" height="16" rx="2"></rect><rect x="8" y="8" width="8" height="8" rx="1"></rect>
        </symbol></defs></svg>
<h3 id="theory">Theory</h3>
<details class="group relative px-4 py-3 my-6 border-l-4 text-base border-teal-600 dark:bg-teal-950/10" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-teal-700 dark:text-teal-400" data-lucide="book-open" viewBox="0 0 24 24"><use href="#book-open"></use></svg>Definition: Stochastic Process<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-teal-700 dark:text-teal-400" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>A stochastic process is a collection of random variables, $\{X_t, t \in \mathcal{I} \}$.
where $\mathcal{I}$ is the index set of the process and $\mathcal{S}$ is the common state space of the random variables $X_t$.</p></div>
</details>
<details class="group relative px-4 py-3 my-6 border-l-4 text-base border-teal-600 dark:bg-teal-950/10" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-teal-700 dark:text-teal-400" data-lucide="book-open" viewBox="0 0 24 24"><use href="#book-open"></use></svg>Definition: Markov Property<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-teal-700 dark:text-teal-400" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>A process fulfills the Markov property if, for any $t_0 \in \mathcal{I}$, whenever $X_{t_0}$ is known, $X_t$ (with $t > t_0$) is independent of the values for $X_s$ for all $s &#x3C; t_0$.</p></div>
</details>
<details class="group relative px-4 py-3 my-6 border-l-4 text-base border-sky-300 dark:bg-sky-950/10" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-sky-500 dark:text-sky-200" data-lucide="rotate-ccw" viewBox="0 0 24 24"><use href="#rotate-ccw"></use></svg>Recall: Conditional Probability and Independence<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-sky-500 dark:text-sky-200" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>Given the events $A$ and $B$, the conditional probability of $A$ given $B$ is defined as,
$$
P(A \mid B) = \frac{P(A \cap B)}{P(B)}
$$
The events $A$ and $B$ are independent if $P(A \cap B) = P(A) P(B)$, or equivalently, if $P(A \mid B) = P(A)$.</p><p>The law of total probability states that if $B_1, B_2, \ldots, B_n$ is a sequence of events that partitions S. Then,
$$
P(A) = \sum_{i=1}^{n} P(A \cap B_i) = \sum_{i=1}^{n} P(A \mid B_i) P(B_i)
$$
Thus, Bayesâ€™ law follow directly from the definition of conditional probability and the law of total probability,
$$
P(B \mid A) = \frac{P(A \mid B) P(B)}{P(A)}
$$</p></div>
</details>
<details class="group relative px-4 py-3 my-6 border-l-4 text-base border-teal-600 dark:bg-teal-950/10" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-teal-700 dark:text-teal-400" data-lucide="book-open" viewBox="0 0 24 24"><use href="#book-open"></use></svg>Definition: Law of Total Expectation<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-teal-700 dark:text-teal-400" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>$$
\mathbb{E}[Y] = \mathbb{E}[\mathbb{E}[Y \mid X]]
$$</p></div>
</details>
<details class="group relative px-4 py-3 my-6 border-l-4 text-base border-teal-600 dark:bg-teal-950/10" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-teal-700 dark:text-teal-400" data-lucide="book-open" viewBox="0 0 24 24"><use href="#book-open"></use></svg>Definition: Law of Total Variance<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-teal-700 dark:text-teal-400" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>Recall that, by definition,
$$
\mathrm{Var}(Y) \coloneqq \mathbb{E}\left[(Y - \mathbb{E}[Y])^2\right] = \mathbb{E}[Y^2] - (\mathbb{E}[Y])^2
$$
Similarly, we have for the conditional variance,
$$
\mathrm{Var}(Y \mid X) \coloneqq \mathbb{E}_{Y \mid X = x}\left[(Y - \mathbb{E}[Y \mid X])^2 \mid X\right]
$$
With these definitions, we can state the law of total variance as,
$$
\mathrm{Var}(Y) = \mathbb{E}[\mathrm{Var}(Y \mid X)] + \mathrm{Var}(\mathbb{E}[Y \mid X])
$$</p></div>
</details>
<details class="group relative px-4 py-3 my-6 border-l-4 text-base border-teal-600 dark:bg-teal-950/10" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-teal-700 dark:text-teal-400" data-lucide="book-open" viewBox="0 0 24 24"><use href="#book-open"></use></svg>Definition: Markov Chain<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-teal-700 dark:text-teal-400" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>Let $S$ be a discrete set (not necessarily finite), called the state space. A Markov Chain is a sequence of random variables $X_0, X_1, X_2, \ldots$ taking values in $S$, with the property,
$$
\pi(X_{n+1} \mid X_0, X_1, \ldots, X_n) = \pi(X_{n+1} \mid X_n)
$$
for all $n \geq 1$.</p><p>The chain is said to be time-homogeneous if, for all $n \geq 0$ <label for="sn-1" class="sidenote-toggle sidenote-number" aria-describedby="sn-1-note">1</label><input type="checkbox" id="sn-1" class="sidenote-checkbox" aria-label="Toggle sidenote 1"><span class="sidenote" role="note" id="sn-1-note"><span class="sidenote-number-inline">1</span>We generally assume this unless otherwise stated.</span>,
$$
\pi(X_{n+1} \mid X_n) = \pi(X_1 \mid X_0)
$$
The transition matrix is defined with,
$$
P_{ij} = \pi(X_{n+1} = j \mid X_n = i)
$$
Further, a stochastic matrix is a square matrix $P$ with non-negative entries, satisfying $P \mathbf{1} = \mathbf{1}$, where $\mathbf{1}$ is a row vector of ones (i.e., all rows sum to one).</p><p>Lastly, all transition matrices are stochastic matrices, and all stochastic matrices can be used as transition matrices.</p></div>
</details>
<details class="group relative px-4 py-3 my-6 border-l-4 text-base border-teal-600 dark:bg-teal-950/10" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-teal-700 dark:text-teal-400" data-lucide="book-open" viewBox="0 0 24 24"><use href="#book-open"></use></svg>Definition: Limiting Distribution<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-teal-700 dark:text-teal-400" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>A limiting distribution for a Markov chain with transition matrix $P$ is a probability vector $v$ such that,
$$
\lim_{n \to \infty} (P^n)_{ij} = v_j
$$
for all states $i$ and $j$.</p><p>An equivalent formulation is, the limit $\lim_{n \to \infty} (P^n)_{ij}$ exists and does not depend on $i$.</p><p>Another equivalent formulation is, $\lim_{n \to \infty} P^n$ is a stochastic matrix with all rows identical.</p><p>Further, a Markov chain has either no or one unique limiting distribution.
If a limiting distribution exists, its probabilities correspond to the proportion of time steps the chain spends at each state in the long run.</p></div>
</details>
<details class="group relative px-4 py-3 my-6 border-l-4 text-base border-teal-600 dark:bg-teal-950/10" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-teal-700 dark:text-teal-400" data-lucide="book-open" viewBox="0 0 24 24"><use href="#book-open"></use></svg>Definition: Stationary Distribution<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-teal-700 dark:text-teal-400" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>A stationary distribution for a Markov chain is a distribution that is unchanged when applying one step of the Markov chain.
If $P$ is the transition matrix, then a probability vector $v$ represents a stationary distribution if and only if,
$$
vP = v
$$
A Markov chain can have zero, one, or many stationary distributions.
Limiting distributions are always stationary distributions (but not necessarily vice versa).</p></div>
</details>
<details class="group relative px-4 py-3 my-6 border-l-4 text-base border-teal-600 dark:bg-teal-950/10" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-teal-700 dark:text-teal-400" data-lucide="book-open" viewBox="0 0 24 24"><use href="#book-open"></use></svg>Definition: Regular Transition Matrices<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-teal-700 dark:text-teal-400" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>A stochastic matrix $P$ is positive if all entries are strictly positive, i.e., $P_{ij} > 0$ for all $i$ and $j$.
A stochastic matrix $P$ is regular if $P^n$ is positive for some $n > 0$.</p></div>
</details>
<details class="group relative px-4 py-3 my-6 border-l-4 text-base border-indigo-500 dark:bg-indigo-950/10" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-indigo-700 dark:text-indigo-400" data-lucide="check-circle" viewBox="0 0 24 24"><use href="#check-circle"></use></svg>Theorem: Limit Theorem for Regular Markov Chains<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-indigo-700 dark:text-indigo-400" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>If the transition matrix $P$ is regular, the limiting distribution exists.
There are no other stationary distributions and the limiting distribution is positive, i.e., all states have positive probability in the limiting distribution.</p></div>
</details>
<details class="group relative px-4 py-3 my-6 border-l-4 text-base border-indigo-500 dark:bg-indigo-950/10" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-indigo-700 dark:text-indigo-400" data-lucide="check-circle" viewBox="0 0 24 24"><use href="#check-circle"></use></svg>Theorem: Random Walks on Undirected Graphs<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-indigo-700 dark:text-indigo-400" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>Random walks in a Markov chains (i.e., undircted graphs) have the stationary distribution $v$ with,
$$
v_i = \frac{\mathrm{deg}(i)}{S}
$$
where $\mathrm{deg}(i)$ is the degree of node $i$ (i.e., the number of edges going into node $i$) and $S$ is the sum over all nodes of their degrees.
Further, weighted random walks in a Markov chains (i.e., weighted undircted graphs) have the stationary distribution $v$ with,
$$
v_i = \frac{w(i)}{e}
$$
where $w(i)$ is the sum of the weights of the edges going into node $i$, and $e$ is the total sum over all nodes of their $w(i)$ values.</p></div>
</details>
<details class="group relative px-4 py-3 my-6 border-l-4 text-base border-sky-300 dark:bg-sky-950/10" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-sky-500 dark:text-sky-200" data-lucide="lightbulb" viewBox="0 0 24 24"><use href="#lightbulb"></use></svg>Intuition: Moving Between States<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-sky-500 dark:text-sky-200" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>State $j$ is accessible from state $i$ if $(P^n)_{ij} > 0$ for some $n \geq 0$.
States $i$ and $j$ communicate if $i$ is accessible from $j$ and $j$ is accessible from $i$.</p><p>â€œCommunicationâ€ is transitive, i.e., if $i$ communicates with $j$ and $j$ communicates with $k$, then $i$ communicates with $k$.</p><p>Communication is an equivalence relation, subdividing all states into communication classes.
Communication classes can be found for example by drawing transition graphs.</p><p>Lastly, a Markov chain is irreducible if it has exactly one communication class.</p></div>
</details>
<details class="group relative px-4 py-3 my-6 border-l-4 text-base border-teal-600 dark:bg-teal-950/10" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-teal-700 dark:text-teal-400" data-lucide="book-open" viewBox="0 0 24 24"><use href="#book-open"></use></svg>Definition: Recurrence and Transience<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-teal-700 dark:text-teal-400" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>Let $T_j$ be the first passage time to state $j$,
$$
T_j = \min {n > 0 : X_n = j }
$$
Let $f_j$ be the probability that a chain starting at $j$ will return to $j$,
$$
f_j = P(T_j &#x3C; \infty \mid X_0 = j)
$$
A state $j$ is recurrent if a chain starting at $j$ will eventually revisit $j$, i.e., if $f_j = 1$.</p><p>A state $j$ is transient if a chain starting at $j$ has a positive probability of never revisiting $j$, i.e., if $f_j &#x3C; 1$.</p><details class="group relative px-4 py-3 my-6 border-l-4 text-base border-blue-500 dark:bg-blue-950/5" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-blue-700 dark:text-blue-300" data-lucide="info" viewBox="0 0 24 24"><use href="#info"></use></svg>Note<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-blue-700 dark:text-blue-300" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>The expected number of visits at $j$ when the chain starts at $i$ is given by $\sum_{n = 0}^{\infty} (P^n)_{ij}$.</p></div>
</details><p>$j$ is recurrent if and only if $\sum_{n = 0}^{\infty} (P^n)_{jj} = \infty$.</p><p>$j$ is transient if and only if $\sum_{n = 0}^{\infty} (P^n)_{jj} &#x3C; \infty$.</p></div>
</details>
<details class="group relative px-4 py-3 my-6 border-l-4 text-base border-blue-500 dark:bg-blue-950/5" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-blue-700 dark:text-blue-300" data-lucide="info" viewBox="0 0 24 24"><use href="#info"></use></svg>Note: Communication Classes<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-blue-700 dark:text-blue-300" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>The states of a communication class are either all recurrent or all transient.
The states of a finite irreducible Markov chain are all recurrent.</p><p>If a state is recurrent, only states inside its communication class are accessible from it.
If no states outside a finite communication class are accessible from it, then the class consists of recurrent states.</p></div>
</details>
<details class="group relative px-4 py-3 my-6 border-l-4 text-base border-indigo-500 dark:bg-indigo-950/10" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-indigo-700 dark:text-indigo-400" data-lucide="check-circle" viewBox="0 0 24 24"><use href="#check-circle"></use></svg>Theorem: Limit Theorem for Finite Irreducible Markov Chains<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-indigo-700 dark:text-indigo-400" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><details class="group relative px-4 py-3 my-6 border-l-4 text-base border-sky-300 dark:bg-sky-950/10" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-sky-500 dark:text-sky-200" data-lucide="rotate-ccw" viewBox="0 0 24 24"><use href="#rotate-ccw"></use></svg>Recall<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-sky-500 dark:text-sky-200" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>In a finite irreducible Markov chain, all states are recurrent.</p></div>
</details><p>Let $\mu_j = \mathbb{E}[T_j \mid X_0 = j]$ be the expected return time to state $j$.
Then $\mu_j &#x3C; \infty$ for all states $j$ and the vector $v$ with $v_j = \frac{1}{\mu_j}$ is the unique stationary distribution.</p><p>Further,
$$
v_j = \lim_{n \to \infty} \frac{1}{n} \sum_{m = 0}^{n - 1} (P^m)_{ij}
$$</p><details class="group relative px-4 py-3 my-6 border-l-4 text-base border-blue-500 dark:bg-blue-950/5" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-blue-700 dark:text-blue-300" data-lucide="info" viewBox="0 0 24 24"><use href="#info"></use></svg>Note<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-blue-700 dark:text-blue-300" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>All finite regular Markov chains are finite irreducible Markov chains, but not vice versa.
The overall conclusion here is weaker than that for finite regular Markov chains. Not all finite irreducible Markov chains have limiting distributions.</p></div>
</details></div>
</details>
<details class="group relative px-4 py-3 my-6 border-l-4 text-base border-teal-600 dark:bg-teal-950/10" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-teal-700 dark:text-teal-400" data-lucide="book-open" viewBox="0 0 24 24"><use href="#book-open"></use></svg>Definition: Periodicity<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-teal-700 dark:text-teal-400" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>The period of a state $i$ is the greatest common divisor of all $n > 0$ such that $(P^n)_{ii} > 0$.
All states of a communication class have the same period.</p><p>A Markov chain is periodic if it is irreducible and all states have period greater than 1.</p><p>A Markov chain is aperiodic if it is irreducible and all states have period 1.</p></div>
</details>
<details class="group relative px-4 py-3 my-6 border-l-4 text-base border-teal-600 dark:bg-teal-950/10" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-teal-700 dark:text-teal-400" data-lucide="book-open" viewBox="0 0 24 24"><use href="#book-open"></use></svg>Definition: Ergodic Markov Chains<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-teal-700 dark:text-teal-400" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>A Markov chain is ergodic if,</p><ol>
<li>
<p>It is irreducible.</p>
</li>
<li>
<p>It is aperiodic.</p>
</li>
<li>
<p>All states are positive recurrent (i..e, have finite expected return times (which always is true if the state space is finite)).</p>
</li>
</ol><details class="group relative px-4 py-3 my-6 border-l-4 text-base border-indigo-500 dark:bg-indigo-950/10" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-indigo-700 dark:text-indigo-400" data-lucide="check-circle" viewBox="0 0 24 24"><use href="#check-circle"></use></svg>Theorem: Fundamental Limit Theorem for Ergodic Markov Chains<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-indigo-700 dark:text-indigo-400" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>There exists a unique stationary distribution $v$ which is the limiting distribution of the chain.</p></div>
</details><details class="group relative px-4 py-3 my-6 border-l-4 text-base border-blue-500 dark:bg-blue-950/5" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-blue-700 dark:text-blue-300" data-lucide="info" viewBox="0 0 24 24"><use href="#info"></use></svg>Note<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-blue-700 dark:text-blue-300" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>We can also show that a finite Markov chain is ergodic if and only if its transition matrix is regular.</p></div>
</details></div>
</details>
<details class="group relative px-4 py-3 my-6 border-l-4 text-base border-teal-600 dark:bg-teal-950/10" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-teal-700 dark:text-teal-400" data-lucide="book-open" viewBox="0 0 24 24"><use href="#book-open"></use></svg>Definition: Time Reversibility<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-teal-700 dark:text-teal-400" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>Let $P$ be the transition matrix of an irreducible Markov chain with stationary distribution $v$.
The chain is time reversible if, when running from its stationary distribution, it looks the same moving forward as backwards, i.e.,
$$
\pi(X_k = i, X_{k + 1} = j) = \pi(X_k = j, X_{k + 1} = i)
$$
This may also be written as $v_i P_{ij} = v_j P_{ji}$ for all states $i$ and $j$.
It is called the detailed balance equations.</p><details class="group relative px-4 py-3 my-6 border-l-4 text-base border-blue-500 dark:bg-blue-950/5" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-blue-700 dark:text-blue-300" data-lucide="info" viewBox="0 0 24 24"><use href="#info"></use></svg>Note<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-blue-700 dark:text-blue-300" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>If $x$ is a probability vector satisfying $x_i P_{ij} = x_j P_{ji}$ for all states $i$ and $j$, then $x$ is the stationary distribution of the chain, and the chain is time reversible.</p><details class="group relative px-4 py-3 my-6 border-l-4 text-base border-amber-500 dark:bg-amber-950/10" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-amber-700 dark:text-amber-300" data-lucide="check-square" viewBox="0 0 24 24"><use href="#check-square"></use></svg>Proof<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-amber-700 dark:text-amber-300" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>We have,
$$
\begin{align*}
(xP)_j &#x26; = \sum_{i} x_i P_{ij} \newline
&#x26; = \sum_i x_j P_{ji} \newline
&#x26; = x_j \sum_i P_{ji} \newline
&#x26; = x_j
\end{align*}
$$
Thus, $xP = x$, so $x$ is the stationary distribution.</p></div>
</details><p>If a Markov chain is defined as a random walk on a weighted undirected graph, then it is time reversible.</p><details class="group relative px-4 py-3 my-6 border-l-4 text-base border-amber-500 dark:bg-amber-950/10" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-amber-700 dark:text-amber-300" data-lucide="check-square" viewBox="0 0 24 24"><use href="#check-square"></use></svg>Proof<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-amber-700 dark:text-amber-300" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>Let $w(i, j)$ be the weight of the edge between nodes $i$ and $j$ (0 if no edge exists).
Let $w(i) = \sum_{k} w(i, k)$ be the sum of weights of edges going into node $i$.
The transition matrix is given by $P_{ij} = \frac{w(i, j)}{w(i)}$.
Let $v_i = \frac{w(i)}{e}$, where $e$ is the total sum over all nodes of their $w(i)$ values.
Then,
$$
\begin{align*}
v_i P_{ij} &#x26; = \frac{w(i)}{e} \cdot \frac{w(i, j)}{w(i)} \newline
&#x26; = \frac{w(i, j)}{e} \newline
&#x26; = \frac{w(j, i)}{e} \newline
&#x26; = \frac{w(j)}{e} \cdot \frac{w(j, i)}{w(j)} \newline
&#x26; = v_j P_{ji}
\end{align*}
$$
Thus, the detailed balance equations are satisfied, so the chain is time reversible.</p></div>
</details><p>If a finite Markov chain is time reversible, it can be represented as a random walk on a weighted undirected graph.</p><details class="group relative px-4 py-3 my-6 border-l-4 text-base border-amber-500 dark:bg-amber-950/10" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-amber-700 dark:text-amber-300" data-lucide="check-square" viewBox="0 0 24 24"><use href="#check-square"></use></svg>Proof<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-amber-700 dark:text-amber-300" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>Let $P$ be the transition matrix of a finite time reversible Markov chain with stationary distribution $v$.
Let $w(i, j) = v_i P_{ij}$ be the weight of the edge between nodes $i$ and $j$.
Then,
$$
\sum_{j} w(i, j) = \sum_{j} v_i P_{ij} = v_i \sum_{j} P_{ij} = v_i
$$
Thus, the sum of weights of edges going into node $i$ is $v_i$.
The transition matrix is given by,
$$
P_{ij} = \frac{w(i, j)}{\sum_{k} w(i, k)} = \frac{v_i P_{ij}}{v_i} = P_{ij}
$$
Thus, the Markov chain can be represented as a random walk on a weighted undirected graph.</p></div>
</details></div>
</details></div>
</details>
<details class="group relative px-4 py-3 my-6 border-l-4 text-base border-teal-600 dark:bg-teal-950/10" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-teal-700 dark:text-teal-400" data-lucide="book-open" viewBox="0 0 24 24"><use href="#book-open"></use></svg>Definition: Absorbing Chains<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-teal-700 dark:text-teal-400" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>State $i$ is absorbing if $P_{ii} = 1$a
A Markov chain is an absorbing chain if it has at least one absorbing state.</p><p>By reordering the states, the transition matrix for an absorbing chain can be written in the block form,
$$
P =
\begin{bmatrix}
Q &#x26; R \newline
0 &#x26; I
\end{bmatrix}
$$
where $I$ is the identity matrix, $0$ is a matrix of zeroes, and $Q$ corresponds to transient states.
We can prove by induction that,
$$
P^n =
\begin{bmatrix}
Q^n &#x26; (I + Q + Q^2 + \ldots + Q^{n - 1}) R \newline
0 &#x26; I
\end{bmatrix}
$$</p><p>Taking the limit and using $\lim_{n \to \infty} Q^n = 0$ (since all states corresponding to $Q$ are transient), we have,
$$
\lim_{n \to \infty} P^n =
\begin{bmatrix}
0 &#x26; (I - Q)^{-1} R \newline
0 &#x26; I
\end{bmatrix}
=
\begin{bmatrix}
0 &#x26; FR \newline
0 &#x26; I
\end{bmatrix}
$$
where $F = (I - Q)^{-1} = \lim_{n \to \infty} (I + Q + Q^2 + \ldots + Q^{n - 1})$ is called the fundamental matrix.</p><p>The probability to be absorbed in a particular absorbing state given a start in a transient state is given by the entries of $FR$.</p><p>Further, the expected number of visits in state $j$ for a chain that starts in the transient state $i$ is given by $F_{ij}$ (as this is equal to $\sum_{n = 0}^{\infty} (P^n)_{ij}$).</p><p>Thus, the expected number of steps until absorption is given by the vector $F \mathbf{1}^T$, where $\mathbf{1}$ is a column vector of ones.</p><details class="group relative px-4 py-3 my-6 border-l-4 text-base border-blue-500 dark:bg-blue-950/5" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-blue-700 dark:text-blue-300" data-lucide="info" viewBox="0 0 24 24"><use href="#info"></use></svg>Note<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-blue-700 dark:text-blue-300" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>Given an irreducible Markov chain, to compute the expected number of steps needed to go from state $i$ to the first visit to state $j$, one can change the chain into one where state $j$ is absorbing, and compute the expected number of steps until absorption when starting at state $i$.</p></div>
</details></div>
</details>
<details class="group relative px-4 py-3 my-6 border-l-4 text-base border-teal-600 dark:bg-teal-950/10" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-teal-700 dark:text-teal-400" data-lucide="book-open" viewBox="0 0 24 24"><use href="#book-open"></use></svg>Definition: Galton-Watson Branching Process<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-teal-700 dark:text-teal-400" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>A (Galton-Watson) branching process is a discrete Markov chain $Z_0, Z_1, \ldots, Z_n, \ldots$ where,</p><ul>
<li>
<p>The state space is the non-negative integers.</p>
</li>
<li>
<p>$Z_0 = 1$ (i.e., the process starts with one individual).</p>
</li>
<li>
<p>$Z_n$ is the sum $X_1 + X_2 + \ldots + X_{Z_{n - 1}}$, where $X_i$ are independent random non-negative integers all with the same offspring distribution,
$$
Z_n = \sum_{i = 1}^{Z_{n - 1}} X_i
$$
Connecting each of the $Z_n$ individuals in generation $n$ with their offspring in generation $n + 1$ we get a tree illustrating the branching process.</p>
</li>
</ul><p>The offspring distribution is described by the probability vector $a = (a_0, a_1, \ldots)$ where $a_j = P(X_i = j)$.</p><p>We will mainly focus on the interesting cases where we assume $a_0 > 0$ (i.e., there is a positive probability of having no offspring) and $a_0 + a_1 &#x3C; 1$ (i.e., there is a positive probability of having more than one offspring).</p></div>
</details>
<details class="group relative px-4 py-3 my-6 border-l-4 text-base border-teal-600 dark:bg-teal-950/10" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-teal-700 dark:text-teal-400" data-lucide="book-open" viewBox="0 0 24 24"><use href="#book-open"></use></svg>Definition: Expected Size of Generations in a Branching Process and Classification of Branching Processes<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-teal-700 dark:text-teal-400" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><details class="group relative px-4 py-3 my-6 border-l-4 text-base border-blue-500 dark:bg-blue-950/5" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-blue-700 dark:text-blue-300" data-lucide="info" viewBox="0 0 24 24"><use href="#info"></use></svg>Note<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-blue-700 dark:text-blue-300" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>Note that the state 0 is abosribing, this absorbtion is called extinction.
Also, as $a_0 > 0$, all nonzero states are transient.
Let $\mu = \mathbb{E}[X_i] = \sum_{j=0}^{\infty} j \cdot a_j$, i.e., the expected number of offspring per individual.</p></div>
</details><p>Then, we may compute that,
$$
\begin{align*}
\mathbb{E}[Z_n] &#x26; = \mathbb{E}\left(\sum_{i = 1}^{Z_{n-1}}\right) X_i \newline
&#x26; = \mathbb{E}\left(\mathbb{E}\left(\sum_{i = 1}^{Z_{n-1}} X_i \mid Z_{n - 1} \right)\right)
&#x26; = \ldots
&#x26; = \mathbb{E}[Z_{n - 1}] \cdot \mu \newline
\end{align*}
$$
Thus, we directly get that,
$$
\mathbb{E}[Z_n] = \mu^n \cdot \underbrace{\mathbb{E}[Z_0]}_{\coloneqq 1} = \mu^n
$$
Based on the value of $\mu$, we classify branching processes into three categories:</p><ol>
<li>
<p>Subcritical branching processes: $\mu &#x3C; 1$. The expected generation size decreases over time, $\lim_{n \to \infty} \mathbb{E}[Z_n] = 0$.</p>
</li>
<li>
<p>Critical branching processes: $\mu = 1$. The expected generation size remains constant over time, $\lim_{n \to \infty} \mathbb{E}[Z_n] = 1$.</p>
</li>
<li>
<p>Supercritical branching processes: $\mu > 1$. The expected generation size increases over time, $\lim_{n \to \infty} \mathbb{E}[Z_n] = \infty$.</p>
</li>
</ol><details class="group relative px-4 py-3 my-6 border-l-4 text-base border-blue-500 dark:bg-blue-950/5" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-blue-700 dark:text-blue-300" data-lucide="info" viewBox="0 0 24 24"><use href="#info"></use></svg>Note<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-blue-700 dark:text-blue-300" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>One can prove that if $\lim_{n \to \infty} Z_n = 0$, then the probability of extinction is 1.
We will do this later.</p></div>
</details></div>
</details>
<details class="group relative px-4 py-3 my-6 border-l-4 text-base border-teal-600 dark:bg-teal-950/10" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-teal-700 dark:text-teal-400" data-lucide="book-open" viewBox="0 0 24 24"><use href="#book-open"></use></svg>Definition: Variance of Generation Sizes in a Branching Process<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-teal-700 dark:text-teal-400" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>Let $\mu$ be defined as above, and let $\sigma^2 = \mathrm{Var}(X_i)$ be the variance of the number of children.</p><p>Using the law of total variance we get,
$$
\begin{align*}
\mathrm{Var}(Z_n) &#x26; = \mathrm{Var}(\mathbb{E}[Z_n \mid Z_{n - 1}]) + \mathbb{E}[\mathrm{Var}(Z_n \mid Z_{n - 1})] \newline
&#x26; = \mathrm{Var}\left(\mathbb{E}\left(\sum_{i = 1}^{Z_{n - 1}} X_i \mid Z_{n - 1}\right)\right) + \mathbb{E}\left[\mathrm{Var}\left(\sum_{i = 1}^{Z_{n - 1}} X_i \mid Z_{n - 1}\right)\right] \newline
&#x26; = \mathrm{Var}(\mu Z_{n - 1}) + \mathbb{E}[\sigma^2 Z_{n - 1}] \newline
&#x26; = \mu^2 \mathrm{Var}(Z_{n - 1}) + \sigma^2 \mathbb{E}[Z_{n - 1}] \newline
\end{align*}
$$
From this, we can prove by induction that, for $n \geq 1$,
$$
\mathrm{Var}(Z_n) = \sigma^2 \mu^{n - 1} \sum_{k = 0}^{n - 1} \mu^k =
\begin{cases}
n \sigma^2 &#x26; \text{if } \mu = 1 \newline
\sigma^2 \mu^{n - 1} \frac{\mu^n - 1}{\mu - 1} &#x26; \text{if } \mu \neq 1
\end{cases}
$$</p></div>
</details>
<details class="group relative px-4 py-3 my-6 border-l-4 text-base border-indigo-500 dark:bg-indigo-950/10" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-indigo-700 dark:text-indigo-400" data-lucide="check-circle" viewBox="0 0 24 24"><use href="#check-circle"></use></svg>Theorem: Extinction Probability Theorem<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-indigo-700 dark:text-indigo-400" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>Let $G_X$ be the probability generating function for the offspring distribution for a branching process.
The probability of eventual extinction is the smallest positive root of the equation $G_X(s) = s$.</p></div>
</details>
<details class="group relative px-4 py-3 my-6 border-l-4 text-base border-sky-300 dark:bg-sky-950/10" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-sky-500 dark:text-sky-200" data-lucide="lightbulb" viewBox="0 0 24 24"><use href="#lightbulb"></use></svg>Intuition: Probability Generating Functions<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-sky-500 dark:text-sky-200" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>For any discrete random variable $X$ taking values in $\{0, 1, 2, \ldots\}$, define the probability function $G_X(s)$ as,
$$
G_X(s) = \mathbb{E}[s^X] = \sum_{k = 0}^{\infty} P(X = k) s^k
$$
The series converges absolutely for $\Vert s \Vert \leq 1$. We assume $s$ is a real number in $[0, 1]$.</p><p>We get a 1-1 correspondence between probability vectors on $\{0, 1, 2, \ldots\}$ and functions represented by a series where the coefficients sum to 1.</p><p>Specifically, if $G_X(s) = G_Y(s)$ for all $s$ for random variables $X$ and $Y$, then $X$ and $Y$ have the same distribution.</p><details class="group relative px-4 py-3 my-6 border-l-4 text-base border-blue-500 dark:bg-blue-950/5" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-blue-700 dark:text-blue-300" data-lucide="info" viewBox="0 0 24 24"><use href="#info"></use></svg>Note: Properties of Probability Generating Functions<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-blue-700 dark:text-blue-300" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><ul>
<li>
<p>To go from $X$ to $G_X(s)$, we compute the (in)finite sum.</p>
</li>
<li>
<p>To go from $G_X(s)$ to $X$, we use that we have,
$$
P(X = k) = \frac{G_X^{(k)}(0)}{k!}
$$</p>
</li>
<li>
<p>If $X$ and $Y$ are independent random variables, then,
$$
G_{X + Y}(s) = \mathbb{E}[s^{X + Y}] = \mathbb{E}[s^X s^Y] = \mathbb{E}[s^X] \mathbb{E}[s^Y] \eqqcolon G_X(s) G_Y(s)
$$</p>
</li>
<li>
<p>$\mathbb{E}[X] = G_X^{\prime}(1)$</p>
</li>
<li>
<p>$\mathbb{E}[X(X - 1)] = G_X^{\prime \prime}(1)$</p>
</li>
<li>
<p>As a consequence, $\mathrm{Var}(X) = G_X^{\prime \prime}(1) + G_X^{\prime}(1) - (G_X^{\prime}(1))^2$</p>
</li>
</ul><p>Further, assume we have a branching process $Z_0, Z_1, \ldots$ with independent offspring variables $X_i$ all with the same distribution as $X$.
By writing $G_n(s) = G_{Z_n}(s) = \mathbb{E}[s^{Z_n}]$ and $G_X(s) = \mathbb{E}[s^X]$, we get,
$$
\begin{align*}
G_n(s) &#x26; = \mathbb{E}[s^{\sum_{k = 1}^{Z_{n - 1}} X_k}] \newline
&#x26; = \mathbb{E}[\mathbb{E}[s^{\sum_{k = 1}^{Z_{n - 1}} X_k} \mid Z_{n - 1}]] \newline
&#x26; = \mathbb{E}\left[\mathbb{E}\left[\prod_{k = 1}^{Z_{n - 1}} s^{X_k} \mid Z_{n - 1}\right]\right] \newline
&#x26; = \mathbb{E}[G(s)^{Z_{n - 1}}] \newline
&#x26; = G_{n - 1}(G_X(s)) \newline
\end{align*}
$$
As $G_0(s) = \mathbb{E}[s^{Z_0}] = s$, it follows that,
$$
G_n(s) = \underbrace{G_X(G_X(\ldots G_X(s) \ldots))}_{n \text{ times}}
$$</p></div>
</details></div>
</details>
<details class="group relative px-4 py-3 my-6 border-l-4 text-base border-indigo-500 dark:bg-indigo-950/10" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-indigo-700 dark:text-indigo-400" data-lucide="check-circle" viewBox="0 0 24 24"><use href="#check-circle"></use></svg>Theorem: Extinction Probability Theorem (Addition)<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-indigo-700 dark:text-indigo-400" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>Let $G_X$ be the probability generating function for the offspring distribution for a branching process.
The probability of eventual extinction is the smallest positive root of the equation $G_X(s) = s$.
Also, if the process is critical ($\mu = 1$) then the extinction probability is 1.</p><details class="group relative px-4 py-3 my-6 border-l-4 text-base border-amber-500 dark:bg-amber-950/10" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-amber-700 dark:text-amber-300" data-lucide="check-square" viewBox="0 0 24 24"><use href="#check-square"></use></svg>Proof: Of the last sentence<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-amber-700 dark:text-amber-300" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>In the critical case,
$$
G_X^{\prime}(1) = \mathbb{E}[X] = \mu = 1
$$
As $G_X^{\prime \prime}(s) > 0$ for $s \in (0, 1)$, we get that $G_X^{\prime}(s) &#x3C; 1$ for $s \in (0, 1)$, and $\frac{d}{ds}(G(s) - s) &#x3C; 0$ for $s \in (0, 1)$.
As $G(1) - 1 = 0$ for any probability generating function, we get that $G(s) = s$ has its smallest positive root at $s = 1$.</p></div>
</details></div>
</details>
<details class="group relative px-4 py-3 my-6 border-l-4 text-base border-indigo-500 dark:bg-indigo-950/10" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-indigo-700 dark:text-indigo-400" data-lucide="check-circle" viewBox="0 0 24 24"><use href="#check-circle"></use></svg>Theorem: Strong Law of Large Numbers<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-indigo-700 dark:text-indigo-400" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>Strong law of large numbers of samples: If $Y_1, Y_2, \ldots, Y_m$ and $Y$ are i.i.d random variables from a distribution with finite mean, and if $\mathbb{E}[r(Y)]$ exists, then, with probability 1,
$$
\lim_{m \to \infty} \frac{r(Y_1) + r(Y_2) + \ldots + r(Y_m)}{m} = \mathbb{E}[r(Y)]
$$</p></div>
</details>
<details class="group relative px-4 py-3 my-6 border-l-4 text-base border-indigo-500 dark:bg-indigo-950/10" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-indigo-700 dark:text-indigo-400" data-lucide="check-circle" viewBox="0 0 24 24"><use href="#check-circle"></use></svg>Theorem: Strong Law of Large Numbers for Markov Chains<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-indigo-700 dark:text-indigo-400" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>Strong law of large numbers for Markov chains: If $X_0, X_1, \ldots$ is an ergodic Markov chain with stationary distribution $\pi$, and if $\mathbb{E}_{X \sim \pi}[r(X)]$ exists, then, with probability 1,
$$
\lim_{m \to \infty} \frac{r(X_0) + r(X_1) + \ldots + r(X_m)}{m} = \mathbb{E}_{X \sim \pi}[r(X)]
$$
where $X$ has distribution $\pi$.</p><details class="group relative px-4 py-3 my-6 border-l-4 text-base border-blue-500 dark:bg-blue-950/5" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-blue-700 dark:text-blue-300" data-lucide="info" viewBox="0 0 24 24"><use href="#info"></use></svg>Note<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-blue-700 dark:text-blue-300" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>When using this theorem in practice, one might improve accuracy by throwing away the first sequence $X_1, \ldots, X_s$ for $s &#x3C; m$ before computing the average. The first sequence is then called the burn-in.</p></div>
</details></div>
</details>
<details class="group relative px-4 py-3 my-6 border-l-4 text-base border-teal-600 dark:bg-teal-950/10" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-teal-700 dark:text-teal-400" data-lucide="book-open" viewBox="0 0 24 24"><use href="#book-open"></use></svg>Definition: The Metropolis-Hastings Algorithm<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-teal-700 dark:text-teal-400" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>The Metropolis-Hastings algorithm is a method to construct a Markov chain having a desired limiting distribution.
Let $\theta$ be a random variable with probability mass function $\pi( \theta)$.
We also assume given a proposal distribution $T(\theta_{\text{new}} \mid \theta)$, which, for every given $\theta$, provides a PMF for a new $\theta_{\text{new}}$.</p><p>Finally, we define, for $\theta$ and $\theta_{\text{new}}$, the acceptance probability,
$$
a = \min\left(1, \frac{\pi(\theta_{\text{new}}) T(\theta \mid \theta_{\text{new}})}{\pi(\theta) T(\theta_{\text{new}} \mid \theta)}\right)
$$
The Metropolis-Hastings algorithm is: Starting with some initial value $\theta_0$, generate $\theta_1, \theta_2, \ldots$ by, at each step, proposing a new $\theta$ based on the old using the proposal function and accepting it with probability $a$.
If it is not accepted, the old value is used again.</p><p>If this defines an ergodic Markov chain, its unique stationary distribution is $\pi(\theta)$.</p><details class="group relative px-4 py-3 my-6 border-l-4 text-base border-amber-500 dark:bg-amber-950/10" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-amber-700 dark:text-amber-300" data-lucide="check-square" viewBox="0 0 24 24"><use href="#check-square"></use></svg>Proof<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-amber-700 dark:text-amber-300" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>Let $P$ be the transition matrix of the Markov chain defined by the Metropolis-Hastings algorithm.
We need to show that $\pi P = \pi$.
It suffices to show that the detailed balance equations are satisfied, i.e., that,
$$
\pi(\theta) P_{\theta \theta_{\text{new}}} = \pi(\theta_{\text{new}}) P_{\theta_{\text{new}} \theta}
$$
for all states $\theta$ and $\theta_{\text{new}}$.
We have,
$$
P_{\theta \theta_{\text{new}}} = T(\theta_{\text{new}} \mid \theta) \cdot a =
T(\theta_{\text{new}} \mid \theta) \cdot \min\left(1, \frac{\pi(\theta_{\text{new}}) T(\theta \mid \theta_{\text{new}})}{\pi(\theta) T(\theta_{\text{new}} \mid \theta)}\right)
$$
and,
$$
P_{\theta_{\text{new}} \theta} = T(\theta \mid \theta_{\text{new}}) \cdot a^{\prime} =
T(\theta \mid \theta_{\text{new}}) \cdot \min\left(1, \frac{\pi(\theta) T(\theta_{\text{new}} \mid \theta)}{\pi(\theta_{\text{new}}) T(\theta \mid \theta_{\text{new}})}\right)
$$
If $\pi(\theta) T(\theta_{\text{new}} \mid \theta) \leq \pi(\theta_{\text{new}}) T(\theta \mid \theta_{\text{new}})$, then,
$$
\begin{align*}
\pi(\theta) P_{\theta \theta_{\text{new}}} &#x26; = \pi(\theta) T(\theta_{\text{new}} \mid \theta) \cdot 1 \newline
&#x26; = \pi(\theta_{\text{new}}) T(\theta \mid \theta_{\text{new}}) \cdot \frac{\pi(\theta) T(\theta_{\text{new}} \mid \theta)}{\pi(\theta_{\text{new}}) T(\theta \mid \theta_{\text{new}})} \newline
&#x26; = \pi(\theta_{\text{new}}) T(\theta \mid \theta_{\text{new}}) \cdot a^{\prime} \newline
&#x26; = \pi(\theta_{\text{new}}) P_{\theta_{\text{new}} \theta}
\end{align*}
$$
If $\pi(\theta) T(\theta_{\text{new}} \mid \theta) > \pi(\theta_{\text{new}}) T(\theta \mid \theta_{\text{new}})$, then,
$$
\begin{align*}
\pi(\theta) P_{\theta \theta_{\text{new}}} &#x26; = \pi(\theta) T(\theta_{\text{new}} \mid \theta) \cdot \frac{\pi(\theta_{\text{new}}) T(\theta \mid \theta_{\text{new}})}{\pi(\theta) T(\theta_{\text{new}} \mid \theta)} \newline
&#x26; = \pi(\theta_{\text{new}}) T(\theta \mid \theta_{\text{new}}) \cdot 1 \newline
&#x26; = \pi(\theta_{\text{new}}) T(\theta \mid \theta_{\text{new}}) \cdot a^{\prime} \newline
&#x26; = \pi(\theta_{\text{new}}) P_{\theta_{\text{new}} \theta}
\end{align*}
$$
Thus, in both cases, the detailed balance equations are satisfied, so $\pi$ is the stationary distribution of the chain.</p></div>
</details></div>
</details>
<details class="group relative px-4 py-3 my-6 border-l-4 text-base border-teal-600 dark:bg-teal-950/10" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-teal-700 dark:text-teal-400" data-lucide="book-open" viewBox="0 0 24 24"><use href="#book-open"></use></svg>Definition: Gibbs Sampling<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-teal-700 dark:text-teal-400" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>For any probability model over a vector $\theta = (\theta_1, \theta_2, \ldots, \theta_n)$, consider a Metropolis-Hastings proposal function changing only one coordinate, with the value of this coordinate simulated from the conditional distribution given the remaining coordinates.
The acceptance probability is always 1, so the proposal is always accepted.</p><details class="group relative px-4 py-3 my-6 border-l-4 text-base border-amber-500 dark:bg-amber-950/10" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-amber-700 dark:text-amber-300" data-lucide="check-square" viewBox="0 0 24 24"><use href="#check-square"></use></svg>Proof<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-amber-700 dark:text-amber-300" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>Let $\theta = (\theta_1, \theta_2, \ldots, \theta_n)$ and $\theta_{\text{new}} = (\theta_1, \ldots, \theta_{i - 1}, \theta_{i,\text{new}}, \theta_{i + 1}, \ldots, \theta_n)$ differ only in coordinate $i$.
The proposal distribution is,
$$
T(\theta_{\text{new}} \mid \theta) = P(\theta_i = \theta_{i,\text{new}} \mid \theta_1, \ldots, \theta_{i - 1}, \theta_{i + 1}, \ldots, \theta_n)
$$
and,
$$
T(\theta \mid \theta_{\text{new}}) = P(\theta_i = \theta_i \mid \theta_1, \ldots, \theta_{i - 1}, \theta_{i + 1}, \ldots, \theta_n)
$$
Using the definition of conditional probability, we have,
$$
\begin{align*}
T(\theta_{\text{new}} \mid \theta)
&#x26; = \frac{P(\theta_1, \ldots, \theta_{i - 1}, \theta_{i,\text{new}}, \theta_{i + 1}, \ldots, \theta_n)}
{P(\theta_1, \ldots, \theta_{i - 1}, \theta_{i + 1}, \ldots, \theta_n)} \
&#x26; = \frac{\pi(\theta_{\text{new}})}
{\sum_x \pi(\theta_1, \ldots, \theta_{i - 1}, x, \theta_{i + 1}, \ldots, \theta_n)} ,
\end{align*}
$$
and,
$$
\begin{align*}
T(\theta \mid \theta_{\text{new}})
&#x26; = \frac{P(\theta_1, \ldots, \theta_{i - 1}, \theta_i, \theta_{i + 1}, \ldots, \theta_n)}
{P(\theta_1, \ldots, \theta_{i - 1}, \theta_{i + 1}, \ldots, \theta_n)} \
&#x26; = \frac{\pi(\theta)}
{\sum_x \pi(\theta_1, \ldots, \theta_{i - 1}, x, \theta_{i + 1}, \ldots, \theta_n)} ,
\end{align*}
$$
Thus, we have,
$$
\begin{align*}
\frac{\pi(\theta_{\text{new}}) T(\theta \mid \theta_{\text{new}})}
{\pi(\theta) T(\theta_{\text{new}} \mid \theta)}
&#x26; = \frac{
\pi(\theta_{\text{new}}) \frac{\pi(\theta)}{\sum_x \pi(\theta_1,\ldots,\theta_{i-1},x,\theta_{i+1},\ldots,\theta_n)}
}{
\pi(\theta) \frac{\pi(\theta_{\text{new}})}{\sum_x \pi(\theta_1,\ldots,\theta_{i-1},x,\theta_{i+1},\ldots,\theta_n)}
} \
&#x26; = \frac{\pi(\theta_{\text{new}})\pi(\theta)}
{\pi(\theta)\pi(\theta_{\text{new}})} = 1 ,
\end{align*}
$$
Thus, the proposal is always accepted.</p></div>
</details><p>Putting together an algorithm updating different coordinates in different steps may create an ergodic Markov chain.</p><p>This is called Gibbs sampling.
Sometimes the conditional distributions are easy to derive. Then this is an easy-to-use version of Metropolis-Hastings.</p></div>
</details>
<details class="group relative px-4 py-3 my-6 border-l-4 text-base border-teal-600 dark:bg-teal-950/10" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-teal-700 dark:text-teal-400" data-lucide="book-open" viewBox="0 0 24 24"><use href="#book-open"></use></svg>Definition: The Ising Model<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-teal-700 dark:text-teal-400" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>Uses a grid of vertices; We will assume an $n \times n$ grid.
Two vertices $v$ and $w$ are neighbours, denoted $v \sim w$, if they are next to each other in the grid.</p><p>Each vertex $v$ can have value $+1$ or $-1$ (called its â€œspinâ€); We denote this by $\sigma_{v} = 1$ or $\sigma_{v} = -1$.</p><p>A configuration $\sigma$ consists of a choice of $+1$ or $-1$ for each vertex. Thus, the set $\Omega$ of possible configurations has $2^{(n^2)}$ elements.
We define the energy of a configuration as $E(\sigma) = - \sum_{v \sim w} \sigma_v \sigma_w$.</p><p>The Gibbs distribution is the probability mass function on $\Omega$ defined by,
$$
\pi(\sigma) \propto \exp(-\beta E(\sigma))
$$
where $\beta$ is a parameter of the model; $\frac{1}{\beta}$ is called the temperature.</p><p>It turns out that when the temperature is high, samples from the model will show a chaotic pattern of spins, but when the temperature sinks below the phase transition value, samples will show chunks of neighbouring vertices with the same spin, i.e., the system will be â€œmagnetizedâ€.</p></div>
</details>
<details class="group relative px-4 py-3 my-6 border-l-4 text-base border-sky-300 dark:bg-sky-950/10" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-sky-500 dark:text-sky-200" data-lucide="lightbulb" viewBox="0 0 24 24"><use href="#lightbulb"></use></svg>Intuition: Simulating from the Ising Model using Gibbs Sampling<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-sky-500 dark:text-sky-200" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>For a vertex configuration $\sigma$ and a vertex $v$, let $\sigma_{-v}$ denote the part of $\sigma$ that does not involve $v$.
Prpose a new configuration $\sigma^{\star}$ given an old configuration $\sigma$ by first choosing a vertex $v$, then, let $\sigma^{\star}$ be identical to $\sigma$ except possibly at $v$.
Decide the spin at $v$ using the conditional distribution given $\sigma_{-v}$,
$$
\begin{align*}
\pi(\sigma^{\star} \mid \sigma_{-v}) &#x26; = \frac{\pi(\sigma_v = 1, \sigma_{-v})}{\pi(\sigma_{-v})} \newline
&#x26; = \frac{\pi(\sigma_v = 1, \sigma_{-v})}{\pi(\sigma_v = 1, \sigma_{-v}) + \pi(\sigma_v = -1, \sigma_{-v})} \newline
&#x26; = \frac{1}{1 + \frac{\pi(\sigma_v = -1, \sigma_{-v})}{\pi(\sigma_v = 1, \sigma_{-v})}} \newline
&#x26; = \frac{1}{1 + \exp(-\beta E(\sigma_v = -1, \sigma_{-v}) + \beta E(\sigma_v = 1, \sigma_{-v}))} \newline
&#x26; = \frac{1}{1 + \exp(\beta \sum_{v \sim w} \sigma_v \sigma_w \mid \sigma_v = -1 - \beta \sum_{v \sim w} \sigma_v \sigma_w \mid \sigma_v = 1)} \newline
&#x26; = \frac{1}{1 + \exp(-2 \beta \sum_{v \sim w} \sigma_w)} \newline
\end{align*}
$$</p></div>
</details>
<details class="group relative px-4 py-3 my-6 border-l-4 text-base border-sky-300 dark:bg-sky-950/10" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-sky-500 dark:text-sky-200" data-lucide="lightbulb" viewBox="0 0 24 24"><use href="#lightbulb"></use></svg>Intuition: Perfect Sampling<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-sky-500 dark:text-sky-200" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>Given an ergodic Markov chain with finite state space of size $k$ and limiting distribution $\pi$.
The idea is that, given $n$ prove that $X_n$ actually has reached the limit distribution $\pi$.</p><p>If we can prove that the distribution at $X_n$ is independent of the starting state $X_0$, then we might be able to conclude that $X_n$ has the limiting distribution $\pi$.</p><p>Construct $k$ Markov chains that are dependent (â€œcoupledâ€) but which are marginally Markov chains as above.
If they start at the $k$ possible value at $X_0$ but have identical values at $X_n$, then we are done.</p><details class="group relative px-4 py-3 my-6 border-l-4 text-base border-blue-500 dark:bg-blue-950/5" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-blue-700 dark:text-blue-300" data-lucide="info" viewBox="0 0 24 24"><use href="#info"></use></svg>Note<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-blue-700 dark:text-blue-300" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>$n$ cannot be determined as the first value where the $k$ chains meet, it must be determined independently of such information.
Thus, usually one wants to generate chains $X_{-n}, X_{-n + 1}, \ldots, X_0$ where $X_0$ has the limiting distribution, and we stepwise increase $n$ to make all chains coalesce to one chain at time 0.</p></div>
</details></div>
</details>
<details class="group relative px-4 py-3 my-6 border-l-4 text-base border-sky-300 dark:bg-sky-950/10" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-sky-500 dark:text-sky-200" data-lucide="lightbulb" viewBox="0 0 24 24"><use href="#lightbulb"></use></svg>Intuition: Using same source of randomness for all chains<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-sky-500 dark:text-sky-200" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>Consider the chains $X^{(j)}_{-n}, \ldots, X^{(j)}_0$ for $j = 1, 2, \ldots, k$.
Instead of simulating $X^{(j)}_{i + 1}$ based on $X^{(j)}_i$ independently for each j, we define a function $g$ so that $X^{(j)}_{i + 1} = g(X^{(j)}_i, U_i)$ for all $j$ where $U_i \sim \mathrm{Uniform}(0, 1)$.</p><p>Thus, if two chains have identical values in $X_i$, they will also be identical in $X_{i + 1}$.</p><p>Thus, for a particular $n$, if all chains have not converged at $X_0$, we simulate $k$ chains from $X_{-2n}$ to $X_{-n}$.
They might only hit a subset of the $k$ states at $X_{-n}$ and thus might coalesce to one state at $X_0$ using the old simulations. If not, double $n$ again.</p></div>
</details>
<details class="group relative px-4 py-3 my-6 border-l-4 text-base border-teal-600 dark:bg-teal-950/10" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-teal-700 dark:text-teal-400" data-lucide="book-open" viewBox="0 0 24 24"><use href="#book-open"></use></svg>Definition: Counting Process<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-teal-700 dark:text-teal-400" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>A counting process $\{N_t\}_{t \in \mathcal{I}}$ is a stochastic process where $\mathcal{I} = \mathbb{R}_0^+$, where the state space is the non-negative integers, and where $0 \leq s \leq t$ implies $N_s \leq  N_t$.</p><p>Generally, when $s &#x3C; t, N_t - N_s$ counts the number of â€œeventsâ€ (in the loose meaning â€œthings happeningâ€) in $(s, t]$.</p><p>A realization of $N_t$ is then a function of $t$ that is a right-continuous step function.</p></div>
</details>
<details class="group relative px-4 py-3 my-6 border-l-4 text-base border-teal-600 dark:bg-teal-950/10" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-teal-700 dark:text-teal-400" data-lucide="book-open" viewBox="0 0 24 24"><use href="#book-open"></use></svg>Definition: Poisson Process I<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-teal-700 dark:text-teal-400" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>A Poisson process $\{N_t\}_{t \geq 0}$ with parameter $\lambda > 0$ is a counting process, fulfilling,</p><ol>
<li>$N_0 = 0$.</li>
<li>$N_t \sim \mathrm{Poisson}(\lambda t)$ for all $t > 0$.</li>
<li>Stationary Increments: $N_{t + s} - N_s$ has the same distribution as $N_t$ for all $s > 0, t > 0$.</li>
<li>Independent Increments: $N_t - N_s$ and $N_r - N_q$ are independent, when $0 \leq q &#x3C; r \leq s &#x3C; t$.</li>
</ol><details class="group relative px-4 py-3 my-6 border-l-4 text-base border-blue-500 dark:bg-blue-950/5" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-blue-700 dark:text-blue-300" data-lucide="info" viewBox="0 0 24 24"><use href="#info"></use></svg>Note<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-blue-700 dark:text-blue-300" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>It is not obvious that such a process necessarily exists. Further, $\mathbb{E}[N_t] = \lambda t$, thus what one is counting occurs with a rate of $\lambda$ items per time unit.</p></div>
</details></div>
</details>
<details class="group relative px-4 py-3 my-6 border-l-4 text-base border-teal-600 dark:bg-teal-950/10" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-teal-700 dark:text-teal-400" data-lucide="book-open" viewBox="0 0 24 24"><use href="#book-open"></use></svg>Definition: Poisson Process II<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-teal-700 dark:text-teal-400" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>Let $X_1, X_2, \ldots$ be a sequence of i.i.d. exponential random variables with parameter $\lambda$.
Let $N_0 = 0$ and, for $t > 0$,
$$
N_t \coloneqq \max\{n : X_1 + \ldots + X_n \leq t\}.
$$
Then, $\{N_t\}_{t \geq 0}$ is a Poisson process with parameter $\lambda$.</p><details class="group relative px-4 py-3 my-6 border-l-4 text-base border-amber-500 dark:bg-amber-950/10" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-amber-700 dark:text-amber-300" data-lucide="check-square" viewBox="0 0 24 24"><use href="#check-square"></use></svg>Proof<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-amber-700 dark:text-amber-300" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>Firstly, if we start with a Poisson process (definition I), and let $X_1, X_2, \ldots$ be the inter-arrival times, i.e., the time between event 1 and event 2, event 2 and event 3, etc., then these are i.i.d. exponential random variables with parameter $\lambda$.
Thus, $N_t$ will be defined as above.</p><p>Conversely, if we construct $N_t$ as above, all properties of definition I can be verified.</p><p>Let $\{M_t\}_{t \geq 0}$ be defined as $M_t \coloneqq N_{t + s} - N_s$ for some $s > 0$.</p><ul>
<li>It is a counting process by definition.</li>
<li>$N_0 = 0$ by definition.</li>
<li>Stationary increments follow from the memoryless property of the exponential distribution: $M_k = N_{s + t + k} - N_{s + t} = \max\{n : X_{N_{s + t} + 1} + \ldots + X_{N_{s + t} + n} \leq k\}$, which has the same distribution as $N_k$.</li>
<li>Independent increments follow from the independence of the $X_i$â€˜s.</li>
<li>$M_k = M_{k + s} - N_s = \max\{n : X_{N_s + 1} + \ldots + X_{N_s + n} \leq k\}$, which has a $\mathrm{Poisson}(\lambda k)$ distribution.</li>
</ul></div>
</details><p>We call $S_n \coloneqq X_1 + \ldots + X_n$ the arrival times of the process.
Let $M = \min\{X_1, \ldots, X_n\}$, where, independently for each $i$, $X_i \sim \mathrm{Exponential}(\lambda_i)$, then,
$$
M \sim \mathrm{Exponential}(\lambda_1 + \ldots + \lambda_n), \quad P(M = X_k) = \frac{\lambda_k}{\lambda_1 + \ldots + \lambda_n}.
$$</p><details class="group relative px-4 py-3 my-6 border-l-4 text-base border-amber-500 dark:bg-amber-950/10" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-amber-700 dark:text-amber-300" data-lucide="check-square" viewBox="0 0 24 24"><use href="#check-square"></use></svg>Proof<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-amber-700 dark:text-amber-300" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>Since the $X_i$â€˜s are independent,
$$
\begin{align*}
P(X_1 > t) P(X_2 > t) \ldots P(X_n > t) &#x26; = e^{-\lambda_1 t} e^{-\lambda_2 t} \ldots e^{-\lambda_n t} \newline
&#x26; = e^{-(\lambda_1 + \ldots + \lambda_n) t} \newline
\end{align*}
$$
Thus, $M \sim \mathrm{Exponential}(\lambda_1 + \ldots + \lambda_n)$.</p><p>Further,
$$
\begin{align*}
P(M = X_1) &#x26; = P(X_2 \geq X_1, \ldots, X_n \geq X_1) \newline
&#x26; = \mathbb{E}[\mathbb{I}[X_2 \geq X_1, \ldots, X_n \geq X_1]] \newline
&#x26; = \mathbb{E}[\mathbb{E}[\mathbb{I}[X_2 \geq X_1, \ldots, X_n \geq X_1] \mid X_1]] \newline
&#x26; = \mathbb{E}[P(X_2 \geq X_1, \ldots, X_n \geq X_1 \mid X_1)] \newline
&#x26; = \mathbb{E}[e^{-\lambda_2 X_1} \ldots e^{-\lambda_n X_1} \mid X_1] \newline
&#x26; = \mathbb{E}[e^{-(\lambda_2 + \ldots + \lambda_n) X_1}] \newline
&#x26; = \int_{0}^{\infty} e^{-(\lambda_2 + \ldots + \lambda_n) x} \lambda_1 e^{-\lambda_1 x} \ dx \newline
&#x26; = \lambda_1 \int_{0}^{\infty} e^{-(\lambda_1 + \lambda_2 + \ldots + \lambda_n) x} \ dx \newline
&#x26; = \frac{\lambda_1}{\lambda_1 + \lambda_2 + \ldots + \lambda_n} \underbrace{\left[-\frac{1}{\lambda_1 + \lambda_2 + \ldots + \lambda_n} e^{-(\lambda_1 + \lambda_2 + \ldots + \lambda_n) x}\right]_{0}^{\infty}}_{= 1} \newline
&#x26; = \frac{\lambda_1}{\lambda_1 + \lambda_2 + \ldots + \lambda_n} \ _\blacksquare
\end{align*}
$$</p></div>
</details></div>
</details>
<details class="group relative px-4 py-3 my-6 border-l-4 text-base border-teal-600 dark:bg-teal-950/10" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-teal-700 dark:text-teal-400" data-lucide="book-open" viewBox="0 0 24 24"><use href="#book-open"></use></svg>Definition: Poisson Process III<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-teal-700 dark:text-teal-400" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>A Poisson process $\{N_t\}_{t \geq 0}$ with parameter $\lambda > 0$ is a counting process, fulfilling,</p><ul>
<li>$N_0 = 0$.</li>
<li>The process has stationary and independent increments.
$$
\begin{align*}
P(N_h = 0) &#x26; = 1 - \lambda h + o(h) \newline
P(N_h = 1) &#x26; = \lambda h + o(h) \newline
P(N_h > 1) &#x26; = o(h) \newline
\end{align*}
$$
for all $h > 0$, where $o(h)$ is a function such that $\lim_{h \to 0} \frac{o(h)}{h} = 0$.</li>
</ul></div>
</details>
<details class="group relative px-4 py-3 my-6 border-l-4 text-base border-indigo-400 dark:bg-indigo-950/10" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-indigo-600 dark:text-indigo-300" data-lucide="puzzle" viewBox="0 0 24 24"><use href="#puzzle"></use></svg>Lemma: Superposition of Poisson Processes<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-indigo-600 dark:text-indigo-300" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>Let $\{N_t^{(1)}\}_{t \geq 0}, \ldots, \{N_t^{(n)}\}_{t \geq 0}$ be independent Poisson processes with parameters $\lambda p_1, \ldots, \lambda p_n$, respectively, where $p = (p_1, \ldots, p_n)$ is a probability vector.
If $c = (c_1, \ldots, c_n)$ are the counts after time $t$ (i.e., $c_i = N_t^{(i)}$), then, the conditional distribution of $(N_t^{(1)}, \ldots, N_t^{(n)})$, an equivalent model is,
$$
c \sim \mathrm{Multinomial}(N_t, p),
$$
where $\{N_t\}_{t \geq 0}$ is a Poisson process with parameter $\lambda$.</p><details class="group relative px-4 py-3 my-6 border-l-4 text-base border-amber-500 dark:bg-amber-950/10" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-amber-700 dark:text-amber-300" data-lucide="check-square" viewBox="0 0 24 24"><use href="#check-square"></use></svg>Proof<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-amber-700 dark:text-amber-300" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>Using the model with independent Poisson processes, the probability of observing the count vector $c$ after time $t$ is (denoting $N = c_1 + \ldots + c_n$),
$$
\begin{align*}
\prod_{i = 1}^n \mathrm{Poisson}(c_i; \lambda p_i t) &#x26; = \prod_{i = 1}^n e^{-\lambda p_i t} \frac{(\lambda p_i t)^{c_i}}{c_i!} \newline
&#x26; = e^{-\lambda t} (\lambda t)^N \prod_{i = 1}^n \frac{p_i^{c_i}}{c_i!} \newline
&#x26; = e^{-\lambda t} \frac{(\lambda t)^N}{N!} \cdot \frac{N!}{c_1! c_2! \ldots c_n!} p_1^{c_1} p_2^{c_2} \ldots p_n^{c_n} \newline
&#x26; = \mathrm{Poisson}(N; \lambda t) \cdot \mathrm{Multinomial}(c; N, p) \newline
\end{align*}
$$
The process for $N$ inherits independent and stationary increments from the sub-processes, so it follows it also a Poisson process with parameter $\lambda$.</p></div>
</details></div>
</details>
<details class="group relative px-4 py-3 my-6 border-l-4 text-base border-indigo-400 dark:bg-indigo-950/10" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-indigo-600 dark:text-indigo-300" data-lucide="puzzle" viewBox="0 0 24 24"><use href="#puzzle"></use></svg>Lemma: Uniformly Distributed Arrival Times<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-indigo-600 dark:text-indigo-300" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>Let $\{N_t\}_{t \geq 0}$ be a Poisson process with parameter $\lambda$.
If we fix that $N_t = k$, and we select uniformly randomly one of the $k$ arrivals, then its arrival time is uniformly distributed on the interval $[0, t]$.</p><details class="group relative px-4 py-3 my-6 border-l-4 text-base border-amber-500 dark:bg-amber-950/10" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-amber-700 dark:text-amber-300" data-lucide="check-square" viewBox="0 0 24 24"><use href="#check-square"></use></svg>Proof<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-amber-700 dark:text-amber-300" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>Let $S_1, S_2, \ldots, S_k$ be the arrival times given that $N_t = k$.
$$
\begin{align*}
P(S_k \geq s \mid k \text{ uniformly random in } {1, \ldots, n}, N_t = n) &#x26; = \frac{1}{n} \sum_{k = 1}^{n} P(S_k \geq s \mid N_t = n) \newline
&#x26; = \frac{1}{n} \sum_{k = 1}^{n} \sum_{j = 0}^{k - 1} P(N_s = j \mid N_t = n) \newline
&#x26; = \frac{1}{n} \sum_{k = 1}^{n} \sum_{j = 0}^{k - 1} \frac{P(N_s = j) P(N_{t - s} = n - j)}{P(N_t = n)} \newline
&#x26; = \frac{1}{n} \sum_{k = 1}^{n} \sum_{j = 0}^{k - 1} \frac{e^{-\lambda s} \frac{(\lambda s)^j}{j!} e^{-\lambda (t - s)} \frac{(\lambda (t - s))^{n - j}}{(n - j)!}}{e^{-\lambda t} \frac{(\lambda t)^n}{n!}} \newline
&#x26; = \frac{1}{n} \sum_{j = 0}^{n - 1} (n - j) \frac{n!}{j! (n - j)!} \left(\frac{s}{t}\right)^j \left(1 - \frac{s}{t}\right)^{n - j} \newline
&#x26; = \left[\sum_{j = 0}^{n - 1} \frac{n!}{j! (n - j - 1)!} \left(\frac{s}{t}\right)^j \left(1 - \frac{s}{t}\right)^{n - j - 1}\right] \cdot \left(1 - \frac{s}{t}\right) \newline
&#x26; = 1 - \frac{s}{t}
\end{align*}
$$</p></div>
</details></div>
</details>
<details class="group relative px-4 py-3 my-6 border-l-4 text-base border-teal-600 dark:bg-teal-950/10" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-teal-700 dark:text-teal-400" data-lucide="book-open" viewBox="0 0 24 24"><use href="#book-open"></use></svg>Definition: Spatial Poisson Process<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-teal-700 dark:text-teal-400" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>A collection of random variables $\{N_A\}_{A \subseteq \mathbb{R}^d}$ is a spatial Poisson process with parameter $\lambda$ if,</p><ul>
<li>For each bounded set $A \subseteq \mathbb{R}^d$, $N_A$ has a Poisson distribution with parameter $\lambda |A|$.</li>
<li>Whenever $A \subseteq B, N_A \leq N_B$ (i.e., spatial counting process).</li>
<li>Whenever $A$ and $B$ are disjoint, $N_A$ and $N_B$ are independent.</li>
</ul></div>
</details>
<details class="group relative px-4 py-3 my-6 border-l-4 text-base border-teal-600 dark:bg-teal-950/10" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-teal-700 dark:text-teal-400" data-lucide="book-open" viewBox="0 0 24 24"><use href="#book-open"></use></svg>Definition: Non-Homogeneous Poisson Process<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-teal-700 dark:text-teal-400" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>A counting process $\{N_t\}_{t \geq 0}$ is a non-homogeneous Poisson process with intensity function $\lambda(t)$ if,</p><ul>
<li>$N_0 = 0$.</li>
<li>For $0 &#x3C; s &#x3C; t$,
$$
N_t - N_s \sim \mathrm{Poisson}\left(\int_{s}^{t} \lambda(x) \ dx\right).
$$</li>
<li>It has independent increments.</li>
</ul></div>
</details>
<details class="group relative px-4 py-3 my-6 border-l-4 text-base border-teal-600 dark:bg-teal-950/10" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-teal-700 dark:text-teal-400" data-lucide="book-open" viewBox="0 0 24 24"><use href="#book-open"></use></svg>Definition: Continuous-Time Markov Chain<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-teal-700 dark:text-teal-400" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>A continuous-time stochastic process $\{X_t\}_{t \geq 0}$ with discrete state space $\mathcal{S}$ is a continuous-time Markov chain if,
$$
P(X_{t + s} = j \mid X_s = i, X_u, 0 \leq u &#x3C; s) = P(X_{t + s} = j \mid X_s = i),
$$
where $s, t \geq 0$ and $i, j, X_u \in \mathcal{S}$.</p><p>The process is time-homogeneous if for $s, t \geq 0$ and all $i, j \in \mathcal{S}$,
$$
P(X_{t + s} = j \mid X_s = i) = P(X_t = j \mid X_0 = i).
$$
We then define the transition function as the matrix function $P(t)$ with entries of the matrix given by,
$$
P(t)_{ij} = P(X_t = j \mid X_0 = i).
$$</p></div>
</details>
<details class="group relative px-4 py-3 my-6 border-l-4 text-base border-indigo-500 dark:bg-indigo-950/10" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-indigo-700 dark:text-indigo-400" data-lucide="check-circle" viewBox="0 0 24 24"><use href="#check-circle"></use></svg>Theorem: Chapman-Kolmogorov Equations<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-indigo-700 dark:text-indigo-400" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>For the transition function $P(t)$ we have,</p><ul>
<li>$P(s + t) = P(s) P(t)$</li>
<li>$P(0) = I$ (identity matrix)</li>
</ul><details class="group relative px-4 py-3 my-6 border-l-4 text-base border-amber-500 dark:bg-amber-950/10" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-amber-700 dark:text-amber-300" data-lucide="check-square" viewBox="0 0 24 24"><use href="#check-square"></use></svg>Proof<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-amber-700 dark:text-amber-300" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>For the first property; If they are same for an arbitrary element $i, j$ of the matrix, then they are equal.
$$
\begin{align*}
P(s + t)_{ij} &#x26; = P(X_{s + t} = j \mid X_s = i) \newline
&#x26; = \sum_k P(X_{s + t} = j, X_s = k \mid X_0 = i) \newline
&#x26; = \sum_k P(X_s = k \mid X_0 = i) P(X_{s + t} = j \mid X_s = k, X_0 = i) \newline
&#x26; = \sum_k P(X_s = k \mid X_0 = i) P(X_{s + t} = j \mid X_s = k) \newline
&#x26; = \sum_k P(X_s = k \mid X_0 = i) P(X_t = j \mid X_0 = k) \newline
&#x26; = \sum_k P(s)_{ik} P(t)_{kj} \newline
&#x26; = (P(s) P(t))_{ij} \ _\blacksquare
\end{align*}
$$
The second property follows directly from the definition of the transition function.</p></div>
</details></div>
</details>
<details class="group relative px-4 py-3 my-6 border-l-4 text-base border-sky-300 dark:bg-sky-950/10" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-sky-500 dark:text-sky-200" data-lucide="lightbulb" viewBox="0 0 24 24"><use href="#lightbulb"></use></svg>Intuition: Holding Times<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-sky-500 dark:text-sky-200" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>Define $T_i$ as the time the continuous-time Markov chain $\{X_t\}_{t \geq 0}$ that always starts in state $i$ stays in $i$ before moving to a different state, so that for any $s > 0$,
$$
P(T_i > s) = P(X_u = i, 0 \leq u \leq s)
$$
The distribution of $T_i$ is memoryless and thus exponential.
We define $q_i$ such that,
$$
T_i \sim \mathrm{Exponential}(q_i)
$$
Remember that this means that the average time the process stays in $i$ is $\frac{1}{q_i}$.
The rate of transition out of the state is $q_i$.</p><details class="group relative px-4 py-3 my-6 border-l-4 text-base border-blue-500 dark:bg-blue-950/5" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-blue-700 dark:text-blue-300" data-lucide="info" viewBox="0 0 24 24"><use href="#info"></use></svg>Note<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-blue-700 dark:text-blue-300" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>We can have $q_i = 0$, meaning that the state $i$ is absorbing,
$$
P(T_i > s) = 1.
$$</p></div>
</details></div>
</details>
<details class="group relative px-4 py-3 my-6 border-l-4 text-base border-sky-300 dark:bg-sky-950/10" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-sky-500 dark:text-sky-200" data-lucide="lightbulb" viewBox="0 0 24 24"><use href="#lightbulb"></use></svg>Intuition: Embedded Markov Chain<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-sky-500 dark:text-sky-200" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>We can define a new stochastic process by listing the states the chain visits.
This will be a discrete time Markov chain called the embedded Markov chain with transition matrix $\tilde{P}$.</p><details class="group relative px-4 py-3 my-6 border-l-4 text-base border-blue-500 dark:bg-blue-950/5" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-blue-700 dark:text-blue-300" data-lucide="info" viewBox="0 0 24 24"><use href="#info"></use></svg>Note<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-blue-700 dark:text-blue-300" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>The transition matrix $\tilde{P}$ has zeros along its diagonal! Why?
Because the process cannot stay in the same state when it makes a transition.</p><p>Further, note that the continuous-time Markov chain is completely determined by the expected holding times $(\frac{1}{q_1}, \ldots, \frac{1}{q_k})$ and the transition matrix of the embedded Markov chain $\tilde{P}$.</p></div>
</details></div>
</details>
<details class="group relative px-4 py-3 my-6 border-l-4 text-base border-sky-300 dark:bg-sky-950/10" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-sky-500 dark:text-sky-200" data-lucide="lightbulb" viewBox="0 0 24 24"><use href="#lightbulb"></use></svg>Intuition: Constructing a Continuous-Time Markov Chain<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-sky-500 dark:text-sky-200" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>A way to describe a continuous-time Markov chain is to describe $k \times (k - 1)$ independent â€œalarm clocksâ€.</p><p>For states $i$ and $j$ so that $i \neq j$, let $q_{ij}$ be the parameter of an Exponentially distributed random variable representing the time until an â€œalarm clockâ€ rings.</p><p>When in state $i$, wait until the first alarm clock $q_i$ rings, then move to the state given by the index $j$ of that alarm clock.
This defines a continuous-time Markov chain.</p><p>The time until the first alarm clock $q_i$ rings is Exponentially distributed with parameter given by,
$$
q_i = q_{i1} + q_{i2} + \ldots + q_{i, i - 1} + q_{i, i + 1} + \ldots + q_{ik}.
$$
i.e., the parameter of the holding time distribution at $i$.</p><p>The chain is completely described by the rates $q_{ij}$.</p><p>Further, we saw also that the chain is completely described by the $p_{ij}$ and the $q_i$.
The relationship is described by the equation above, and,
$$
p_{ij} = \frac{q_{ij}}{q_{i1} + q_{i2} + \ldots + q_{i, i - 1} + q_{i, i + 1} + \ldots + q_{ik}} = \frac{q_{ij}}{q_i}.
$$
for $i \neq j$.</p></div>
</details>
<details class="group relative px-4 py-3 my-6 border-l-4 text-base border-sky-300 dark:bg-sky-950/10" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-sky-500 dark:text-sky-200" data-lucide="lightbulb" viewBox="0 0 24 24"><use href="#lightbulb"></use></svg>Intuition: Infinitesimal Generator Matrix<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-sky-500 dark:text-sky-200" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>To relate $P(t)$ to the $q_{ij}$â€˜s, we first relate them to $P^{\prime}(0)$.</p><p>Assuming $P(t)$ is differentiable, we can show that,
$$
P^{\prime}(0) =
\begin{bmatrix}
-q_1 &#x26; q_{12} &#x26; q_{13} &#x26; \ldots &#x26; q_{1k} \newline
q_{21} &#x26; -q_2 &#x26; q_{23} &#x26; \ldots &#x26; q_{2k} \newline
\vdots &#x26; \vdots &#x26; \vdots &#x26; \ddots &#x26; \vdots \newline
q_{k1} &#x26; q_{k2} &#x26; q_{k3} &#x26; \ldots &#x26; -q_k \newline
\end{bmatrix} = Q,
$$</p><details class="group relative px-4 py-3 my-6 border-l-4 text-base border-amber-500 dark:bg-amber-950/10" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-amber-700 dark:text-amber-300" data-lucide="check-square" viewBox="0 0 24 24"><use href="#check-square"></use></svg>Proof: Lazy â€œproofâ€<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-amber-700 dark:text-amber-300" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>Firstly, letâ€™s show that $Q_{12} = P^{\prime}(0)_{12} = q_{12}$.
$$
\begin{align*}
Q_{12} &#x26; = \lim_{h \to 0} \frac{P(X_h = 2 \mid X_0 = 1)}{h} \newline
&#x26; = \lim_{h \to 0} \frac{P(h)_{12}}{h} \newline
&#x26; = \lim_{h \to 0} \frac{P(h)_{12} - P(0)_{12}}{h} \newline
&#x26; \eqqcolon P^{\prime}(0)_{12} \newline
\end{align*}
$$
Secondly, show that $-Q_1 = P^{\prime}(0)_{11}$.
$$
\begin{align*}
-Q_1 &#x26; = -[Q_{12} + Q_{13} + \ldots + Q_{1k}] \newline
&#x26; = - \lim_{h \to 0} \frac{P(h)_{12} + P(h)_{13} + \ldots + P(h)_{1k}}{h} \newline
&#x26; = - \lim_{h \to 0} \frac{1 - P(h)_{11}}{h} \newline
&#x26; = \lim_{h \to 0} \frac{P(h)_{11} - 1}{h} \newline
&#x26; = \lim_{h \to 0} \frac{P(h)_{11} - P(0)_{11}}{h} \newline
&#x26; \eqqcolon P^{\prime}(0)_{11} \newline
\end{align*}
$$
The other elements can be shown similarly $_\blacksquare$.</p></div>
</details><p>Note that the rows of $P^{\prime}(0)$, i.e., $Q$, sum to zero!</p></div>
</details>
<details class="group relative px-4 py-3 my-6 border-l-4 text-base border-indigo-500 dark:bg-indigo-950/10" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-indigo-700 dark:text-indigo-400" data-lucide="check-circle" viewBox="0 0 24 24"><use href="#check-circle"></use></svg>Theorem: Kolmogorov Forward and Backward Equations<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-indigo-700 dark:text-indigo-400" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>The Kolmogorov Forward and Backward equations describe how the transition function $P(t)$ evolves over time.</p><p>We get that for all $t \geq 0$,
$$
P^{\prime}(t) = P(t) Q = Q P(t).
$$
Thus, what this means in terms of the components of $P(t)$,
$$
\begin{align*}
P^{\prime}(t)_{ij} &#x26; = -P_{ij}(t) q_j + \sum_{k \neq j} P_{ik}(t) q_{kj} \newline
P^{\prime}(t)_{ij} &#x26; = -q_i P_{ij}(t) + \sum_{k \neq i} q_{ik} P_{kj}(t) \newline
\end{align*}
$$
Thus, the above equations define a set of differential equations which the components of the matrix function $P(t)$ must satisfy.</p><details class="group relative px-4 py-3 my-6 border-l-4 text-base border-amber-500 dark:bg-amber-950/10" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-amber-700 dark:text-amber-300" data-lucide="check-square" viewBox="0 0 24 24"><use href="#check-square"></use></svg>Proof<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-amber-700 dark:text-amber-300" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>$$
\begin{align*}
P^{\prime}(t) &#x26; = \lim_{h \to 0} \frac{P(t + h) - P(t)}{h} \newline
&#x26; = \lim_{h \to 0} \frac{P(t) P(h) - P(t)}{h} \newline
&#x26; = \lim_{h \to 0} P(t) \frac{P(h) - I}{h} \newline
&#x26; = P(t) \lim_{h \to 0} \frac{P(h) - I}{h} \newline
&#x26; = P(t) \underbrace{\lim_{h \to 0} \frac{P(h) - P(0)}{h}}_{P^{\prime}(0) = Q} \newline
&#x26; = P(t) Q \ _\blacksquare
\end{align*}
$$
Since we arbitrarily chose to write $P(t + h)$ as $P(t) P(h)$, we could have equally written it as $P(h) P(t)$, leading to the other equation, thus completing the proof.</p></div>
</details></div>
</details>
<details class="group relative px-4 py-3 my-6 border-l-4 text-base border-sky-300 dark:bg-sky-950/10" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-sky-500 dark:text-sky-200" data-lucide="lightbulb" viewBox="0 0 24 24"><use href="#lightbulb"></use></svg>Intuition: Matrix Exponential Solution<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-sky-500 dark:text-sky-200" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>The solution to the Kolmogorov Forward and Backward equations is given by the matrix exponential.
For any square matrix $A$ we can define the matrix exponential as,
$$
e^A \coloneqq \sum_{n = 0}^{\infty} \frac{1}{n!} A^n = I + A + \frac{1}{2} A^2 + \frac{1}{6} A^3 + \ldots
$$
The series converges for all square matrices $A$ (but we will not prove this here).</p><p>Some important properties of the matrix exponential are:</p><ul>
<li>$e^0 = I$</li>
<li>$e^A e^{-A} = I$</li>
<li>$e^{(s + t) A} = e^{sA} e^{tA}$</li>
<li>If $AB = BA$, then $e^{A + B} = e^A e^B = e^B e^A$</li>
<li>$\frac{\partial}{\partial t} e^{tA} = A e^{tA} = e^{tA} A$</li>
</ul><p>Note that $P(t) = e^{tQ}$ is the unique solution to the differential equations given by the Kolmogorov Forward and Backward equations with initial condition $P(0) = I$.</p><p>Further, note that $P^\prime(t) = Q P(t)$ for all $t \geq 0$ and $P(0) = I$.</p><p>In <code>R</code> one can use the <code>expm</code> package to compute matrix exponentials.</p></div>
</details>
<details class="group relative px-4 py-3 my-6 border-l-4 text-base border-teal-600 dark:bg-teal-950/10" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-teal-700 dark:text-teal-400" data-lucide="book-open" viewBox="0 0 24 24"><use href="#book-open"></use></svg>Definition: Multinomial Distribution<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-teal-700 dark:text-teal-400" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>A vector $x = (x_1, x_2, \ldots, x_k)$ of non-negative integers has a Multinomial distribution with parameters $n$ and $p$, where $n > 0$ is an integer and $p$ is a probability vector of length $k$, if $\sum_{i = 1}^k x_i = n$ and the probability mass function is given by,
$$
\pi(x \mid n, p) = \frac{n!}{x_1! x_2! \ldots x_k!} p_1^{x_1} p_2^{x_2} \ldots p_k^{x_k}.
$$
We write $x \sim \mathrm{Multinomial}(n, p)$.</p></div>
</details>
<details class="group relative px-4 py-3 my-6 border-l-4 text-base border-teal-600 dark:bg-teal-950/10" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-teal-700 dark:text-teal-400" data-lucide="book-open" viewBox="0 0 24 24"><use href="#book-open"></use></svg>Definition: Dirichlet Distribution<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-teal-700 dark:text-teal-400" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>A vector $p = (p_1, p_2, \ldots, p_k)$ of non-negative real numbers satisfying $\sum_{i = 1}^k p_i = 1$ has a Dirichlet distribution with parameter vector $\alpha = (\alpha_1, \alpha_2, \ldots, \alpha_k)$, if it has probability density function,
$$
\pi(p \mid \alpha) = \frac{\Gamma(\alpha_1 + \alpha_2 + \ldots + \alpha_k)}{\Gamma(\alpha_1) \Gamma(\alpha_2) \ldots \Gamma(\alpha_k)} p_1^{\alpha_1 - 1} p_2^{\alpha_2 - 1} \ldots p_k^{\alpha_k - 1},
$$
where $\alpha_i > 0$ for all $i = 1, 2, \ldots, k$.
We write $p \sim \mathrm{Dirichlet}(\alpha)$.</p></div>
</details>
<details class="group relative px-4 py-3 my-6 border-l-4 text-base border-indigo-500 dark:bg-indigo-950/10" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-indigo-700 dark:text-indigo-400" data-lucide="check-circle" viewBox="0 0 24 24"><use href="#check-circle"></use></svg>Theorem: Multinomial-Dirichlet Conjugacy<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-indigo-700 dark:text-indigo-400" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>Let $x = (x_1, x_2, \ldots, x_k)$ be a vector of counts with $x \sim \mathrm{Multinomial}(n, p)$ and prior $p \sim \mathrm{Dirichlet}(\alpha)$.
Then the posterior distribution of $p$ given $x$ is,
$$
p \mid x \sim \mathrm{Dirichlet}(\alpha_1 + x_1, \alpha_2 + x_2, \ldots, \alpha_k + x_k).
$$
Further, if $p \sim \mathrm{Dirichlet}(\alpha)$, then $\mathbb{E}[p_i] = \frac{\alpha_i}{\sum_{j = 1}^k \alpha_j}$ for $i = 1, 2, \ldots, k$.</p><details class="group relative px-4 py-3 my-6 border-l-4 text-base border-amber-500 dark:bg-amber-950/10" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-amber-700 dark:text-amber-300" data-lucide="check-square" viewBox="0 0 24 24"><use href="#check-square"></use></svg>Proof: Multinomial-Dirichlet Conjugacy<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-amber-700 dark:text-amber-300" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>Let $\pi(x \mid p) = \mathrm{Multinomial}(x; n, p)$ and $\pi(p) = \mathrm{Dirichlet}(p; \alpha)$, respectively.
Then,
$$
\begin{align*}
\pi(p \mid x) &#x26; \propto \pi(x \mid p) \pi(p) \newline
&#x26; = \mathrm{Multinomial}(x; n, p) \mathrm{Dirichlet}(p; \alpha) \newline
&#x26; \propto_p p_1^{x_1} p_2^{x_2} \ldots p_k^{x_k} \cdot p_1^{\alpha_1 - 1} p_2^{\alpha_2 - 1} \ldots p_k^{\alpha_k - 1} \newline
&#x26; \propto_p p_1^{\alpha_1 + x_1 - 1} p_2^{\alpha_2 + x_2 - 1} \ldots p_k^{\alpha_k + x_k - 1} \newline
&#x26; = \mathrm{Dirichlet}(p; \alpha_1 + x_1, \alpha_2 + x_2, \ldots, \alpha_k + x_k) \ _\blacksquare
\end{align*}
$$</p></div>
</details><details class="group relative px-4 py-3 my-6 border-l-4 text-base border-amber-500 dark:bg-amber-950/10" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-amber-700 dark:text-amber-300" data-lucide="check-square" viewBox="0 0 24 24"><use href="#check-square"></use></svg>Proof: Expectation of Dirichlet Distribution<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-amber-700 dark:text-amber-300" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>Let $p \sim \mathrm{Dirichlet}(\alpha)$.
Then,
$$
\begin{align*}
\mathbb{E}[p_i] &#x26; = \int \cdots \int p_i \frac{\Gamma(\alpha_1 + \alpha_2 + \ldots + \alpha_k)}{\Gamma(\alpha_1) \Gamma(\alpha_2) \ldots \Gamma(\alpha_k)} p_1^{\alpha_1 - 1} p_2^{\alpha_2 - 1} \ldots p_k^{\alpha_k - 1} \ dp_1 dp_2 \ldots dp_k \newline
&#x26; = \frac{\Gamma(\alpha_1 + \alpha_2 + \ldots + \alpha_k)}{\Gamma(\alpha_1) \Gamma(\alpha_2) \ldots \Gamma(\alpha_k)} \int \cdots \int p_1^{\alpha_1 - 1} p_2^{\alpha_2 - 1} \ldots p_i^{\alpha_i} \ldots p_k^{\alpha_k - 1} \ dp_1 dp_2 \ldots dp_k \newline
&#x26; = \frac{\Gamma(\alpha_1 + \alpha_2 + \ldots + \alpha_k)}{\Gamma(\alpha_1) \Gamma(\alpha_2) \ldots \Gamma(\alpha_k)} \cdot \frac{\Gamma(\alpha_1) \Gamma(\alpha_2) \ldots \Gamma(\alpha_i + 1) \ldots \Gamma(\alpha_k)}{\Gamma(\alpha_1 + \alpha_2 + \ldots + \alpha_k + 1)} \newline
&#x26; = \frac{\Gamma(\alpha_i + 1)}{\Gamma(\alpha_i)} \cdot \frac{\Gamma(\alpha_1 + \alpha_2 + \ldots + \alpha_k)}{\Gamma(\alpha_1 + \alpha_2 + \ldots + \alpha_k + 1)} \newline
&#x26; = \alpha_i \cdot \frac{1}{\alpha_1 + \alpha_2 + \ldots + \alpha_k} \newline
&#x26; = \frac{\alpha_i}{\sum_{j = 1}^k \alpha_j} \ _\blacksquare
\end{align*}
$$</p></div>
</details></div>
</details>
<details class="group relative px-4 py-3 my-6 border-l-4 text-base border-sky-300 dark:bg-sky-950/10" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-sky-500 dark:text-sky-200" data-lucide="lightbulb" viewBox="0 0 24 24"><use href="#lightbulb"></use></svg>Intuition: Predictions for The Multinomial-Dirichlet Model<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-sky-500 dark:text-sky-200" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>If $p \sim \mathrm{Dirichlet}(\alpha)$ and $x \mid p \sim \mathrm{Multinomial}(n, p)$, then the predictive distribution is given by,
$$
\pi(x) = \frac{n!}{x_1! x_2! \ldots x_k!} \cdot \frac{\Gamma(\alpha_1 + x_1)}{\Gamma(\alpha_1)} \cdot \frac{\Gamma(\alpha_2 + x_2)}{\Gamma(\alpha_2)} \cdots \frac{\Gamma(\alpha_k + x_k)}{\Gamma(\alpha_k)} \cdot \frac{\Gamma(\sum_{i = 1}^k \alpha_i)}{\Gamma(n + \sum_{i = 1}^k \alpha_i)}.
$$
For example, if $e_i$ is the vector with 1 at position $i$ and zeros elsewhere, then $\pi(x = e_i) = \frac{\alpha_i}{\sum_{j = 1}^k \alpha_j}$.
Further, if $x_{\text{new}}$ is a vector of new counts, then, as $p \mid x \sim \mathrm{Multinomial}(x + \alpha)$, we get,
$$
\pi(x_{\text{new}} = e_i \mid x) = \frac{\alpha_i + x_i}{\sum_{j = 1}^k \alpha_j + n}.
$$
The $\alpha_i$ in the prior are often called pseudocounts, as they can be interpreted as prior counts added to the observed counts.</p></div>
</details>
<details class="group relative px-4 py-3 my-6 border-l-4 text-base border-teal-600 dark:bg-teal-950/10" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-teal-700 dark:text-teal-400" data-lucide="book-open" viewBox="0 0 24 24"><use href="#book-open"></use></svg>Definition: Hidden Markov Model<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-teal-700 dark:text-teal-400" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>A Hidden Markov Model (HMMs) consists of:</p><ul>
<li>A Markov chain $X_0, \ldots, X_n, \ldots$ and,</li>
<li>another sequence $Y_0, \ldots, Y_n, \ldots$ such that,
$$
P(Y_k \mid Y_0, \ldots, Y_{k - 1}, X_0, \ldots, X_n) = P(Y_k \mid X_k).
$$
In some models we may instead have,
$$
P(Y_k \mid Y_0, \ldots, Y_{k - 1}, X_0, \ldots, X_n) = P(Y_k \mid Y_{k - 1}, X_k).
$$
Generally, $Y_0, \ldots, Y_n$ are called observations and $X_0, \ldots, X_n$ are called hidden states.
The $X_i$â€˜s represent the â€œunderlying processâ€ that the observed values $Y_i$â€˜s depend on.
Further, generally the $X_k$ have a finite state space.</li>
</ul></div>
</details>
<details class="group relative px-4 py-3 my-6 border-l-4 text-base border-sky-300 dark:bg-sky-950/10" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-sky-500 dark:text-sky-200" data-lucide="lightbulb" viewBox="0 0 24 24"><use href="#lightbulb"></use></svg>Intuition: Inference in HMMs<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-sky-500 dark:text-sky-200" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>When the parameters of the HMM are known, we want to know about the values of the hidden variables $X_i$, for example,</p><ul>
<li>What is the most likely sequence $X_0, X_1, \ldots, X_n$ given the data?</li>
<li>What is the probability distribution for a single $X_i$ given the data?
However, when the parameters of the HMM are unknown, we need to infer these from some data.</li>
</ul><p>If data with all $X_i$ and $Y_i$ known is available, inference for parameters is based on counts of transitions.
The inference for the Markov chain is exactly as for the Markov chains we have looked at before.
The inference for the emission probabilities, i.e., the parameters of $P(Y_k \mid X_k)$, can be done independently of the inference for the Markov chain.</p></div>
</details>
<details class="group relative px-4 py-3 my-6 border-l-4 text-base border-sky-300 dark:bg-sky-950/10" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-sky-500 dark:text-sky-200" data-lucide="lightbulb" viewBox="0 0 24 24"><use href="#lightbulb"></use></svg>Intuition: Bayesian Inference for Poisson Processes<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-sky-500 dark:text-sky-200" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>For a homogeneous Poisson process, we setup up a prior $\pi(\lambda)$ for its parameter $\lambda$, and find the posterior given the observations.</p><p>The likelihood for observing $y$ events in an interval of length $t$ is given by,
$$
\mathrm{Poisson}(y; \lambda t) = \exp(-\lambda t) \frac{(\lambda t)^y}{y!} \propto_{\lambda} \exp(-\lambda t) \lambda^y.
$$
A convenient prior to use is $\lambda \sim \mathrm{Gamma}(\alpha, \beta)$.</p><p>In this case, the posterior becomes,
$$
\lambda \mid \mathcal{D} \sim \mathrm{Gamma}(\alpha + y, \beta + t),
$$
and the predictive distribution for the number of observations $y_n$ in a different interval of length $u$ becomes,
$$
\pi(y_n) = \mathrm{Negative-Binomial}\left(y_n; \alpha, \frac{\beta}{\beta + u}\right).
$$</p></div>
</details>
<details class="group relative px-4 py-3 my-6 border-l-4 text-base border-sky-300 dark:bg-sky-950/10" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-sky-500 dark:text-sky-200" data-lucide="lightbulb" viewBox="0 0 24 24"><use href="#lightbulb"></use></svg>Intuition: Bayesian Inference for Continuous-Time Markov Chains<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-sky-500 dark:text-sky-200" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>Lastyl, recall that a continuous-time Markov chain with finite state space is completely characterized by its holding times parameter vector $q$ and the transition matrix $\tilde{P}$ of its embedded Markov chain.</p><p>Parametrizing instead with the â€œalarm clockâ€ parameters $q_{ij}$ gives an equivalent description of the process.</p><p>The two parts of the data can be considered independently are,</p><ul>
<li>We learn about $\tilde{P}$ from the counts of transitions between states, and</li>
<li>We learn about $q$ from the observed lengths of stays the process has in each state.</li>
</ul><p>For $\tilde{P}$ the situation is analogous to the one for discrete-time Markov chains, except that the diagonal of $\tilde{P}$ must be zero, so the prior must exclude the possibility of non-zero diagonal elements.</p><p>For example, for $\tilde{P}_1$, the first row of $\tilde{P}$, we might use the prior $\mathrm{Dirichlet}(0, 1, \ldots, 1)$, i.e., a Dirichlet prior with a zero pseudocount for the first element.</p><p>The holding times in state $i$ are distributed as $\mathrm{Exponential}(q_i)$.
If we have observed a total holding time of $h$ over $n$ intervals, that data has likelihood proportional to $e^{-hq_i}q_i^n$.
Using $q_i \sim \mathrm{Gamma}(\alpha, \beta)$ as prior results in the posterior $q_i \mid \mathcal{D} \sim \mathrm{Gamma}(\alpha + n, \beta + h)$.</p></div>
</details>
<details class="group relative px-4 py-3 my-6 border-l-4 text-base border-teal-600 dark:bg-teal-950/10" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-teal-700 dark:text-teal-400" data-lucide="book-open" viewBox="0 0 24 24"><use href="#book-open"></use></svg>Definition: Stationary Distribution for Continuous-Time Markov Chains<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-teal-700 dark:text-teal-400" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>In the context of continuous-time Markov chains, $v$ is a stationary distribution if and only if $0 = v Q$, where $Q$ is the generator matrix of the chain.</p><details class="group relative px-4 py-3 my-6 border-l-4 text-base border-amber-500 dark:bg-amber-950/10" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-amber-700 dark:text-amber-300" data-lucide="check-square" viewBox="0 0 24 24"><use href="#check-square"></use></svg>Proof: Stationary Distribution and Generator Matrix<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-amber-700 dark:text-amber-300" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>Firstly, let $vQ = 0$,
$$
\begin{align*}
\frac{d}{dt} (v P(t)) &#x26; \coloneqq v \frac{d}{dt} P(t) \newline
&#x26; \eqqcolon v Q P(t) \newline
&#x26; = 0 \newline
\end{align*}
$$
as $vQ = 0$ by assumption.
Thus, $v P(t)$ is constant in $t$, i.e., $v P(t) = v P(0) = v I = v$ for all $t \geq 0$.</p><p>Conversely, let $v$ be a stationary distribution, i.e., $v = v P(t)$ for all $t \geq 0$.
Then,
$$
\begin{align*}
\frac{d}{dt} (v P(t)) &#x26; \coloneqq v \frac{d}{dt} P(t) \newline
&#x26; \eqqcolon v Q P(t) \newline
&#x26; = 0 \newline
\end{align*}
$$
as $v P(t)$ is constant in $t$ by assumption.
In particular, for $t = 0$ we get $v Q P(0) = v Q I = v Q = 0$.
Thus, the proof is complete $_\blacksquare$.</p></div>
</details></div>
</details>
<details class="group relative px-4 py-3 my-6 border-l-4 text-base border-sky-300 dark:bg-sky-950/10" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-sky-500 dark:text-sky-200" data-lucide="lightbulb" viewBox="0 0 24 24"><use href="#lightbulb"></use></svg>Intuition: Long-Term Behavior of Continuous-Time Markov Chains<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-sky-500 dark:text-sky-200" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>A continuous-time Markov chain is irreducible if for all $i$ and $j$ there exists a $t > 0$ such that $P_{ij}(t) > 0$, i.e., it is possible to get to any state from any state.</p><p>However, periodic continuous-time Markov chains do not exist. If $P_{ij}(t) > 0$ for some $t > 0$, then $P_{ij}(t) > 0$ for all $t > 0$.</p></div>
</details>
<details class="group relative px-4 py-3 my-6 border-l-4 text-base border-indigo-500 dark:bg-indigo-950/10" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-indigo-700 dark:text-indigo-400" data-lucide="check-circle" viewBox="0 0 24 24"><use href="#check-circle"></use></svg>Theorem: Fundamental Limit Theorem for Continuous-Time Markov Chains<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-indigo-700 dark:text-indigo-400" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>Let $\{X_t\}_{t \geq 0}$ be a finite, irreducible, continuous-time Markov chain with transition function $P(t)$.
Then there exists a unique positive stationary distribution vector $v$ which is also the limiting distribution.</p><p>The limiting distribution of such a chain can be found as the unique $v$ satisfying $v Q = 0$</p></div>
</details>
<details class="group relative px-4 py-3 my-6 border-l-4 text-base border-teal-600 dark:bg-teal-950/10" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-teal-700 dark:text-teal-400" data-lucide="book-open" viewBox="0 0 24 24"><use href="#book-open"></use></svg>Definition: Absorbing State<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-teal-700 dark:text-teal-400" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>An absorbing state is one where the rate of leaving it is zero.</p><p>Assume $\{X_t\}_{t \geq 0}$ is a continuous-time Markov chain with $k$ states.
Assume the last state is absorbing and the rest are not (If the chain is irreducible they are then transient).</p><p>WE have that $q_k = 0$ and the entire last row must consist of zeros. We thus get,
$$
Q =
\begin{bmatrix}
V &#x26; \star \newline
\mathbf{0} &#x26; 0 \newline
\end{bmatrix}.
$$
Let $F$ be the $(k - 1) \times (k - 1)$ matrix such that $F_{ij}$ (with $i &#x3C; k, j &#x3C; k$) is the expected time spent in state $j$ when the chain starts in $i$.
We can show that $F = -V^{-1}$.</p><details class="group relative px-4 py-3 my-6 border-l-4 text-base border-amber-500 dark:bg-amber-950/10" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-amber-700 dark:text-amber-300" data-lucide="check-square" viewBox="0 0 24 24"><use href="#check-square"></use></svg>Proof: Expected Time in Transient States Before Absorption<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-amber-700 dark:text-amber-300" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>Generally, we can define $D$ as the matrix with $(\frac{1}{q_1}, \ldots, \frac{1}{q_k})$ along its diagonal, with all other entries zero.
If there are no absorbing states,
$$
\tilde{P} = DQ + I_k.
$$
Write $A\_$ for a square matrix without its last row and column, so, e.g., $Q\_ = V$.</p><p>If the last state is absorbing, i.e., $q_k = 0$, we get,
$$
\tilde{P}\_ = D\_ Q\_ + I_{k - 1}.
$$
Further, let $F^{\prime}$ be the matrix where $F^{\prime}_{ij}$ is the expected number of stays in state $j$ before absorbtion when starting in state $i$.
As the lengths of stays and changes in states are independent, we get $F^{\prime}_{ij} = F_{ij} \frac{1}{q_j}$ and thus,
$$
F = F^{\prime} D\_.
$$
By the theory for discrete-time Markov chains with absorbing states, we have,
$$
F^{\prime} = (I_{k - 1} - \tilde{P}\_)^{-1}.
$$
Thus,
$$
\begin{align*}
F &#x26; = F^{\prime} D\_ \newline
&#x26; = (I_{k - 1} - \tilde{P}\_)^{-1} D\_ \newline
&#x26; = (I_{k - 1} - (D\_ Q\_ + I_{k - 1}))^{-1} D\_ \newline
&#x26; = (-D\_ Q\_)^{-1} D\_ \newline
&#x26; = -Q\_^{-1} D\_^{-1} D\_ \newline
&#x26; = -Q\_^{-1} \newline
&#x26; \eqqcolon -V^{-1} \ _\blacksquare
\end{align*}
$$</p></div>
</details><p>$F$ is called the fundamental matrix (similar to the discrete-time case).</p><details class="group relative px-4 py-3 my-6 border-l-4 text-base border-blue-500 dark:bg-blue-950/5" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-blue-700 dark:text-blue-300" data-lucide="info" viewBox="0 0 24 24"><use href="#info"></use></svg>Note<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-blue-700 dark:text-blue-300" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>If the chain starts in state $i$, the expected time until absorption is the sum of the $i$-th row of $F$.
Thus, the expected times until absorption are given by the matrix product $F1$ of $F$ with a column of 1s.</p></div>
</details></div>
</details>
<details class="group relative px-4 py-3 my-6 border-l-4 text-base border-sky-300 dark:bg-sky-950/10" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-sky-500 dark:text-sky-200" data-lucide="lightbulb" viewBox="0 0 24 24"><use href="#lightbulb"></use></svg>Intuition: Stationary Distribution of the Embedded Markov Chain<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-sky-500 dark:text-sky-200" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>The embedded chain of a continuous-time Markov chain: The discrete-time Markov chain where holding times are ignored.</p><p>The stationary distribution for the embedded chain and for the continuous-time chain are generally not the same!</p><p>However, there is a simple relationship: A probability vector $\pi$ is a stationary distribution for a continuous-time Markov chain if and only if $\psi$ is a stationary distribution for the embedded chain, where $\psi_j = C \pi_j q_j$ for a constant $C$ making the entries sum to 1.</p><details class="group relative px-4 py-3 my-6 border-l-4 text-base border-amber-500 dark:bg-amber-950/10" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-amber-700 dark:text-amber-300" data-lucide="check-square" viewBox="0 0 24 24"><use href="#check-square"></use></svg>Proof: Stationary Distribution of the Embedded Markov Chain<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-amber-700 dark:text-amber-300" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>Using notation as above, we have $\tilde{P} = DQ + I$. For any vector $v$, we get,
$$
v \tilde{P} = v (DQ + I) = v DQ + v.
$$
so $v \tilde{P} = v$ if and only if $v DQ = 0$.</p></div>
</details></div>
</details>
<details class="group relative px-4 py-3 my-6 border-l-4 text-base border-teal-600 dark:bg-teal-950/10" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-teal-700 dark:text-teal-400" data-lucide="book-open" viewBox="0 0 24 24"><use href="#book-open"></use></svg>Definition: Global Balance Equations<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-teal-700 dark:text-teal-400" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>Let $v = (v_1, v_2, \ldots, v_n)$ be the stationary distribution of a continuous-time Markov chain with generator matrix $Q$.
At $v$, the flow into a state must be equal to the flow out of the state, by the definition of stationary distribution.
Which are exactly the equations we get from $v Q = 0$,
$$
(v_1, v_2, \ldots, v_n)
\begin{bmatrix}
-q_1 &#x26; q_{12} &#x26; \cdots &#x26; q_{1n} \newline
q_{21} &#x26; -q_2 &#x26; \cdots &#x26; q_{2n} \newline
\vdots &#x26; \vdots &#x26; \ddots &#x26; \vdots \newline
q_{n1} &#x26; q_{n2} &#x26; \cdots &#x26; -q_n \newline
\end{bmatrix}
$$
Thus, because $vQ = 0$, for each state $j$ we have,
$$
\sum_{i \neq j} v_i q_{ij} = v_j q_j.
$$
This is called the global balance equations.</p><p>One can generalize this to: If $A$ is a set of states, then the long term rates of movement into and out of $A$ are the same,
$$
\sum_{i \in A} \sum_{j \notin A} v_i q_{ij} = \sum_{i \notin A} \sum_{j \in A} v_i q_{ij}.
$$</p></div>
</details>
<details class="group relative px-4 py-3 my-6 border-l-4 text-base border-teal-600 dark:bg-teal-950/10" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-teal-700 dark:text-teal-400" data-lucide="book-open" viewBox="0 0 24 24"><use href="#book-open"></use></svg>Definition: Local Balance Equations and Time-Reversible Chains<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-teal-700 dark:text-teal-400" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>A stronger condition than global balance is local balance. The flow between every pair of states is balanced.</p><p>Formally, an irreducible continuous-time Markov chain with stationary distribution $v$ is said to be time-reversible if, for all states $i$ and $j$,
$$
v_i q_{ij} = v_j q_{ji}.
$$</p><details class="group relative px-4 py-3 my-6 border-l-4 text-base border-blue-500 dark:bg-blue-950/5" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-blue-700 dark:text-blue-300" data-lucide="info" viewBox="0 0 24 24"><use href="#info"></use></svg>Note<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-blue-700 dark:text-blue-300" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>The rate of observed changes from $i$ to $j$ is the same as the rate of observed change from $j$ to $i$.
Thus, this is also called time-reversibility, as the process looks the same when observed backward in time.</p><p>Further, If a probability vector $v$ satisfies the local balance equations, then it is a stationary distribution of the chain.</p></div>
</details></div>
</details>
<details class="group relative px-4 py-3 my-6 border-l-4 text-base border-teal-600 dark:bg-teal-950/10" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-teal-700 dark:text-teal-400" data-lucide="book-open" viewBox="0 0 24 24"><use href="#book-open"></use></svg>Definition: Markov Process on a Tree<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-teal-700 dark:text-teal-400" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>Firstly, a tree is a connected (undirected) graph with no cycles.
Thus, a transition graph gives rise to an undirected graph by connecting all nodes between which there is some rate of transition.
Further, assume that the transition graph of an irreducible continuous-time Markov chain is (or gives rise to) a tree.</p><p>In a tree, any edge between two states divides all states into two groups (disjoint sets), each on each side of the edge.
Thus, the flow must be balanced between across each edge.</p><p>In this scenario, the global balance condition then implies the local balance condition over this edge.</p></div>
</details>
<details class="group relative px-4 py-3 my-6 border-l-4 text-base border-teal-600 dark:bg-teal-950/10" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-teal-700 dark:text-teal-400" data-lucide="book-open" viewBox="0 0 24 24"><use href="#book-open"></use></svg>Definition: Birth-and-Death Process<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-teal-700 dark:text-teal-400" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>A birth-and-death process is a continuous-time Markov chain where the state space is the set of non-negative integers and transitions only occur to neighboring states.
The process is necessarily time-reversible, as the transition graph is a tree (in fact a line, if we further assume irreducibility).</p><p>We denote the births from $i$ to $i + 1$ with $\lambda_i$, and the rate of deaths from $i$ to $i - 1$ with $\mu_i$.
Thus, the generator matrix has the form,
$$
Q =
\begin{bmatrix}
-\lambda_0 &#x26; \lambda_0 &#x26; 0 &#x26; 0 &#x26; \cdots \newline
\mu_1 &#x26; -(\lambda_1 + \mu_1) &#x26; \lambda_1 &#x26; 0 &#x26; \cdots \newline
0 &#x26; \mu_2 &#x26; -(\lambda_2 + \mu_2) &#x26; \lambda_2 &#x26; \cdots \newline
0 &#x26; 0 &#x26; \mu_3 &#x26; -(\lambda_3 + \mu_3) &#x26; \cdots \newline
\vdots &#x26; \vdots &#x26; \vdots &#x26; \vdots &#x26; \ddots \newline
\end{bmatrix}
$$
where $\lambda_i, \mu_i > 0$ for all $i \geq 0$.</p><p>Provided that $\sum_{k = 1}^{\infty} \prod_{i = 1}^{k} \frac{\lambda_{i - 1}}{\mu_{i}} &#x3C; \infty$, (i.e., the stationary distribution exists), the stationary distribution is given by,
$$
\begin{align*}
v_k &#x26; = v_0 \prod_{i = 1}^{k} \frac{\lambda_{i - 1}}{\mu_i}, \newline
v_0 &#x26; = \left(1 + \sum_{k = 1}^{\infty} \prod_{i = 1}^{k} \frac{\lambda_{i - 1}}{\mu_i}\right)^{-1}. \newline
\end{align*}
$$</p><details class="group relative px-4 py-3 my-6 border-l-4 text-base border-amber-500 dark:bg-amber-950/10" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-amber-700 dark:text-amber-300" data-lucide="check-square" viewBox="0 0 24 24"><use href="#check-square"></use></svg>Proof: Stationary Distribution of Birth-and-Death Processes<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-amber-700 dark:text-amber-300" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>Using the local balance equations, we have,
$$
\begin{align*}
v_k \lambda_k &#x26; = v_{k + 1} \mu_{k + 1}, \newline
\end{align*}
$$
which gives,
$$
\begin{align*}
v_{k + 1} &#x26; = v_k \frac{\lambda_k}{\mu_{k + 1}} \newline
&#x26; = v_0 \prod_{i = 1}^{k + 1} \frac{\lambda_{i - 1}}{\mu_i}. \newline
\end{align*}
$$
Further, as $v$ is a probability vector, we have,
$$
\begin{align*}
1 &#x26; = \sum_{k = 0}^{\infty} v_k \newline
&#x26; = v_0 \left(1 + \sum_{k = 1}^{\infty} \prod_{i = 1}^{k} \frac{\lambda_{i - 1}}{\mu_i}\right). \newline
&#x26; \Rightarrow v_0 = \left(1 + \sum_{k = 1}^{\infty} \prod_{i = 1}^{k} \frac{\lambda_{i - 1}}{\mu_i}\right)^{-1}. \newline
\end{align*}
$$
Thus, the proof is complete. $_\blacksquare$</p></div>
</details></div>
</details>
<details class="group relative px-4 py-3 my-6 border-l-4 text-base border-teal-600 dark:bg-teal-950/10" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-teal-700 dark:text-teal-400" data-lucide="book-open" viewBox="0 0 24 24"><use href="#book-open"></use></svg>Definition: Brownian Motion<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-teal-700 dark:text-teal-400" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>Brownian motion is a continuous-time stochastic process $\{B_t\}_{t \geq 0}$ with the following properties:</p><ol>
<li>
<p>$B_0 = 0$.</p>
</li>
<li>
<p>For $t >0$, $B_t \sim \mathcal{N}(0, t)$ (i.e., normally distributed with mean $0$ and variance $t$).</p>
</li>
<li>
<p>For $s, t > 0$, $B_{t + s} - B_s \sim \mathcal{N}(0, t)$ (i.e., the increments are stationary).</p>
</li>
<li>
<p>For $0 \leq q &#x3C; r \leq s &#x3C; t$, $B_t - B_s$ is independent of $B_r - B_q$ (i.e., the increments are independent).</p>
</li>
<li>
<p>The function $t \mapsto B_t$ is continuous with probability $1$ (almost surely).</p>
</li>
</ol></div>
</details>
<details class="group relative px-4 py-3 my-6 border-l-4 text-base border-sky-300 dark:bg-sky-950/10" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-sky-500 dark:text-sky-200" data-lucide="lightbulb" viewBox="0 0 24 24"><use href="#lightbulb"></use></svg>Intuition: Brownian Motion as Limit of Random Walks<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-sky-500 dark:text-sky-200" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>A random walk is a discrete-time Markov chain $S_0, S_1, S_2, \ldots$ where $S_0 = 0$ and,
$$
S_n = Y_1 + Y_2 + \ldots + Y_n,
$$
and $Y_1, Y_2, \ldots$ are i.i.d. random variables. Assume $\mathbb{E}[Y_i] = 0$.</p><p>Further, if we assume $\mathrm{Var}(Y_i) = 1$, we get $\mathrm{Var}(S_n) = n$.</p><p>Interpolating between the values $S_n$ we can make this into a continuous-time process $S_t$ where $\mathrm{Var}(S_t) \approx t$.</p><p>We may scale with an $s > 0$ to get processes $S_t^{(s)} = \frac{S_{st}}{\sqrt{s}}$ where we get $\lim_{s \to \infty} \mathrm{Var}(S_t^{(s)}) = t$.</p><p>It turns out that the processes $S_t^{(s)}$ when $s \to \infty$ are exactly Brownian motion, no matter what type of $Y_i$ we start with.</p><p>This is the Donskerâ€™s invariance principle, which is a generalization of the central limit theorem to stochastic processes <sup><a href="#user-content-fn-2" id="user-content-fnref-2" data-footnote-ref="" aria-describedby="footnote-label">1</a></sup>.</p></div>
</details>
<details class="group relative px-4 py-3 my-6 border-l-4 text-base border-teal-600 dark:bg-teal-950/10" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-teal-700 dark:text-teal-400" data-lucide="book-open" viewBox="0 0 24 24"><use href="#book-open"></use></svg>Definition: Gaussian Process<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-teal-700 dark:text-teal-400" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>A Gaussian process is a continuous-time stochastic process $\{X_t\}_{t \geq 0}$ with the property that for all $n \geq 1$ and $0 \leq t_1 &#x3C; t_2 &#x3C; \ldots &#x3C; t_n$, $X_{t_1}, X_{t_2}, \ldots, X_{t_n}$ have a multivariate normal distribution.</p><p>Thus, a Gaussian process is completely determined by its mean function $\mathbb{E}[X_t]$ and its covariance function $\mathrm{Cov}(X_s, X_t)$.</p></div>
</details>
<details class="group relative px-4 py-3 my-6 border-l-4 text-base border-sky-300 dark:bg-sky-950/10" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-sky-500 dark:text-sky-200" data-lucide="lightbulb" viewBox="0 0 24 24"><use href="#lightbulb"></use></svg>Intuition: Brownian Motion as a Gaussian Process<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-sky-500 dark:text-sky-200" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>Brownian motion is a Gaussian process, as we can show that any $a_1 B_{t_1} + a_2 B_{t_2} + \ldots + a_n B_{t_n}$ is normally distributed.</p><p>A Gaussian process $\{X_t\}_{t \geq 0}$ is a Brownian motion if and only if,</p><ol>
<li>
<p>$X_0 = 0$.</p>
</li>
<li>
<p>$\mathbb{E}[X_t] = 0$ for all $t$.</p>
</li>
<li>
<p>$\mathrm{Cov}(X_s, X_t) = \min(s, t)$ for all $s, t$.</p>
</li>
<li>
<p>The function $t \mapsto X_t$ is continuous with probability $1$ (almost surely).</p>
</li>
</ol></div>
</details>
<details class="group relative px-4 py-3 my-6 border-l-4 text-base border-sky-300 dark:bg-sky-950/10" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-sky-500 dark:text-sky-200" data-lucide="lightbulb" viewBox="0 0 24 24"><use href="#lightbulb"></use></svg>Intuition: Transformations of Brownian Motion<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-sky-500 dark:text-sky-200" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>The following transformations of Brownian motion also yield Brownian motion:</p><ul>
<li>$\{-B_t\}_{t \geq 0}$, negating the process yields another (reflected) Brownian motion.</li>
<li>$\{B_{t + s} - B_s\}_{t \geq 0}$ for any fixed $s \geq 0$, shifting the time origin yields another Brownian motion.</li>
<li>$\{\frac{1}{\sqrt{a}} B_{a t}\}_{t \geq 0}$ for any fixed $a > 0$, scaling time and space yields another Brownian motion.</li>
<li>The process $\{X_t\}_{t \geq 0}$ where $X_0 = 0$ and $X_t = t B_{\frac{1}{t}}$ for $t > 0$, time inversion yields another Brownian motion.</li>
</ul></div>
</details>
<details class="group relative px-4 py-3 my-6 border-l-4 text-base border-sky-300 dark:bg-sky-950/10" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-sky-500 dark:text-sky-200" data-lucide="lightbulb" viewBox="0 0 24 24"><use href="#lightbulb"></use></svg>Intuition: Stopping Times<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-sky-500 dark:text-sky-200" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>We saw above that, for any fixed $t$ $(B_{t + s} - B_s)_{t \geq 0}$ is a Brownian motion.
Does this phenomenon also hold if we start the chain anew from $T$ when $T$ is random? It depends.</p><p>If $T$ is the largest value less than 1 where $B_T = 0$, then $(B_{T + s} - B_T)_{s \geq 0}$ is not a Brownian motion.</p><p>If $T$ is the smallest value where $B_T = a$ for some constant $a$, then $(B_{T + s} - B_T)_{s \geq 0}$ is a Brownian motion.
The reason is that the event $T = t$ can be determined based on $B_r$ where $0 \leq r \leq t$.</p><p>Random $T$â€˜s that have this property are called stopping times. For these $B_{T + s} - B_T$ is a Brownian motion.</p></div>
</details>
<details class="group relative px-4 py-3 my-6 border-l-4 text-base border-sky-300 dark:bg-sky-950/10" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-sky-500 dark:text-sky-200" data-lucide="lightbulb" viewBox="0 0 24 24"><use href="#lightbulb"></use></svg>Intuition: The Distribution of the First Hitting Time<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-sky-500 dark:text-sky-200" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>Given that $a \neq 0$, what is the distribution of the first hitting time $T_a = \min\{t : B_t = a\}$?</p><p>We will prove that,
$$
\frac{1}{T_a} \sim \mathrm{Gamma}\left(\frac{1}{2}, \frac{a^2}{2}\right).
$$</p><p>Assuming that $a > 0$ and using that $T_a$ is a stopping time we get for any $t > 0$ that $P(B_{\frac{1}{t}} > a \mid T_a &#x3C; \frac{1}{t}) = P(B_{\frac{1}{t} - T_a} > 0) = \frac{1}{2}$.</p><p>We also have,
$$
\begin{align*}
P(B_{\frac{1}{t}} > a \mid T_a &#x3C; \frac{1}{t}) &#x26; = \frac{P(B_{\frac{1}{t}} > a, T_a &#x3C; \frac{1}{t})}{P(T_a &#x3C; \frac{1}{t})} \newline
&#x26; = \frac{P(B_{\frac{1}{t}} > a)}{P(T_a &#x3C; \frac{1}{t})}.
\end{align*}
$$
Further, it follows that $P(T_a &#x3C; \frac{1}{t}) = 2 P(B_{\frac{1}{t}} > a)$ and thus,
$$
\begin{align*}
P\left(\frac{1}{T_a} \leq t\right) &#x26; = 2 P\left(B_{\frac{1}{t}} > a\right) -1 \newline
&#x26; = 2 P(B_1 \leq a \sqrt{t}) - 1 \newline
\end{align*}
$$
Taking the derivative with respect to $t$ we get the Gamma density,
$$
\pi_{1/T_a}(t) = 2 \frac{1}{\sqrt{2 \pi}} \exp\left(-\frac{1}{2} \left(a \sqrt{t}\right)^2\right) \frac{a}{2} t^{-1/2}.
$$</p></div>
</details>
<details class="group relative px-4 py-3 my-6 border-l-4 text-base border-sky-300 dark:bg-sky-950/10" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-sky-500 dark:text-sky-200" data-lucide="lightbulb" viewBox="0 0 24 24"><use href="#lightbulb"></use></svg>Intuition: Maximum of Brownian Motion<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-sky-500 dark:text-sky-200" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>We can define $M_t \coloneqq \max_{0 \leq s \leq t} B_s$.</p><p>We may compute for $a > 0$ (using the results above),
$$
\begin{align*}
P(M_t > a) &#x26; = P(T_a &#x3C; t) \newline
&#x26; = 2 P(B_t > a) \newline
&#x26; = P(|B_t| > a).
\end{align*}
$$
Thus, $M_t$ has the same d istribution as $|B_t|$, i.e., the absolute value of $B_t$.</p></div>
</details>
<details class="group relative px-4 py-3 my-6 border-l-4 text-base border-sky-300 dark:bg-sky-950/10" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-sky-500 dark:text-sky-200" data-lucide="lightbulb" viewBox="0 0 24 24"><use href="#lightbulb"></use></svg>Intuition: Zeroes of Brownian Motion<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-sky-500 dark:text-sky-200" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>Let $L$ be the last zero in $(0, 1)$ of a Brownian motion. (i.e., $L = \max \ \{t : 0 &#x3C; t &#x3C; 1, B_t = 0\}$.
Then,
$$
L \sim \mathrm{Beta}\left(\frac{1}{2}, \frac{1}{2}\right).
$$</p><details class="group relative px-4 py-3 my-6 border-l-4 text-base border-amber-500 dark:bg-amber-950/10" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-amber-700 dark:text-amber-300" data-lucide="check-square" viewBox="0 0 24 24"><use href="#check-square"></use></svg>Proof: Outline of Proof<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-amber-700 dark:text-amber-300" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>$$
\begin{align*}
P(L > s) &#x26; = \int_{-\infty}^{\infty} P(L > s \mid B_s = t) \ \mathcal{N}(t; 0, s) \ dt \newline
&#x26; = 2 \int_{-\infty}^{0} P(L > s \mid B_s = t) \ \mathcal{N}(t; 0, s) \ dt \newline
&#x26; = 2 \int_{-\infty}^{0} P(M_{1 - s} > -t) \ \mathcal{N}(t; 0, s) \ dt \newline
&#x26; = 2 \int_{0}^{\infty} 2 P(B_{1 - s} > t) \ \mathcal{N}(t; 0, s) \ dt \newline
&#x26; = 4 \int_{0}^{\infty} \int_{t}^{\infty} \mathcal{N}(r; 0, 1 - s) \ \mathcal{N}(t; 0, s) \ dr \ dt \newline
&#x26; = \ldots \newline
&#x26; = \frac{1}{\pi} \int_s^1 \frac{1}{\sqrt{x(1 - x)}} \ dx \newline
&#x26; = \int_s^1 \mathrm{Beta}\left(x; \frac{1}{2}, \frac{1}{2}\right) \ dx. \newline
\end{align*}
$$
We can then, let $L_t$ be the last zero in $(0, t)$. Then,
$$
\frac{L_t}{t} \sim \mathrm{Beta}\left(\frac{1}{2}, \frac{1}{2}\right).
$$</p></div>
</details><details class="group relative px-4 py-3 my-6 border-l-4 text-base border-blue-500 dark:bg-blue-950/5" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-blue-700 dark:text-blue-300" data-lucide="info" viewBox="0 0 24 24"><use href="#info"></use></svg>Note<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-blue-700 dark:text-blue-300" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>The probability that a Brownian motion has at least one zero in $(r, t)$ for $0 \leq r &#x3C; t$ is $1 - P(L_t &#x3C; r)$.</p><p>Further, the cumulative distribution for the $\mathrm{Beta}\left(\frac{1}{2}, \frac{1}{2}\right)$ density can be computed with the arcsin function,
$$
P(L_t &#x3C; r) = \int_0^{\frac{r}{t}} \mathrm{Beta}\left(s; \frac{1}{2}, \frac{1}{2}\right) \ ds = \frac{2}{\pi} \arcsin\left(\sqrt{\frac{r}{t}}\right).
$$</p></div>
</details></div>
</details>
<details class="group relative px-4 py-3 my-6 border-l-4 text-base border-teal-600 dark:bg-teal-950/10" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-teal-700 dark:text-teal-400" data-lucide="book-open" viewBox="0 0 24 24"><use href="#book-open"></use></svg>Definition: Brownian Bridge<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-teal-700 dark:text-teal-400" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>Define a Gaussian process $X_t$ by conditioning a Brownian motion $B_t$ on $B_1 = 0$. Then $X_t$ is a Brownian bridge.</p><p>If $0 &#x3C; s &#x3C; t &#x3C; 1$, then $(B_s, B_t, B_1)$ is a multivariate normal with,
$$
\begin{align*}
\mathbb{E}[(B_s, B_t, B_1)] &#x26; = (0, 0, 0) \newline
\mathrm{Var}((B_s, B_t, B_1)) &#x26; = \Sigma =
\begin{pmatrix}
s &#x26; s &#x26; s \newline
s &#x26; t &#x26; t \newline
s &#x26; t &#x26; 1 \newline
\end{pmatrix}. \newline
\end{align*}
$$
Conditioning on $B_1 = 0$ and using the properties of the multivariate normal we get that $\mathbb{E}[X_t] = 0$ and,
$$
\mathrm{Cov}(X_s, X_t) = s(1 - t) = s - st.
$$
It follows that this is identical to the Brownian bridge defined above.</p></div>
</details>
<details class="group relative px-4 py-3 my-6 border-l-4 text-base border-teal-600 dark:bg-teal-950/10" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-teal-700 dark:text-teal-400" data-lucide="book-open" viewBox="0 0 24 24"><use href="#book-open"></use></svg>Definition: Brownian Motion with Drift<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-teal-700 dark:text-teal-400" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>For any real $\mu > 0$ and $\sigma > 0$ we can define the Gaussian process $X_t$ as,
$$
X_t = \mu t + \sigma B_t.
$$
This is a Brownian motion with a draft, and is often a more useful model than standard Brownian motion.</p><details class="group relative px-4 py-3 my-6 border-l-4 text-base border-blue-500 dark:bg-blue-950/5" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-blue-700 dark:text-blue-300" data-lucide="info" viewBox="0 0 24 24"><use href="#info"></use></svg>Note<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-blue-700 dark:text-blue-300" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>Note that $X_t$ is Normal with expectation $\mu t$ and variance $\sigma^2 t$.</p></div>
</details><p>This is a Gaussian process with continuous paths and stationary and independent increments.</p></div>
</details>
<details class="group relative px-4 py-3 my-6 border-l-4 text-base border-teal-600 dark:bg-teal-950/10" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-teal-700 dark:text-teal-400" data-lucide="book-open" viewBox="0 0 24 24"><use href="#book-open"></use></svg>Definition: Geometric Brownian Motion<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-teal-700 dark:text-teal-400" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>The stochastic process,
$$
G_t = G_0 e^{\mu t + \sigma B_t},
$$
where $G_0 > 0 $ is called a geometric Brownian motion with drift parameter $\mu$ and variance parameter $\sigma^2$.</p><p>$\log(G_t)$ is a Gaussian process with expectation $\log(G_0) + \mu t$ and variance $\sigma^2 t$.</p><details class="group relative px-4 py-3 my-6 border-l-4 text-base border-blue-500 dark:bg-blue-950/5" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-blue-700 dark:text-blue-300" data-lucide="info" viewBox="0 0 24 24"><use href="#info"></use></svg>Note<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-blue-700 dark:text-blue-300" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>One can show that,
$$
\begin{align*}
\mathbb{E}[G_t] &#x26; = G_0 e^{t(\mu + \frac{1}{2} \sigma^2)} \newline
\mathrm{Var}(G_t) &#x26; = G_0^2 e^{2 t(\mu + \sigma^2)} (e^{\sigma^2 t} - 1). \newline
\end{align*}
$$</p><details class="group relative px-4 py-3 my-6 border-l-4 text-base border-amber-500 dark:bg-amber-950/10" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-amber-700 dark:text-amber-300" data-lucide="check-square" viewBox="0 0 24 24"><use href="#check-square"></use></svg>Proof<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-amber-700 dark:text-amber-300" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>Using that $\log(G_t) \sim \mathcal{N}(\log(G_0) + \mu t, \sigma^2 t)$ we have,
$$
\begin{align*}
\mathbb{E}[G_t] &#x26; = \mathbb{E}[e^{\log(G_t)}] \newline
&#x26; = \int_{-\infty}^{\infty} e^x \ \mathcal{N}(x; \log(G_0) + \mu t, \sigma^2 t) \ dx \newline
&#x26; = \int_{-\infty}^{\infty} \frac{1}{\sqrt{2 \pi \sigma^2 t}} \exp\left(-\frac{(x - (\log(G_0) + \mu t))^2}{2 \sigma^2 t} + x\right) \ dx \newline
&#x26; = \int_{-\infty}^{\infty} \frac{1}{\sqrt{2 \pi \sigma^2 t}} \exp\left(-\frac{(x - (\log(G_0) + \mu t - \sigma^2 t))^2}{2 \sigma^2 t} + \log(G_0) + \mu t + \frac{1}{2} \sigma^2 t\right) \ dx \newline
&#x26; = e^{\log(G_0) + \mu t + \frac{1}{2} \sigma^2 t} \int_{-\infty}^{\infty} \frac{1}{\sqrt{2 \pi \sigma^2 t}} \exp\left(-\frac{(x - (\log(G_0) + \mu t - \sigma^2 t))^2}{2 \sigma^2 t}\right) \ dx \newline
&#x26; = e^{\log(G_0) + \mu t + \frac{1}{2} \sigma^2 t} \newline
&#x26; = G_0 e^{t(\mu + \frac{1}{2} \sigma^2)}. \newline
\end{align*}
$$
Similarly, we can compute $\mathbb{E}[G_t^2]$ and use $\mathrm{Var}(G_t) = \mathbb{E}[G_t^2] - (\mathbb{E}[G_t])^2$ to get the variance,
$$
\begin{align*}
\mathbb{E}[G_t^2] &#x26; = \mathbb{E}[e^{2 \log(G_t)}] \newline
&#x26; = \int_{-\infty}^{\infty} e^{2x} \ \mathcal{N}(x; \log(G_0) + \mu t, \sigma^2 t) \ dx \newline
&#x26; = \int_{-\infty}^{\infty} \frac{1}{\sqrt{2 \pi \sigma^2 t}} \exp\left(-\frac{(x - (\log(G_0) + \mu t))^2}{2 \sigma^2 t} + 2x\right) \ dx \newline
&#x26; = \int_{-\infty}^{\infty} \frac{1}{\sqrt{2 \pi \sigma^2 t}} \exp\left(-\frac{(x - (\log(G_0) + \mu t - 2 \sigma^2 t))^2}{2 \sigma^2 t} + \log(G_0) + \mu t + 2 \sigma^2 t\right) \ dx \newline
&#x26; = e^{\log(G_0) + \mu t + 2 \sigma^2 t} \int_{-\infty}^{\infty} \frac{1}{\sqrt{2 \pi \sigma^2 t}} \exp\left(-\frac{(x - (\log(G_0) + \mu t - 2 \sigma^2 t))^2}{2 \sigma^2 t}\right) \ dx \newline
&#x26; = e^{\log(G_0) + \mu t + 2 \sigma^2 t} \newline
&#x26; = G_0^2 e^{t(2 \mu + 2 \sigma^2)}. \newline
\end{align*}
$$
Thus,
$$
\begin{align*}
\mathrm{Var}(G_t) &#x26; = G_0^2 e^{t(2 \mu + 2 \sigma^2)} - \left(G_0 e^{t(\mu + \frac{1}{2} \sigma^2)}\right)^2 \newline
&#x26; = G_0^2 e^{2 t(\mu + \sigma^2)} (e^{\sigma^2 t} - 1). \newline
\end{align*}
$$
$_\blacksquare$</p></div>
</details></div>
</details></div>
</details>
<details class="group relative px-4 py-3 my-6 border-l-4 text-base border-sky-300 dark:bg-sky-950/10" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-sky-500 dark:text-sky-200" data-lucide="lightbulb" viewBox="0 0 24 24"><use href="#lightbulb"></use></svg>Intuition: Stock Options<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-sky-500 dark:text-sky-200" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>A (European) stock option is a right (but not an obligation) to buy a stock at a given time $t$ in the future for a given price $K$.</p><p>How much can you expect to earn from a stock option at that future time?</p><p>We get that (we will derive this),
$$
\mathbb{E}[\max(G_t - K, 0)] = G_0 e^{t(\mu + \frac{\sigma^2}{2})} P\left(B_1 > \frac{\beta - \sigma t}{\sqrt{t}}\right) - K P\left(B_1 > \frac{\beta}{\sqrt{t}}\right),
$$
where $\beta = \frac{\log(K / G_0) - \mu t}{\sigma}$.</p><details class="group relative px-4 py-3 my-6 border-l-4 text-base border-emerald-500 dark:bg-emerald-950/10" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-emerald-600 dark:text-emerald-300" data-lucide="pen-tool" viewBox="0 0 24 24"><use href="#pen-tool"></use></svg>Derivation<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-emerald-600 dark:text-emerald-300" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>Firstly, we need to prove the algebraic identity,
$$
e^{\sigma x} \mathcal{N}(x; 0, t) = e^{\frac{\sigma^2 t}{2}} \mathcal{N}(x; \sigma t, t).
$$</p><details class="group relative px-4 py-3 my-6 border-l-4 text-base border-amber-500 dark:bg-amber-950/10" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-amber-700 dark:text-amber-300" data-lucide="check-square" viewBox="0 0 24 24"><use href="#check-square"></use></svg>Proof<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-amber-700 dark:text-amber-300" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>We have,
$$
\begin{align*}
e^{\sigma x} \mathcal{N}(x; 0, t) &#x26; = \frac{1}{\sqrt{2 \pi t}} \exp\left(-\frac{x^2}{2 t} + \sigma x\right) \newline
&#x26; = \frac{1}{\sqrt{2 \pi t}} \exp\left(-\frac{(x - \sigma t)^2}{2 t} + \frac{\sigma^2 t}{2}\right) \newline
&#x26; = e^{\frac{\sigma^2 t}{2}} \mathcal{N}(x; \sigma t, t). \ _\blacksquare
\end{align*}
$$
Then, defining $\beta = \frac{\log(K / G_0) - \mu t}{\sigma}$ we get,
$$
\begin{align*}
\mathbb{E}[\max(G_t - K, 0)] &#x26; \coloneqq \mathbb{E}[\max(G_0 e^{\mu t + \sigma B_t} - K, 0)] \newline
&#x26; = \int_{-\infty}^{\infty} \max(G_0 e^{\mu t + \sigma x} - K, 0) \ \mathcal{N}(x; 0, t) \ dx \newline
&#x26; = \int_{\beta}^{\infty} (G_0 e^{\mu t + \sigma x} - K) \ \mathcal{N}(x; 0, t) \ dx \newline
&#x26; = G_0 e^{\mu t} \int_{\beta}^{\infty} e^{\sigma x} \ \mathcal{N}(x; 0, t) \ dx - K \int_{\beta}^{\infty} \mathcal{N}(x; 0, t) \ dx \newline
&#x26; = G_0 e^{t(\mu + \frac{\sigma^2}{2})} \int_{\beta}^{\infty} \mathcal{N}(x; \sigma t, t) \ dx - K \int_{\beta}^{\infty} \mathcal{N}(x; 0, t) \ dx \newline
&#x26; = G_0 e^{t(\mu + \frac{\sigma^2}{2})} P\left(B_1 > \frac{\beta - \sigma t}{\sqrt{t}}\right) - K P\left(B_1 > \frac{\beta}{\sqrt{t}}\right). \ _\blacksquare
\end{align*}
$$</p></div>
</details></div>
</details></div>
</details>
<details class="group relative px-4 py-3 my-6 border-l-4 text-base border-teal-600 dark:bg-teal-950/10" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-teal-700 dark:text-teal-400" data-lucide="book-open" viewBox="0 0 24 24"><use href="#book-open"></use></svg>Definition: Martingale<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-teal-700 dark:text-teal-400" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>A stochastic process $\{Y_t\}_{t \geq 0}$ is a martingale if for $t \geq 0$,</p><ul>
<li>$\mathbb{E}[Y_t \mid Y_r, 0 \leq r \leq s] = Y_s$ for $0 \leq s \leq t$.</li>
<li>$\mathbb{E}[|Y_t|] &#x3C; \infty$.
A Brownian motion $B_t$ is a martingale.</li>
</ul><details class="group relative px-4 py-3 my-6 border-l-4 text-base border-amber-500 dark:bg-amber-950/10" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-amber-700 dark:text-amber-300" data-lucide="check-square" viewBox="0 0 24 24"><use href="#check-square"></use></svg>Proof<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-amber-700 dark:text-amber-300" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>We have,
$$
\begin{align*}
\mathbb{E}[B_t \mid B_r, 0 \leq r \leq s] &#x26; = \mathbb{E}[B_t - B_s + B_s \mid B_r, 0 \leq r \leq s] \newline
&#x26; = \mathbb{E}[B_t - B_s \mid B_r, 0 \leq r \leq s] + \mathbb{E}[B_s \mid B_r, 0 \leq r \leq s] \newline
&#x26; = 0 + B_s \newline
&#x26; = B_s.
\end{align*}
$$
and,
$$
\begin{align*}
\mathbb{E}[|B_t|] &#x26; = \int_{-\infty}^{\infty} |x| \ \mathcal{N}(x; 0, t) \ dx \newline
&#x26; = 2 \int_{0}^{\infty} x \ \mathcal{N}(x; 0, t) \ dx \newline
&#x26; = 2 \int_{0}^{\infty} x \ \frac{1}{\sqrt{2 \pi t}} \exp\left(-\frac{x^2}{2 t}\right) \ dx \newline
&#x26; = 2 \cdot \frac{1}{\sqrt{2 \pi t}} \cdot t \newline
&#x26; = \sqrt{\frac{2 t}{\pi}} &#x3C; \infty. \newline
\end{align*}
$$</p></div>
</details><p>Further, one can define a martingale with respect to other stochastic processes.</p><p>$\{Y_t\}_{t \geq 0}$ is a martingale with respect to $\{X_t\}_{t \geq 0}$ if for $t \geq 0$,</p><ul>
<li>$\mathbb{E}[Y_t \mid X_r, 0 \leq r \leq s] = Y_s$ for $0 \leq s \leq t$.</li>
<li>$\mathbb{E}[|Y_t|] &#x3C; \infty$.</li>
</ul></div>
</details>
<details class="group relative px-4 py-3 my-6 border-l-4 text-base border-emerald-500 dark:bg-emerald-950/10" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-emerald-600 dark:text-emerald-300" data-lucide="pen-tool" viewBox="0 0 24 24"><use href="#pen-tool"></use></svg>Derivation: Geometric Brownian Motion can be a Martingale<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-emerald-600 dark:text-emerald-300" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>Let $G_t \coloneqq G_0 e^{\mu t + \sigma B_t}$ be a geometric Brownian motion.
We can derive that,
$$
\begin{align*}
\mathbb{E}[G_t \mid B_r, 0 \leq r \leq s] &#x26; \coloneqq \mathbb{E}[G_0 e^{\mu t + \sigma B_t} \mid B_r, 0 \leq r \leq s] \newline
&#x26; = \mathbb{E}[G_0 e^{\mu(t - s) + \sigma (B_t - B_s) + \mu s + \sigma B_s} e^{\mu s + \sigma B_s} \mid B_r, 0 \leq r \leq s] \newline
&#x26; = \mathbb{E}[G_{t - s}] e^{\mu s + \sigma B_s} \newline
&#x26; = G_0 e^{(t - s)(\mu + \frac{\sigma^2}{2})} e^{\mu s + \sigma B_s}. \newline
&#x26; = G_s e^{(t - s)(\mu + \frac{\sigma^2}{2})}. \newline
\end{align*}
$$
We see that $G_t$ is a martingale with respect to $B_t$ if and only if $\mu + \frac{\sigma^2}{2} = 0$, i.e., $\mu = -\frac{\sigma^2}{2}$.</p></div>
</details>
<h3 id="examples">Examples</h3>
<details class="group relative px-4 py-3 my-6 border-l-4 text-base border-sky-500 dark:bg-sky-950/10" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-sky-600 dark:text-sky-300" data-lucide="code" viewBox="0 0 24 24"><use href="#code"></use></svg>Example: Toy Example of MCMC<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-sky-600 dark:text-sky-300" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>Consider the Markov chain $X_0, X_1, \ldots$ with states $\{0, 1, 2\}$ and with,
$$
P =
\begin{bmatrix}
0.99 &#x26; 0.01 &#x26; 0 \newline
0 &#x26; 0.9 &#x26; 0.1 \newline
0.2 &#x26; 0 &#x26; 0.8
\end{bmatrix}
$$
One can find that the limiting distribution is $v = (\frac{20}{23}, \frac{2}{23}, \frac{1}{23})$.</p><p>Consider the function $r(x) = x^5$. If $X$ is a random variable with the limiting distribution,
$$
\mathbb{E}[r(X)] = 0^5 \cdot \frac{20}{23} + 1^5 \cdot \frac{2}{23} + 2^5 \cdot \frac{1}{23} = \frac{34}{23} = 1.4783
$$
If $Y_1, \ldots, Y_n$ are all i.i.d variables with the limiting distribution, we can check numerically that,
$$
\lim_{n \to \infty} \frac{r(Y_1) + r(Y_2) + \ldots + r(Y_n)}{n} = 1.4783
$$
We also get for $X_0, X_1, \ldots$ that,
$$
\lim_{n \to \infty} \frac{r(X_1) + r(X_2) + \ldots + r(X_n)}{n} = 1.4783
$$
but in this case the limit is approached more slowly.</p></div>
</details>
<details class="group relative px-4 py-3 my-6 border-l-4 text-base border-sky-500 dark:bg-sky-950/10" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-sky-600 dark:text-sky-300" data-lucide="code" viewBox="0 0 24 24"><use href="#code"></use></svg>Example: Counting Zeroes<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-sky-600 dark:text-sky-300" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>How many zeroes does $B_t$ have in the interval $(0, s)$?</p><p>If $L_s$ is the last zero in $(0, s)$, we saw that,
$$
\frac{L_s}{s} \sim \mathrm{Beta}\left(\frac{1}{2}, \frac{1}{2}\right),
$$
which means that, with probability one, there exists a zero in the interval $(0, s)$ and for the last zero $L_s$ we have $0 &#x3C; L_s &#x3C; s$.</p><p>Repeating the argument, we have that $0 &#x3C; L_{L_s} &#x3C; L_s$ with probability one, and thus there exists another zero in $(0, L_s) \subset (0, s)$.</p><p>The conclusion is that, with probability one, there is an infinite number of zeroes in $(0, s)$ for any $s > 0$.</p></div>
</details>
<details class="group relative px-4 py-3 my-6 border-l-4 text-base border-sky-500 dark:bg-sky-950/10" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-sky-600 dark:text-sky-300" data-lucide="code" viewBox="0 0 24 24"><use href="#code"></use></svg>Example: Simulating from the Ising Model using Perfect Sampling<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-sky-600 dark:text-sky-300" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>We saw above how to use Gibbs sampling to simulate from the Ising model. We then simulated from the conditional distributions, using,
$$
\pi(\sigma_v^{\star} = 1 \mid \sigma_{-v}) = \ldots = \frac{1}{1 + \exp(-2 \beta \sum_{v \sim w} \sigma_w)}
$$
Now, we extend this method into a perfect sampling.</p><p>Define the partial ordering on configurations $\sigma, \tau$ be defining,
$$
\sigma \leq \tau \iff \sigma_v \leq \tau_v \text{ for all vertices } v
$$
We have minimal and maximal elements $m = (-1, \ldots, -1)$ and $M = (1, \ldots, 1)$.</p><details class="group relative px-4 py-3 my-6 border-l-4 text-base border-blue-500 dark:bg-blue-950/5" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-blue-700 dark:text-blue-300" data-lucide="info" viewBox="0 0 24 24"><use href="#info"></use></svg>Note<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-blue-700 dark:text-blue-300" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>iF $\sigma \leq \tau$, then for all $v$ $\pi(\sigma_v^{\star} = 1 \mid \sigma_{-v}) \leq \pi(\tau_v^{\star} = 1 \mid \tau_{-v})$.</p></div>
</details><p>Defining $g(\sigma, U)_v = 2 I (U \leq \pi(\sigma_v^{\star} = 1 \mid \sigma_{-v}) ) - 1$, makes $g$ monotone.</p><p>Given an Ising model with $\beta > 0$, start with choosing an integer $n > 0$ and setting configurations,
$$
\begin{align*}
\sigma^{(-n)} &#x26; = m = (-1, \ldots, -1) \newline
\tau^{(-n)} &#x26; = M = (1, \ldots, 1) \newline
\end{align*}
$$</p><details class="group relative px-4 py-3 my-6 border-l-4 text-base border-emerald-600 dark:bg-emerald-950/10" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-emerald-700 dark:text-emerald-300" data-lucide="cpu" viewBox="0 0 24 24"><use href="#cpu"></use></svg>Algorithm: Perfect Sampling for the Ising Model<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-emerald-700 dark:text-emerald-300" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><ul>
<li>
<p>For $i = -n +1, \ldots, 0$ set $\sigma^{(i)} = \sigma^{(i - 1)}$, $\tau^{(i)} = \tau^{(i - 1)}$ and then,</p>
<ul>
<li>Looping through all vertices $v$:
<ul>
<li>Compute $\pi(\sigma_v^{\star} = 1 \mid \sigma_{-v}^{(i)})$ and $\pi(\tau_v^{\star} = 1 \mid \tau_{-v}^{(i)})$.</li>
<li>Simulate $U \sim \mathrm{Uniform}(0, 1)$.</li>
<li>Update $\sigma_v^{(i)} = g(\sigma^{(i)}, U)_v$ and $\tau_v^{(i)} = g(\tau^{(i)}, U)_v$.</li>
</ul>
</li>
</ul>
</li>
<li>
<p>If $\sigma^{(0)} = \tau^{(0)}$, this is the result. Otherwise, double $n$ and repeat.</p>
</li>
</ul></div>
</details></div>
</details>
<details class="group relative px-4 py-3 my-6 border-l-4 text-base border-sky-500 dark:bg-sky-950/10" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-sky-600 dark:text-sky-300" data-lucide="code" viewBox="0 0 24 24"><use href="#code"></use></svg>Example: Using a Binomial Likelihood<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-sky-600 dark:text-sky-300" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>Assume the offspring process is $\mathrm{Binomial}(N, p)$ for some parameter $p$ and a fixed (known) $N$.
By definition, we get the likelihood,
$$
\pi(y_1, y_2, \ldots, y_n \mid p) \coloneqq \prod_{i = 1}^n \mathrm{Binomial}(y_i; N, p)
$$
A possibility is to use a prior $p \sim \mathrm{Beta}(\alpha, \beta)$. Writing $S = \sum_{i = 1}^n y_i$, we get the posterior,
$$
p \mid \mathcal{D} \sim \mathrm{Beta}(\alpha + S, \beta + nN - S).
$$
where $\mathcal{D} = {y_1, y_2, \ldots, y_n}$ is the data.</p><p>More generally, if $\pi(p) = f(p)$ for any positive function integrating to 1 on $[0, 1]$, we get the posterior,
$$
\pi(p \mid \mathcal{D}) \propto_p \mathrm{Beta}(p; S + 1, nN - S + 1) f(p).
$$
We can then for example compute numerically the posterior probability that the branching process is supercritical, i.e., that $P(p > \frac{1}{N} \mid \mathcal{D})$, with,
$$
\int_{\frac{1}{N}}^1 \pi(p \mid \mathcal{D}) \ dp = \frac{\int_{\frac{1}{N}}^1 \mathrm{Beta}(p; S + 1, nN - S + 1) f(p) \ dp}{\int_0^1 \mathrm{Beta}(p; S + 1, nN - S + 1) f(p) \ dp}.
$$</p></div>
</details>
<details class="group relative px-4 py-3 my-6 border-l-4 text-base border-sky-500 dark:bg-sky-950/10" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-sky-600 dark:text-sky-300" data-lucide="code" viewBox="0 0 24 24"><use href="#code"></use></svg>Example: Using a Multinomial Likelihood<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-sky-600 dark:text-sky-300" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>Assume there is a maximum of $N$ offspring and that now $p = (p_0, p_1, \ldots, p_N)$ is an (unknown) probability vector such that $p_i$ is the probability of $i$ offspring.
By definition, we get the likelihood,
$$
\pi(y_1, y_2, \ldots, y_n \mid p) \coloneqq \mathrm{Multinomial}(c; p),
$$
where $c = (c_0, c_1, \ldots, c_N)$ is the vector of counts in the data of cases with $0, \ldots, N$ offspring, respectively.</p><p>If we use a prior $p \sim \mathrm{Dirichlet}(\alpha)$, where $\alpha = (\alpha_0, \alpha_1, \ldots, \alpha_N)$ is a vector of pseudocounts, we get the posterior,
$$
p \mid \mathcal{D} \sim \mathrm{Dirichlet}(\alpha + c),
$$
with expecation,
$$
\mathbb{E}[p_i \mid \mathcal{D}] = \frac{\alpha_i + c_i}{\sum_{j = 0}^N (\alpha_j + c_j)}.
$$</p></div>
</details>
<details class="group relative px-4 py-3 my-6 border-l-4 text-base border-sky-500 dark:bg-sky-950/10" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-sky-600 dark:text-sky-300" data-lucide="code" viewBox="0 0 24 24"><use href="#code"></use></svg>Example: Simplest Birth-and-Death Process<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-sky-600 dark:text-sky-300" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>The simplest example of a birth-and-death process is when $\lambda_i = \lambda$ and $\mu_i = \mu$ for all $i \geq 0$.
In this case, the stationary distribution is given by,
$$
\begin{align*}
v_k &#x26; = v_0 \left(\frac{\lambda}{\mu}\right)^k = v_0 \left(\frac{\lambda}{\mu}\right)^k, \newline
v_0 &#x26; = \left(\sum_{k = 0}^{\infty} \left(\frac{\lambda}{\mu}\right)^k\right)^{-1} = \frac{1}{1 + \frac{\lambda}{\mu} + \left(\frac{\lambda}{\mu}\right)^2 + \ldots} = \frac{1}{\frac{1}{1 - \frac{\lambda}{\mu}}} = 1 - \frac{\lambda}{\mu}.
\end{align*}
$$
Which is a geometric distribution with parameter $1 - \frac{\lambda}{\mu}$, $\mathrm{Geometric}\left(1 - \frac{\lambda}{\mu}\right)$.
Thus, the long-term average value of $X_t$ is,
$$
E[X_t] \coloneqq \frac{\frac{\lambda}{\mu}}{1 - \frac{\lambda}{\mu}} = \frac{\lambda}{\mu - \lambda}.
$$</p></div>
</details>
<details class="group relative px-4 py-3 my-6 border-l-4 text-base border-sky-500 dark:bg-sky-950/10" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-sky-600 dark:text-sky-300" data-lucide="code" viewBox="0 0 24 24"><use href="#code"></use></svg>Example: Probability Computation with Brownian Motion<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-sky-600 dark:text-sky-300" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>Show that $B_1 + B_3 + 2 B_7 \sim \mathcal{N}(0, 50)$.</p><details class="group relative px-4 py-3 my-6 border-l-4 text-base border-pink-300 dark:bg-pink-950/5">
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-pink-500 dark:text-pink-200" data-lucide="check-circle-2" viewBox="0 0 24 24"><use href="#check-circle-2"></use></svg>Solution<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-pink-500 dark:text-pink-200" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>We can write,
$$
\begin{align*}
B_1 + B_3 + 2 B_7 &#x26; = B_1 + (B_3 - B_1) + B_1 + 2 (B_7 - B_3) + 2 B_3 \newline
&#x26; = 2 B_1 + (B_3 - B_1) + 2 (B_7 - B_3) + 2(B_3 - B_1) + 2 B_1 \newline
&#x26; = 4 B_1 + 2 (B_3 - B_1) + 2 (B_7 - B_3).
\end{align*}
$$
Looking at each term separately, we have,
$$
\begin{align*}
\mathbb{E}[4 B_1] &#x26; = 0 \newline
\mathrm{Var}(4 B_1) &#x26; = 4^2 \mathrm{Var}(B_1) = 4^2
\end{align*}
$$
and,
$$
\begin{align*}
\mathbb{E}[2 (B_3 - B_1)] &#x26; = 0 \newline
\mathrm{Var}(2 (B_3 - B_1)) &#x26; = 2^2 \mathrm{Var}(B_3 - B_1) = 2^2 \cdot 2
\end{align*}
$$
and,
$$
\begin{align*}
\mathbb{E}[2 (B_7 - B_3)] &#x26; = 0 \newline
\mathrm{Var}(2 (B_7 - B_3)) &#x26; = 2^2 \mathrm{Var}(B_7 - B_3) = 2^2 \cdot 4
\end{align*}
$$
Since the increments are independent, we have,
$$
\begin{align*}
\mathbb{E}[B_1 + B_3 + 2 B_7] &#x26; = 0 \newline
\mathrm{Var}(B_1 + B_3 + 2 B_7) &#x26; = 4^2 + 2^2 \cdot 2 + 2^2 \cdot 4 = 50. \newline
\end{align*}
$$
Thus, $B_1 + B_3 + 2 B_7 \sim \mathcal{N}(0, 50)$. $_\blacksquare$</p></div>
</details></div>
</details>
<details class="group relative px-4 py-3 my-6 border-l-4 text-base border-sky-500 dark:bg-sky-950/10" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-sky-600 dark:text-sky-300" data-lucide="code" viewBox="0 0 24 24"><use href="#code"></use></svg>Example: Conditional Distribution with Brownian Motion<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-sky-600 dark:text-sky-300" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>Show that $P(B_2 > 0 \mid B_1 = 1) = 0.8413$.</p><details class="group relative px-4 py-3 my-6 border-l-4 text-base border-pink-300 dark:bg-pink-950/5">
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-pink-500 dark:text-pink-200" data-lucide="check-circle-2" viewBox="0 0 24 24"><use href="#check-circle-2"></use></svg>Solution<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-pink-500 dark:text-pink-200" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>We can rewrite the conditional probability as,
$$
P(B_2 - B_1 0 - 1 \mid B_1 = 1).
$$
Since we have independent increments, $B_2 - B_1$ is independent of $B_1$.
$$
P(B_2 - B_1 -1)
$$
Further, $B_2 - B_1 \sim \mathcal{N}(0, 1)$.
Thus, we have,
$$
P(B_2 - B_1 -1) = P\left(Z > -1\right) = 0.8413,
$$
where $Z \sim \mathcal{N}(0, 1)$. $_\blacksquare$ (we can compute this with <code>1 - pnorm(-1, 0, 1)</code> in <code>R</code>).</p></div>
</details></div>
</details>
<details class="group relative px-4 py-3 my-6 border-l-4 text-base border-sky-500 dark:bg-sky-950/10" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-sky-600 dark:text-sky-300" data-lucide="code" viewBox="0 0 24 24"><use href="#code"></use></svg>Example: Covariance Computation with Brownian Motion<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-sky-600 dark:text-sky-300" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>Show that $\mathrm{Cov}(B_s, B_t) = \min(s, t)$.</p><details class="group relative px-4 py-3 my-6 border-l-4 text-base border-pink-300 dark:bg-pink-950/5">
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-pink-500 dark:text-pink-200" data-lucide="check-circle-2" viewBox="0 0 24 24"><use href="#check-circle-2"></use></svg>Solution<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-pink-500 dark:text-pink-200" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>Without loss of generality, assume that $s \leq t$.
We can write,
$$
\begin{align*}
\mathrm{Cov}(B_s, B_t) &#x26; = \mathrm{Cov}(B_s, B_t - B_s + B_s) \newline
&#x26; = \mathrm{Cov}(B_s, B_t - B_s) + \mathrm{Cov}(B_s, B_s) \newline
&#x26; = 0 + \mathrm{Var}(B_s) \newline
&#x26; = s \newline
\end{align*}
$$
Conversely, if $t \leq s$, we would get $\mathrm{Cov}(B_s, B_t) = t$.
Thus, we have,
$$
\mathrm{Cov}(B_s, B_t) = \min(s, t) \ _\blacksquare .
$$</p></div>
</details></div>
</details>
<details class="group relative px-4 py-3 my-6 border-l-4 text-base border-sky-500 dark:bg-sky-950/10" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-sky-600 dark:text-sky-300" data-lucide="code" viewBox="0 0 24 24"><use href="#code"></use></svg>Example<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-sky-600 dark:text-sky-300" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>What is the probability that $M_3 > 5$?</p><details class="group relative px-4 py-3 my-6 border-l-4 text-base border-pink-300 dark:bg-pink-950/5">
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-pink-500 dark:text-pink-200" data-lucide="check-circle-2" viewBox="0 0 24 24"><use href="#check-circle-2"></use></svg>Solution<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-pink-500 dark:text-pink-200" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>We have,
$$
\begin{align*}
P(M_3 5) &#x26; = P(|B_3| > 5) \newline
&#x26; = 2 P(B_3 5) \newline
&#x26; = 2 P\left(Z \frac{5}{\sqrt{3}}\right) \newline
&#x26; = 0.046.
\end{align*}
$$
where $Z \sim \mathcal{N}(0, 1)$. $_\blacksquare$ (we can compute this with <code>2 * (1 - pnorm(5 / sqrt(3), 0, 1))</code> in <code>R</code>).</p></div>
</details></div>
</details>
<details class="group relative px-4 py-3 my-6 border-l-4 text-base border-sky-500 dark:bg-sky-950/10" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-sky-600 dark:text-sky-300" data-lucide="code" viewBox="0 0 24 24"><use href="#code"></use></svg>Example<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-sky-600 dark:text-sky-300" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>Find $t$ such that $P(M_t \leq 4) = 0.9$.</p><details class="group relative px-4 py-3 my-6 border-l-4 text-base border-pink-300 dark:bg-pink-950/5">
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-pink-500 dark:text-pink-200" data-lucide="check-circle-2" viewBox="0 0 24 24"><use href="#check-circle-2"></use></svg>Solution<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-pink-500 dark:text-pink-200" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>We have,
$$
\begin{align*}
P(M_t \leq 4) &#x26; = P(|B_t| \leq 4) \newline
&#x26; = 1 - 2 P(B_t 4) \newline
&#x26; = 1 - 2 P\left(Z \frac{4}{\sqrt{t}}\right). \newline
\end{align*}
$$
Setting this equal to $0.9$ we get,
$$
P\left(Z \frac{4}{\sqrt{t}}\right) = 0.05.
$$
Looking up in the standard normal table (or using <code>qnorm(0.95, 0, 1)</code> in <code>R</code>) we get $\frac{4}{\sqrt{t}} = 1.645$ and thus $t = 5.92$. $_\blacksquare$</p></div>
</details></div>
</details>
<details class="group relative px-4 py-3 my-6 border-l-4 text-base border-sky-500 dark:bg-sky-950/10" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-sky-600 dark:text-sky-300" data-lucide="code" viewBox="0 0 24 24"><use href="#code"></use></svg>Example: Stock Prices<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-sky-600 dark:text-sky-300" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>From what we have seen so far, one can model the price of a stock with:</p><ul>
<li>Use a continuous-time stochastic model.</li>
<li>Consider the factor with which it changes, not the differences in prices.</li>
<li>Consider the log-normal distribution for such factors.</li>
<li>Use a parameter for the trend of the price (drift), and one for the volatility (variance) of the price.</li>
<li>Make a Markov assumption (although, we have to reflect on this choice).</li>
</ul><p>This leads to using a geometric Brownian motion as a model,
$$
G_t = G_0 e^{\mu t + \sigma B_t}.
$$
In this context $\sigma$ is called the volatility of the stock.</p><details class="group relative px-4 py-3 my-6 border-l-4 text-base border-sky-500 dark:bg-sky-950/10" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-sky-600 dark:text-sky-300" data-lucide="code" viewBox="0 0 24 24"><use href="#code"></use></svg>Example<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-sky-600 dark:text-sky-300" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>A stock price is modeled with $G_0 = 67.3$, $\mu = 0.08$, and $\sigma = 0.3$.
What is the probability that the price is above 100 after 3 years?</p><details class="group relative px-4 py-3 my-6 border-l-4 text-base border-pink-300 dark:bg-pink-950/5">
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-pink-500 dark:text-pink-200" data-lucide="check-circle-2" viewBox="0 0 24 24"><use href="#check-circle-2"></use></svg>Solution<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-pink-500 dark:text-pink-200" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>We want to compute,
$$
\begin{align*}
P(G_3 > 100) &#x26; \coloneqq P\left(G_0 e^{\mu \cdot 3 + \sigma B_3} > 100\right) \newline
&#x26; = P\left(e^{\mu \cdot 3 + \sigma B_3} > \frac{100}{G_0}\right) \newline
&#x26; = P\left(\mu \cdot 3 + \sigma B_3 > \log\left(\frac{100}{G_0}\right)\right) \newline
&#x26; = P\left(B_3 > \frac{\log\left(\frac{100}{G_0}\right) - \mu \cdot 3}{\sigma}\right) \newline
\end{align*}
$$
Since $B_3 \sim \mathcal{N}(0, 3)$ we can compute this as <code>1 - pnorm((log(100 / 67.3) - 0.08 * 3) / 0.3, mean = 0, sd = sqrt(3))</code> in <code>R</code>.</p></div>
</details></div>
</details></div>
</details>
<details class="group relative px-4 py-3 my-6 border-l-4 text-base border-sky-500 dark:bg-sky-950/10" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-sky-600 dark:text-sky-300" data-lucide="code" viewBox="0 0 24 24"><use href="#code"></use></svg>Example<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-sky-600 dark:text-sky-300" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>A stock price is modeled with $G_0 = 67.3$, $\mu = 0.08$, and $\sigma = 0.3$.
What is the expected payoff from an option to buy the stock at 100 in 3 years?</p><details class="group relative px-4 py-3 my-6 border-l-4 text-base border-pink-300 dark:bg-pink-950/5">
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-pink-500 dark:text-pink-200" data-lucide="check-circle-2" viewBox="0 0 24 24"><use href="#check-circle-2"></use></svg>Solution<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-pink-500 dark:text-pink-200" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>We want to compute,
$$
\begin{align*}
\mathbb{E}[\max(G_3 - 100, 0)] &#x26; = 67.3 e^{3(0.08 + \frac{0.3^2}{2})} P\left(B_1 \frac{\beta - 0.3 \cdot 3}{\sqrt{3}}\right) - 100 P\left(B_1 > \frac{\beta}{\sqrt{3}}\right) \newline
\end{align*}
$$
where,
$$
\beta = \frac{\log(100 / 67.3) - 0.08 \cdot 3}{0.3} \approx 1.213.
$$
Thus, we can compute this as <code>67.3 * exp(3 * (0.08 + 0.3^2 / 2)) * (1 - pnorm((1.213 - 0.3 * 3) / sqrt(3), mean = 0, sd = 1)) - 100 * (1 - pnorm(1.213 / sqrt(3), mean = 0, sd = 1))</code> in <code>R</code>.</p></div>
</details></div>
</details>
<details class="group relative px-4 py-3 my-6 border-l-4 text-base border-sky-500 dark:bg-sky-950/10" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-sky-600 dark:text-sky-300" data-lucide="code" viewBox="0 0 24 24"><use href="#code"></use></svg>Example<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-sky-600 dark:text-sky-300" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>Let $Y_t \coloneqq B_t^2 - t$ for $t \geq 0$. Then, $\{Y_t\}_{t \geq 0}$ is a martingale with respect to the Brownian motion $\{B_t\}_{t \geq 0}$.</p><details class="group relative px-4 py-3 my-6 border-l-4 text-base border-amber-500 dark:bg-amber-950/10" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-amber-700 dark:text-amber-300" data-lucide="check-square" viewBox="0 0 24 24"><use href="#check-square"></use></svg>Proof<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-amber-700 dark:text-amber-300" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>We have,
$$
\begin{align*}
\mathbb{E}[Y_t \mid B_r, 0 \leq r \leq s] &#x26; = \mathbb{E}[B_t^2 - t \mid B_r, 0 \leq r \leq s] \newline
&#x26; = \mathbb{E}[(B_t - B_s + B_s)^2 - t \mid B_r, 0 \leq r \leq s] \newline
&#x26; = \mathbb{E}[(B_t - B_s)^2 \mid B_r, 0 \leq r \leq s] + 2 B_s \mathbb{E}[B_t - B_s \mid B_r, 0 \leq r \leq s] + B_s^2 - t \newline
&#x26; = (t - s) + 0 + B_s^2 - t \newline
&#x26; = B_s^2 - s \newline
&#x26; = Y_s.
\end{align*}
$$
Further,
$$
\begin{align*}
\mathbb{E}[|Y_t|] &#x26; = \mathbb{E}[|B_t^2 - t|] \newline
&#x26; \leq \mathbb{E}[B_t^2] + t \newline
&#x26; = \mathrm{Var}(B_t) + (\mathbb{E}[B_t])^2 + t \newline
&#x26; = t + 0 + t \newline
&#x26; = 2 t &#x3C; \infty. \newline
\end{align*}
$$
Thus, $\{Y_t\}_{t \geq 0}$ is a martingale with respect to $\{B_t\}_{t \geq 0}$. $_\blacksquare$</p></div>
</details></div>
</details>
<details class="group relative px-4 py-3 my-6 border-l-4 text-base border-sky-500 dark:bg-sky-950/10" open>
<summary class="flex items-center cursor-pointer font-medium text-base [&#x26;::-webkit-details-marker]:hidden"><svg class="mr-2 w-6 h-6 text-sky-600 dark:text-sky-300" data-lucide="code" viewBox="0 0 24 24"><use href="#code"></use></svg>Example: Discounting Future Values of Stocks &#x26; The Black-Scholes Formula for Option Pricing<svg class="ml-auto w-5 h-5 transform transition-transform duration-200 group-open:rotate-180 text-sky-600 dark:text-sky-300" data-lucide="chevron-down" viewBox="0 0 24 24"><use href="#chevron-down"></use></svg></summary>
<div class="mt-2 text-base leading-relaxed prose dark:prose-invert"><p>When making investments, there is always a range of choices, some of which are sometimes called â€œrisk-freeâ€.
Such investments may pay a fixed interest.</p><p>When interests are compounded frequently, a reasonable model is that an investment of $G_0$ has a value $G_0 e^{rt}$ after time $t$, where $r$ is the â€œrisk-freeâ€ investment rate of return.</p><p>A common way to take this alternative into account is to instead â€œdiscountâ€ all other investments with the factor $e^{-rt}$.</p><p>For example, the discounted value of a stock can be modeled as,
$$
e^{-rt} G_t = e^{-rt} G_0 e^{\mu t + \sigma B_t} = G_0 e^{(\mu - r) t + \sigma B_t}.
$$
A possible assumption about the trend $\mu$ of a stock price is that the discounted value behaves as a martingale with respect to the Brownian motion $B_t$.</p><p>Thus, we get,
$$
\mu - r + \frac{\sigma^2}{2} = 0, \quad \text{i.e.,} \quad \mu = r - \frac{\sigma^2}{2}.
$$</p><p>The Black-Scholes formula for option pricing is based on,</p><ul>
<li>Assuming the discounted stock price is a martingale with respect to the Brownian motion.</li>
<li>Using discounting when computing the value of the option.</li>
</ul><p>From this, we get,
$$
e^{-rt} \mathbb{E}[\max(G_t - K, 0)] = G_0 P\left(B_1 > \frac{\beta - \sigma t}{\sqrt{t}}\right) - K e^{-rt} P\left(B_1 > \frac{\beta}{\sqrt{t}}\right),
$$
where $\beta = \frac{\log(K / G_0) - (r - \frac{\sigma^2}{2}) t}{\sigma}$.</p></div>
</details>
<section data-footnotes="" class="footnotes"><h2 class="sr-only" id="footnote-label">Footnotes</h2>
<ol>
<li id="user-content-fn-2">
<p><a href="https://en.wikipedia.org/wiki/Donsker&#x27;s_theorem" rel="nofollow noreferrer noopener" target="_blank">Wikipedia: Donskerâ€™s invariance principle</a> <a href="#user-content-fnref-2" data-footnote-backref="" aria-label="Back to reference 1" class="data-footnote-backref">â†©</a></p>
</li>
</ol>
</section>


</body></html> </article> <nav class="col-start-2 grid grid-cols-1 gap-4 sm:grid-cols-2"> <a href="/notes/master/mve550/mve550_15" target="_self" class="duration-300 ease-in-out gap-2 whitespace-nowrap text-sm font-medium transition-all disabled:pointer-events-none disabled:opacity-50 [&#38;_svg]:pointer-events-none [&#38;_svg:not([class*='size-'])]:size-4 shrink-0 [&#38;_svg]:shrink-0 outline-none focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:ring-[3px] aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive border bg-background shadow-xs hover:bg-accent hover:text-accent-foreground dark:bg-input/30 dark:border-input dark:hover:bg-input/50 px-4 py-2 has-[>svg]:px-3 rounded-lg group flex items-center justify-start size-full" aria-disabled="false">  <svg width="1em" height="1em" viewBox="0 0 24 24" class="mr-2 size-4 transition-transform group-hover:-translate-x-1" data-icon="lucide:arrow-left">   <use href="#ai:lucide:arrow-left"></use>  </svg> <div class="flex flex-col items-start overflow-hidden text-wrap"> <span class="text-muted-foreground text-left text-xs"> Previous Post </span> <span class="w-full text-left text-sm text-balance text-ellipsis"> Part 15 - Brownian Motion and Gaussian Processes III </span> </div>  </a>  <a href="#" target="_self" class="duration-300 ease-in-out gap-2 whitespace-nowrap text-sm font-medium transition-all disabled:pointer-events-none disabled:opacity-50 [&#38;_svg]:pointer-events-none [&#38;_svg:not([class*='size-'])]:size-4 shrink-0 [&#38;_svg]:shrink-0 outline-none focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:ring-[3px] aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive border bg-background shadow-xs hover:bg-accent hover:text-accent-foreground dark:bg-input/30 dark:border-input dark:hover:bg-input/50 px-4 py-2 has-[>svg]:px-3 rounded-lg group flex items-center justify-end size-full pointer-events-none opacity-50 cursor-not-allowed" aria-disabled="true">  <div class="flex flex-col items-end overflow-hidden text-wrap"> <span class="text-muted-foreground text-right text-xs"> Next Post </span> <span class="w-full text-right text-sm text-balance text-ellipsis"> You&#39;re at the newest post! </span> </div> <svg width="1em" height="1em" viewBox="0 0 24 24" class="ml-2 size-4 transition-transform group-hover:translate-x-1" data-icon="lucide:arrow-right">   <use href="#ai:lucide:arrow-right"></use>  </svg>  </a> </nav> <div class="col-start-2"> <section class="mx-auto mt-12"> <script data-astro-rerun src="https://giscus.app/client.js" data-repo="rezaarezvan/rezarezvan.com" data-repo-id="R_kgDOHvQr3w" data-category="General" data-category-id="DIC_kwDOHvQr384CiWVC" data-mapping="og:title" data-strict="0" data-reactions-enabled="1" data-emit-metadata="0" data-input-position="bottom" data-theme="preferred_color_scheme" data-lang="en" data-loading="lazy" crossorigin="anonymous" async></script> </section> <script>
  function updateGiscusTheme() {
    const element = document.documentElement
    const theme = element.getAttribute('data-theme')
    const iframe = document.querySelector('iframe.giscus-frame')
    if (!iframe) return
    iframe.contentWindow.postMessage(
      { giscus: { setConfig: { theme } } },
      'https://giscus.app',
    )
  }

  const observer = new MutationObserver(updateGiscusTheme)
  observer.observe(document.documentElement, {
    attributes: true,
    attributeFilter: ['class'],
  })

  window.onload = () => {
    updateGiscusTheme()
  }
</script> </div> </section> <button data-slot="button" class="items-center justify-center gap-2 whitespace-nowrap rounded-md text-sm font-medium transition-all disabled:pointer-events-none disabled:opacity-50 [&amp;_svg]:pointer-events-none [&amp;_svg:not([class*=&#x27;size-&#x27;])]:size-4 shrink-0 [&amp;_svg]:shrink-0 outline-none focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:ring-[3px] aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive border bg-background shadow-xs hover:bg-accent hover:text-accent-foreground dark:bg-input/30 dark:border-input dark:hover:bg-input/50 size-9 group fixed right-8 bottom-8 z-50 hidden" id="scroll-to-top" title="Scroll to top" aria-label="Scroll to top"> <svg width="1em" height="1em" class="mx-auto size-4 transition-all group-hover:-translate-y-0.5" data-icon="lucide:arrow-up">   <symbol id="ai:lucide:arrow-up" viewBox="0 0 24 24"><path fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="m5 12l7-7l7 7m-7 7V5"/></symbol><use href="#ai:lucide:arrow-up"></use>  </svg> </button> <script type="module">document.addEventListener("astro:page-load",()=>{const t=document.getElementById("scroll-to-top"),s=document.querySelector("footer");t&&s&&(t.addEventListener("click",()=>{window.scrollTo({top:0,behavior:"smooth"})}),window.addEventListener("scroll",()=>{const e=s.getBoundingClientRect().top<=window.innerHeight;t.classList.toggle("hidden",window.scrollY<=300||e)}));const n=document.querySelectorAll(".sidenote-toggle");if(n.length>0){const c=new IntersectionObserver(e=>{e.forEach(i=>{const o=i.target,l=o.getAttribute("for"),r=document.getElementById(`${l}-note`);i.isIntersecting?(o.classList.add("active"),r?.classList.add("active")):(o.classList.remove("active"),r?.classList.remove("active"))})},{rootMargin:"-20% 0px -60% 0px",threshold:0});n.forEach(e=>c.observe(e))}});</script>  </div> </main> <footer class="py-4"> <div class="mx-auto flex max-w-3xl flex-col items-center justify-center gap-y-2 px-4 sm:flex-row sm:justify-between"> <div class="flex flex-wrap items-center justify-center gap-x-2 text-center"> <span class="text-muted-foreground text-sm">
&copy; 2026 â€¢ rezarezvan.com </span> </div> </div> </footer> <div id="backdrop" class="invisible fixed top-0 left-0 z-50 flex h-screen w-full justify-center bg-[rgba(0,0,0,0.5)] p-6 backdrop-blur-sm" data-astro-transition-persist="astro-t6dxx5el-4"> <div id="pagefind-container" class="m-0 flex h-fit max-h-[80%] w-full max-w-screen-sm flex-col overflow-auto rounded border border-black/15 bg-neutral-100 p-2 px-4 py-3 shadow-lg dark:border-white/20 dark:bg-neutral-900"> <div id="search" class="pagefind-ui pagefind-init" data-pagefind-ui data-bundle-path="/pagefind/" data-ui-options="{&#34;showImages&#34;:false,&#34;excerptLength&#34;:15,&#34;resetStyles&#34;:false}"></div> <script type="module" src="/_astro/Search.astro_astro_type_script_index_0_lang.tZYucdM2.js"></script> <div class="dark:prose-invert mr-2 pt-4 pb-1 text-right text-xs">
Press <span class="prose dark:prose-invert text-xs"><kbd class="">Esc</kbd></span> or click anywhere to close
</div> </div> </div> <script>
  document.addEventListener('DOMContentLoaded', () => {
    const magnifyingGlass = document.getElementById('magnifying-glass')
    const backdrop = document.getElementById('backdrop')

    function openPagefind() {
      const searchDiv = document.getElementById('search')
      const search = searchDiv.querySelector('input')
      setTimeout(() => {
        search.focus()
      }, 0)
      backdrop?.classList.remove('invisible')
      backdrop?.classList.add('visible')
    }

    function closePagefind() {
      const searchDiv = document.getElementById('search')
      const search = searchDiv.querySelector('input')
      if (search) {
        search.value = ''
      }
      backdrop?.classList.remove('visible')
      backdrop?.classList.add('invisible')
    }

    // open pagefind
    magnifyingGlass?.addEventListener('click', () => {
      openPagefind()
    })

    document.addEventListener('keydown', (e) => {
      if (e.key === 'Escape') {
        closePagefind()
      }
    })

    // close pagefind when searched result(link) clicked
    document.addEventListener('click', (event) => {
      if (event.target.classList.contains('pagefind-ui__result-link')) {
        closePagefind()
      }
    })

    backdrop?.addEventListener('click', (event) => {
      if (!event.target.closest('#pagefind-container')) {
        closePagefind()
      }
    })

    // prevent form submission
    const form = document.getElementById('form')
    form?.addEventListener('submit', (event) => {
      event.preventDefault()
    })
  })
</script>  </div> </body></html>